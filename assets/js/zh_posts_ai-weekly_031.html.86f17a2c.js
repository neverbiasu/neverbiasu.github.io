"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[3668],{66262:(e,t)=>{t.A=(e,t)=>{const a=e.__vccOpts||e;for(const[e,r]of t)a[e]=r;return a}},88609:(e,t,a)=>{a.r(t),a.d(t,{comp:()=>i,data:()=>o});var r=a(20641);const n={},i=(0,a(66262).A)(n,[["render",function(e,t){return(0,r.uX)(),(0,r.CE)("div",null,t[0]||(t[0]=[(0,r.Fv)('<h1 id="conceptrol精准概念控制-chatanyone实时数字人-lumina-image-2-0突【ai周报】" tabindex="-1"><a class="header-anchor" href="#conceptrol精准概念控制-chatanyone实时数字人-lumina-image-2-0突【ai周报】"><span>Conceptrol精准概念控制 | ChatAnyone实时数字人|Lumina-Image 2.0突【AI周报】</span></a></h1><figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9469f5ed-e000-4aeb-ab93-4b40865a7c7b/original=true,quality=90/00320-919909395-1girl, hatsune_miku, lips, thin lips, parted lips, solo, looking at viewer, camisole, upper body, dark, underlightling, masterpi.jpeg" alt="封面源自C站作者Koal2" tabindex="0" loading="lazy"><figcaption>封面源自C站作者Koal2</figcaption></figure><h2 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span>摘要</span></a></h2><p>本周亮点：Conceptrol实现精细风格控制；SMS优化视频表征；FAR提升长时序理解；ChatAnyone风格化数字人；Lumina-Image-2.0加速扩散模型推理；CFG-Zero⋆优化无分类器引导，增强生成质量，其余详见正文。</p><hr><h2 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span>目录</span></a></h2><ol><li><a href="#conceptrol%E9%9B%B6%E6%A0%B7%E6%9C%AC%E4%B8%AA%E6%80%A7%E5%8C%96%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E7%9A%84%E6%A6%82%E5%BF%B5%E6%8E%A7%E5%88%B6">Conceptrol：零样本个性化图像生成的概念控制</a></li><li><a href="#sms%E5%9F%BA%E4%BA%8E-style-matching-score-%E7%9A%84%E5%B9%B3%E8%A1%A1%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E5%8C%96">SMS：基于 Style Matching Score 的平衡图像风格化</a></li><li><a href="#far%E5%9F%BA%E4%BA%8E%E8%87%AA%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%95%BF%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90">FAR：基于自回归模型的长视频生成</a></li><li><a href="#editclip%E9%9D%A2%E5%90%91%E5%9B%BE%E5%83%8F%E7%BC%96%E8%BE%91%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0">EditCLIP：面向图像编辑的表示学习</a></li><li><a href="#chatanyone%E5%9F%BA%E4%BA%8E%E5%88%86%E5%B1%82%E8%BF%90%E5%8A%A8%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9E%E6%97%B6%E9%A3%8E%E6%A0%BC%E5%8C%96%E8%82%96%E5%83%8F%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90">ChatAnyone：基于分层运动扩散模型的实时风格化肖像视频生成</a></li><li><a href="#lumina-image-20%E7%BB%9F%E4%B8%80%E9%AB%98%E6%95%88%E7%9A%84%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E6%A1%86%E6%9E%B6">Lumina-Image 2.0：统一高效的文本生成图像框架</a></li><li><a href="#cfg-zero%E6%94%B9%E8%BF%9B%E6%B5%81%E5%8C%B9%E9%85%8D%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%97%A0%E5%88%86%E7%B1%BB%E5%99%A8%E5%BC%95%E5%AF%BC%E6%96%B9%E6%B3%95">CFG-Zero⋆：改进流匹配模型的无分类器引导方法</a></li></ol><hr><h2 id="conceptrol-零样本个性化图像生成的概念控制" tabindex="-1"><a class="header-anchor" href="#conceptrol-零样本个性化图像生成的概念控制"><span>Conceptrol：零样本个性化图像生成的概念控制</span></a></h2><figure><img src="https://github.com/QY-H00/Conceptrol/raw/main/demo/teaser.png" alt="Conceptrol Teaser 图" tabindex="0" loading="lazy"><figcaption>Conceptrol Teaser 图</figcaption></figure><p><strong>概要</strong>：<strong>Conceptrol</strong> 是由 <strong>新加坡国立大学</strong> 提出的一种创新方法，旨在提升零样本适配器在个性化图像生成中的性能。现有方法在平衡个性化内容保留和文本提示遵循方面存在困难。Conceptrol 通过引入文本概念掩码，约束视觉规范的注意力机制，从而增强个性化内容的生成能力。该方法无需额外训练或数据，即可在 Stable Diffusion、SDXL 和 FLUX 等模型上实现高效的个性化图像生成。实验结果显示，Conceptrol 相较于传统零样本适配器，在个性化基准测试中性能提升高达89%，并且在某些情况下超越了如 DreamBooth LoRA 等需要微调的模型。</p><p><strong>标签</strong>：#个性化图像生成 #零样本学习 #概念控制 #Stable Diffusion #新加坡国立大学</p><hr><h2 id="sms-基于-style-matching-score-的平衡图像风格化" tabindex="-1"><a class="header-anchor" href="#sms-基于-style-matching-score-的平衡图像风格化"><span>SMS：基于 Style Matching Score 的平衡图像风格化</span></a></h2><figure><img src="https://github.com/showlab/SMS/raw/main/assets/teaser-f.png" alt="SMS Teaser 图" tabindex="0" loading="lazy"><figcaption>SMS Teaser 图</figcaption></figure><p><strong>概要</strong>：<strong>SMS</strong>（Style Matching Score）是由 <strong>新加坡国立大学</strong> 等机构提出的一种创新图像风格化方法，旨在平衡风格迁移中的风格匹配与内容保留。该方法将图像风格化视为风格分布匹配问题，通过设计精巧的评分函数，从预训练的风格相关 LoRA 模型中估计目标风格分布。为自适应地保留内容信息，SMS 提出了渐进式频谱正则化（Progressive Spectrum Regularization），在频域中引导风格化过程，从低频布局逐步过渡到高频细节。此外，SMS 引入了语义感知梯度优化技术（Semantic-Aware Gradient Refinement），利用扩散模型的语义先验生成的相关性图，选择性地对语义重要区域进行风格化。该优化方法将风格化从像素空间扩展到参数空间，可直接应用于轻量级前馈生成器，实现高效的一步风格化。实验结果表明，SMS 在风格对齐和内容保留方面优于现有方法。</p><p><strong>标签</strong>：#图像风格化 #风格匹配 #内容保留 #扩散模型 #LoRA</p><hr><h2 id="far-基于自回归模型的长视频生成" tabindex="-1"><a class="header-anchor" href="#far-基于自回归模型的长视频生成"><span>FAR：基于自回归模型的长视频生成</span></a></h2><figure><img src="https://farlongctx.github.io/static/assets/pipeline.png" alt="FAR Pipeline 图" tabindex="0" loading="lazy"><figcaption>FAR Pipeline 图</figcaption></figure><p><strong>概要</strong>：<strong>FAR</strong>（Frame AutoRegressive）是由 <strong>新加坡国立大学</strong> 提出的一种视频自回归建模方法，旨在提升长视频生成的质量和效率。该模型通过预测连续帧之间的时间因果关系，实现了比传统基于离散标记的自回归模型更好的收敛性。FAR引入了FlexRoPE技术，在测试时为旋转位置编码添加灵活的时间衰减，支持将视频长度扩展至训练时的16倍。此外，FAR采用长短期上下文建模策略，结合高分辨率的短期窗口和低分辨率的长期窗口，平衡了局部细节和全局信息，显著提升了长视频的生成质量和时间一致性。</p><p><strong>标签</strong>：#视频生成 #自回归模型 #长视频建模 #FlexRoPE #时间一致性</p><hr><h2 id="editclip-面向图像编辑的表示学习" tabindex="-1"><a class="header-anchor" href="#editclip-面向图像编辑的表示学习"><span>EditCLIP：面向图像编辑的表示学习</span></a></h2><figure><img src="https://github.com/QianWangX/EditCLIP/raw/main/assets/teaser_editclip.png" alt="EditCLIP Teaser 图" tabindex="0" loading="lazy"><figcaption>EditCLIP Teaser 图</figcaption></figure><p><strong>概要</strong>：<strong>EditCLIP</strong> 由 <strong>沙特阿卜杜拉国王科技大学（KAUST）</strong> 提出，旨在通过联合编码原始图像及其编辑版本，学习统一的编辑表示。该方法在示例引导的图像编辑和自动编辑评估任务中表现出色。具体而言，EditCLIP用参考图像对的嵌入替代 InstructPix2Pix 中的文本指令，实现高效且多样化的编辑效果。此外，EditCLIP 通过测量图像对的嵌入相似度，提供与人类判断高度一致的编辑质量评估指标。</p><p><strong>标签</strong>：#图像编辑 #表示学习 #CLIP #InstructPix2Pix #自动评估</p><hr><h2 id="chatanyone-基于分层运动扩散模型的实时风格化肖像视频生成" tabindex="-1"><a class="header-anchor" href="#chatanyone-基于分层运动扩散模型的实时风格化肖像视频生成"><span>ChatAnyone：基于分层运动扩散模型的实时风格化肖像视频生成</span></a></h2><figure><img src="https://humanaigc.github.io/chat-anyone/content/overview.png" alt="ChatAnyone Overview 图" tabindex="0" loading="lazy"><figcaption>ChatAnyone Overview 图</figcaption></figure><p><strong>概要</strong>：<strong>ChatAnyone</strong> 是由 <strong>阿里巴巴通义实验室</strong> 推出的一种实时风格化肖像视频生成框架，旨在通过音频输入生成具有丰富表情和上半身动作的肖像视频。该方法采用高效的分层运动扩散模型，结合显式和隐式运动表示，实现头部与身体动作的同步生成，并支持细粒度的风格控制。此外，ChatAnyone 引入了混合控制融合技术，通过注入手部控制信号和面部细化模块，生成更为真实和生动的上半身动作，包括手势和面部表情。该框架支持最高 512×768 分辨率、30fps 的实时生成，适用于交互式视频聊天等应用场景。</p><p><strong>标签</strong>：#实时视频生成 #肖像动画 #分层运动扩散模型 #风格化 #交互式视频聊天</p><hr><h2 id="lumina-image-2-0-统一高效的文本生成图像框架" tabindex="-1"><a class="header-anchor" href="#lumina-image-2-0-统一高效的文本生成图像框架"><span>Lumina-Image 2.0：统一高效的文本生成图像框架</span></a></h2><figure><img src="https://github.com/Alpha-VLLM/Lumina-Image-2.0/raw/main/assets/Demo.png" alt="Lumina-Image 2.0 Demo 图" tabindex="0" loading="lazy"><figcaption>Lumina-Image 2.0 Demo 图</figcaption></figure><p><strong>概要</strong>：<strong>Lumina-Image 2.0</strong> 是由 <strong>Alpha-VLLM</strong> 团队推出的先进文本生成图像框架，旨在提升图像生成的质量和效率。该模型采用统一的 Next-DiT 架构，将文本和图像标记视为联合序列，实现自然的跨模态交互，并支持无缝任务扩展。此外，引入了统一的描述生成器（UniCap），专为文本生成图像任务设计，能够生成全面且准确的图像描述，促进模型收敛并增强对提示词的响应能力。在训练方面，Lumina-Image 2.0 采用多阶段渐进式策略，引入高质量数据集和辅助损失，提升图像细节和质量。在推理阶段，模型通过改进的采样方法，实现高效的图像生成。评估结果显示，尽管参数量仅为 26 亿，Lumina-Image 2.0 在多个基准测试中表现出色，体现了其良好的可扩展性和设计效率。</p><p><strong>标签</strong>：#文本生成图像 #DiT #高效训练 #图像生成 #Lumina</p><hr><h2 id="cfg-zero⋆-改进流匹配模型的无分类器引导方法" tabindex="-1"><a class="header-anchor" href="#cfg-zero⋆-改进流匹配模型的无分类器引导方法"><span>CFG-Zero⋆：改进流匹配模型的无分类器引导方法</span></a></h2><figure><img src="https://github.com/WeichenFan/CFG-Zero-star/raw/main/assets/wan2.1/1322140014_ours.gif" alt="CFG-Zero⋆ Demo 图" tabindex="0" loading="lazy"><figcaption>CFG-Zero⋆ Demo 图</figcaption></figure><p><strong>概要</strong>：<strong>CFG-Zero⋆</strong> 是由 <strong>南洋理工大学</strong> 和 <strong>普渡大学</strong> 联合提出的改进型无分类器引导（Classifier-Free Guidance, CFG）方法，旨在提升流匹配（Flow Matching）模型在图像和视频生成任务中的质量和可控性。传统的 CFG 方法在模型训练初期可能因速度估计不准确，导致样本偏离最优轨迹。为解决这一问题，CFG-Zero⋆ 引入了两个关键改进：1. <strong>优化缩放因子（Optimized Scale）</strong>：通过引入可优化的缩放因子，校正条件和无条件速度场之间的偏差，提升引导的准确性。2. <strong>零初始化（Zero-Init）</strong>：在 ODE 求解器的前几步中将预测速度设为零，避免初始阶段的错误引导，确保样本沿正确轨迹生成。</p><p><strong>标签</strong>：#CFG #流匹配模型 #图像生成 #视频生成</p><hr><h3 id="参考链接" tabindex="-1"><a class="header-anchor" href="#参考链接"><span><strong>参考链接</strong></span></a></h3><ol><li><a href="https://qy-h00.github.io/Conceptrol/" target="_blank" rel="noopener noreferrer">Conceptrol 官网</a></li><li><a href="https://github.com/QY-H00/Conceptrol" target="_blank" rel="noopener noreferrer">Conceptrol GitHub</a></li><li><a href="https://arxiv.org/html/2503.06568v1" target="_blank" rel="noopener noreferrer">Conceptrol 论文</a></li><li><a href="https://yuxinn-j.github.io/projects/SMS.html" target="_blank" rel="noopener noreferrer">SMS 官网</a></li><li><a href="https://github.com/showlab/SMS" target="_blank" rel="noopener noreferrer">SMS GitHub</a></li><li><a href="https://arxiv.org/html/2503.07601v1" target="_blank" rel="noopener noreferrer">SMS 论文</a></li><li><a href="https://farlongctx.github.io/" target="_blank" rel="noopener noreferrer">FAR 官网</a></li><li><a href="https://github.com/showlab/FAR" target="_blank" rel="noopener noreferrer">FAR GitHub</a></li><li><a href="https://arxiv.org/html/2503.19325v1" target="_blank" rel="noopener noreferrer">FAR 论文</a></li><li><a href="https://qianwangx.github.io/EditCLIP/" target="_blank" rel="noopener noreferrer">EditCLIP 官网</a></li><li><a href="https://github.com/QianWangX/EditCLIP" target="_blank" rel="noopener noreferrer">EditCLIP GitHub</a></li><li><a href="https://humanaigc.github.io/chat-anyone/" target="_blank" rel="noopener noreferrer">ChatAnyone 官网</a></li><li><a href="https://arxiv.org/html/2503.21144v1" target="_blank" rel="noopener noreferrer">ChatAnyone 论文</a></li><li><a href="https://github.com/Alpha-VLLM/Lumina-Image-2.0" target="_blank" rel="noopener noreferrer">Lumina-Image 2.0 GitHub</a></li><li><a href="https://arxiv.org/html/2503.21758v1" target="_blank" rel="noopener noreferrer">Lumina-Image 2.0 论文</a></li><li><a href="https://weichenfan.github.io/webpage-cfg-zero-star/" target="_blank" rel="noopener noreferrer">CFG-Zero⋆ 官网</a></li><li><a href="https://github.com/WeichenFan/CFG-Zero-star" target="_blank" rel="noopener noreferrer">CFG-Zero⋆ GitHub</a></li><li><a href="https://arxiv.org/html/2503.18886v1" target="_blank" rel="noopener noreferrer">CFG-Zero⋆ 论文</a></li></ol>',45)]))}]]),o=JSON.parse('{"path":"/zh/posts/ai-weekly/031.html","title":"Conceptrol精准概念控制 | ChatAnyone实时数字人|Lumina-Image 2.0突【AI周报】","lang":"zh-CN","frontmatter":{"description":"Conceptrol精准概念控制 | ChatAnyone实时数字人|Lumina-Image 2.0突【AI周报】 封面源自C站作者Koal2封面源自C站作者Koal2 摘要 本周亮点：Conceptrol实现精细风格控制；SMS优化视频表征；FAR提升长时序理解；ChatAnyone风格化数字人；Lumina-Image-2.0加速扩散模型推理；C...","gitInclude":[],"head":[["meta",{"property":"og:url","content":"https://neverbiasu.github.io/zh/posts/ai-weekly/031.html"}],["meta",{"property":"og:site_name","content":"Nlog"}],["meta",{"property":"og:title","content":"Conceptrol精准概念控制 | ChatAnyone实时数字人|Lumina-Image 2.0突【AI周报】"}],["meta",{"property":"og:description","content":"Conceptrol精准概念控制 | ChatAnyone实时数字人|Lumina-Image 2.0突【AI周报】 封面源自C站作者Koal2封面源自C站作者Koal2 摘要 本周亮点：Conceptrol实现精细风格控制；SMS优化视频表征；FAR提升长时序理解；ChatAnyone风格化数字人；Lumina-Image-2.0加速扩散模型推理；C..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9469f5ed-e000-4aeb-ab93-4b40865a7c7b/original=true,quality=90/00320-919909395-1girl,%20hatsune_miku,%20lips,%20thin%20lips,%20parted%20lips,%20solo,%20looking%20at%20viewer,%20camisole,%20upper%20body,%20dark,%20underlightling,%20masterpi.jpeg"}],["meta",{"property":"og:locale","content":"zh-CN"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Conceptrol精准概念控制 | ChatAnyone实时数字人|Lumina-Image 2.0突【AI周报】\\",\\"image\\":[\\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9469f5ed-e000-4aeb-ab93-4b40865a7c7b/original=true,quality=90/00320-919909395-1girl,%20hatsune_miku,%20lips,%20thin%20lips,%20parted%20lips,%20solo,%20looking%20at%20viewer,%20camisole,%20upper%20body,%20dark,%20underlightling,%20masterpi.jpeg\\",\\"https://github.com/QY-H00/Conceptrol/raw/main/demo/teaser.png\\",\\"https://github.com/showlab/SMS/raw/main/assets/teaser-f.png\\",\\"https://farlongctx.github.io/static/assets/pipeline.png\\",\\"https://github.com/QianWangX/EditCLIP/raw/main/assets/teaser_editclip.png\\",\\"https://humanaigc.github.io/chat-anyone/content/overview.png\\",\\"https://github.com/Alpha-VLLM/Lumina-Image-2.0/raw/main/assets/Demo.png\\",\\"https://github.com/WeichenFan/CFG-Zero-star/raw/main/assets/wan2.1/1322140014_ours.gif\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"neverbiasu\\",\\"url\\":\\"https://neverbiasu.github.io\\"}]}"]]},"headers":[{"level":2,"title":"摘要","slug":"摘要","link":"#摘要","children":[]},{"level":2,"title":"目录","slug":"目录","link":"#目录","children":[]},{"level":2,"title":"Conceptrol：零样本个性化图像生成的概念控制","slug":"conceptrol-零样本个性化图像生成的概念控制","link":"#conceptrol-零样本个性化图像生成的概念控制","children":[]},{"level":2,"title":"SMS：基于 Style Matching Score 的平衡图像风格化","slug":"sms-基于-style-matching-score-的平衡图像风格化","link":"#sms-基于-style-matching-score-的平衡图像风格化","children":[]},{"level":2,"title":"FAR：基于自回归模型的长视频生成","slug":"far-基于自回归模型的长视频生成","link":"#far-基于自回归模型的长视频生成","children":[]},{"level":2,"title":"EditCLIP：面向图像编辑的表示学习","slug":"editclip-面向图像编辑的表示学习","link":"#editclip-面向图像编辑的表示学习","children":[]},{"level":2,"title":"ChatAnyone：基于分层运动扩散模型的实时风格化肖像视频生成","slug":"chatanyone-基于分层运动扩散模型的实时风格化肖像视频生成","link":"#chatanyone-基于分层运动扩散模型的实时风格化肖像视频生成","children":[]},{"level":2,"title":"Lumina-Image 2.0：统一高效的文本生成图像框架","slug":"lumina-image-2-0-统一高效的文本生成图像框架","link":"#lumina-image-2-0-统一高效的文本生成图像框架","children":[]},{"level":2,"title":"CFG-Zero⋆：改进流匹配模型的无分类器引导方法","slug":"cfg-zero⋆-改进流匹配模型的无分类器引导方法","link":"#cfg-zero⋆-改进流匹配模型的无分类器引导方法","children":[{"level":3,"title":"参考链接","slug":"参考链接","link":"#参考链接","children":[]}]}],"readingTime":{"minutes":7.57,"words":2270},"filePathRelative":"zh/posts/ai-weekly/031.md","excerpt":"\\n<figure><img src=\\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9469f5ed-e000-4aeb-ab93-4b40865a7c7b/original=true,quality=90/00320-919909395-1girl, hatsune_miku, lips, thin lips, parted lips, solo, looking at viewer, camisole, upper body, dark, underlightling, masterpi.jpeg\\" alt=\\"封面源自C站作者Koal2\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>封面源自C站作者Koal2</figcaption></figure>","autoDesc":true}')}}]);