"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[7308],{6262:(e,a)=>{a.A=(e,a)=>{const r=e.__vccOpts||e;for(const[e,t]of a)r[e]=t;return r}},2716:(e,a,r)=>{r.r(a),r.d(a,{comp:()=>o,data:()=>l});var t=r(641);const n={},o=(0,r(6262).A)(n,[["render",function(e,a){return(0,t.uX)(),(0,t.CE)("div",null,a[0]||(a[0]=[(0,t.Fv)('<h1 id="ai-艺术工具通讯" tabindex="-1"><a class="header-anchor" href="#ai-艺术工具通讯"><span>AI 艺术工具通讯</span></a></h1><h3 id="创刊号-🎉" tabindex="-1"><a class="header-anchor" href="#创刊号-🎉"><span>创刊号 🎉</span></a></h3><p>AI 领域的发展速度令人惊叹，回想一年前我们还在为生成正确手指数量的人像而苦苦挣扎的场景，恍如隔世 😂。</p><p>过去两年对开源模型和艺术创作工具而言具有里程碑意义。创意表达的 AI 工具从未像现在这般触手可及，然而这仅仅是冰山一角。让我们共同回顾 2024 年 AI 艺术领域的关键突破与创新工具，并展望 2025 年的发展趋势。</p><h2 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span>目录</span></a></h2><ul><li><a href="#2024-%E9%87%8D%E5%A4%A7%E5%8F%91%E5%B8%83">2024 重大发布</a></li><li><a href="#%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90">图像生成</a><ul><li><a href="#%E6%96%87%E7%94%9F%E5%9B%BE">文生图</a></li><li><a href="#%E4%B8%AA%E6%80%A7%E5%8C%96%E4%B8%8E%E9%A3%8E%E6%A0%BC%E5%8C%96">个性化与风格化</a></li></ul></li><li><a href="#%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90">视频生成</a></li><li><a href="#2024-%E9%97%AA%E8%80%80%E5%88%9B%E6%84%8F%E5%B7%A5%E5%85%B7">2024 闪耀创意工具</a></li><li><a href="#2025-%E5%B9%B4-AI-%E8%89%BA%E6%9C%AF%E8%B6%8B%E5%8A%BF%E5%B1%95%E6%9C%9B">2025 年 AI 艺术趋势展望</a></li><li><a href="#%E5%BC%BA%E5%8A%BF%E5%BC%80%E5%B1%80-2025-%E5%B9%B4-1-%E6%9C%88%E5%BC%80%E6%BA%90%E6%96%B0%E4%BD%9C">强势开局: 2025 年 1 月开源新作</a></li></ul><h2 id="_2024-重大发布" tabindex="-1"><a class="header-anchor" href="#_2024-重大发布"><span>2024 重大发布</span></a></h2><p>2024 年哪些创意 AI 工具最引人注目？我们将重点盘点艺术创作领域的重要发布，特别关注文生图、视频生成等热门任务中的开源进展。</p><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ai_art_newsletter_1/timeline_2.png" width="700" height="auto" alt="2024 年重要时刻时间轴 "><h2 id="图像生成" tabindex="-1"><a class="header-anchor" href="#图像生成"><span>图像生成</span></a></h2><p>自初代 Stable Diffusion 掀起开源文生图浪潮已逾两年，如今在文本到图像生成、图像编辑和可控生成领域，开源模型已能与闭源产品分庭抗礼。</p><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ai_art_newsletter_1/finger_meme.png" width="424" height="auto" alt=" 手指生成梗图 "><h3 id="文生图" tabindex="-1"><a class="header-anchor" href="#文生图"><span>文生图</span></a></h3><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ai_art_newsletter_1/flux_grid.png" width="600" height="auto" alt="Flux 模型效果展示 "><p>2024 年见证了扩散模型的范式转变——从传统 U-Net 架构转向扩散 Transformer (DiT)，同时目标函数也进化为流匹配 (flow matching)。</p><p><strong>技术速览</strong>: 扩散模型与 <strong>高斯</strong> 流匹配本质相通。流匹配通过不同的向量场参数化方式，为网络输出提供了新视角。</p><ul><li>推荐阅读 <a href="https://diffusionflow.github.io" target="_blank" rel="noopener noreferrer">Google DeepMind 的技术博客</a>，深入了解流匹配与扩散模型的关联。</li></ul><p><strong>实践进展</strong>: Stability AI 率先推出 <a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium" target="_blank" rel="noopener noreferrer">Stable Diffusion 3</a>，而 <a href="https://huggingface.co/Tencent-Hunyuan/HunyuanDiT" target="_blank" rel="noopener noreferrer">腾讯混元 DiT</a> 则成为首个开源的 DiT 架构模型。后续 <a href="https://huggingface.co/fal/AuraFlow" target="_blank" rel="noopener noreferrer">AuraFlow</a>、<a href="https://huggingface.co/black-forest-labs/FLUX.1-dev" target="_blank" rel="noopener noreferrer">Flux.1</a> 和 <a href="https://huggingface.co/stabilityai/stable-diffusion-3.5-large" target="_blank" rel="noopener noreferrer">Stable Diffusion 3.5</a> 延续了这一趋势。</p><p>在开源图像生成模型的里程碑中，<a href="https://huggingface.co/black-forest-labs/FLUX.1-dev" target="_blank" rel="noopener noreferrer">Flux.1</a> 的发布堪称革命性。该模型在多项基准测试中超越 Midjourney v6.0、DALL·E 3 (HD) 等闭源模型，刷新了开源模型的性能纪录。</p><h3 id="个性化与风格化" tabindex="-1"><a class="header-anchor" href="#个性化与风格化"><span>个性化与风格化</span></a></h3><p>图像模型的进步带动了个性化生成技术的飞跃。2022 年 8 月，<a href="https://textual-inversion.github.io" target="_blank" rel="noopener noreferrer">Textual Inversion</a> 和 <a href="https://dreambooth.github.io" target="_blank" rel="noopener noreferrer">DreamBooth</a> 等开创性工作实现了 <strong>向文生图模型注入概念</strong>，极大扩展了应用边界。这些技术催生了 LoRA 等改进方案，推动个性化生成进入新阶段。</p><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ai_art_newsletter_1/personalization_1.png" width="424" height="auto" alt=" 个性化技术对比 "><p>然而，微调模型的质量受限于基础模型性能。Stable Diffusion XL (SDXL) 的发布为开源个性化生成树立新标杆，当前多数个性化方案仍基于 SDXL 架构。随着对扩散模型各组件语义角色的深入理解，我们不禁思考: <strong>能否实现不进行额外繁琐优化的高质量生成？</strong></p><p><em>Zero-shot 技术风暴来袭</em> ——2024 年见证了仅需 <strong>单张参考图</strong> 即可生成高质量人像的技术突破。<a href="https://huggingface.co/spaces/multimodalart/Ip-Adapter-FaceID" target="_blank" rel="noopener noreferrer">IP-Adapter FaceID</a>、<a href="https://huggingface.co/spaces/InstantX/InstantID" target="_blank" rel="noopener noreferrer">InstantID</a>、<a href="https://huggingface.co/spaces/TencentARC/PhotoMaker-V2" target="_blank" rel="noopener noreferrer">PhotoMaker</a> 等免训练方案展现出媲美微调模型的实力。</p><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ai_art_newsletter_1/instantid.png" width="600" height="auto" alt="InstantID 效果展示 "><p>图像编辑与可控生成 (如边缘/深度/姿态控制) 也取得长足进步，这既得益于基础模型的发展，也源于社区对模型组件的深入理解 (<a href="https://huggingface.co/spaces/InstantX/InstantStyle" target="_blank" rel="noopener noreferrer">Instant Style</a>、<a href="https://huggingface.co/spaces/Yardenfren/B-LoRA" target="_blank" rel="noopener noreferrer">B-LoRA</a>)。</p><p><strong>未来展望</strong>: 尽管 DiT 架构模型 (如 Flux、SD3.5) 已开始探索个性化的应用，但对 DiT 组件语义角色的理解尚不及 U-Net 深入。2025 年或将揭开 DiT 的组件奥秘，释放新一代图像模型的全部潜能。</p><h2 id="视频生成" tabindex="-1"><a class="header-anchor" href="#视频生成"><span>视频生成</span></a></h2>',28),(0,t.Lk)("figure",{class:"image flex flex-col items-center text-center m-0 w-full"},[(0,t.Lk)("video",{alt:" 混元视频演示 ",autoplay:"",loop:"",autobuffer:"",muted:"",playsinline:""},[(0,t.Lk)("source",{src:"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/video_gen/hunyuan-output.mp4",type:"video/mp4"})])],-1),(0,t.Fv)('<p>相较图像生成，视频生成仍任重道远。但必须承认，我们已取得显著进步。OpenAI 的 Sora 极大提升了行业预期，正如 fofr 在 <a href="https://replicate.com/blog/ai-video-is-having-its-stable-diffusion-moment" target="_blank" rel="noopener noreferrer">《AI 视频正迎来 Stable Diffusion 时刻》</a> 中所言——它让人们看到了可能性。</p><p>近期开源视频模型的爆发 (<a href="https://huggingface.co/THUDM/CogVideoX-5b" target="_blank" rel="noopener noreferrer">CogVideoX</a>、<a href="https://huggingface.co/genmo/mochi-1-preview" target="_blank" rel="noopener noreferrer">Mochi</a>、<a href="https://huggingface.co/rhymes-ai/Allegro" target="_blank" rel="noopener noreferrer">Allegro</a>、<a href="https://huggingface.co/Lightricks/LTX-Video" target="_blank" rel="noopener noreferrer">LTX Video</a>、<a href="https://huggingface.co/tencent/HunyuanVideo" target="_blank" rel="noopener noreferrer">混元视频</a>) 同样值得关注。视频生成面临画面动作是否自然、前后画面是否流畅、人物外观是否保持一致等多重挑战，加之计算资源需求巨大，导致生成延迟较高。尽管内存优化和量化技术可缓解硬件压力，但往往会影响生成的质量。尽管如此，开源社区仍在持续突破，最新进展可参阅 <a href="https://huggingface.co/blog/video_gen" target="_blank" rel="noopener noreferrer">开源视频生成模型现状</a>。</p><p>虽然多数用户仍难以本地运行视频模型，但这也预示着 2025 年将迎来更大突破。</p><h2 id="音频生成" tabindex="-1"><a class="header-anchor" href="#音频生成"><span>音频生成</span></a></h2><p>音频生成在过去一年突飞猛进，从制作简单的声音效果到创作完整的歌曲都取得了很大进步。尽管面临信号复杂度高、训练数据稀缺等挑战，2024 年仍涌现 <a href="https://huggingface.co/OuteAI/OuteTTS-0.2-500M" target="_blank" rel="noopener noreferrer">OuteTTS</a>、<a href="https://huggingface.co/ai4bharat/indic-parler-tts" target="_blank" rel="noopener noreferrer">IndicParlerTTS</a> 等开源语音合成模型，以及 OpenAI 的 <a href="https://huggingface.co/openai/whisper-large-v3-turbo" target="_blank" rel="noopener noreferrer">Whisper large v3 turbo</a> 语音识别模型。2025 年开年即迎来 <a href="https://huggingface.co/hexgrad/Kokoro-82M" target="_blank" rel="noopener noreferrer">Kokoro</a>、<a href="https://huggingface.co/HKUSTAudio/Llasa-3B" target="_blank" rel="noopener noreferrer">LLasa TTS</a>、<a href="https://huggingface.co/OuteAI/OuteTTS-0.3-1B" target="_blank" rel="noopener noreferrer">OuteTTS 0.3</a> 等语音模型，以及 <a href="https://huggingface.co/models?search=jasco" target="_blank" rel="noopener noreferrer">JASCO</a>、<a href="https://huggingface.co/m-a-p/YuE-s1-7B-anneal-en-cot" target="_blank" rel="noopener noreferrer">YuE</a> 音乐模型的集中发布，预示着音频领域将迎来爆发年。</p><p>下方歌曲由 YuE 生成🤯</p><figure class="image flex flex-col items-center text-center m-0 w-full"><audio alt="yue.mp3" controls><source src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ai_art_newsletter_1/I_wont_back_down_pop.mp3" type="audio/mp3"></audio></figure><h2 id="_2024-闪耀创意工具" tabindex="-1"><a class="header-anchor" href="#_2024-闪耀创意工具"><span>2024 闪耀创意工具</span></a></h2><p>开源之美在于集社区之力探索模型新可能。本年度众多创意工具正是这种协作精神的结晶:</p><h4 id="flux-fine-tuning" tabindex="-1"><a class="header-anchor" href="#flux-fine-tuning"><span>Flux fine-tuning</span></a></h4><p><a href="https://huggingface.co/ostris" target="_blank" rel="noopener noreferrer">ostris</a> 开发的 <a href="https://github.com/ostris/ai-toolkit" target="_blank" rel="noopener noreferrer">AI 工具包</a> 助力社区创作出惊艳的 <a href="https://huggingface.co/spaces/multimodalart/flux-lora-the-explorer" target="_blank" rel="noopener noreferrer">Flux 微调模型</a>。</p><h4 id="face-to-all" tabindex="-1"><a class="header-anchor" href="#face-to-all"><span>Face to All</span></a></h4><p>受 <a href="https://github.com/fofr/cog-face-to-many" target="_blank" rel="noopener noreferrer">face-to-many</a> 启发，<a href="https://huggingface.co/spaces/multimodalart/face-to-all" target="_blank" rel="noopener noreferrer">Face to All</a> 将爆款模型 <a href="https://huggingface.co/spaces/InstantX/InstantID" target="_blank" rel="noopener noreferrer">Instant ID</a> 与深度 ControlNet、社区微调的 SDXL LoRA 结合，实现免训练的高质量风格化人像生成。</p><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ai_art_newsletter_1/face-to-all.png" width="512" height="auto" alt="Face to All 效果展示 "><h4 id="flux-风格塑形" tabindex="-1"><a class="header-anchor" href="#flux-风格塑形"><span>Flux 风格塑形</span></a></h4><p>基于 <a href="https://x.com/CitizenPlain" target="_blank" rel="noopener noreferrer">Nathan Shipley</a> 的 ComfyUI 工作流，<a href="https://huggingface.co/spaces/multimodalart/flux-style-shaping" target="_blank" rel="noopener noreferrer">Flux 风格塑形</a> 通过融合 Flux [dev] Redux 与 Depth 模型，实现风格迁移与视错觉创作。</p><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ai_art_newsletter_1/styleshaping.jpeg" width="512" height="auto" alt=" 风格塑形效果 "><h4 id="智能图像外扩" tabindex="-1"><a class="header-anchor" href="#智能图像外扩"><span>智能图像外扩</span></a></h4><p><a href="https://huggingface.co/spaces/fffiloni/diffusers-image-outpaint" target="_blank" rel="noopener noreferrer">Diffusers Image Outpaint</a> 利用 SDXL Fill Pipeline 与联合 ControlNet，实现无缝图像外扩。</p><h4 id="动态人像" tabindex="-1"><a class="header-anchor" href="#动态人像"><span>动态人像</span></a></h4><p><a href="https://huggingface.co/spaces/KwaiVGI/LivePortrait" target="_blank" rel="noopener noreferrer">Live Portrait</a> 与 <a href="https://huggingface.co/spaces/jbilcke-hf/FacePoke" target="_blank" rel="noopener noreferrer">Face Poke</a> 让静态人像瞬间动起来。</p>',21),(0,t.Lk)("figure",{class:"image flex flex-col items-center text-center m-0 w-full"},[(0,t.Lk)("video",{alt:" 面部动画演示 ",autoplay:"",loop:"",autobuffer:"",muted:"",playsinline:""},[(0,t.Lk)("source",{src:"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ai_art_newsletter_1/isaac_1.mp4",type:"video/mp4"})])],-1),(0,t.Lk)("h4",{id:"trellis-3d-引擎",tabindex:"-1"},[(0,t.Lk)("a",{class:"header-anchor",href:"#trellis-3d-引擎"},[(0,t.Lk)("span",null,"TRELLIS 3D 引擎")])],-1),(0,t.Lk)("p",null,[(0,t.Lk)("a",{href:"https://huggingface.co/spaces/JeffreyXiang/TRELLIS",target:"_blank",rel:"noopener noreferrer"},"TRELLIS"),(0,t.eW)(" 以惊艳效果重塑 3D 生成格局，支持多样化高质量资产创建。")],-1),(0,t.Lk)("figure",{class:"image flex flex-col items-center text-center m-0 w-full"},[(0,t.Lk)("video",{alt:"TRELLIS 演示 ",autoplay:"",loop:"",autobuffer:"",muted:"",playsinline:""},[(0,t.Lk)("source",{src:"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ai_art_newsletter_1/trellis.mp4",type:"video/mp4"})])],-1),(0,t.Fv)('<h4 id="ic-light" tabindex="-1"><a class="header-anchor" href="#ic-light"><span>IC Light</span></a></h4><p><a href="https://huggingface.co/spaces/lllyasviel/IC-Light" target="_blank" rel="noopener noreferrer">IC-Light</a> 通过前景条件实现智能光影重构。</p><h2 id="_2025-年-ai-艺术趋势展望" tabindex="-1"><a class="header-anchor" href="#_2025-年-ai-艺术趋势展望"><span>2025 年 AI 艺术趋势展望</span></a></h2><p>2025 年将是开源社区在视频、动态与音频模型领域迎头赶上的一年。随着高效计算与量化技术的突破，开源视频模型有望实现跨越式发展。当图像生成进入自然平台期，我们的目光将转向多模态创新。</p><h2 id="强势开局-2025-年-1-月开源新作" tabindex="-1"><a class="header-anchor" href="#强势开局-2025-年-1-月开源新作"><span>强势开局: 2025 年 1 月开源新作</span></a></h2><ol><li><strong>YuE 音乐生成模型</strong></li></ol><p>Apache 2.0 协议开源的 <a href="https://huggingface.co/m-a-p/YuE-s1-7B-anneal-en-cot" target="_blank" rel="noopener noreferrer">YuE</a> 在音乐生成质量上比肩 Suno 等闭源产品，<a href="https://huggingface.co/spaces/fffiloni/YuE" target="_blank" rel="noopener noreferrer">在线体验</a>。</p>',7),(0,t.Lk)("figure",{class:"image flex flex-col items-center text-center m-0 w-full"},[(0,t.Lk)("video",{alt:"YuE 歌曲演示 ",autobuffer:"",playsinline:""},[(0,t.Lk)("source",{src:"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ai_art_newsletter_1/My first YuE (open source Suno) AI generated full song.mp4",type:"video/mp4"})])],-1),(0,t.Fv)('<ol start="2"><li><strong>3D 生成三剑客</strong></li></ol><p>继 TRELLIS 之后，<a href="https://huggingface.co/tencent/Hunyuan3D-2" target="_blank" rel="noopener noreferrer">混元 3D-2</a>、<a href="https://huggingface.co/stabilityai/stable-point-aware-3d" target="_blank" rel="noopener noreferrer">SPAR3D</a>、<a href="https://huggingface.co/chenguolin/DiffSplat" target="_blank" rel="noopener noreferrer">DiffSplat</a> 持续革新 3D 生成领域。</p><ol start="3"><li><strong>Lumina-Image 2.0</strong></li></ol><p>这款 20 亿参数的 <a href="https://huggingface.co/Alpha-VLLM/Lumina-Image-2.0" target="_blank" rel="noopener noreferrer">文生图模型</a> 以 Apache 2.0 协议开源，性能比肩 80 亿参数的 Flux.1，<a href="https://huggingface.co/spaces/benjamin-paine/Lumina-Image-2.0" target="_blank" rel="noopener noreferrer">在线体验</a>。</p><ol start="4"><li><strong>ComfyUI 转 Gradio 指南</strong></li></ol><p>这份 <a href="https://huggingface.co/blog/run-comfyui-workflows-on-spaces" target="_blank" rel="noopener noreferrer">教程</a> 详细介绍了如何将复杂 ComfyUI 工作流转换为 Gradio 应用，并免费部署于 Hugging Face Spaces。</p><h2 id="开启资讯新时代-🗞️" tabindex="-1"><a class="header-anchor" href="#开启资讯新时代-🗞️"><span>开启资讯新时代 🗞️</span></a></h2><p>从本期开始，我们 (<a href="https://huggingface.co/multimodalart" target="_blank" rel="noopener noreferrer">Poli</a> 与 <a href="https://huggingface.co/linoyts" target="_blank" rel="noopener noreferrer">Linoy</a>) 将每月为您精选创意 AI 领域最新动态。在这个快速迭代的领域，我们愿做您的信息顾问，让创意工具触手可及。</p>',8)]))}]]),l=JSON.parse('{"path":"/zh/posts/reprint/ai-art-newsletter-jan-25.html","title":"AI艺术工具通讯 - 第1期","lang":"zh-CN","frontmatter":{"title":"AI艺术工具通讯 - 第1期","thumbnail":"/blog/assets/ai_art_newsletter_1/thumbnail.png","authors":[{"user":"linoyts"},{"user":"multimodalart"}],"translators":[{"user":"yaoqih"},{"user":"zhongdongy","proofreader":true}],"description":"AI 艺术工具通讯 创刊号 🎉 AI 领域的发展速度令人惊叹，回想一年前我们还在为生成正确手指数量的人像而苦苦挣扎的场景，恍如隔世 😂。 过去两年对开源模型和艺术创作工具而言具有里程碑意义。创意表达的 AI 工具从未像现在这般触手可及，然而这仅仅是冰山一角。让我们共同回顾 2024 年 AI 艺术领域的关键突破与创新工具，并展望 2025 年的发展...","gitInclude":[],"head":[["link",{"rel":"alternate","hreflang":"en-us","href":"https://neverbiasu.github.io/posts/reprint/ai-art-newsletter-jan-25.html"}],["meta",{"property":"og:url","content":"https://neverbiasu.github.io/zh/posts/reprint/ai-art-newsletter-jan-25.html"}],["meta",{"property":"og:site_name","content":"Nlog"}],["meta",{"property":"og:title","content":"AI艺术工具通讯 - 第1期"}],["meta",{"property":"og:description","content":"AI 艺术工具通讯 创刊号 🎉 AI 领域的发展速度令人惊叹，回想一年前我们还在为生成正确手指数量的人像而苦苦挣扎的场景，恍如隔世 😂。 过去两年对开源模型和艺术创作工具而言具有里程碑意义。创意表达的 AI 工具从未像现在这般触手可及，然而这仅仅是冰山一角。让我们共同回顾 2024 年 AI 艺术领域的关键突破与创新工具，并展望 2025 年的发展..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:locale:alternate","content":"en-US"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"AI艺术工具通讯 - 第1期\\",\\"image\\":[\\"\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"neverbiasu\\",\\"url\\":\\"https://neverbiasu.github.io\\"}]}"]]},"headers":[{"level":3,"title":"创刊号 🎉","slug":"创刊号-🎉","link":"#创刊号-🎉","children":[]},{"level":2,"title":"目录","slug":"目录","link":"#目录","children":[]},{"level":2,"title":"2024 重大发布","slug":"_2024-重大发布","link":"#_2024-重大发布","children":[]},{"level":2,"title":"图像生成","slug":"图像生成","link":"#图像生成","children":[{"level":3,"title":"文生图","slug":"文生图","link":"#文生图","children":[]},{"level":3,"title":"个性化与风格化","slug":"个性化与风格化","link":"#个性化与风格化","children":[]}]},{"level":2,"title":"视频生成","slug":"视频生成","link":"#视频生成","children":[]},{"level":2,"title":"音频生成","slug":"音频生成","link":"#音频生成","children":[]},{"level":2,"title":"2024 闪耀创意工具","slug":"_2024-闪耀创意工具","link":"#_2024-闪耀创意工具","children":[]},{"level":2,"title":"2025 年 AI 艺术趋势展望","slug":"_2025-年-ai-艺术趋势展望","link":"#_2025-年-ai-艺术趋势展望","children":[]},{"level":2,"title":"强势开局: 2025 年 1 月开源新作","slug":"强势开局-2025-年-1-月开源新作","link":"#强势开局-2025-年-1-月开源新作","children":[]},{"level":2,"title":"开启资讯新时代 🗞️","slug":"开启资讯新时代-🗞️","link":"#开启资讯新时代-🗞️","children":[]}],"readingTime":{"minutes":8.03,"words":2408},"filePathRelative":"zh/posts/reprint/ai-art-newsletter-jan-25.md","excerpt":"\\n<h3>创刊号 🎉</h3>\\n<p>AI 领域的发展速度令人惊叹，回想一年前我们还在为生成正确手指数量的人像而苦苦挣扎的场景，恍如隔世 😂。</p>\\n<p>过去两年对开源模型和艺术创作工具而言具有里程碑意义。创意表达的 AI 工具从未像现在这般触手可及，然而这仅仅是冰山一角。让我们共同回顾 2024 年 AI 艺术领域的关键突破与创新工具，并展望 2025 年的发展趋势。</p>\\n<h2>目录</h2>\\n<ul>\\n<li><a href=\\"#2024-%E9%87%8D%E5%A4%A7%E5%8F%91%E5%B8%83\\">2024 重大发布</a></li>\\n<li><a href=\\"#%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90\\">图像生成</a>\\n<ul>\\n<li><a href=\\"#%E6%96%87%E7%94%9F%E5%9B%BE\\">文生图</a></li>\\n<li><a href=\\"#%E4%B8%AA%E6%80%A7%E5%8C%96%E4%B8%8E%E9%A3%8E%E6%A0%BC%E5%8C%96\\">个性化与风格化</a></li>\\n</ul>\\n</li>\\n<li><a href=\\"#%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90\\">视频生成</a></li>\\n<li><a href=\\"#2024-%E9%97%AA%E8%80%80%E5%88%9B%E6%84%8F%E5%B7%A5%E5%85%B7\\">2024 闪耀创意工具</a></li>\\n<li><a href=\\"#2025-%E5%B9%B4-AI-%E8%89%BA%E6%9C%AF%E8%B6%8B%E5%8A%BF%E5%B1%95%E6%9C%9B\\">2025 年 AI 艺术趋势展望</a></li>\\n<li><a href=\\"#%E5%BC%BA%E5%8A%BF%E5%BC%80%E5%B1%80-2025-%E5%B9%B4-1-%E6%9C%88%E5%BC%80%E6%BA%90%E6%96%B0%E4%BD%9C\\">强势开局: 2025 年 1 月开源新作</a></li>\\n</ul>","autoDesc":true}')}}]);