"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[40],{66262:(e,a)=>{a.A=(e,a)=>{const r=e.__vccOpts||e;for(const[e,t]of a)r[e]=t;return r}},62426:(e,a,r)=>{r.r(a),r.d(a,{comp:()=>n,data:()=>s});var t=r(20641);const i={},n=(0,r(66262).A)(i,[["render",function(e,a){return(0,t.uX)(),(0,t.CE)("div",null,a[0]||(a[0]=[(0,t.Fv)('<h1 id="voxtral-mini多模态音频-hidream-e1-1稀疏扩散图像编辑-pusav1高效视频生成【hf周报】" tabindex="-1"><a class="header-anchor" href="#voxtral-mini多模态音频-hidream-e1-1稀疏扩散图像编辑-pusav1高效视频生成【hf周报】"><span>Voxtral-Mini多模态音频 | HiDream-E1-1稀疏扩散图像编辑 | PusaV1高效视频生成【HF周报】</span></a></h1><figure><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/hf-weekly-dc-cover.png" alt="封面图" tabindex="0" loading="lazy"><figcaption>封面图</figcaption></figure><h2 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span>摘要</span></a></h2><p>本周亮点：Mistral推多模态音频模型，HiDream革新图像编辑，PusaV1高效视频生成。英伟达、LG等模型及Hermes-3、rStar-Coder数据集同步亮相，详情见正文。</p><hr><h2 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span>目录</span></a></h2><ol><li><a href="#voxtral-mini-3b-2507mistral-ai%E5%8F%91%E5%B8%83%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E9%9F%B3%E9%A2%91%E6%A8%A1%E5%9E%8B">Voxtral-Mini-3B-2507：Mistral AI发布的多模态音频模型</a></li><li><a href="#exaone-40-32b-lg-ai-research%E6%8E%A8%E5%87%BA%E7%9A%84%E5%8F%8C%E6%A8%A1%E6%8E%A8%E7%90%86%E5%A4%A7%E6%A8%A1%E5%9E%8B">EXAONE-4.0-32B：LG AI Research推出的双模推理大模型</a></li><li><a href="#pusav1%E9%AB%98%E6%95%88%E5%A4%9A%E4%BB%BB%E5%8A%A1%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90%E4%B8%8E%E7%BC%96%E8%BE%91%E6%96%B0%E8%8C%83%E5%BC%8F">PusaV1：高效多任务视频生成与编辑新范式</a></li><li><a href="#hidream-e1-1%E5%9F%BA%E4%BA%8E%E7%A8%80%E7%96%8F%E6%89%A9%E6%95%A3transformer%E7%9A%84%E5%9B%BE%E5%83%8F%E7%BC%96%E8%BE%91%E6%A8%A1%E5%9E%8B">HiDream-E1-1：基于稀疏扩散Transformer的图像编辑模型</a></li><li><a href="#canary-qwen-25b%E8%8B%B1%E4%BC%9F%E8%BE%BE%E5%BC%80%E6%BA%90%E7%9A%84sota%E8%8B%B1%E6%96%87%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B">Canary-Qwen-2.5B：英伟达开源的SOTA英文语音识别模型</a></li><li><a href="#hermes-3-datasetnous-research%E5%8F%91%E5%B8%83%E7%9A%84%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%AF%B9%E8%AF%9D%E6%95%B0%E6%8D%AE%E9%9B%86">Hermes-3-Dataset：Nous Research发布的大规模对话数据集</a></li><li><a href="#rstar-coder%E5%BE%AE%E8%BD%AF%E5%8F%91%E5%B8%83%E7%9A%84%E5%A4%A7%E8%A7%84%E6%A8%A1%E4%BB%A3%E7%A0%81%E6%8E%A8%E7%90%86%E6%95%B0%E6%8D%AE%E9%9B%86">rStar-Coder：微软发布的大规模代码推理数据集</a></li></ol><hr><h2 id="voxtral-mini-3b-2507-mistral-ai发布的多模态音频模型" tabindex="-1"><a class="header-anchor" href="#voxtral-mini-3b-2507-mistral-ai发布的多模态音频模型"><span>Voxtral-Mini-3B-2507：Mistral AI发布的多模态音频模型</span></a></h2><figure><img src="https://cdn-uploads.huggingface.co/production/uploads/64161701107962562e9b1006/puASxtajF1lDeGYPrRK5y.png" alt="Voxtral-Mini-3B-2507 Benchmark 图" tabindex="0" loading="lazy"><figcaption>Voxtral-Mini-3B-2507 Benchmark 图</figcaption></figure><p><strong>概要</strong>：Mistral AI 发布 Voxtral-Mini-3B-2507，一款基于Ministral-3B增强的3B级多模态音频语言模型。该模型不仅保留了强大的文本理解能力，还具备卓越的音频处理功能，包括专用转录模式、长达40分钟的音频理解、内置问答与摘要、8种主流语言的自动检测与转录，以及直接从语音触发函数调用的能力。Voxtral-Mini支持32k长上下文，为实现复杂的语音交互应用提供了高效解决方案。</p><p><strong>标签</strong>：#MistralAI #VoxtralMini #多模态音频 #语音识别 #函数调用</p><hr><h2 id="exaone-4-0-32b-lg-ai-research推出的双模推理大模型" tabindex="-1"><a class="header-anchor" href="#exaone-4-0-32b-lg-ai-research推出的双模推理大模型"><span>EXAONE-4.0-32B：LG AI Research推出的双模推理大模型</span></a></h2><figure><img src="https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B/resolve/main/assets/EXAONE_Symbol+BI_3d.png" alt="EXAONE-4.0-32B Logo 图" tabindex="0" loading="lazy"><figcaption>EXAONE-4.0-32B Logo 图</figcaption></figure><p><strong>概要</strong>：LG AI Research 发布 EXAONE-4.0-32B，一个拥有320亿参数的多语言大模型。该模型创新性地集成了“非推理”和“推理”两种模式，以兼顾通用性与复杂任务处理能力。EXAONE-4.0支持128K超长上下文，具备Agent工具使用能力，并将多语言支持扩展至西班牙语、韩语和英语。其架构采用混合注意力机制和QK-Reorder-Norm等新技术，在多项基准测试中表现出色。</p><p><strong>标签</strong>：#LGAIResearch #EXAONE4 #双模推理 #混合注意力 #多语言大模型</p><hr><h2 id="pusav1-高效多任务视频生成与编辑新范式" tabindex="-1"><a class="header-anchor" href="#pusav1-高效多任务视频生成与编辑新范式"><span>PusaV1：高效多任务视频生成与编辑新范式</span></a></h2><figure><img src="https://huggingface.co/RaphaelLiu/PusaV1/resolve/main/pusa_benchmark_figure_dark.png" alt="PusaV1 Benchmark 图" tabindex="0" loading="lazy"><figcaption>PusaV1 Benchmark 图</figcaption></figure><p><strong>概要</strong>：RaphaelLiu 发布 PusaV1，一个基于矢量化时间步适应（VTA）技术的高效视频生成模型。该模型在SOTA文生视频模型Wan2.1-T2V-14B基础上进行微调，以低于$500的成本和4K样本数据，实现了超越基线模型的性能，训练成本和数据量仅为基线的1/200和1/2500。PusaV1不仅在图生视频（I2V）任务上达到SOTA水平，还零样本解锁了视频续写、补全、转场等多种复杂任务。</p><p><strong>标签</strong>：#PusaV1 #视频生成 #矢量化时间步 #高效微调 #多任务视频</p><hr><h2 id="hidream-e1-1-基于稀疏扩散transformer的图像编辑模型" tabindex="-1"><a class="header-anchor" href="#hidream-e1-1-基于稀疏扩散transformer的图像编辑模型"><span>HiDream-E1-1：基于稀疏扩散Transformer的图像编辑模型</span></a></h2><figure><img src="https://huggingface.co/HiDream-ai/HiDream-E1-1/resolve/main/demo.jpg" alt="HiDream-E1-1 Example 图" tabindex="0" loading="lazy"><figcaption>HiDream-E1-1 Example 图</figcaption></figure><p><strong>概要</strong>：HiDream.ai 发布 HiDream-E1-1，一款基于其稀疏扩散Transformer架构（HiDream-I1）构建的图像编辑模型。该模型在EmuEdit和ReasonEdit等基准上表现出色，展示了强大的指令驱动图像内容修改能力。HiDream-E1-1集成了来自FLUX.1的VAE和Llama-3.1-8B的文本编码器，通过高效的架构和训练策略，为用户提供高质量、高效率的图像编辑体验。</p><p><strong>标签</strong>：#HiDreamAI #HiDreamE1 #图像编辑 #稀疏扩散 #DiffusionTransformer</p><hr><h2 id="canary-qwen-2-5b-英伟达开源的sota英文语音识别模型" tabindex="-1"><a class="header-anchor" href="#canary-qwen-2-5b-英伟达开源的sota英文语音识别模型"><span>Canary-Qwen-2.5B：英伟达开源的SOTA英文语音识别模型</span></a></h2><figure><img src="https://raw.githubusercontent.com/neverbiasu/neverbiasu.github.io/9314894963ad475c03414e91c53cceb60537471d/src/.vuepress/public/assets/images/hf-weekly/canary-qwen-2.5b-space.png" alt="Canary-Qwen-2.5B Demo 图" tabindex="0" loading="lazy"><figcaption>Canary-Qwen-2.5B Demo 图</figcaption></figure><p><strong>概要</strong>：英伟达（NVIDIA）发布 Canary-Qwen-2.5B，一款在多项英文语音识别基准上达到SOTA性能的25亿参数模型。该模型属于语音增强语言模型（SALM），集成了FastConformer编码器和基于Qwen3-1.7B的Transformer解码器。它支持纯转录（ASR）和语言模型（LLM）两种模式，前者专注于高精度语音转文本，后者则可用于对转录稿进行摘要、问答等后处理，为商业应用提供了强大而灵活的工具。</p><p><strong>标签</strong>：#NVIDIA #CanaryQwen #语音识别 #SALM #FastConformer</p><hr><h2 id="hermes-3-dataset-nous-research发布的大规模对话数据集" tabindex="-1"><a class="header-anchor" href="#hermes-3-dataset-nous-research发布的大规模对话数据集"><span>Hermes-3-Dataset：Nous Research发布的大规模对话数据集</span></a></h2><figure><img src="https://nousresearch.com/wp-content/uploads/2025/07/Screenshot-2025-06-06-at-7.10.10-PM.png" alt="Hermes-3-Dataset Logo 图" tabindex="0" loading="lazy"><figcaption>Hermes-3-Dataset Logo 图</figcaption></figure><p><strong>概要</strong>：Nous Research 发布 Hermes-3-Dataset，一个包含近百万（95.9万）条高质量对话的大规模数据集。该数据集旨在用于训练无偏见、无审查的AI助手，数据格式遵循system-human-gpt的对话结构，涵盖了代码生成、规划、创意写作、知识问答等多种复杂任务。Hermes-3的发布为社区训练更强大、更安全的开源模型提供了宝贵的资源。</p><p><strong>标签</strong>：#NousResearch #Hermes3 #数据集 #对话数据 #AI助手</p><hr><h2 id="rstar-coder-微软发布的大规模代码推理数据集" tabindex="-1"><a class="header-anchor" href="#rstar-coder-微软发布的大规模代码推理数据集"><span>rStar-Coder：微软发布的大规模代码推理数据集</span></a></h2><figure><img src="https://huggingface.co/datasets/microsoft/rStar-Coder/resolve/main/mutual_verification.png" alt="rStar-Coder Mutual Verification 图" tabindex="0" loading="lazy"><figcaption>rStar-Coder Mutual Verification 图</figcaption></figure><p><strong>概要</strong>：微软（Microsoft）发布 rStar-Coder，一个规模宏大（超480GB）的、经过验证的代码推理数据集。该数据集旨在提升模型在编程竞赛级别的代码生成与推理能力，包含人类种子数据和合成数据两大类，并同时支持监督微调（SFT）和强化学习（RL）两种训练范式。rStar-Coder的发布，为训练下一代高性能代码大模型奠定了坚实的数据基础。</p><p><strong>标签</strong>：#Microsoft #rStarCoder #代码推理 #编程竞赛 #大规模数据集</p><hr><h3 id="参考链接" tabindex="-1"><a class="header-anchor" href="#参考链接"><span>参考链接</span></a></h3><ol><li><a href="https://huggingface.co/mistralai/Voxtral-Mini-3B-2507" target="_blank" rel="noopener noreferrer">mistralai/Voxtral-Mini-3B-2507</a></li><li><a href="https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B" target="_blank" rel="noopener noreferrer">LGAI-EXAONE/EXAONE-4.0-32B</a></li><li><a href="https://huggingface.co/RaphaelLiu/PusaV1" target="_blank" rel="noopener noreferrer">RaphaelLiu/PusaV1</a></li><li><a href="https://huggingface.co/HiDream-ai/HiDream-E1-1" target="_blank" rel="noopener noreferrer">HiDream-ai/HiDream-E1-1</a></li><li><a href="https://huggingface.co/nvidia/canary-qwen-2.5b" target="_blank" rel="noopener noreferrer">nvidia/canary-qwen-2.5b</a></li><li><a href="https://huggingface.co/datasets/NousResearch/Hermes-3-Dataset" target="_blank" rel="noopener noreferrer">NousResearch/Hermes-3-Dataset</a></li><li><a href="https://huggingface.co/datasets/microsoft/rStar-Coder" target="_blank" rel="noopener noreferrer">microsoft/rStar-Coder</a></li></ol>',45)]))}]]),s=JSON.parse('{"path":"/zh/posts/hf-weekly/004.html","title":"Voxtral-Mini多模态音频 | HiDream-E1-1稀疏扩散图像编辑 | PusaV1高效视频生成【HF周报】","lang":"zh-CN","frontmatter":{"description":"Voxtral-Mini多模态音频 | HiDream-E1-1稀疏扩散图像编辑 | PusaV1高效视频生成【HF周报】 封面图封面图 摘要 本周亮点：Mistral推多模态音频模型，HiDream革新图像编辑，PusaV1高效视频生成。英伟达、LG等模型及Hermes-3、rStar-Coder数据集同步亮相，详情见正文。 目录 Voxtral-M...","gitInclude":[],"head":[["meta",{"property":"og:url","content":"https://neverbiasu.github.io/zh/posts/hf-weekly/004.html"}],["meta",{"property":"og:site_name","content":"Nlog"}],["meta",{"property":"og:title","content":"Voxtral-Mini多模态音频 | HiDream-E1-1稀疏扩散图像编辑 | PusaV1高效视频生成【HF周报】"}],["meta",{"property":"og:description","content":"Voxtral-Mini多模态音频 | HiDream-E1-1稀疏扩散图像编辑 | PusaV1高效视频生成【HF周报】 封面图封面图 摘要 本周亮点：Mistral推多模态音频模型，HiDream革新图像编辑，PusaV1高效视频生成。英伟达、LG等模型及Hermes-3、rStar-Coder数据集同步亮相，详情见正文。 目录 Voxtral-M..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/hf-weekly-dc-cover.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Voxtral-Mini多模态音频 | HiDream-E1-1稀疏扩散图像编辑 | PusaV1高效视频生成【HF周报】\\",\\"image\\":[\\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/hf-weekly-dc-cover.png\\",\\"https://cdn-uploads.huggingface.co/production/uploads/64161701107962562e9b1006/puASxtajF1lDeGYPrRK5y.png\\",\\"https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B/resolve/main/assets/EXAONE_Symbol+BI_3d.png\\",\\"https://huggingface.co/RaphaelLiu/PusaV1/resolve/main/pusa_benchmark_figure_dark.png\\",\\"https://huggingface.co/HiDream-ai/HiDream-E1-1/resolve/main/demo.jpg\\",\\"https://raw.githubusercontent.com/neverbiasu/neverbiasu.github.io/9314894963ad475c03414e91c53cceb60537471d/src/.vuepress/public/assets/images/hf-weekly/canary-qwen-2.5b-space.png\\",\\"https://nousresearch.com/wp-content/uploads/2025/07/Screenshot-2025-06-06-at-7.10.10-PM.png\\",\\"https://huggingface.co/datasets/microsoft/rStar-Coder/resolve/main/mutual_verification.png\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"neverbiasu\\",\\"url\\":\\"https://neverbiasu.github.io\\"}]}"]]},"headers":[{"level":2,"title":"摘要","slug":"摘要","link":"#摘要","children":[]},{"level":2,"title":"目录","slug":"目录","link":"#目录","children":[]},{"level":2,"title":"Voxtral-Mini-3B-2507：Mistral AI发布的多模态音频模型","slug":"voxtral-mini-3b-2507-mistral-ai发布的多模态音频模型","link":"#voxtral-mini-3b-2507-mistral-ai发布的多模态音频模型","children":[]},{"level":2,"title":"EXAONE-4.0-32B：LG AI Research推出的双模推理大模型","slug":"exaone-4-0-32b-lg-ai-research推出的双模推理大模型","link":"#exaone-4-0-32b-lg-ai-research推出的双模推理大模型","children":[]},{"level":2,"title":"PusaV1：高效多任务视频生成与编辑新范式","slug":"pusav1-高效多任务视频生成与编辑新范式","link":"#pusav1-高效多任务视频生成与编辑新范式","children":[]},{"level":2,"title":"HiDream-E1-1：基于稀疏扩散Transformer的图像编辑模型","slug":"hidream-e1-1-基于稀疏扩散transformer的图像编辑模型","link":"#hidream-e1-1-基于稀疏扩散transformer的图像编辑模型","children":[]},{"level":2,"title":"Canary-Qwen-2.5B：英伟达开源的SOTA英文语音识别模型","slug":"canary-qwen-2-5b-英伟达开源的sota英文语音识别模型","link":"#canary-qwen-2-5b-英伟达开源的sota英文语音识别模型","children":[]},{"level":2,"title":"Hermes-3-Dataset：Nous Research发布的大规模对话数据集","slug":"hermes-3-dataset-nous-research发布的大规模对话数据集","link":"#hermes-3-dataset-nous-research发布的大规模对话数据集","children":[]},{"level":2,"title":"rStar-Coder：微软发布的大规模代码推理数据集","slug":"rstar-coder-微软发布的大规模代码推理数据集","link":"#rstar-coder-微软发布的大规模代码推理数据集","children":[{"level":3,"title":"参考链接","slug":"参考链接","link":"#参考链接","children":[]}]}],"readingTime":{"minutes":5.27,"words":1582},"filePathRelative":"zh/posts/hf-weekly/004.md","excerpt":"\\n<figure><img src=\\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/hf-weekly-dc-cover.png\\" alt=\\"封面图\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>封面图</figcaption></figure>\\n<h2>摘要</h2>\\n<p>本周亮点：Mistral推多模态音频模型，HiDream革新图像编辑，PusaV1高效视频生成。英伟达、LG等模型及Hermes-3、rStar-Coder数据集同步亮相，详情见正文。</p>","autoDesc":true}')}}]);