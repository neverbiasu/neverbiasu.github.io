"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[410],{66262:(e,r)=>{r.A=(e,r)=>{const a=e.__vccOpts||e;for(const[e,t]of r)a[e]=t;return a}},65113:(e,r,a)=>{a.r(r),a.d(r,{comp:()=>n,data:()=>o});var t=a(20641);const i={},n=(0,a(66262).A)(i,[["render",function(e,r){return(0,t.uX)(),(0,t.CE)("div",null,r[0]||(r[0]=[(0,t.Fv)('<h1 id="minicpm4发布高效端侧模型-seedance-1-0引领视频生成进阶-comfyui‐r1打造智能工作流引擎【ai周报】" tabindex="-1"><a class="header-anchor" href="#minicpm4发布高效端侧模型-seedance-1-0引领视频生成进阶-comfyui‐r1打造智能工作流引擎【ai周报】"><span>MiniCPM4发布高效端侧模型 | Seedance 1.0引领视频生成进阶 | ComfyUI‑R1打造智能工作流引擎【AI周报】</span></a></h1><figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bc7e4820-82c0-4d95-a196-9627d8cb4578/original=true,quality=90/00003-2892726208.jpeg" alt="封面源自C站作者Koal2" tabindex="0" loading="lazy"><figcaption>封面源自C站作者Koal2</figcaption></figure><h2 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span>摘要</span></a></h2><p>本周亮点：MiniCPM4发布超高效端侧模型；Seedance 1.0引领视频生成；ComfyUI-R1自动化工作流创建；PartCrafter革新3D生成；Magistral推出透明多语言推理系统；AniMaker实现AI动画制作。</p><hr><h2 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span>目录</span></a></h2><ol><li><a href="#minicpm4%E8%B6%85%E9%AB%98%E6%95%88%E7%AB%AF%E4%BE%A7%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E5%88%97">MiniCPM4：超高效端侧大模型系列</a></li><li><a href="#seedance-10%E9%AB%98%E6%80%A7%E8%83%BD%E6%96%87%E6%9C%AC%E5%92%8C%E5%9B%BE%E5%83%8F%E9%A9%B1%E5%8A%A8%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B">Seedance 1.0：高性能文本和图像驱动视频生成模型</a></li><li><a href="#partcrafter%E7%BB%93%E6%9E%84%E5%8C%96-3d-%E7%BD%91%E6%A0%BC%E7%94%9F%E6%88%90%E7%9A%84%E5%88%9B%E6%96%B0%E6%8E%A2%E7%B4%A2">PartCrafter：结构化 3D 网格生成的创新探索</a></li><li><a href="#comfyuir1%E9%A6%96%E4%B8%AA%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E9%A9%B1%E5%8A%A8%E7%9A%84%E8%87%AA%E5%8A%A8%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%94%9F%E6%88%90%E7%B3%BB%E7%BB%9F">ComfyUI‑R1：首个大规模推理模型驱动的自动工作流生成系统</a></li><li><a href="#magistral%E9%A6%96%E4%B8%AA%E5%BC%80%E6%BA%90%E9%AB%98%E9%80%8F%E6%98%8E%E5%A4%9A%E8%AF%AD%E7%A7%8D%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B">Magistral：首个开源高透明多语种推理模型</a></li><li><a href="#animaker%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%8A%A8%E7%94%BB%E5%8F%99%E4%BA%8B%E7%94%9F%E6%88%90%E7%B3%BB%E7%BB%9F">AniMaker：多智能体动画叙事生成系统</a></li><li><a href="#frame-guidance-video%E6%97%A0%E9%9C%80%E8%AE%AD%E7%BB%83%E7%9A%84%E5%B8%A7%E7%BA%A7%E8%A7%86%E9%A2%91%E6%89%A9%E6%95%A3%E5%8F%AF%E6%8E%A7%E6%A1%86%E6%9E%B6">Frame Guidance：无需训练的帧级视频扩散可控框架</a></li></ol><hr><h2 id="minicpm4-超高效端侧大模型系列" tabindex="-1"><a class="header-anchor" href="#minicpm4-超高效端侧大模型系列"><span>MiniCPM4：超高效端侧大模型系列</span></a></h2><figure><img src="https://arxiv.org/html/2506.07900v1/x1.png" alt="MiniCPM4 Evaluation 图" tabindex="0" loading="lazy"><figcaption>MiniCPM4 Evaluation 图</figcaption></figure><p><strong>概要</strong>：<strong>MiniCPM4</strong> 是 <strong>OpenBMB</strong> 团队推出的高效端侧大模型家族，提供 0.5B 和 8B 两个版本。该系列通过在模型结构、预训练数据、高效训练算法与推理系统四个维度的联动优化，实现了在主流相同性能下的极致加速体验。例如 8B 版本采用可训练稀疏注意力 InfLLM v2，构建 UltraClean 高质量语料并配合 UltraChat v2 精调数据，同时辅以 ModelTunnel v2 的训练调度，和 CPM.cu 的推理优化，在长文本处理效率方面超越 Qwen3-8B，并在端侧设备上实现 5 倍以上生成速度提升。</p><p><strong>标签</strong>：#端侧LLM #稀疏注意力 #高效预训练 #模型量化 #长文本处理</p><hr><h2 id="seedance-1-0-高性能文本和图像驱动视频生成模型" tabindex="-1"><a class="header-anchor" href="#seedance-1-0-高性能文本和图像驱动视频生成模型"><span>Seedance 1.0：高性能文本和图像驱动视频生成模型</span></a></h2><figure><img src="hhttps://arxiv.org/html/2506.09113v1/x4.png" alt="Seedance Leaderboard 图" tabindex="0" loading="lazy"><figcaption>Seedance Leaderboard 图</figcaption></figure><p><strong>概要</strong>：<strong>Seedance 1.0</strong> 是由 <strong>字节跳动 Seed 团队</strong> 最新发布的基础视频生成模型，旨在解决文本或图像驱动视频生成中的关键挑战：提示执行、运动连贯性和视觉质量之间的平衡。研究团队通过多源数据精细标注训练样本，并设计了支持单段与多段生成任务的高效架构，自然融合了文本到视频和图像到视频的任务能力。同时，项目采用后训练阶段精调与 RLHF 的强化学习策略，并通过多阶段蒸馏与系统级优化，实现了约10倍的推理加速。在 NVIDIA L20 环境下，Seedance 可在约41秒内生成一段1080p、5秒长的高质量视频，展现出出色的时空流畅性、结构稳定性与镜头叙事能力。该模型已在六月集成至多平台，并在业内指标中全面领先，同时提供 API 接入与上线支持。</p><p><strong>标签</strong>：#视频生成 #文本到视频 #图像到视频 #RLHF #多段生成 #高效推理</p><hr><h2 id="partcrafter-结构化-3d-网格生成的创新探索" tabindex="-1"><a class="header-anchor" href="#partcrafter-结构化-3d-网格生成的创新探索"><span>PartCrafter：结构化 3D 网格生成的创新探索</span></a></h2><figure><img src="https://wgsxm.github.io/projects/partcrafter/static/images/teaser.png" alt="PartCrafter Teaser 图" tabindex="0" loading="lazy"><figcaption>PartCrafter Teaser 图</figcaption></figure><p><strong>概要</strong>：<strong>PartCrafter</strong> 是由<strong>北京大学、字节跳动和卡内基·梅隆大学</strong>联合提出的首个结构化 3D 生成模型，能够从单张 RGB 图像一次性生成多个语义明确、几何独立的 3D 网格部件。该方法摒弃了传统的 “先分割再重建” 流程，通过组合式潜在空间和层次注意力机制，实现端到端的零预分割多部件生成。模型基于预训练的 3D Mesh Diffusion Transformer（DiT），构建可独立编辑和组合的部件标记，并使用本地–全局注意力维持整体一致性。团队进一步制作了覆盖 50 k+ 多部件对象和 300 k 部件的数据集，在 Objaverse、ShapeNet 等基准上展示出优于现有方法的分割网格生成质量与生成速度：生成时间从 18 分钟缩至 34 秒，F‑Score 提升至约 0.7472，Chamfer Distance 降至 0.1726 。</p><p><strong>标签</strong>：#3D生成 #结构化网格 #DiffusionTransformer #多部件</p><hr><h2 id="comfyui‐r1-首个大规模推理模型驱动的自动工作流生成系统" tabindex="-1"><a class="header-anchor" href="#comfyui‐r1-首个大规模推理模型驱动的自动工作流生成系统"><span>ComfyUI‑R1：首个大规模推理模型驱动的自动工作流生成系统</span></a></h2><figure><img src="https://arxiv.org/html/2506.09790v1/x3.png" alt="ComfyUI‑R1 Comparison 图" tabindex="0" loading="lazy"><figcaption>ComfyUI‑R1 Comparison 图</figcaption></figure><p><strong>概要</strong>：<strong>ComfyUI‑R1</strong> 是 <strong>阿里巴巴 AIDC 团队</strong> 专为 <strong>ComfyUI</strong> 平台设计的首个大型推理模型，采用长链式思维（Chain-of-Thought）和强化学习策略，显著提升自动生成图像创作工作流的能力。研究团队构建了包含 ~4 K 完整 ComfyUI 工作流的数据集，基于 Qwen2.5-Coder-7B-Instruct 进行两阶段训练：首先以监督微调方式适应领域，随后使用规则与评估指标混合奖励进行强化学习优化，确保生成工作流在格式、结构及节点精度方面都非常可靠。实验结果表明，该模型达到了 97% 格式有效性，并在节点级别和图级别的 F1 分数等指标上大幅超越 GPT‑4o 和闭源模型，进一步证明了长链推理模型在 AI 艺术生成中的实用性与潜力。</p><p><strong>标签</strong>：#工作流生成 #长链推理 #强化学习 #自动化 #ComfyUI</p><hr><h2 id="magistral-首个开源高透明多语种推理模型" tabindex="-1"><a class="header-anchor" href="#magistral-首个开源高透明多语种推理模型"><span>Magistral：首个开源高透明多语种推理模型</span></a></h2><figure><img src="https://arxiv.org/html/2506.10910v1/extracted/6535757/images/magistral-vs-r1.png" alt="Magistral Comparison 图" tabindex="0" loading="lazy"><figcaption>Magistral Comparison 图</figcaption></figure><p><strong>概要</strong>：<strong>Magistral</strong> 是由 <strong>Mistral AI</strong> 发布的首个高透明度、多语种推理语言模型系列，分为 Medium 版和 Small（24B）版，采用自研纯强化学习（RL）训练流程，自底向上构建推理能力。该模型的核心亮点在于其透明可审计的逐步逻辑链（chain-of-thought）推理，覆盖专业领域问题解答，并且在多语言（包括英语、法语、西班牙语、中文等）中都保持一致的推理连贯性。Magistral 能以极高的速度处理复杂任务，在本地实现对话级 reasoning 实时响应，适合合规要求高、需要检验逻辑来源的场景。</p><p><strong>标签</strong>：#推理语言模型 #透明推理 #强化学习 #多语种 #可审计</p><hr><h2 id="animaker-多智能体动画叙事生成系统" tabindex="-1"><a class="header-anchor" href="#animaker-多智能体动画叙事生成系统"><span>AniMaker：多智能体动画叙事生成系统</span></a></h2><figure><img src="https://arxiv.org/html/2506.10540v1/extracted/6535659/figures/model.png" alt="AniMaker Overview 图" tabindex="0" loading="lazy"><figcaption>AniMaker Overview 图</figcaption></figure><p><strong>概要</strong>：<strong>AniMaker</strong> 是由 <strong>哈尔滨工业大学影视与多模态生成团队（HITsz-TMG）</strong> 提出的多智能体动画叙事生成系统，旨在从文本输入自动生成连贯的多场景动画视频。系统引入了导演（Director）代理生成分镜脚本、摄影（Photography）代理生成多个候选动画片段、评审（Reviewer）代理基于 AniEval 模型挑选最佳片段，以及后期（Post-Production）代理负责剪辑整合与配音。AniMaker 采用蒙特卡罗树搜索（MCTS-Gen）策略提升生成效率，并使用 AniEval 模型衡量剧情连贯性、动作完成度等叙事指标。实验显示，其生成的动画在 VBench 和 AniEval 等多项评价体系中均优于现有方法，同时在资源使用效率上也显著提升 。</p><p><strong>标签</strong>：#多智能体 #动画生成 #MCTS #叙事一致性 #视频生成框架</p><hr><h2 id="frame-guidance-无需训练的帧级视频扩散可控框架" tabindex="-1"><a class="header-anchor" href="#frame-guidance-无需训练的帧级视频扩散可控框架"><span>Frame Guidance：无需训练的帧级视频扩散可控框架</span></a></h2><p><img src="https://frame-guidance-video.github.io/figure/overview.jpg" alt="Frame Guidance Overview 图" loading="lazy"><strong>概要</strong>：<strong>Frame Guidance</strong> 是一个基于视频扩散模型的新型训练免疫控制方法，由 <strong>KAIST</strong>，<strong>Adobe Research</strong> 等提出。该方法通过帧级引导信息（如关键帧、风格图、草图或深度图）直接作用于扩散过程，无需对视频模型进行任何微调或训练。其核心在于对潜在隐变量进行“帧级优化”，显著降低显存开销，并实现全球一致的视频质量。该机制支持多样化控制任务，包括关键帧重定向、风格迁移、循环视频生成等，并可与任何现有视频生成模型兼容。实验证明，在保持高视频质量和时序连贯性的同时，Frame Guidance 能有效增强可控性，是一种高效、通用的多任务视频扩散指导手段。</p><p><strong>标签</strong>：#视频生成 #帧级控制 #扩散模型 #训练免疫 #多任务可控</p><hr><h3 id="参考链接" tabindex="-1"><a class="header-anchor" href="#参考链接"><span><strong>参考链接</strong></span></a></h3><ol><li><a href="https://github.com/openbmb/minicpm" target="_blank" rel="noopener noreferrer">MiniCPM4 Github 仓库</a></li><li><a href="https://arxiv.org/html/2506.07900v1" target="_blank" rel="noopener noreferrer">MiniCPM4 论文</a></li><li><a href="https://seed.bytedance.com/zh/seedance" target="_blank" rel="noopener noreferrer">Seedance 项目页面</a></li><li><a href="https://arxiv.org/html/2506.09113" target="_blank" rel="noopener noreferrer">Seedance 论文</a></li><li><a href="https://wgsxm.github.io/projects/partcrafter/" target="_blank" rel="noopener noreferrer">PartCrafter 项目页面</a></li><li><a href="https://github.com/wgsxm/PartCrafter" target="_blank" rel="noopener noreferrer">PartCrafter Github 仓库</a></li><li><a href="https://arxiv.org/html/2506.05573" target="_blank" rel="noopener noreferrer">PartCrafter 论文</a></li><li><a href="https://github.com/AIDC-AI/ComfyUI-Copilot" target="_blank" rel="noopener noreferrer">ComfyUI-Copilot Github 仓库</a></li><li><a href="https://arxiv.org/html/2506.09790" target="_blank" rel="noopener noreferrer">ComfyUI-R1 论文</a></li><li><a href="https://arxiv.org/html/2506.10910" target="_blank" rel="noopener noreferrer">Magistral 论文</a></li><li><a href="https://github.com/HITsz-TMG/Anim-Director" target="_blank" rel="noopener noreferrer">AniMaker Github 仓库</a></li><li><a href="https://arxiv.org/html/2506.10540" target="_blank" rel="noopener noreferrer">AniMaker 论文</a></li><li><a href="https://frame-guidance-video.github.io/" target="_blank" rel="noopener noreferrer">Frame Guidance 项目页面</a></li><li><a href="https://github.com/agwmon/frame-guidance" target="_blank" rel="noopener noreferrer">Frame Guidance Github 仓库</a></li><li><a href="https://arxiv.org/html/2506.07177" target="_blank" rel="noopener noreferrer">Frame Guidance 论文</a></li></ol>',44)]))}]]),o=JSON.parse('{"path":"/zh/posts/ai-weekly/042.html","title":"MiniCPM4发布高效端侧模型 | Seedance 1.0引领视频生成进阶 | ComfyUI‑R1打造智能工作流引擎【AI周报】","lang":"zh-CN","frontmatter":{"description":"MiniCPM4发布高效端侧模型 | Seedance 1.0引领视频生成进阶 | ComfyUI‑R1打造智能工作流引擎【AI周报】 封面源自C站作者Koal2封面源自C站作者Koal2 摘要 本周亮点：MiniCPM4发布超高效端侧模型；Seedance 1.0引领视频生成；ComfyUI-R1自动化工作流创建；PartCrafter革新3D生成；...","gitInclude":[],"head":[["meta",{"property":"og:url","content":"https://neverbiasu.github.io/zh/posts/ai-weekly/042.html"}],["meta",{"property":"og:site_name","content":"Nlog"}],["meta",{"property":"og:title","content":"MiniCPM4发布高效端侧模型 | Seedance 1.0引领视频生成进阶 | ComfyUI‑R1打造智能工作流引擎【AI周报】"}],["meta",{"property":"og:description","content":"MiniCPM4发布高效端侧模型 | Seedance 1.0引领视频生成进阶 | ComfyUI‑R1打造智能工作流引擎【AI周报】 封面源自C站作者Koal2封面源自C站作者Koal2 摘要 本周亮点：MiniCPM4发布超高效端侧模型；Seedance 1.0引领视频生成；ComfyUI-R1自动化工作流创建；PartCrafter革新3D生成；..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bc7e4820-82c0-4d95-a196-9627d8cb4578/original=true,quality=90/00003-2892726208.jpeg"}],["meta",{"property":"og:locale","content":"zh-CN"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"MiniCPM4发布高效端侧模型 | Seedance 1.0引领视频生成进阶 | ComfyUI‑R1打造智能工作流引擎【AI周报】\\",\\"image\\":[\\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bc7e4820-82c0-4d95-a196-9627d8cb4578/original=true,quality=90/00003-2892726208.jpeg\\",\\"https://arxiv.org/html/2506.07900v1/x1.png\\",\\"hhttps://arxiv.org/html/2506.09113v1/x4.png\\",\\"https://wgsxm.github.io/projects/partcrafter/static/images/teaser.png\\",\\"https://arxiv.org/html/2506.09790v1/x3.png\\",\\"https://arxiv.org/html/2506.10910v1/extracted/6535757/images/magistral-vs-r1.png\\",\\"https://arxiv.org/html/2506.10540v1/extracted/6535659/figures/model.png\\",\\"https://frame-guidance-video.github.io/figure/overview.jpg\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"neverbiasu\\",\\"url\\":\\"https://neverbiasu.github.io\\"}]}"]]},"headers":[{"level":2,"title":"摘要","slug":"摘要","link":"#摘要","children":[]},{"level":2,"title":"目录","slug":"目录","link":"#目录","children":[]},{"level":2,"title":"MiniCPM4：超高效端侧大模型系列","slug":"minicpm4-超高效端侧大模型系列","link":"#minicpm4-超高效端侧大模型系列","children":[]},{"level":2,"title":"Seedance 1.0：高性能文本和图像驱动视频生成模型","slug":"seedance-1-0-高性能文本和图像驱动视频生成模型","link":"#seedance-1-0-高性能文本和图像驱动视频生成模型","children":[]},{"level":2,"title":"PartCrafter：结构化 3D 网格生成的创新探索","slug":"partcrafter-结构化-3d-网格生成的创新探索","link":"#partcrafter-结构化-3d-网格生成的创新探索","children":[]},{"level":2,"title":"ComfyUI‑R1：首个大规模推理模型驱动的自动工作流生成系统","slug":"comfyui‐r1-首个大规模推理模型驱动的自动工作流生成系统","link":"#comfyui‐r1-首个大规模推理模型驱动的自动工作流生成系统","children":[]},{"level":2,"title":"Magistral：首个开源高透明多语种推理模型","slug":"magistral-首个开源高透明多语种推理模型","link":"#magistral-首个开源高透明多语种推理模型","children":[]},{"level":2,"title":"AniMaker：多智能体动画叙事生成系统","slug":"animaker-多智能体动画叙事生成系统","link":"#animaker-多智能体动画叙事生成系统","children":[]},{"level":2,"title":"Frame Guidance：无需训练的帧级视频扩散可控框架","slug":"frame-guidance-无需训练的帧级视频扩散可控框架","link":"#frame-guidance-无需训练的帧级视频扩散可控框架","children":[{"level":3,"title":"参考链接","slug":"参考链接","link":"#参考链接","children":[]}]}],"readingTime":{"minutes":7.51,"words":2252},"filePathRelative":"zh/posts/ai-weekly/042.md","excerpt":"\\n<figure><img src=\\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bc7e4820-82c0-4d95-a196-9627d8cb4578/original=true,quality=90/00003-2892726208.jpeg\\" alt=\\"封面源自C站作者Koal2\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>封面源自C站作者Koal2</figcaption></figure>\\n<h2>摘要</h2>\\n<p>本周亮点：MiniCPM4发布超高效端侧模型；Seedance 1.0引领视频生成；ComfyUI-R1自动化工作流创建；PartCrafter革新3D生成；Magistral推出透明多语言推理系统；AniMaker实现AI动画制作。</p>","autoDesc":true}')}}]);