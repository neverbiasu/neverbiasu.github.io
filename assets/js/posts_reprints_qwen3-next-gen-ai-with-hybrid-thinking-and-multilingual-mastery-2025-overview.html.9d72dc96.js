"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[8467],{66262:(i,s)=>{s.A=(i,s)=>{const e=i.__vccOpts||i;for(const[i,n]of s)e[i]=n;return e}},99194:(i,s,e)=>{e.r(s),e.d(s,{comp:()=>t,data:()=>l});var n=e(20641);const a={},t=(0,e(66262).A)(a,[["render",function(i,s){return(0,n.uX)(),(0,n.CE)("div",null,s[0]||(s[0]=[(0,n.Fv)('<h1 id="qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview" tabindex="-1"><a class="header-anchor" href="#qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview"><span>Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 Overview</span></a></h1><figure><img src="https://altctrlai.com/content/images/size/w2000/2025/04/834B968B-9CED-4EF4-B81F-845F8241AC0A.webp" alt="Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 Overview" tabindex="0" loading="lazy"><figcaption>Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 Overview</figcaption></figure><p>Qwen3 represents a significant advancement in artificial intelligence, delivering improved reasoning capabilities, multilingual support, and enhanced performance across various benchmarks. This latest addition to the Qwen family of large language models introduces innovative features and architectural improvements that position it as a competitive alternative to leading models from major AI labs. The following comprehensive analysis explores Qwen3&#39;s capabilities, technical specifications, and practical applications.</p><h2 id="introduction-to-qwen3" tabindex="-1"><a class="header-anchor" href="#introduction-to-qwen3"><span>Introduction to Qwen3</span></a></h2><p>Qwen3, released by Alibaba Group in April 2025, marks the newest generation in the Qwen family of large language models. The flagship model, Qwen3-235B-A22B, demonstrates competitive performance against industry leaders such as DeepSeek-R1, o1, o3-mini, Grok-3, and Gemini-2.5-Pro across various benchmarks, including coding, mathematics, and general capabilities. The smaller MoE (Mixture-of-Experts) model, Qwen3-30B-A3B, outperforms QwQ-32B despite using only one-tenth of the activated parameters, while even the compact Qwen3-4B model rivals the capabilities of the significantly larger Qwen2.5-72B-Instruct.</p><p>This release includes both MoE and dense models, all available under open-weight licenses. The two MoE models-Qwen3-235B-A22B and Qwen3-30B-A3B-are complemented by six dense models: Qwen3-32B, Qwen3-14B, Qwen3-8B, Qwen3-4B, Qwen3-1.7B, and Qwen3-0.6B, all licensed under Apache 2.0.</p><h2 id="the-qwen3-model-family" tabindex="-1"><a class="header-anchor" href="#the-qwen3-model-family"><span>The Qwen3 Model Family</span></a></h2><h3 id="moe-models" tabindex="-1"><a class="header-anchor" href="#moe-models"><span>MoE Models</span></a></h3><ol><li><strong>Qwen3-235B-A22B</strong>: The flagship model featuring 235 billion total parameters with 22 billion activated parameters. It consists of 94 layers, 64 query attention heads, 4 key-value attention heads, and 128 experts with 8 activated. The model supports a native context length of 32,768 tokens, expandable to 131,072 tokens with YaRN technology.</li><li><strong>Qwen3-30B-A3B</strong>: A smaller MoE model with 30.5 billion total parameters and 3.3 billion activated parameters. It has 48 layers, 32 query attention heads, 4 key-value attention heads, and also features 128 experts with 8 activated. Like its larger counterpart, it supports extensive context lengths.</li></ol><h3 id="dense-models" tabindex="-1"><a class="header-anchor" href="#dense-models"><span>Dense Models</span></a></h3><p>Qwen3 also offers six dense models of varying sizes:</p><table><thead><tr><th>Model</th><th>Layers</th><th>Heads (Q / KV)</th><th>Context Length</th></tr></thead><tbody><tr><td>Qwen3-0.6B</td><td>28</td><td>16 / 8</td><td>32K</td></tr><tr><td>Qwen3-1.7B</td><td>28</td><td>16 / 8</td><td>32K</td></tr><tr><td>Qwen3-4B</td><td>36</td><td>32 / 8</td><td>32K</td></tr><tr><td>Qwen3-8B</td><td>36</td><td>32 / 8</td><td>128K</td></tr><tr><td>Qwen3-14B</td><td>40</td><td>40 / 8</td><td>128K</td></tr><tr><td>Qwen3-32B</td><td>64</td><td>64 / 8</td><td>128K</td></tr></tbody></table><p>These models are designed to accommodate different computational requirements and use cases, from resource-constrained environments to high-performance applications.</p><h2 id="key-innovations-and-features" tabindex="-1"><a class="header-anchor" href="#key-innovations-and-features"><span>Key Innovations and Features</span></a></h2><h3 id="hybrid-thinking-modes" tabindex="-1"><a class="header-anchor" href="#hybrid-thinking-modes"><span>Hybrid Thinking Modes</span></a></h3><p>One of Qwen3&#39;s most distinctive features is its support for dual thinking modes within a single model architecture:</p><ul><li><strong>Thinking Mode</strong>: Designed for complex tasks requiring logical reasoning, mathematical computation, or coding challenges. In this mode, the model takes time to reason step by step before delivering an answer, similar to how humans approach complex problems.</li><li><strong>Non-Thinking Mode</strong>: Optimized for providing quick responses to more straightforward queries, maintaining efficiency for general-purpose dialogue.</li></ul><p>This innovative approach allows users to control the model&#39;s reasoning depth based on task complexity. For challenging problems, the thinking mode enables extended reasoning, while simpler questions can be addressed directly without unnecessary computational overhead. The implementation includes a soft switching mechanism, enabling users to dynamically control behavior by adding <code>/think</code> and <code>/no_think</code> tags to prompts or system messages.</p><h3 id="expansive-multilingual-capabilities" tabindex="-1"><a class="header-anchor" href="#expansive-multilingual-capabilities"><span>Expansive Multilingual Capabilities</span></a></h3><p>Qwen3 supports an impressive 119 languages and dialects, tripling the coverage of its predecessor, Qwen2.5. This extensive linguistic range spans multiple language families:</p><ul><li>Indo-European (English, French, Spanish, Russian, Hindi, etc.)</li><li>Sino-Tibetan (Chinese variants, Burmese)</li><li>Afro-Asiatic (Arabic variants, Hebrew)</li><li>Austronesian (Indonesian, Malay, Tagalog)</li><li>Dravidian (Tamil, Telugu, Kannada)</li><li>Turkic (Turkish, Uzbek)</li><li>Tai-Kadai, Uralic, Austroasiatic, and others</li></ul><p>This comprehensive multilingual support positions Qwen3 for global adoption, particularly in regions with linguistic diversity.</p><h3 id="advanced-agentic-capabilities" tabindex="-1"><a class="header-anchor" href="#advanced-agentic-capabilities"><span>Advanced Agentic Capabilities</span></a></h3><p>Qwen3 has been optimized for coding and agentic operations, with enhanced support for Model-Conditional Prompting (MCP). These improvements enable more sophisticated applications, such as autonomous agents and precise developer tooling. The models excel at tool integration in both thinking and non-thinking modes, achieving leading performance among open-source models in complex agent-based tasks.</p><h2 id="technical-architecture-and-training" tabindex="-1"><a class="header-anchor" href="#technical-architecture-and-training"><span>Technical Architecture and Training</span></a></h2><h3 id="pre-training-process" tabindex="-1"><a class="header-anchor" href="#pre-training-process"><span>Pre-training Process</span></a></h3><p>The pre-training dataset for Qwen3 is substantially larger than its predecessor&#39;s, comprising approximately 36 trillion tokens covering 119 languages and dialects-nearly twice the 18 trillion tokens used for Qwen2.5. The data collection process was rigorous:</p><ol><li>Web-sourced content was supplemented with text extracted from PDF-like documents</li><li>Qwen2.5-VL was employed to extract text from documents</li><li>Qwen2.5 was used to enhance the quality of extracted content</li><li>Qwen2.5-Math and Qwen2.5-Coder generated synthetic data to augment math and code content</li></ol><p>The pre-training followed a three-stage process:</p><ol><li><strong>Stage 1 (S1)</strong>: Training on over 30 trillion tokens with a context length of 4K tokens, establishing foundational language skills and general knowledge</li><li><strong>Stage 2 (S2)</strong>: Training on an additional 5 trillion tokens with an increased proportion of knowledge-intensive data (STEM, coding, reasoning)</li><li><strong>Stage 3 (S3)</strong>: Extension of context length to 32K tokens using high-quality long-context data</li></ol><p>This extensive training regime has resulted in Qwen3 dense base models matching or exceeding the performance of larger Qwen2.5 models. For example, Qwen3-1.7B/4B/8B/14B/32B-Base perform comparably to Qwen2.5-3B/7B/14B/32B/72B-Base, respectively, while excelling in specialized domains like STEM, coding, and reasoning.</p><h3 id="post-training-methodology" tabindex="-1"><a class="header-anchor" href="#post-training-methodology"><span>Post-training Methodology</span></a></h3><p>To develop the hybrid model capable of both detailed reasoning and rapid responses, a four-stage training pipeline was implemented:</p><ol><li><strong>Long chain-of-thought (CoT) cold start</strong>: Fine-tuning on diverse CoT data spanning mathematics, coding, logical reasoning, and STEM problems</li><li><strong>Reasoning-based reinforcement learning (RL)</strong>: Scaling computational resources for RL with rule-based rewards to enhance exploration and exploitation</li><li><strong>Thinking mode fusion</strong>: Integration of non-thinking capabilities into the thinking model through fine-tuning on combined data</li><li><strong>General RL</strong>: Application of reinforcement learning across more than 20 general-domain tasks to strengthen capabilities and correct undesired behaviors</li></ol><h2 id="performance-and-benchmark-results" tabindex="-1"><a class="header-anchor" href="#performance-and-benchmark-results"><span>Performance and Benchmark Results</span></a></h2><p>According to benchmark evaluations, Qwen3 models demonstrate impressive performance across various metrics:</p><figure><img src="https://altctrlai.com/content/images/2025/04/IMG_1140.jpeg" alt="Image 4" tabindex="0" loading="lazy"><figcaption>Image 4</figcaption></figure><figure><img src="https://altctrlai.com/content/images/2025/04/IMG_1141.jpeg" alt="Image 5" tabindex="0" loading="lazy"><figcaption>Image 5</figcaption></figure><p>These benchmarks indicate that Qwen3 models are competitive with or surpass industry-leading alternatives in several key areas. The flagship Qwen3-235B-A22B model consistently ranks among the top performers, particularly in challenging reasoning tasks.</p><p>When comparing the older Qwen models with competitors, there are noticeable improvements in benchmark performance. Qwen3-30B-A3B significantly outperforms Qwen-30B-A3B (shown as Qwen3-30B-A3B in the image), and even the smaller Qwen3 models demonstrate enhanced capabilities compared to their predecessors.</p><h2 id="development-and-practical-applications" tabindex="-1"><a class="header-anchor" href="#development-and-practical-applications"><span>Development and Practical Applications</span></a></h2><h3 id="using-qwen3-models" tabindex="-1"><a class="header-anchor" href="#using-qwen3-models"><span>Using Qwen3 Models</span></a></h3><p>Qwen3 models are accessible through multiple platforms, including Hugging Face, ModelScope, and Kaggle. For deployment, SGLang and vLLM are recommended frameworks, while local usage is supported through tools such as Ollama, LMStudio, MLX, llama.cpp, and KTransformers.</p><p>A basic example of using Qwen3-30B-A3B with Hugging Face transformers:</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> modelscope </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> AutoModelForCausalLM, AutoTokenizer</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">model_name </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;Qwen/Qwen3-30B-A3B&quot;</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Load the tokenizer and model</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">tokenizer </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> AutoTokenizer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(model_name)</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">model </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> AutoModelForCausalLM.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    model_name,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">    torch_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;auto&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">    device_map</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;auto&quot;</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Prepare model input</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">prompt </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;Give me a short introduction to large language model.&quot;</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">messages </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    {</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;role&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;user&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;content&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: prompt}</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">text </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tokenizer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">apply_chat_template</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    messages,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">    tokenize</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">False</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">    add_generation_prompt</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">    enable_thinking</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # Toggle between thinking and non-thinking modes</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">model_inputs </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> tokenizer</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">([text], </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">return_tensors</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;pt&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">).</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">to</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(model.device)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Generate text</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">generated_ids </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> model.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">generate</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    **model_inputs,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">    max_new_tokens</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">32768</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">output_ids </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> generated_ids[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">][</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">len</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(model_inputs.input_ids[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]):].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">tolist</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Parse thinking content</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">try</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # Find &lt;/think&gt; token (151668)</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    index </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> len</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(output_ids) </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> output_ids[::</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">index</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">151668</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">except</span><span style="--shiki-light:#0184BC;--shiki-dark:#ABB2BF;"> ValueError</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    index </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 0</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">thinking_content </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tokenizer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">decode</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(output_ids[:index], </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">skip_special_tokens</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">).</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">strip</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\n</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">content </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tokenizer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">decode</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(output_ids[index:], </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">skip_special_tokens</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">).</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">strip</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\n</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;thinking content:&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, thinking_content)</span></span>\n<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;content:&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, content)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>For deployment using SGLang (version 0.4.6.post1 or later) to create an OpenAI-compatible API endpoint:</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>python -m sglang.launch_server --model-path Qwen/Qwen3-30B-A3B --reasoning-parser qwen3</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>For deployment using vLLM (version 0.8.4 or later):</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>vllm serve Qwen/Qwen3-30B-A3B --enable-reasoning --reasoning-parser deepseek_r1</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>For local development using Ollama:</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>ollama run qwen3:30b-a3b</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="agentic-capabilities" tabindex="-1"><a class="header-anchor" href="#agentic-capabilities"><span>Agentic Capabilities</span></a></h3><p>Qwen3 excels in tool-calling capabilities and is compatible with Qwen-Agent, which encapsulates tool-calling templates and parsers to simplify implementation. An example of agent implementation:</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> qwen_agent.agents </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> Assistant</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Define LLM</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">llm_cfg </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> {</span></span>\n<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &#39;model&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;Qwen3-30B-A3B&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>\n<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &#39;model_server&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;http://localhost:8000/v1&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># api_base</span></span>\n<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &#39;api_key&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;EMPTY&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">}</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Define Tools</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">tools </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    {</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;mcpServers&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: {  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># MCP configuration</span></span>\n<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &#39;time&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: {</span></span>\n<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">            &#39;command&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;uvx&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>\n<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">            &#39;args&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: [</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;mcp-server-time&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;--local-timezone=Asia/Shanghai&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        },</span></span>\n<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;fetch&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: {</span></span>\n<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">            &quot;command&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;uvx&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>\n<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">            &quot;args&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: [</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;mcp-server-fetch&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        }</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    }},</span></span>\n<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &#39;code_interpreter&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Built-in tools</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Create Agent</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bot </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> Assistant</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">llm</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">llm_cfg, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">function_list</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">tools)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Generate responses</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">messages </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [{</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;role&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;user&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;content&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;https://qwenlm.github.io/blog/ Introduce the latest developments of Qwen&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">}]</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> responses </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> bot.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">run</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">messages</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">messages):</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    pass</span></span>\n<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(responses)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>This flexibility in implementation enables diverse applications across various domains, from conversational agents to specialized tools for specific professional contexts.</p><h2 id="future-development-directions" tabindex="-1"><a class="header-anchor" href="#future-development-directions"><span>Future Development Directions</span></a></h2><p>Qwen3 represents a significant milestone in the journey toward Artificial General Intelligence (AGI) and Artificial Superintelligence (ASI). Looking ahead, the development team aims to enhance models across multiple dimensions:</p><ol><li>Refining model architectures and training methodologies</li><li>Scaling data and increasing model size</li><li>Extending context length capabilities</li><li>Broadening modality support</li><li>Advancing reinforcement learning with environmental feedback for long-horizon reasoning</li></ol><p>The team envisions a transition from an era focused on training models to one centered on training agents. Future iterations are expected to bring meaningful advancements to both professional and personal applications.</p><h2 id="conclusion" tabindex="-1"><a class="header-anchor" href="#conclusion"><span>Conclusion</span></a></h2><p>Qwen3 represents a significant advancement in large language model technology, offering competitive performance against industry leaders while providing unique capabilities like hybrid thinking modes and extensive multilingual support. The open-weighted approach, with models ranging from compact 0.6B parameter versions to the powerful 235B-A22B flagship, makes advanced AI accessible across various computational environments and use cases.</p><p>The model&#39;s architectural innovations-particularly its mixture-of-experts design and ability to dynamically switch between thinking and non-thinking modes-provide both efficiency and flexibility for diverse applications. As AI continues to evolve toward more sophisticated reasoning and agency, Qwen3 stands as an important contribution to the field, balancing performance, accessibility, and practical utility.</p><p>With its strong performance on key benchmarks and comprehensive development ecosystem, Qwen3 offers researchers, developers, and organizations powerful tools to build innovative AI solutions. The ongoing commitment to enhancing capabilities across multiple dimensions suggests that future iterations will continue to push the boundaries of what&#39;s possible in artificial intelligence.</p>',63)]))}]]),l=JSON.parse('{"path":"/posts/reprints/qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html","title":"Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 Overview","lang":"en-US","frontmatter":{"title":"Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 Overview","icon":"fa-solid:robot","cover":"https://altctrlai.com/content/images/size/w2000/2025/04/834B968B-9CED-4EF4-B81F-845F8241AC0A.webp","date":"2025-04-29T00:00:00.000Z","category":["reprint"],"tag":["Qwen","Qwen3","Alibaba AI research","Alibaba AI","large language models","LLMs","LLM benchmarks","Multilingual AI","Multimodal AI","AI reasoning","MCP"],"sticky":false,"star":false,"article":true,"footer":"Reprinted from AltCtrlAI","copyright":"reprint","author":"Jainil Prajapati","description":"Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 Overview Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 OverviewQwen3: Next-Gen ...","gitInclude":[],"head":[["link",{"rel":"alternate","hreflang":"zh-cn","href":"https://neverbiasu.github.io/zh/posts/reprints/qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html"}],["meta",{"property":"og:url","content":"https://neverbiasu.github.io/posts/reprints/qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html"}],["meta",{"property":"og:site_name","content":"Nlog"}],["meta",{"property":"og:title","content":"Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 Overview"}],["meta",{"property":"og:description","content":"Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 Overview Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 OverviewQwen3: Next-Gen ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://altctrlai.com/content/images/size/w2000/2025/04/834B968B-9CED-4EF4-B81F-845F8241AC0A.webp"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:locale:alternate","content":"zh-CN"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:src","content":"https://altctrlai.com/content/images/size/w2000/2025/04/834B968B-9CED-4EF4-B81F-845F8241AC0A.webp"}],["meta",{"name":"twitter:image:alt","content":"Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 Overview"}],["meta",{"property":"article:author","content":"Jainil Prajapati"}],["meta",{"property":"article:tag","content":"Qwen"}],["meta",{"property":"article:tag","content":"Qwen3"}],["meta",{"property":"article:tag","content":"Alibaba AI research"}],["meta",{"property":"article:tag","content":"Alibaba AI"}],["meta",{"property":"article:tag","content":"large language models"}],["meta",{"property":"article:tag","content":"LLMs"}],["meta",{"property":"article:tag","content":"LLM benchmarks"}],["meta",{"property":"article:tag","content":"Multilingual AI"}],["meta",{"property":"article:tag","content":"Multimodal AI"}],["meta",{"property":"article:tag","content":"AI reasoning"}],["meta",{"property":"article:tag","content":"MCP"}],["meta",{"property":"article:published_time","content":"2025-04-29T00:00:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 Overview\\",\\"image\\":[\\"https://altctrlai.com/content/images/size/w2000/2025/04/834B968B-9CED-4EF4-B81F-845F8241AC0A.webp\\",\\"https://altctrlai.com/content/images/2025/04/IMG_1140.jpeg\\",\\"https://altctrlai.com/content/images/2025/04/IMG_1141.jpeg\\"],\\"datePublished\\":\\"2025-04-29T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Jainil Prajapati\\"}]}"]]},"headers":[{"level":2,"title":"Introduction to Qwen3","slug":"introduction-to-qwen3","link":"#introduction-to-qwen3","children":[]},{"level":2,"title":"The Qwen3 Model Family","slug":"the-qwen3-model-family","link":"#the-qwen3-model-family","children":[{"level":3,"title":"MoE Models","slug":"moe-models","link":"#moe-models","children":[]},{"level":3,"title":"Dense Models","slug":"dense-models","link":"#dense-models","children":[]}]},{"level":2,"title":"Key Innovations and Features","slug":"key-innovations-and-features","link":"#key-innovations-and-features","children":[{"level":3,"title":"Hybrid Thinking Modes","slug":"hybrid-thinking-modes","link":"#hybrid-thinking-modes","children":[]},{"level":3,"title":"Expansive Multilingual Capabilities","slug":"expansive-multilingual-capabilities","link":"#expansive-multilingual-capabilities","children":[]},{"level":3,"title":"Advanced Agentic Capabilities","slug":"advanced-agentic-capabilities","link":"#advanced-agentic-capabilities","children":[]}]},{"level":2,"title":"Technical Architecture and Training","slug":"technical-architecture-and-training","link":"#technical-architecture-and-training","children":[{"level":3,"title":"Pre-training Process","slug":"pre-training-process","link":"#pre-training-process","children":[]},{"level":3,"title":"Post-training Methodology","slug":"post-training-methodology","link":"#post-training-methodology","children":[]}]},{"level":2,"title":"Performance and Benchmark Results","slug":"performance-and-benchmark-results","link":"#performance-and-benchmark-results","children":[]},{"level":2,"title":"Development and Practical Applications","slug":"development-and-practical-applications","link":"#development-and-practical-applications","children":[{"level":3,"title":"Using Qwen3 Models","slug":"using-qwen3-models","link":"#using-qwen3-models","children":[]},{"level":3,"title":"Agentic Capabilities","slug":"agentic-capabilities","link":"#agentic-capabilities","children":[]}]},{"level":2,"title":"Future Development Directions","slug":"future-development-directions","link":"#future-development-directions","children":[]},{"level":2,"title":"Conclusion","slug":"conclusion","link":"#conclusion","children":[]}],"readingTime":{"minutes":6.03,"words":1808},"filePathRelative":"posts/reprints/qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.md","localizedDate":"April 29, 2025","excerpt":"\\n<figure><img src=\\"https://altctrlai.com/content/images/size/w2000/2025/04/834B968B-9CED-4EF4-B81F-845F8241AC0A.webp\\" alt=\\"Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 Overview\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 Overview</figcaption></figure>","autoDesc":true}')}}]);