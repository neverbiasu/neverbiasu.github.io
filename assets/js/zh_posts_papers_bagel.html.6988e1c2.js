"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[5346],{6262:(e,a)=>{a.A=(e,a)=>{const i=e.__vccOpts||e;for(const[e,r]of a)i[e]=r;return i}},7456:(e,a,i)=>{i.r(a),i.d(a,{comp:()=>s,data:()=>n});var r=i(641);const t={},s=(0,i(6262).A)(t,[["render",function(e,a){return(0,r.uX)(),(0,r.CE)("div",null,a[0]||(a[0]=[(0,r.Fv)('<h1 id="【论文精读】bagel-统一多模态预训练中的涌现属性-emerging-properties-in-unified-multimodal-pretraining" tabindex="-1"><a class="header-anchor" href="#【论文精读】bagel-统一多模态预训练中的涌现属性-emerging-properties-in-unified-multimodal-pretraining"><span>【论文精读】BAGEL: 统一多模态预训练中的涌现属性 (Emerging Properties in Unified Multimodal Pretraining)</span></a></h1><figure><img src="https://paper-assets.alphaxiv.org/figures/2505.14683/img-0.jpeg" alt="BAGEL 的多模态能力展示" tabindex="0" loading="lazy"><figcaption>BAGEL 的多模态能力展示</figcaption></figure><h2 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span>摘要</span></a></h2><p>BAGEL 是由 ByteDance Seed 等机构开发的开源统一多模态基础模型，拥有 7B 活跃参数（总共 14B 参数）。通过在万亿级别交错多模态数据上进行预训练，展现出复杂的推理能力。BAGEL 采用 Transformer 专家混合（MoT）架构，在单个解码器模型中统一了理解和生成能力。在标准基准测试中显著优于 Qwen2.5-VL 和 InternVL-2.5 等顶尖开源模型，并展示了自由格式图像操作、未来帧预测、3D 操作和世界导航等前沿能力。</p><hr><h2 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span>目录</span></a></h2><ol><li><a href="#%E8%83%8C%E6%99%AF%E4%B8%8E%E7%A0%94%E7%A9%B6%E7%9B%AE%E6%A0%87">背景与研究目标</a></li><li><a href="#%E6%96%B9%E6%B3%95%E4%B8%8E%E5%88%9B%E6%96%B0%E7%82%B9">方法与创新点</a></li><li><a href="#%E5%AE%9E%E9%AA%8C%E4%B8%8E%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90">实验与结果分析</a></li><li><a href="#%E6%A8%A1%E5%9E%8B%E5%90%AF%E5%8F%91%E4%B8%8E%E6%96%B9%E6%B3%95%E5%BB%B6%E4%BC%B8">模型启发与方法延伸</a></li><li><a href="#%E7%BB%93%E8%AE%BA%E4%B8%8E%E6%9C%AA%E6%9D%A5%E5%B1%95%E6%9C%9B">结论与未来展望</a></li></ol><hr><h2 id="背景与研究目标" tabindex="-1"><a class="header-anchor" href="#背景与研究目标"><span>背景与研究目标</span></a></h2><h3 id="多模态ai发展现状" tabindex="-1"><a class="header-anchor" href="#多模态ai发展现状"><span>多模态AI发展现状</span></a></h3><p>多模态人工智能系统近年来取得显著进展。GPT-4o 和 Gemini 2.0 等先进的专有模型已展示出强大的多模态推理能力，但开源模型在性能上仍存在较大差距。</p><p>主要原因在于数据质量差异、架构局限和训练规模不足。开源模型多基于标准图文配对数据训练，缺乏复杂的多模态交错数据，传统方法往往分离理解和生成功能。</p><h3 id="核心研究问题" tabindex="-1"><a class="header-anchor" href="#核心研究问题"><span>核心研究问题</span></a></h3><p>本研究引入 BAGEL 模型，旨在解决以下关键问题：</p><ol><li><strong>如何弥合开源与专有模型的性能差距？</strong></li><li><strong>大规模多模态交错数据如何促进涌现能力的产生？</strong></li><li><strong>如何在单一架构中高效统一理解和生成任务？</strong></li></ol><h3 id="主要贡献" tabindex="-1"><a class="header-anchor" href="#主要贡献"><span>主要贡献</span></a></h3><p>BAGEL 模型的主要贡献包括：统一模型设计，首次在开源模型中实现多模态理解与生成的高度统一；涌现能力发现，系统研究并验证了大规模训练中的能力涌现现象；MoT 架构创新，提出 Transformer 专家混合架构；开源生态贡献，完整开放模型权重、训练细节和数据构建流程。</p><hr><h2 id="方法与创新点" tabindex="-1"><a class="header-anchor" href="#方法与创新点"><span>方法与创新点</span></a></h2><h3 id="mot-transformer-专家混合-架构" tabindex="-1"><a class="header-anchor" href="#mot-transformer-专家混合-架构"><span>MoT（Transformer 专家混合）架构</span></a></h3><figure><img src="https://paper-assets.alphaxiv.org/figures/2505.14683/img-1.jpeg" alt="BAGEL 的架构图：Transformer 专家混合（MoT）架构，显示了用于理解和生成的两个并行 FFN 路径，以及共享的多模态自注意力" tabindex="0" loading="lazy"><figcaption>BAGEL 的架构图：Transformer 专家混合（MoT）架构，显示了用于理解和生成的两个并行 FFN 路径，以及共享的多模态自注意力</figcaption></figure><p>BAGEL 的核心创新在于 <strong>Transformer 专家混合（MoT）</strong> 架构。该设计通过共享自注意力层实现多模态融合，同时使用两个专门的前馈网络（FFN）分别处理理解和生成任务。</p><figure><img src="https://paper-assets.alphaxiv.org/figures/2505.14683/img-2.jpeg" alt="架构对比图：Dense、MoE 和 MoT 架构之间的交叉熵（CE）和均方误差（MSE）损失比较，显示了 MoT 的卓越性能" tabindex="0" loading="lazy"><figcaption>架构对比图：Dense、MoE 和 MoT 架构之间的交叉熵（CE）和均方误差（MSE）损失比较，显示了 MoT 的卓越性能</figcaption></figure><p><strong>关键优势</strong>：相比传统密集模型具有更高参数效率，相比标准 MoE 在多模态任务上表现更优，在理解和生成任务上保持一致的高性能。</p><h3 id="多模态交错数据策略" tabindex="-1"><a class="header-anchor" href="#多模态交错数据策略"><span>多模态交错数据策略</span></a></h3><figure><img src="https://paper-assets.alphaxiv.org/figures/2505.14683/img-3.jpeg" alt="数据准备流程图：展示了原始视频和网络内容如何被处理成交错的多模态训练数据" tabindex="0" loading="lazy"><figcaption>数据准备流程图：展示了原始视频和网络内容如何被处理成交错的多模态训练数据</figcaption></figure><p>BAGEL 使用精心策划的万亿级别交错多模态数据进行训练，包含文本、图像、视频和网络内容。这种交错结构模拟真实世界的多模态交互，促进模型发展认知推理能力。</p><h3 id="多阶段训练流程" tabindex="-1"><a class="header-anchor" href="#多阶段训练流程"><span>多阶段训练流程</span></a></h3><p><strong>四个核心阶段</strong>：</p><ol><li><strong>跨模态对齐</strong>：建立不同模态间的基础对应关系</li><li><strong>大规模预训练</strong>：在万亿级别交错数据上学习通用表示</li><li><strong>持续训练</strong>：使用高分辨率数据进行精细化训练</li><li><strong>监督微调</strong>：使用高质量指令数据对齐人类偏好</li></ol><figure><img src="https://paper-assets.alphaxiv.org/figures/2505.14683/img-5.jpeg" alt="学习率影响图：不同学习率对交叉熵和 MSE 损失的影响，展示了正确选择学习率的重要性" tabindex="0" loading="lazy"><figcaption>学习率影响图：不同学习率对交叉熵和 MSE 损失的影响，展示了正确选择学习率的重要性</figcaption></figure><p><strong>关键技术</strong>：采用混合精度训练、梯度检查点、高效数据加载和内存优化注意力机制，并使用广义因果注意力处理交错的多模态生成样本。</p><hr><h2 id="实验与结果分析" tabindex="-1"><a class="header-anchor" href="#实验与结果分析"><span>实验与结果分析</span></a></h2><h3 id="涌现能力研究" tabindex="-1"><a class="header-anchor" href="#涌现能力研究"><span>涌现能力研究</span></a></h3><p>研究中最引人注目的发现是，随着训练数据的增加和训练的深入，模型会涌现出新的、更高级的能力。这些能力并非随训练线性平滑提升，而是在达到特定的训练数据量阈值后突然显现，表现为性能的显著跃迁。</p><h4 id="_1-基础多模态理解能力" tabindex="-1"><a class="header-anchor" href="#_1-基础多模态理解能力"><span>1. 基础多模态理解能力</span></a></h4><p><strong>涌现阈值</strong>：约在处理 0.18T tokens 数据后出现</p><figure><img src="https://paper-assets.alphaxiv.org/figures/2505.14683/img-6.jpeg" alt="理解能力涌现图：理解能力的涌现，在大约 0.18T tokens 处有显著跃升" tabindex="0" loading="lazy"><figcaption>理解能力涌现图：理解能力的涌现，在大约 0.18T tokens 处有显著跃升</figcaption></figure><p>这是模型获得的第一个重要涌现能力，标志着模型开始真正理解不同模态间的关联关系。</p><h4 id="_2-高保真图像生成能力" tabindex="-1"><a class="header-anchor" href="#_2-高保真图像生成能力"><span>2. 高保真图像生成能力</span></a></h4><p><strong>涌现阈值</strong>：约在处理 0.68T tokens 数据后出现</p><figure><img src="https://paper-assets.alphaxiv.org/figures/2505.14683/img-8.jpeg" alt="生成能力涌现图：生成能力的涌现，在大约 0.68T tokens 处有显著阈值" tabindex="0" loading="lazy"><figcaption>生成能力涌现图：生成能力的涌现，在大约 0.68T tokens 处有显著阈值</figcaption></figure><p>此阶段模型开始具备高质量的图像生成能力，能够根据文本描述创建具有较高保真度的图像。</p><h4 id="_3-图像编辑能力" tabindex="-1"><a class="header-anchor" href="#_3-图像编辑能力"><span>3. 图像编辑能力</span></a></h4><p><strong>涌现阈值</strong>：约在处理 2.64T tokens 数据后出现</p><figure><img src="https://paper-assets.alphaxiv.org/figures/2505.14683/img-7.jpeg" alt="图像编辑能力涌现图：图像编辑能力的涌现，阈值大约在 2.64T tokens" tabindex="0" loading="lazy"><figcaption>图像编辑能力涌现图：图像编辑能力的涌现，阈值大约在 2.64T tokens</figcaption></figure><p>模型开始获得对现有图像进行智能编辑的能力，包括对象删除、风格迁移等操作。</p><h4 id="_4-复杂推理与智能编辑能力" tabindex="-1"><a class="header-anchor" href="#_4-复杂推理与智能编辑能力"><span>4. 复杂推理与智能编辑能力</span></a></h4><p><strong>涌现阈值</strong>：约在处理 3.61T tokens 数据后出现</p><figure><img src="https://paper-assets.alphaxiv.org/figures/2505.14683/img-9.jpeg" alt="智能编辑能力涌现图：智能编辑能力的涌现，需要大约 3.61T tokens 的训练" tabindex="0" loading="lazy"><figcaption>智能编辑能力涌现图：智能编辑能力的涌现，需要大约 3.61T tokens 的训练</figcaption></figure><p>最高级的涌现能力，包含复杂的推理过程和精细的智能编辑操作。</p><h3 id="性能基准测试" tabindex="-1"><a class="header-anchor" href="#性能基准测试"><span>性能基准测试</span></a></h3><h4 id="_1-文本到图像生成效果" tabindex="-1"><a class="header-anchor" href="#_1-文本到图像生成效果"><span>1. 文本到图像生成效果</span></a></h4><figure><img src="https://paper-assets.alphaxiv.org/figures/2505.14683/img-10.jpeg" alt="文本到图像的进展图：文本到图像生成质量从 1.5T 到 4.5T tokens 的训练进展，显示了图像保真度和对提示的遵守程度的明显提高" tabindex="0" loading="lazy"><figcaption>文本到图像的进展图：文本到图像生成质量从 1.5T 到 4.5T tokens 的训练进展，显示了图像保真度和对提示的遵守程度的明显提高</figcaption></figure><figure><img src="https://paper-assets.alphaxiv.org/figures/2505.14683/img-12.jpeg" alt="生成示例图：BAGEL 在不同宽高比和样式规范下的文本到图像生成能力示例" tabindex="0" loading="lazy"><figcaption>生成示例图：BAGEL 在不同宽高比和样式规范下的文本到图像生成能力示例</figcaption></figure><p>随着训练的进行（从1.5T到4.5T tokens），生成图像的质量、保真度以及对提示的遵循度均有显著提高。BAGEL 在文本到图像生成质量上可与 SD3 等专业图像生成模型相媲美。</p><h4 id="_2-图像编辑能力评估" tabindex="-1"><a class="header-anchor" href="#_2-图像编辑能力评估"><span>2. 图像编辑能力评估</span></a></h4><figure><img src="https://paper-assets.alphaxiv.org/figures/2505.14683/img-11.jpeg" alt="图像编辑进展图：不同训练阶段图像编辑能力的进展，显示了各种编辑任务的改进" tabindex="0" loading="lazy"><figcaption>图像编辑进展图：不同训练阶段图像编辑能力的进展，显示了各种编辑任务的改进</figcaption></figure><p>模型的图像编辑能力随着训练阶段的推进而增强，在多种编辑任务上均有改进，包括对象移除、情感改变、元素添加、风格迁移等操作。</p><h4 id="_3-与主流模型对比" tabindex="-1"><a class="header-anchor" href="#_3-与主流模型对比"><span>3. 与主流模型对比</span></a></h4><figure><img src="https://paper-assets.alphaxiv.org/figures/2505.14683/img-13.jpeg" alt="模型对比图：BAGEL 与其他模型（IC-Edit、Step1X-Edit、Gemini 2.0、GPT-4o）在各种图像处理任务上的比较" tabindex="0" loading="lazy"><figcaption>模型对比图：BAGEL 与其他模型（IC-Edit、Step1X-Edit、Gemini 2.0、GPT-4o）在各种图像处理任务上的比较</figcaption></figure><figure><img src="https://paper-assets.alphaxiv.org/figures/2505.14683/img-15.jpeg" alt="多模态推理对比图：BAGEL 与其他模型在需要多模态推理的专门任务上的比较" tabindex="0" loading="lazy"><figcaption>多模态推理对比图：BAGEL 与其他模型在需要多模态推理的专门任务上的比较</figcaption></figure><p>根据官方数据，BAGEL 在主流的多模态理解排行榜上超越了 Qwen2.5-VL 和 InternVL-2.5 等顶尖开源模型，在视觉问答、图像描述等任务上表现出色，展现出强大的跨模态推理能力。</p><h4 id="_4-概念推理能力展示" tabindex="-1"><a class="header-anchor" href="#_4-概念推理能力展示"><span>4. 概念推理能力展示</span></a></h4><figure><img src="https://paper-assets.alphaxiv.org/figures/2505.14683/img-16.jpeg" alt="概念推理图：BAGEL 对提示&quot;一辆由小型汽车制成的汽车&quot;的响应，展示了其概念推理能力" tabindex="0" loading="lazy"><figcaption>概念推理图：BAGEL 对提示&quot;一辆由小型汽车制成的汽车&quot;的响应，展示了其概念推理能力</figcaption></figure><p>BAGEL 展示了出色的概念推理能力，能够理解复杂的创意指令并生成相应的视觉内容。</p><h3 id="多模态能力展示" tabindex="-1"><a class="header-anchor" href="#多模态能力展示"><span>多模态能力展示</span></a></h3><p>BAGEL 展示了统一的多模态能力，主要包括高质量的文本到图像生成、多样化的图像编辑操作（对象移除、情感改变、元素添加等）、以及基于生成与编辑的思考式推理能力。</p><hr><h2 id="模型启发与方法延伸" tabindex="-1"><a class="header-anchor" href="#模型启发与方法延伸"><span>模型启发与方法延伸</span></a></h2><p><strong>方法的通用性与可迁移性</strong>：BAGEL 的统一架构设计及其在海量、多样化交错多模态数据上的预训练，赋予了其良好的通用性和跨任务、跨领域的可迁移性。</p><p><strong>对相关领域/任务的启发</strong>：</p><ul><li><strong>数据策略的重要性</strong>：强调了精心构建和大规模应用多模态交错数据对于激发模型高级认知和推理能力的决定性作用</li><li><strong>统一架构的潜力</strong>：MoT 架构为如何在单一模型内高效统一看似不同的任务（如理解与生成）提供了新的思路和范例</li><li><strong>涌现能力的启示</strong>：对模型涌现能力的研究，为我们理解大规模AI模型如何学习并掌握复杂技能提供了宝贵的线索和视角</li></ul><p><strong>潜在应用场景与未来改进方向</strong>：BAGEL 所展示的能力已触及**世界建模（world-modeling）**的范畴，包括自由格式图像操作、未来帧预测、3D 理解与操作、虚拟环境导航和多视角图像合成等前沿应用。</p><hr><h2 id="结论与未来展望" tabindex="-1"><a class="header-anchor" href="#结论与未来展望"><span>结论与未来展望</span></a></h2><p><strong>论文贡献总结</strong>：成功引入并开源了 BAGEL，一个性能强大的统一多模态模型。有力证明了通过扩展在精心策划的多模态交错数据上的预训练，可以催生出模型的高级涌现能力。BAGEL 在多模态理解和生成任务上均超越了现有的主流开源模型。</p><p><strong>方法优势与不足</strong>：</p><ul><li><strong>优势</strong>：实现了多模态理解与生成的高度统一；具备强大的多模态推理和编辑能力；完全开源，促进社区发展</li><li><strong>不足</strong>：计算资源需求较大，在特定细分任务上仍有提升空间</li></ul><p><strong>未来发展趋势与应用前景</strong>：BAGEL 的成功将进一步激励多模态大模型的研究与探索。模型所展现的&quot;世界建模&quot;相关能力，为实现更通用、更智能的 AI 应用铺平了道路，在机器人、自动驾驶、虚拟现实等领域具有广阔的应用前景。</p><hr><h3 id="参考链接" tabindex="-1"><a class="header-anchor" href="#参考链接"><span>参考链接</span></a></h3><ol><li><a href="https://bagel-ai.org/" target="_blank" rel="noopener noreferrer">项目官方网站</a></li><li><a href="https://arxiv.org/abs/2505.14683" target="_blank" rel="noopener noreferrer">论文arXiv链接</a></li><li><a href="https://github.com/ByteDance-Seed/Bagel" target="_blank" rel="noopener noreferrer">官方GitHub仓库</a></li><li><a href="https://github.com/neverbiasu/ComfyUI-BAGEL" target="_blank" rel="noopener noreferrer">ComfyUI-BAGEL（由 neverbiasu 贡献）</a></li></ol>',84)]))}]]),n=JSON.parse('{"path":"/zh/posts/papers/bagel.html","title":"【论文精读】BAGEL: 统一多模态预训练中的涌现属性 (Emerging Properties in Unified Multimodal Pretraining)","lang":"zh-CN","frontmatter":{"description":"【论文精读】BAGEL: 统一多模态预训练中的涌现属性 (Emerging Properties in Unified Multimodal Pretraining) BAGEL 的多模态能力展示BAGEL 的多模态能力展示 摘要 BAGEL 是由 ByteDance Seed 等机构开发的开源统一多模态基础模型，拥有 7B 活跃参数（总共 14B 参...","gitInclude":[],"head":[["meta",{"property":"og:url","content":"https://neverbiasu.github.io/zh/posts/papers/bagel.html"}],["meta",{"property":"og:site_name","content":"Nlog"}],["meta",{"property":"og:title","content":"【论文精读】BAGEL: 统一多模态预训练中的涌现属性 (Emerging Properties in Unified Multimodal Pretraining)"}],["meta",{"property":"og:description","content":"【论文精读】BAGEL: 统一多模态预训练中的涌现属性 (Emerging Properties in Unified Multimodal Pretraining) BAGEL 的多模态能力展示BAGEL 的多模态能力展示 摘要 BAGEL 是由 ByteDance Seed 等机构开发的开源统一多模态基础模型，拥有 7B 活跃参数（总共 14B 参..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://paper-assets.alphaxiv.org/figures/2505.14683/img-0.jpeg"}],["meta",{"property":"og:locale","content":"zh-CN"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"【论文精读】BAGEL: 统一多模态预训练中的涌现属性 (Emerging Properties in Unified Multimodal Pretraining)\\",\\"image\\":[\\"https://paper-assets.alphaxiv.org/figures/2505.14683/img-0.jpeg\\",\\"https://paper-assets.alphaxiv.org/figures/2505.14683/img-1.jpeg\\",\\"https://paper-assets.alphaxiv.org/figures/2505.14683/img-2.jpeg\\",\\"https://paper-assets.alphaxiv.org/figures/2505.14683/img-3.jpeg\\",\\"https://paper-assets.alphaxiv.org/figures/2505.14683/img-5.jpeg\\",\\"https://paper-assets.alphaxiv.org/figures/2505.14683/img-6.jpeg\\",\\"https://paper-assets.alphaxiv.org/figures/2505.14683/img-8.jpeg\\",\\"https://paper-assets.alphaxiv.org/figures/2505.14683/img-7.jpeg\\",\\"https://paper-assets.alphaxiv.org/figures/2505.14683/img-9.jpeg\\",\\"https://paper-assets.alphaxiv.org/figures/2505.14683/img-10.jpeg\\",\\"https://paper-assets.alphaxiv.org/figures/2505.14683/img-12.jpeg\\",\\"https://paper-assets.alphaxiv.org/figures/2505.14683/img-11.jpeg\\",\\"https://paper-assets.alphaxiv.org/figures/2505.14683/img-13.jpeg\\",\\"https://paper-assets.alphaxiv.org/figures/2505.14683/img-15.jpeg\\",\\"https://paper-assets.alphaxiv.org/figures/2505.14683/img-16.jpeg\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"neverbiasu\\",\\"url\\":\\"https://neverbiasu.github.io\\"}]}"]]},"headers":[{"level":2,"title":"摘要","slug":"摘要","link":"#摘要","children":[]},{"level":2,"title":"目录","slug":"目录","link":"#目录","children":[]},{"level":2,"title":"背景与研究目标","slug":"背景与研究目标","link":"#背景与研究目标","children":[{"level":3,"title":"多模态AI发展现状","slug":"多模态ai发展现状","link":"#多模态ai发展现状","children":[]},{"level":3,"title":"核心研究问题","slug":"核心研究问题","link":"#核心研究问题","children":[]},{"level":3,"title":"主要贡献","slug":"主要贡献","link":"#主要贡献","children":[]}]},{"level":2,"title":"方法与创新点","slug":"方法与创新点","link":"#方法与创新点","children":[{"level":3,"title":"MoT（Transformer 专家混合）架构","slug":"mot-transformer-专家混合-架构","link":"#mot-transformer-专家混合-架构","children":[]},{"level":3,"title":"多模态交错数据策略","slug":"多模态交错数据策略","link":"#多模态交错数据策略","children":[]},{"level":3,"title":"多阶段训练流程","slug":"多阶段训练流程","link":"#多阶段训练流程","children":[]}]},{"level":2,"title":"实验与结果分析","slug":"实验与结果分析","link":"#实验与结果分析","children":[{"level":3,"title":"涌现能力研究","slug":"涌现能力研究","link":"#涌现能力研究","children":[]},{"level":3,"title":"性能基准测试","slug":"性能基准测试","link":"#性能基准测试","children":[]},{"level":3,"title":"多模态能力展示","slug":"多模态能力展示","link":"#多模态能力展示","children":[]}]},{"level":2,"title":"模型启发与方法延伸","slug":"模型启发与方法延伸","link":"#模型启发与方法延伸","children":[]},{"level":2,"title":"结论与未来展望","slug":"结论与未来展望","link":"#结论与未来展望","children":[{"level":3,"title":"参考链接","slug":"参考链接","link":"#参考链接","children":[]}]}],"readingTime":{"minutes":9.16,"words":2747},"filePathRelative":"zh/posts/papers/bagel.md","excerpt":"\\n<figure><img src=\\"https://paper-assets.alphaxiv.org/figures/2505.14683/img-0.jpeg\\" alt=\\"BAGEL 的多模态能力展示\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>BAGEL 的多模态能力展示</figcaption></figure>\\n<h2>摘要</h2>\\n<p>BAGEL 是由 ByteDance Seed 等机构开发的开源统一多模态基础模型，拥有 7B 活跃参数（总共 14B 参数）。通过在万亿级别交错多模态数据上进行预训练，展现出复杂的推理能力。BAGEL 采用 Transformer 专家混合（MoT）架构，在单个解码器模型中统一了理解和生成能力。在标准基准测试中显著优于 Qwen2.5-VL 和 InternVL-2.5 等顶尖开源模型，并展示了自由格式图像操作、未来帧预测、3D 操作和世界导航等前沿能力。</p>","autoDesc":true}')}}]);