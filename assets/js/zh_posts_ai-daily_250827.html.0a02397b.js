"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[7060],{66262:(e,i)=>{i.A=(e,i)=>{const n=e.__vccOpts||e;for(const[e,a]of i)n[e]=a;return n}},31526:(e,i,n)=>{n.r(i),n.d(i,{comp:()=>o,data:()=>r});var a=n(20641);const t={},o=(0,n(66262).A)(t,[["render",function(e,i){return(0,a.uX)(),(0,a.CE)("div",null,i[0]||(i[0]=[(0,a.Fv)('<h1 id="marvis-tts-实时语音克隆-nano-bananas-正式发布-omnihuman-1-5-认知仿真驱动长序列talkinghead【ai日报】" tabindex="-1"><a class="header-anchor" href="#marvis-tts-实时语音克隆-nano-bananas-正式发布-omnihuman-1-5-认知仿真驱动长序列talkinghead【ai日报】"><span>Marvis-TTS 实时语音克隆 | Nano-Bananas 正式发布 | OmniHuman-1.5 认知仿真驱动长序列TalkingHead【AI日报】</span></a></h1><figure><img src="/assets/images/placeholder.png" alt="封面图" tabindex="0" loading="lazy"><figcaption>封面图</figcaption></figure><h2 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span>摘要</span></a></h2><p>本日亮点：Marvis-TTS 实现边缘端实时语音克隆；Gemini 图像编辑提升多轮一致性；InstantX 开源 Qwen-Image ControlNet，ComfyUI 首日集成；OmniHuman-1.5 基于认知仿真驱动长时序角色动画。</p><hr><h2 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span>目录</span></a></h2><ol><li><a href="#marvis-tts%EF%BC%9A%E9%9D%A2%E5%90%91%E8%BE%B9%E7%BC%98%E4%B8%8E%E5%AE%9E%E6%97%B6%E6%B5%81%E5%BC%8F%E7%9A%84%E8%AF%AD%E9%9F%B3%E5%85%8B%E9%9A%86">Marvis-TTS：面向边缘与实时流式的语音克隆</a></li><li><a href="#nano-banana%EF%BC%9Agemini-2-5-flash-%E5%9B%BE%E5%83%8F%E7%BC%96%E8%BE%91%E6%A8%A1%E5%9E%8B">Nano-Bananas：Gemini 2.5 Flash 图像编辑模型</a></li><li><a href="#qwen-image-controlnet%EF%BC%9Ainstantx-%E5%BC%80%E6%BA%90%E7%9A%84-union-controlnet">Qwen-Image-ControlNet：InstantX 开源的Union ControlNet</a></li><li><a href="#comfyui-vibevoice%EF%BC%9A%E5%9C%A8-comfyui-%E4%B8%AD%E7%9A%84%E5%A4%9A%E8%AF%B4%E8%AF%9D%E4%BA%BA-tts-%E8%8A%82%E7%82%B9">ComfyUI-VibeVoice：在 ComfyUI 中的多说话人 TTS 节点</a></li><li><a href="#whisperlivekit%EF%BC%9A%E5%AE%9E%E6%97%B6%E8%BD%AC%E5%86%99%E4%B8%8E-diarization-%E5%B7%A5%E5%85%B7%E5%8C%85">WhisperLiveKit：实时转写与 diarization 工具包</a></li><li><a href="#omnihuman-15%EF%BC%9A%E8%AE%A4%E7%9F%A5%E4%BB%BF%E7%9C%9F%E9%A9%B1%E5%8A%A8%E7%9A%84%E9%95%BF%E6%97%B6%E5%BA%8F%E8%A7%92%E8%89%B2%E5%8A%A8%E7%94%BB">OmniHuman-1.5：认知仿真驱动的长时序角色动画</a></li></ol><hr><h2 id="marvis-tts-面向边缘与实时流式的语音克隆" tabindex="-1"><a class="header-anchor" href="#marvis-tts-面向边缘与实时流式的语音克隆"><span>Marvis-TTS：面向边缘与实时流式的语音克隆</span></a></h2><p><strong>概要</strong>：Marvis-TTS（marvis-tts-250m）主打低延迟实时流式合成与 10 秒语音克隆，支持 MLX 与 Transformers 两套推理接口。模型量化后约 500MB，便于在移动与边缘设备本地部署并实现边说边合成；基于多模态 CSM（250M backbone + 60M audio decoder），可连贯处理整段文本以减少伪影。许可证 Apache‑2.0；使用时注意隐私与合规风险，Hugging Face 与 GitHub 提供快速上手示例。</p><p><strong>标签</strong>：#MarvisTTS #语音合成 #语音克隆 #实时流式 #边缘部署</p><hr><h2 id="nano-banan-gemini-2-5-flash-图像编辑模型" tabindex="-1"><a class="header-anchor" href="#nano-banan-gemini-2-5-flash-图像编辑模型"><span>Nano-Banan：Gemini 2.5 Flash 图像编辑模型</span></a></h2><figure><img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Blog_hero_image_JSSFrGW.width-1600.format-webp.webp" alt="Gemini Example 图" tabindex="0" loading="lazy"><figcaption>Gemini Example 图</figcaption></figure><p><strong>概要</strong>：DeepMind 在 Gemini App 推出的 gemini-2.5-flash-image-preview（代号 Nano‑Banan）显著提升多轮图像编辑中的外观一致性与图像混合能力，适合换装、发型与场景替换等多步编辑。输出含显式水印并嵌入 SynthID（隐式指纹）以标注 AI 生成内容；已在 Gemini App 开放试用，使用时请注意肖像与版权合规。</p><p><strong>标签</strong>：#Gemini #图像编辑 #多轮编辑 #SynthID #DeepMind</p><hr><h2 id="qwen-image-controlnet-instantx-开源的union-controlnet" tabindex="-1"><a class="header-anchor" href="#qwen-image-controlnet-instantx-开源的union-controlnet"><span>Qwen-Image-ControlNet：InstantX 开源的Union ControlNet</span></a></h2><figure><img src="https://substack-post-media.s3.amazonaws.com/public/images/fe6938d5-f648-46da-a7ce-b553928df0f6_5760x2400.png" alt="Qwen-Image ControlNet Demo 图" tabindex="0" loading="lazy"><figcaption>Qwen-Image ControlNet Demo 图</figcaption></figure><p><strong>概要</strong>：InstantX 的 Qwen-Image-ControlNet-Union 是统一 ControlNet，支持 Canny、SoftEdge、Depth 与 Pose 四类结构化控制，面向 Qwen-Image 基座模型的高分辨率条件生成与编辑。作者提供基于 diffusers 的推理脚本（QwenImageControlNetPipeline）与训练细节，ComfyUI Day‑1 即集成并提供 subgraph 模板。建议在含文字的场景于 prompt 加入 &#39;TEXT&#39; 以保留小字，并通过 controlnet_conditioning_scale 调整控制强度。</p><p><strong>标签</strong>：#QwenImage #ControlNet #InstantX #结构化生成 #ComfyUI</p><hr><h2 id="comfyui-vibevoice-在-comfyui-中的多说话人-tts-节点" tabindex="-1"><a class="header-anchor" href="#comfyui-vibevoice-在-comfyui-中的多说话人-tts-节点"><span>ComfyUI-VibeVoice：在 ComfyUI 中的多说话人 TTS 节点</span></a></h2><figure><img src="https://raw.githubusercontent.com/wildminder/ComfyUI-VibeVoice/main/example_workflows/VibeVoice_example.png" alt="ComfyUI VibeVoice Example 图" tabindex="0" loading="lazy"><figcaption>ComfyUI VibeVoice Example 图</figcaption></figure><p><strong>概要</strong>：ComfyUI‑VibeVoice 将微软 VibeVoice 集成到 ComfyUI，提供最多 4 人的多说话人输出、零样本克隆與自动模型管理，便于在可视化管道中生成对话音轨。通过 <code>Speaker N:</code> 指定说话人，节点会自动下载并缓存模型以节省 VRAM。安装可用 ComfyUI Manager，或将仓库克隆至 <code>custom_nodes</code> 并安装依赖后重启。</p><p><strong>标签</strong>：#ComfyUI #VibeVoice #多说话人 #TTS #零样本克隆</p><hr><h2 id="whisperlivekit-实时转写与-diarization-工具包" tabindex="-1"><a class="header-anchor" href="#whisperlivekit-实时转写与-diarization-工具包"><span>WhisperLiveKit：实时转写与 diarization 工具包</span></a></h2><figure><img src="https://raw.githubusercontent.com/QuentinFuxa/WhisperLiveKit/main/demo.png" alt="WhisperLiveKit Demo 图" tabindex="0" loading="lazy"><figcaption>WhisperLiveKit Demo 图</figcaption></figure><p><strong>概要</strong>：WhisperLiveKit 提供本地实时转写服务器與 Web 前端，支持 SimulStreaming、Whisper 與 Sortformer 等后端，适合会议、直播與低延迟场景。支持说话人分离（Sortformer/Diart）、Docker 与 CLI 部署（示例：<code>whisperlivekit-server --model base --language en</code>），并内置 HTML/JS 前端用于 WebSocket 测试与集成。</p><p><strong>标签</strong>：#WhisperLiveKit #实时转写 #diarization #SimulStreaming #直播转写</p><hr><h2 id="omnihuman-1-5-认知仿真驱动的长时序角色动画" tabindex="-1"><a class="header-anchor" href="#omnihuman-1-5-认知仿真驱动的长时序角色动画"><span>OmniHuman-1.5：认知仿真驱动的长时序角色动画</span></a></h2><figure><img src="https://arxiv.org/html/2508.19209v1/figs/teaser.jpg" alt="OmniHuman Teaser 图" tabindex="0" loading="lazy"><figcaption>OmniHuman Teaser 图</figcaption></figure><p><strong>概要</strong>：OmniHuman‑1.5 以“系统1/系统2”认知仿真为核心，提出双系统架构结合多模态 LLM 與 Diffusion Transformer，从单张图像與音轨生成连贯的长时序人物动画，可表现情绪与复杂动作并支持多角色场景。演示含超过 1 分钟的连续表演與摄像机运动。项目页與论文含示例、BibTeX 與伦理说明；该系统可与 VibeVoice 與 WhisperLiveKit 组合为端到端创作流水线。</p><p><strong>标签</strong>：#OmniHuman1_5 #虚拟人 #角色动画 #认知仿真 #多模态</p><hr><h3 id="参考链接" tabindex="-1"><a class="header-anchor" href="#参考链接"><span><strong>参考链接</strong></span></a></h3><ol><li><a href="https://github.com/Marvis-Labs/marvis-tts" target="_blank" rel="noopener noreferrer">Marvis-TTS 代码仓库</a></li><li><a href="https://huggingface.co/Marvis-AI/marvis-tts-250m-v0.1" target="_blank" rel="noopener noreferrer">Marvis-TTS 模型仓库</a></li><li><a href="https://deepmind.google/discover/blog/image-editing-in-gemini-just-got-a-major-upgrade/" target="_blank" rel="noopener noreferrer">DeepMind 博客：Gemini 图像编辑升级</a></li><li><a href="https://blog.comfy.org/p/day-1-support-of-qwen-image-instantx" target="_blank" rel="noopener noreferrer">Comfy Blog：Day-1 support of Qwen-Image InstantX</a></li><li><a href="https://huggingface.co/InstantX/Qwen-Image-ControlNet-Union" target="_blank" rel="noopener noreferrer">InstantX / Qwen-Image-ControlNet-Union 模型仓库</a></li><li><a href="https://github.com/wildminder/ComfyUI-VibeVoice" target="_blank" rel="noopener noreferrer">ComfyUI-VibeVoice 代码仓库</a></li><li><a href="https://github.com/QuentinFuxa/WhisperLiveKit" target="_blank" rel="noopener noreferrer">WhisperLiveKit 代码仓库</a></li><li><a href="https://omnihuman-lab.github.io/v1_5/" target="_blank" rel="noopener noreferrer">OmniHuman-1.5 项目主页</a></li><li><a href="https://arxiv.org/abs/2508.19209" target="_blank" rel="noopener noreferrer">OmniHuman-1.5 论文</a></li></ol>',39)]))}]]),r=JSON.parse('{"path":"/zh/posts/ai-daily/250827.html","title":"Marvis-TTS 实时语音克隆 | Nano-Bananas 正式发布 | OmniHuman-1.5 认知仿真驱动长序列TalkingHead【AI日报】","lang":"zh-CN","frontmatter":{"description":"Marvis-TTS 实时语音克隆 | Nano-Bananas 正式发布 | OmniHuman-1.5 认知仿真驱动长序列TalkingHead【AI日报】 封面图封面图 摘要 本日亮点：Marvis-TTS 实现边缘端实时语音克隆；Gemini 图像编辑提升多轮一致性；InstantX 开源 Qwen-Image ControlNet，Comfy...","gitInclude":[],"head":[["meta",{"property":"og:url","content":"https://neverbiasu.github.io/zh/posts/ai-daily/250827.html"}],["meta",{"property":"og:site_name","content":"Nlog"}],["meta",{"property":"og:title","content":"Marvis-TTS 实时语音克隆 | Nano-Bananas 正式发布 | OmniHuman-1.5 认知仿真驱动长序列TalkingHead【AI日报】"}],["meta",{"property":"og:description","content":"Marvis-TTS 实时语音克隆 | Nano-Bananas 正式发布 | OmniHuman-1.5 认知仿真驱动长序列TalkingHead【AI日报】 封面图封面图 摘要 本日亮点：Marvis-TTS 实现边缘端实时语音克隆；Gemini 图像编辑提升多轮一致性；InstantX 开源 Qwen-Image ControlNet，Comfy..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://neverbiasu.github.io/assets/images/placeholder.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Marvis-TTS 实时语音克隆 | Nano-Bananas 正式发布 | OmniHuman-1.5 认知仿真驱动长序列TalkingHead【AI日报】\\",\\"image\\":[\\"https://neverbiasu.github.io/assets/images/placeholder.png\\",\\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Blog_hero_image_JSSFrGW.width-1600.format-webp.webp\\",\\"https://substack-post-media.s3.amazonaws.com/public/images/fe6938d5-f648-46da-a7ce-b553928df0f6_5760x2400.png\\",\\"https://raw.githubusercontent.com/wildminder/ComfyUI-VibeVoice/main/example_workflows/VibeVoice_example.png\\",\\"https://raw.githubusercontent.com/QuentinFuxa/WhisperLiveKit/main/demo.png\\",\\"https://arxiv.org/html/2508.19209v1/figs/teaser.jpg\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"neverbiasu\\",\\"url\\":\\"https://neverbiasu.github.io\\"}]}"]]},"headers":[{"level":2,"title":"摘要","slug":"摘要","link":"#摘要","children":[]},{"level":2,"title":"目录","slug":"目录","link":"#目录","children":[]},{"level":2,"title":"Marvis-TTS：面向边缘与实时流式的语音克隆","slug":"marvis-tts-面向边缘与实时流式的语音克隆","link":"#marvis-tts-面向边缘与实时流式的语音克隆","children":[]},{"level":2,"title":"Nano-Banan：Gemini 2.5 Flash 图像编辑模型","slug":"nano-banan-gemini-2-5-flash-图像编辑模型","link":"#nano-banan-gemini-2-5-flash-图像编辑模型","children":[]},{"level":2,"title":"Qwen-Image-ControlNet：InstantX 开源的Union ControlNet","slug":"qwen-image-controlnet-instantx-开源的union-controlnet","link":"#qwen-image-controlnet-instantx-开源的union-controlnet","children":[]},{"level":2,"title":"ComfyUI-VibeVoice：在 ComfyUI 中的多说话人 TTS 节点","slug":"comfyui-vibevoice-在-comfyui-中的多说话人-tts-节点","link":"#comfyui-vibevoice-在-comfyui-中的多说话人-tts-节点","children":[]},{"level":2,"title":"WhisperLiveKit：实时转写与 diarization 工具包","slug":"whisperlivekit-实时转写与-diarization-工具包","link":"#whisperlivekit-实时转写与-diarization-工具包","children":[]},{"level":2,"title":"OmniHuman-1.5：认知仿真驱动的长时序角色动画","slug":"omnihuman-1-5-认知仿真驱动的长时序角色动画","link":"#omnihuman-1-5-认知仿真驱动的长时序角色动画","children":[{"level":3,"title":"参考链接","slug":"参考链接","link":"#参考链接","children":[]}]}],"readingTime":{"minutes":3.98,"words":1195},"filePathRelative":"zh/posts/ai-daily/250827.md","excerpt":"\\n<figure><img src=\\"/assets/images/placeholder.png\\" alt=\\"封面图\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>封面图</figcaption></figure>\\n<h2>摘要</h2>\\n<p>本日亮点：Marvis-TTS 实现边缘端实时语音克隆；Gemini 图像编辑提升多轮一致性；InstantX 开源 Qwen-Image ControlNet，ComfyUI 首日集成；OmniHuman-1.5 基于认知仿真驱动长时序角色动画。</p>\\n<hr>\\n<h2>目录</h2>\\n<ol>\\n<li><a href=\\"#marvis-tts%EF%BC%9A%E9%9D%A2%E5%90%91%E8%BE%B9%E7%BC%98%E4%B8%8E%E5%AE%9E%E6%97%B6%E6%B5%81%E5%BC%8F%E7%9A%84%E8%AF%AD%E9%9F%B3%E5%85%8B%E9%9A%86\\">Marvis-TTS：面向边缘与实时流式的语音克隆</a></li>\\n<li><a href=\\"#nano-banana%EF%BC%9Agemini-2-5-flash-%E5%9B%BE%E5%83%8F%E7%BC%96%E8%BE%91%E6%A8%A1%E5%9E%8B\\">Nano-Bananas：Gemini 2.5 Flash 图像编辑模型</a></li>\\n<li><a href=\\"#qwen-image-controlnet%EF%BC%9Ainstantx-%E5%BC%80%E6%BA%90%E7%9A%84-union-controlnet\\">Qwen-Image-ControlNet：InstantX 开源的Union ControlNet</a></li>\\n<li><a href=\\"#comfyui-vibevoice%EF%BC%9A%E5%9C%A8-comfyui-%E4%B8%AD%E7%9A%84%E5%A4%9A%E8%AF%B4%E8%AF%9D%E4%BA%BA-tts-%E8%8A%82%E7%82%B9\\">ComfyUI-VibeVoice：在 ComfyUI 中的多说话人 TTS 节点</a></li>\\n<li><a href=\\"#whisperlivekit%EF%BC%9A%E5%AE%9E%E6%97%B6%E8%BD%AC%E5%86%99%E4%B8%8E-diarization-%E5%B7%A5%E5%85%B7%E5%8C%85\\">WhisperLiveKit：实时转写与 diarization 工具包</a></li>\\n<li><a href=\\"#omnihuman-15%EF%BC%9A%E8%AE%A4%E7%9F%A5%E4%BB%BF%E7%9C%9F%E9%A9%B1%E5%8A%A8%E7%9A%84%E9%95%BF%E6%97%B6%E5%BA%8F%E8%A7%92%E8%89%B2%E5%8A%A8%E7%94%BB\\">OmniHuman-1.5：认知仿真驱动的长时序角色动画</a></li>\\n</ol>","autoDesc":true}')}}]);