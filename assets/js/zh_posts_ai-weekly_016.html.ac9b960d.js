"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[4171],{6262:(e,t)=>{t.A=(e,t)=>{const i=e.__vccOpts||e;for(const[e,a]of t)i[e]=a;return i}},9182:(e,t,i)=>{i.r(t),i.d(t,{comp:()=>n,data:()=>s});var a=i(641);const r={},n=(0,i(6262).A)(r,[["render",function(e,t){return(0,a.uX)(),(0,a.CE)("div",null,t[0]||(t[0]=[(0,a.Fv)('<h1 id="easyref多模态高效图参考生成框架-syncammaster实现视角同步-swiftedit支持高速图像编辑【ai周报】" tabindex="-1"><a class="header-anchor" href="#easyref多模态高效图参考生成框架-syncammaster实现视角同步-swiftedit支持高速图像编辑【ai周报】"><span>EasyRef多模态高效图参考生成框架|SynCamMaster实现视角同步|SwiftEdit支持高速图像编辑【AI周报】</span></a></h1><figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/49053226-463c-4b1a-ae6d-74e4079be9f0/width=450/44419355.jpeg" alt="封面源自C站作者tavoltennis837" tabindex="0" loading="lazy"><figcaption>封面源自C站作者tavoltennis837</figcaption></figure><h2 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span>摘要</span></a></h2><p>本周聚焦生成与编辑：EasyRef 推出高效视频参考生成；SynCamMaster 实现多相机视角同步；StyleMaster 提供艺术风格视频转换；SwiftEdit 用单步扩散实现高速图像编辑，助力创意表达。详见正文。</p><hr><h2 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span>目录</span></a></h2><ol><li><a href="#EasyRef%EF%BC%9A%E5%A4%9A%E6%A8%A1%E6%80%81%E9%AB%98%E6%95%88%E5%9B%BE%E5%8F%82%E8%80%83%E7%94%9F%E6%88%90%E6%A1%86%E6%9E%B6">EasyRef：多模态高效图参考生成框架</a></li><li><a href="#SynCamMaster%EF%BC%9A%E5%A4%9A%E7%9B%B8%E6%9C%BA%E8%A7%86%E8%A7%92%E5%90%8C%E6%AD%A5%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90">SynCamMaster：多相机视角同步视频生成</a></li><li><a href="#StyleMaster%EF%BC%9A%E8%89%BA%E6%9C%AF%E9%A3%8E%E6%A0%BC%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90%E4%B8%8E%E8%BD%AC%E6%8D%A2">StyleMaster：艺术风格视频生成与转换</a></li><li><a href="#StyleStudio%EF%BC%9A%E6%96%87%E6%9C%AC%E9%A9%B1%E5%8A%A8%E7%9A%84%E5%A4%9A%E5%85%83%E7%B4%A0%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB">StyleStudio：文本驱动的多元素风格迁移</a></li><li><a href="#DiffSensei%EF%BC%9A%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AE%9A%E5%88%B6%E5%8C%96%E6%BC%AB%E7%94%BB%E7%94%9F%E6%88%90%E6%A1%86%E6%9E%B6">DiffSensei：多模态定制化漫画生成框架</a></li><li><a href="#SwiftEdit%EF%BC%9A%E8%B6%85%E9%AB%98%E9%80%9F%E6%96%87%E6%9C%AC%E5%BC%95%E5%AF%BC%E5%9B%BE%E5%83%8F%E7%BC%96%E8%BE%91">SwiftEdit：超高速文本引导图像编辑</a></li></ol><hr><h2 id="easyref-多模态高效图参考生成框架" tabindex="-1"><a class="header-anchor" href="#easyref-多模态高效图参考生成框架"><span>EasyRef：多模态高效图参考生成框架</span></a></h2><figure><img src="https://easyref-gen.github.io/static/images/easyref_webpage/teaser_page_1.png" alt="EasyRef Teaser 图" tabindex="0" loading="lazy"><figcaption>EasyRef Teaser 图</figcaption></figure><p><strong>概要</strong>：<strong>EasyRef</strong> 是一种面向扩散模型的多参考图像生成工具，结合多模态大模型 (MLLM) 和适配器结构实现个性化生成。通过高效的参考融合和渐进式训练，EasyRef 能捕获多张参考图像中的一致视觉元素，并支持零样本泛化任务。此外，其新推出的 MRBench 基准测试证明了在多领域生成中的卓越表现。</p><p><strong>标签</strong>：#多模态AI #参考生成 #扩散模型 #个性化生成</p><hr><h2 id="syncammaster-多相机视角同步视频生成" tabindex="-1"><a class="header-anchor" href="#syncammaster-多相机视角同步视频生成"><span>SynCamMaster：多相机视角同步视频生成</span></a></h2><figure><img src="https://jianhongbai.github.io/SynCamMaster/pics/fig_pipe.jpg" alt="SynCamMaster Pipeline 图" tabindex="0" loading="lazy"><figcaption>SynCamMaster Pipeline 图</figcaption></figure><p><strong>概要</strong>：<strong>SynCamMaster</strong> 是由浙江大学与快手联合开发的多相机同步视频生成框架，旨在提升开域场景的多视角一致性视频生成能力。框架采用预训练的文本到视频模型，并通过引入相机嵌入和视角同步模块，实现动态内容在不同视角之间的几何一致性。此外，项目设计了渐进式训练方案，利用合成与单目视频数据提高生成效果，可支持 6 自由度相机运动的内容创作。</p><p><strong>标签</strong>：#多视角生成 #相机同步 #文本到视频 #动态一致性</p><hr><h2 id="stylemaster-艺术风格视频生成与转换" tabindex="-1"><a class="header-anchor" href="#stylemaster-艺术风格视频生成与转换"><span>StyleMaster：艺术风格视频生成与转换</span></a></h2><figure><img src="https://zixuan-ye.github.io/stylemaster/image/pipeline.png" alt="StyleMaster Pipeline 图" tabindex="0" loading="lazy"><figcaption>StyleMaster Pipeline 图</figcaption></figure><p><strong>概要</strong>：<strong>StyleMaster</strong> 是一款聚焦视频艺术风格生成与转换的工具，结合局部纹理选择、全局风格提取和动作适配模块，有效提升生成质量。项目通过 Gray Tile ControlNet 提供精确内容引导，支持多样化的风格迁移。StyleMaster 能生成与参考图像风格高度一致的高质量视频，适用于艺术创作、动态设计等领域。</p><p><strong>标签</strong>：#风格迁移 #视频生成 #内容引导 #ControlNet</p><hr><h2 id="stylestudio-文本驱动的多元素风格迁移" tabindex="-1"><a class="header-anchor" href="#stylestudio-文本驱动的多元素风格迁移"><span>StyleStudio：文本驱动的多元素风格迁移</span></a></h2><figure><img src="https://stylestudio-official.github.io/assets/teaser.jpg" alt="StyleStudio Teaser 图" tabindex="0" loading="lazy"><figcaption>StyleStudio Teaser 图</figcaption></figure><p><strong>概要</strong>：<strong>StyleStudio</strong> 是一款文本驱动的风格迁移工具，通过跨模态自适应归一化 (AdaIN) 和风格分类无引导方法 (SCFG)，实现对风格元素的选择性控制。框架还引入了教师模型，在早期生成阶段稳定空间布局，减少伪影产生。StyleStudio 不依赖额外微调，可轻松整合到现有风格迁移框架中，为文本到图像任务提供了更高质量和灵活性的风格控制。</p><p><strong>标签</strong>：#风格迁移 #文本驱动 #多模态 #风格控制 #AdaIN</p><hr><h2 id="diffsensei-多模态定制化漫画生成框架" tabindex="-1"><a class="header-anchor" href="#diffsensei-多模态定制化漫画生成框架"><span>DiffSensei：多模态定制化漫画生成框架</span></a></h2><figure><img src="https://jianzongwu.github.io/projects/diffsensei/static/images/nobel_prize/image.png" alt="DiffSensei Demo 图" tabindex="0" loading="lazy"><figcaption>DiffSensei Demo 图</figcaption></figure><p><strong>概要</strong>：<strong>DiffSensei</strong> 是一种结合多模态大模型 (LLMs) 与扩散模型的漫画生成工具，支持从输入角色图像和文本描述生成定制化的黑白漫画。框架利用角色适配模块和细粒度生成控制方法，实现多分辨率漫画面板的灵活生成。此外，项目提供了开放数据集 MangaZero，进一步支持社区研究与实践。</p><p><strong>标签</strong>：#漫画生成 #多模态大模型 #Diffusion模型 #角色适配</p><hr><h2 id="swiftedit-超高速文本引导图像编辑" tabindex="-1"><a class="header-anchor" href="#swiftedit-超高速文本引导图像编辑"><span>SwiftEdit：超高速文本引导图像编辑</span></a></h2><figure><img src="https://swift-edit.github.io/images/method/main_diagram.png" alt="SwiftEdit Overview 图" tabindex="0" loading="lazy"><figcaption>SwiftEdit Overview 图</figcaption></figure><p><strong>概要</strong>：<strong>SwiftEdit</strong> 是一种基于单步扩散的图像编辑框架，专注于实现超高速文本引导的局部和全局图像修改。框架引入了一步反演 (one-step inversion) 和注意力重缩放机制，显著加快编辑速度（达 0.23 秒），且保持生成质量。相比多步扩散方法，SwiftEdit 计算效率提升超 50 倍，是一款面向实时图像编辑应用的突破性工具。</p><p><strong>标签</strong>：#图像编辑 #单步扩散 #高效生成 #文本引导 #注意力机制</p><hr><h3 id="参考链接" tabindex="-1"><a class="header-anchor" href="#参考链接"><span><strong>参考链接</strong></span></a></h3><ol><li><a href="https://easyref-gen.github.io/" target="_blank" rel="noopener noreferrer">EasyRef 项目主页</a></li><li><a href="https://github.com/TempleX98/EasyRef" target="_blank" rel="noopener noreferrer">EasyRef GitHub</a></li><li><a href="https://arxiv.org/html/2412.09618" target="_blank" rel="noopener noreferrer">EasyRef 论文</a></li><li><a href="https://jianhongbai.github.io/SynCamMaster/" target="_blank" rel="noopener noreferrer">SynCamMaster 项目主页</a></li><li><a href="https://github.com/KwaiVGI/SynCamMaster" target="_blank" rel="noopener noreferrer">SynCamMaster GitHub</a></li><li><a href="https://arxiv.org/html/2412.07760v1" target="_blank" rel="noopener noreferrer">SynCamMaster 论文</a></li><li><a href="https://zixuan-ye.github.io/stylemaster/" target="_blank" rel="noopener noreferrer">StyleMaster 项目主页</a></li><li><a href="https://github.com/KwaiVGI/StyleMaster" target="_blank" rel="noopener noreferrer">StyleMaster GitHub</a></li><li><a href="https://arxiv.org/html/2412.07744v1" target="_blank" rel="noopener noreferrer">StyleMaster 论文</a></li><li><a href="https://stylestudio-official.github.io/" target="_blank" rel="noopener noreferrer">StyleStudio 项目主页</a></li><li><a href="https://github.com/Westlake-AGI-Lab/StyleStudio" target="_blank" rel="noopener noreferrer">StyleStudio GitHub</a></li><li><a href="https://arxiv.org/html/2412.08503v1" target="_blank" rel="noopener noreferrer">StyleStudio 论文</a></li><li><a href="https://jianzongwu.github.io/projects/diffsensei/" target="_blank" rel="noopener noreferrer">DiffSensei 项目主页</a></li><li><a href="https://github.com/jianzongwu/DiffSensei" target="_blank" rel="noopener noreferrer">DiffSensei GitHub</a></li><li><a href="https://arxiv.org/html/2412.07589v1" target="_blank" rel="noopener noreferrer">DiffSensei 论文</a></li><li><a href="https://swift-edit.github.io/#" target="_blank" rel="noopener noreferrer">SwiftEdit 项目主页</a></li><li><a href="https://arxiv.org/html/2412.04301v2" target="_blank" rel="noopener noreferrer">SwiftEdit 论文</a></li></ol>',40)]))}]]),s=JSON.parse('{"path":"/zh/posts/ai-weekly/016.html","title":"EasyRef多模态高效图参考生成框架|SynCamMaster实现视角同步|SwiftEdit支持高速图像编辑【AI周报】","lang":"zh-CN","frontmatter":{"description":"EasyRef多模态高效图参考生成框架|SynCamMaster实现视角同步|SwiftEdit支持高速图像编辑【AI周报】 封面源自C站作者tavoltennis837封面源自C站作者tavoltennis837 摘要 本周聚焦生成与编辑：EasyRef 推出高效视频参考生成；SynCamMaster 实现多相机视角同步；StyleMaster 提供...","gitInclude":[],"head":[["meta",{"property":"og:url","content":"https://neverbiasu.github.io/zh/posts/ai-weekly/016.html"}],["meta",{"property":"og:site_name","content":"Nlog"}],["meta",{"property":"og:title","content":"EasyRef多模态高效图参考生成框架|SynCamMaster实现视角同步|SwiftEdit支持高速图像编辑【AI周报】"}],["meta",{"property":"og:description","content":"EasyRef多模态高效图参考生成框架|SynCamMaster实现视角同步|SwiftEdit支持高速图像编辑【AI周报】 封面源自C站作者tavoltennis837封面源自C站作者tavoltennis837 摘要 本周聚焦生成与编辑：EasyRef 推出高效视频参考生成；SynCamMaster 实现多相机视角同步；StyleMaster 提供..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/49053226-463c-4b1a-ae6d-74e4079be9f0/width=450/44419355.jpeg"}],["meta",{"property":"og:locale","content":"zh-CN"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"EasyRef多模态高效图参考生成框架|SynCamMaster实现视角同步|SwiftEdit支持高速图像编辑【AI周报】\\",\\"image\\":[\\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/49053226-463c-4b1a-ae6d-74e4079be9f0/width=450/44419355.jpeg\\",\\"https://easyref-gen.github.io/static/images/easyref_webpage/teaser_page_1.png\\",\\"https://jianhongbai.github.io/SynCamMaster/pics/fig_pipe.jpg\\",\\"https://zixuan-ye.github.io/stylemaster/image/pipeline.png\\",\\"https://stylestudio-official.github.io/assets/teaser.jpg\\",\\"https://jianzongwu.github.io/projects/diffsensei/static/images/nobel_prize/image.png\\",\\"https://swift-edit.github.io/images/method/main_diagram.png\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"neverbiasu\\",\\"url\\":\\"https://neverbiasu.github.io\\"}]}"]]},"headers":[{"level":2,"title":"摘要","slug":"摘要","link":"#摘要","children":[]},{"level":2,"title":"目录","slug":"目录","link":"#目录","children":[]},{"level":2,"title":"EasyRef：多模态高效图参考生成框架","slug":"easyref-多模态高效图参考生成框架","link":"#easyref-多模态高效图参考生成框架","children":[]},{"level":2,"title":"SynCamMaster：多相机视角同步视频生成","slug":"syncammaster-多相机视角同步视频生成","link":"#syncammaster-多相机视角同步视频生成","children":[]},{"level":2,"title":"StyleMaster：艺术风格视频生成与转换","slug":"stylemaster-艺术风格视频生成与转换","link":"#stylemaster-艺术风格视频生成与转换","children":[]},{"level":2,"title":"StyleStudio：文本驱动的多元素风格迁移","slug":"stylestudio-文本驱动的多元素风格迁移","link":"#stylestudio-文本驱动的多元素风格迁移","children":[]},{"level":2,"title":"DiffSensei：多模态定制化漫画生成框架","slug":"diffsensei-多模态定制化漫画生成框架","link":"#diffsensei-多模态定制化漫画生成框架","children":[]},{"level":2,"title":"SwiftEdit：超高速文本引导图像编辑","slug":"swiftedit-超高速文本引导图像编辑","link":"#swiftedit-超高速文本引导图像编辑","children":[{"level":3,"title":"参考链接","slug":"参考链接","link":"#参考链接","children":[]}]}],"readingTime":{"minutes":4.48,"words":1344},"filePathRelative":"zh/posts/ai-weekly/016.md","excerpt":"\\n<figure><img src=\\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/49053226-463c-4b1a-ae6d-74e4079be9f0/width=450/44419355.jpeg\\" alt=\\"封面源自C站作者tavoltennis837\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>封面源自C站作者tavoltennis837</figcaption></figure>\\n<h2>摘要</h2>\\n<p>本周聚焦生成与编辑：EasyRef 推出高效视频参考生成；SynCamMaster 实现多相机视角同步；StyleMaster 提供艺术风格视频转换；SwiftEdit 用单步扩散实现高速图像编辑，助力创意表达。详见正文。</p>","autoDesc":true}')}}]);