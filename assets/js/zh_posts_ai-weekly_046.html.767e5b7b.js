"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[4222],{6262:(e,t)=>{t.A=(e,t)=>{const n=e.__vccOpts||e;for(const[e,r]of t)n[e]=r;return n}},3706:(e,t,n)=>{n.r(t),n.d(t,{comp:()=>i,data:()=>o});var r=n(641);const a={},i=(0,n(6262).A)(a,[["render",function(e,t){return(0,r.uX)(),(0,r.CE)("div",null,t[0]||(t[0]=[(0,r.Fv)('<h1 id="t-lora开启单图微调新时代-memos发布llm记忆操作系统-omnipart推动3d可编辑生成【ai周报】" tabindex="-1"><a class="header-anchor" href="#t-lora开启单图微调新时代-memos发布llm记忆操作系统-omnipart推动3d可编辑生成【ai周报】"><span>T-LoRA开启单图微调新时代 | MemOS发布LLM记忆操作系统 | OmniPart推动3D可编辑生成【AI周报】</span></a></h1><figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bc7e4820-82c0-4d95-a196-9627d8cb4578/original=true,quality=90/00003-2892726208.jpeg" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span>摘要</span></a></h2><p>本周亮点：MemOS 推出首个大模型记忆操作系统，T‑LoRA 实现单图扩散微调，OmniPart 支持可控 3D 生成，FM‑Vision‑Evals 建立多模态视觉评测基准。详见正文，参考链接见文末。</p><hr><h2 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span>目录</span></a></h2><ol><li><a href="#t%E2%80%91lora%E5%8D%95%E5%9B%BE%E5%83%8F%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E5%BF%AB%E9%80%9F%E5%AE%9A%E5%88%B6%E6%97%A0%E8%AE%AD%E7%BB%83%E4%B9%9F%E4%B8%8D%E5%8D%A1%E7%B2%BE%E5%BA%A6">T‑LoRA：单图像扩散模型快速定制，无训练也不卡精度</a></li><li><a href="#memos%E9%9D%A2%E5%90%91-llm-%E7%9A%84%E8%AE%B0%E5%BF%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F">MemOS：面向 LLM 的记忆操作系统</a></li><li><a href="#vlv%E2%80%91autoencoder%E6%97%A0%E7%9B%91%E7%9D%A3%E6%89%A9%E6%95%A3%E8%92%B8%E9%A6%8F%E8%A7%86%E8%A7%89%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B">VLV‑AutoEncoder：无监督扩散蒸馏视觉语言模型</a></li><li><a href="#4kagent%E9%80%9A%E7%94%A8%E5%9B%BE%E5%83%8F%E5%88%B04k%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%9A%84%E6%99%BA%E8%83%BD%E4%BB%A3%E7%90%86%E7%B3%BB%E7%BB%9F">4KAgent：通用图像到4K超分辨率的智能代理系统</a></li><li><a href="#omnipart%E5%8F%AF%E7%BC%96%E8%BE%91%E8%AF%AD%E4%B9%89%E9%83%A8%E4%BB%B6%E9%A9%B1%E5%8A%A8%E7%9A%84-3d-%E5%AF%B9%E8%B1%A1%E7%94%9F%E6%88%90%E6%A1%86%E6%9E%B6">OmniPart：可编辑语义部件驱动的 3D 对象生成框架</a></li><li><a href="#fm%E2%80%91vision%E2%80%91evals%E8%AF%84%E6%B5%8B%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3%E8%83%BD%E5%8A%9B%E5%9F%BA%E5%87%86%E5%B9%B3%E5%8F%B0">FM‑Vision‑Evals：评测多模态模型的视觉理解能力基准平台</a></li></ol><hr><h2 id="t‐lora-单图像扩散模型快速定制-无训练也不卡精度" tabindex="-1"><a class="header-anchor" href="#t‐lora-单图像扩散模型快速定制-无训练也不卡精度"><span>T‑LoRA：单图像扩散模型快速定制，无训练也不卡精度</span></a></h2><figure><img src="https://github.com/ControlGenAI/T-LoRA/raw/main/docs/teaser.png" alt="T-LoRA Teaser 图" tabindex="0" loading="lazy"><figcaption>T-LoRA Teaser 图</figcaption></figure><p><strong>概要</strong>：<strong>T‑LoRA</strong> 是由 <strong>ControlGenAI</strong> 团队提出的一种高效扩散模型适配技术，针对“仅有一张概念图像”的场景设计。该方法引入<strong>时步感知低秩适配机制</strong>（Timestep‑Dependent Low‑Rank Adaptation），并在参数初始化中加入<strong>正交策略</strong>，解决了标准 LoRA 在有限样本下的过拟合与泛化不足问题。T‑LoRA 可根据扩散时步动态调节低秩矩阵更新，并实现各组件参数独立初始化，显著提升概念保真度与文本对齐效果。设定下，其在单图临摹情况下对扩散模型进行快速细调，相较原 LoRA 方法大幅提高质量与对齐度，同时支持 Diffusers 框架，几秒内完成训练，适合高效低资源自定义。</p><p><strong>标签</strong>：#图像生成 #扩散模型定制 #LoRA优化 #单图适配</p><hr><h2 id="memos-面向-llm-的记忆操作系统" tabindex="-1"><a class="header-anchor" href="#memos-面向-llm-的记忆操作系统"><span>MemOS：面向 LLM 的记忆操作系统</span></a></h2><figure><img src="https://camo.githubusercontent.com/72d0297632bd2955107fb7adf0bbee2239dc2d5bbea8a20c62bdd35d1a7a94e4/68747470733a2f2f737461746963732e6d656d74656e736f722e636f6d2e636e2f6d656d6f732f736f74615f73636f72652e6a7067" alt="MemOS Performance 图" tabindex="0" loading="lazy"><figcaption>MemOS Performance 图</figcaption></figure><p><strong>概要</strong>：<strong>MemOS</strong> 是由来自 <strong>上海交通大学</strong> 、 <strong>人大</strong> 、 <strong>中科大</strong> 等机构联合提出的“记忆操作系统”框架，旨在将长期记忆作为大型语言模型（LLMs）的一级资源进行管理。MemOS 定义了包含纯文本、激活和参数三类格式的内存单元——MemCube，赋予它们统一的生命周期管理、检索、融合与版本控制能力。系统具备预测性调度、异步融合机制和可移植记忆协议，支持跨模型、跨会话甚至设备共享记忆。实验证明，在 LoCoMo 基准上，MemOS 相比 OpenAI 基线模型在时间推理任务上提升了 <strong>159%</strong> 性能，整体准确率提升近 <strong>39%</strong>，同时令 token 使用量减少约 <strong>61%</strong> 。</p><p><strong>标签</strong>：#记忆操作系统 #LLM记忆 #长期推理 #MemCube架构 #跨模型融合</p><hr><h2 id="vlv‐autoencoder-vision‐language‐vision-auto‐encoder-无监督扩散蒸馏视觉语言模型" tabindex="-1"><a class="header-anchor" href="#vlv‐autoencoder-vision‐language‐vision-auto‐encoder-无监督扩散蒸馏视觉语言模型"><span>VLV‑AutoEncoder（Vision‑Language‑Vision Auto‑Encoder）：无监督扩散蒸馏视觉语言模型</span></a></h2><figure><img src="https://github.com/Tiezheng11/Vision-Language-Vision/raw/main/document/teaser.png" alt="VLV‑AutoEncoder Teaser 图" tabindex="0" loading="lazy"><figcaption>VLV‑AutoEncoder Teaser 图</figcaption></figure><p><strong>概要</strong>：<strong>VLV‑AutoEncoder</strong> 是由 <strong>约翰霍普金斯大学</strong> 、 <strong>清华大学</strong> 和 <strong>瑞士莱斯大学</strong> 学者联合提出的创新模型，具备通过无监督方法利用扩散模型（如 Stable Diffusion）进行知识蒸馏的能力。该框架首先冻结文本生成扩散模型的解码器，并将其作为“语义信息瓶颈”。通过视觉编码器提取图像特征，对应转换为语言嵌入，之后由预训练大语言模型生成高质量图像描述。基于此设计，VLV 能显著降低训练成本（约 1,000 美元）且不需海量图文对齐数据，即在图像标注任务上实现性能与 GPT‑4o / Gemini 2.0 Flash 等顶尖模型相当。该方法不仅具备语义空间重构与多图像组合理解能力，还实现了从图像到语言的高质量端到端自动生成。</p><p><strong>标签</strong>：#多模态自监督 #扩散蒸馏 #视觉语言模型 #知识瓶颈 #高效训练</p><hr><h2 id="_4kagent-通用图像到4k超分辨率的智能代理系统" tabindex="-1"><a class="header-anchor" href="#_4kagent-通用图像到4k超分辨率的智能代理系统"><span>4KAgent：通用图像到4K超分辨率的智能代理系统</span></a></h2><figure><img src="https://github.com/taco-group/4KAgent/raw/main/assets/teaser.jpg" alt="4KAgent Teaser 图" tabindex="0" loading="lazy"><figcaption>4KAgent Teaser 图</figcaption></figure><p><strong>概要</strong>：<strong>4KAgent</strong> 是 <strong>斯坦福大学</strong> 联合 <strong>Snap Inc</strong> 等一同开发的一款图像超分辨率智能代理系统，专为将任意输入图像提升至 4K 质量而设计。系统采用多智能体结构，由感知代理（Perception Agent）分析图像内容与降质类型，并生成恢复策略，由恢复代理（Restoration Agent）执行递归式“执行→反思→回滚”流程。该模型还集成 Q-MoE 专家策略与专用人脸修复流程，以不同模块协同优化不同图像区域。团队制作了大规模测试集 DIV4K-50，用于评价超分精度与重建质量。4KAgent 在处理传统照片、AI 图像、遥感和显微成像等广泛场景下表现稳定，其通用性和模块化设计使其可适配多种恢复任务。</p><p><strong>标签</strong>：#图像超分 #Agent #4K增强 #Q-MoE #面部修复</p><hr><h2 id="omnipart-可编辑语义部件驱动的-3d-对象生成框架" tabindex="-1"><a class="header-anchor" href="#omnipart-可编辑语义部件驱动的-3d-对象生成框架"><span>OmniPart：可编辑语义部件驱动的 3D 对象生成框架</span></a></h2><figure><img src="https://omnipart.github.io/assets/images/pipeline-overview.png" alt="OmniPart Overview 图" tabindex="0" loading="lazy"><figcaption>OmniPart Overview 图</figcaption></figure><p><strong>概要</strong>：<strong>OmniPart</strong> 是一项面向交互式应用的创新研究，由一组学者共同提出，旨在生成具有显式、可编辑部件结构的 3D 资产。相较于传统生成的整体网格，OmniPart 能根据用户定义的部件粒度，自动规划部件结构并通过顺序生成方式创建各部件，兼顾结构连贯与部件语义解耦。其核心包括自回归结构规划模块和空间条件调整流（rectified flow）模型，使生成对象既具备高度可编辑性，又在整体形态上保持稳健一致。凭借该框架，用户可以仅输入单张 2D 图像并指定部分 mask，即可迅速获得可控、可编辑的 3D 模型。</p><p><strong>标签</strong>：#3D生成 #语义解耦 #可编辑部件 #自回归规划 #扩散模型</p><hr><h2 id="fm‐vision‐evals-评测多模态模型的视觉理解能力基准平台" tabindex="-1"><a class="header-anchor" href="#fm‐vision‐evals-评测多模态模型的视觉理解能力基准平台"><span>FM‑Vision‑Evals：评测多模态模型的视觉理解能力基准平台</span></a></h2><figure><img src="https://github.com/EPFL-VILAB/fm-vision-evals/raw/main/assets/pull_figure.svg" alt="FM‑Vision‑Evals Teaser 图" tabindex="0" loading="lazy"><figcaption>FM‑Vision‑Evals Teaser 图</figcaption></figure><p><strong>概要</strong>：<strong>FM‑Vision‑Evals</strong> 是 EPFL VILAB 发布的首个基于 <em>prompt chaining</em> 框架，多任务评测包括语义分割、目标检测、图像分类、深度估计和表面法线预测等标准视觉任务的数据集。团队通过将视觉任务拆解为可由 MFM（如 GPT‑4o、Gemini、Claude、Qwen2‑VL、Llama 等）以文本方式处理的子任务，建立统一评测流程，形成公平可比较的评价体系。研究发现：GPT‑4o 在语义任务上表现最优，但所有多模态基础模型（MFMs）在几何任务上均落后于专业视觉模型；相比之下，MFMs 在语义任务上表现接近，但仍不及专用模型。基于 GPT‑4o 的原生图像生成探索显示其存在“语义重构”倾向而非精准像素级输出。</p><p><strong>标签</strong>：#视觉基准 #多模态评测 #Benchmark #GPT‑4o</p><hr><h3 id="参考链接" tabindex="-1"><a class="header-anchor" href="#参考链接"><span><strong>参考链接</strong></span></a></h3><ol><li><a href="https://github.com/ControlGenAI/T-LoRA" target="_blank" rel="noopener noreferrer">T-LoRA Github 仓库</a></li><li><a href="https://arxiv.org/html/2507.05964v1" target="_blank" rel="noopener noreferrer">T-LoRA 论文</a></li><li><a href="https://memos.openmem.net/" target="_blank" rel="noopener noreferrer">MemOS 官网</a></li><li><a href="https://github.com/MemTensor/MemOS" target="_blank" rel="noopener noreferrer">MemOS Github 仓库</a></li><li><a href="https://arxiv.org/html/2507.03724" target="_blank" rel="noopener noreferrer">MemOS 论文</a></li><li><a href="https://tiezheng11.github.io/VLV-WebPage/" target="_blank" rel="noopener noreferrer">VLV‑AutoEncoder 项目页面</a></li><li><a href="https://github.com/Tiezheng11/Vision-Language-Vision" target="_blank" rel="noopener noreferrer">VLV‑AutoEncoder Github 仓库</a></li><li><a href="https://arxiv.org/html/2507.07104v1" target="_blank" rel="noopener noreferrer">VLV‑AutoEncoder 论文</a></li><li><a href="https://4kagent.github.io/" target="_blank" rel="noopener noreferrer">4KAgent 项目页面</a></li><li><a href="https://github.com/taco-group/4KAgent" target="_blank" rel="noopener noreferrer">4KAgent Github 仓库</a></li><li><a href="https://arxiv.org/html/2507.07105" target="_blank" rel="noopener noreferrer">4KAgent 论文</a></li><li><a href="https://omnipart.github.io/" target="_blank" rel="noopener noreferrer">OmniPart 项目页面</a></li><li><a href="https://huggingface.co/spaces/omnipart/OmniPart" target="_blank" rel="noopener noreferrer">OmniPart Hugging Face Spaces</a></li><li><a href="https://arxiv.org/html/2507.06165" target="_blank" rel="noopener noreferrer">OmniPart 论文</a></li><li><a href="https://fm-vision-evals.epfl.ch/" target="_blank" rel="noopener noreferrer">FM‑Vision‑Evals 官网</a></li><li><a href="https://github.com/EPFL-VILAB/fm-vision-evals" target="_blank" rel="noopener noreferrer">FM‑Vision‑Evals Github 仓库</a></li><li><a href="https://arxiv.org/pdf/2507.01955" target="_blank" rel="noopener noreferrer">FM‑Vision‑Evals 论文</a></li></ol>',40)]))}]]),o=JSON.parse('{"path":"/zh/posts/ai-weekly/046.html","title":"T-LoRA开启单图微调新时代 | MemOS发布LLM记忆操作系统 | OmniPart推动3D可编辑生成【AI周报】","lang":"zh-CN","frontmatter":{"description":"T-LoRA开启单图微调新时代 | MemOS发布LLM记忆操作系统 | OmniPart推动3D可编辑生成【AI周报】 摘要 本周亮点：MemOS 推出首个大模型记忆操作系统，T‑LoRA 实现单图扩散微调，OmniPart 支持可控 3D 生成，FM‑Vision‑Evals 建立多模态视觉评测基准。详见正文，参考链接见文末。 目录 T‑LoRA：...","gitInclude":[],"head":[["meta",{"property":"og:url","content":"https://neverbiasu.github.io/zh/posts/ai-weekly/046.html"}],["meta",{"property":"og:site_name","content":"Nlog"}],["meta",{"property":"og:title","content":"T-LoRA开启单图微调新时代 | MemOS发布LLM记忆操作系统 | OmniPart推动3D可编辑生成【AI周报】"}],["meta",{"property":"og:description","content":"T-LoRA开启单图微调新时代 | MemOS发布LLM记忆操作系统 | OmniPart推动3D可编辑生成【AI周报】 摘要 本周亮点：MemOS 推出首个大模型记忆操作系统，T‑LoRA 实现单图扩散微调，OmniPart 支持可控 3D 生成，FM‑Vision‑Evals 建立多模态视觉评测基准。详见正文，参考链接见文末。 目录 T‑LoRA：..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bc7e4820-82c0-4d95-a196-9627d8cb4578/original=true,quality=90/00003-2892726208.jpeg"}],["meta",{"property":"og:locale","content":"zh-CN"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"T-LoRA开启单图微调新时代 | MemOS发布LLM记忆操作系统 | OmniPart推动3D可编辑生成【AI周报】\\",\\"image\\":[\\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bc7e4820-82c0-4d95-a196-9627d8cb4578/original=true,quality=90/00003-2892726208.jpeg\\",\\"https://github.com/ControlGenAI/T-LoRA/raw/main/docs/teaser.png\\",\\"https://camo.githubusercontent.com/72d0297632bd2955107fb7adf0bbee2239dc2d5bbea8a20c62bdd35d1a7a94e4/68747470733a2f2f737461746963732e6d656d74656e736f722e636f6d2e636e2f6d656d6f732f736f74615f73636f72652e6a7067\\",\\"https://github.com/Tiezheng11/Vision-Language-Vision/raw/main/document/teaser.png\\",\\"https://github.com/taco-group/4KAgent/raw/main/assets/teaser.jpg\\",\\"https://omnipart.github.io/assets/images/pipeline-overview.png\\",\\"https://github.com/EPFL-VILAB/fm-vision-evals/raw/main/assets/pull_figure.svg\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"neverbiasu\\",\\"url\\":\\"https://neverbiasu.github.io\\"}]}"]]},"headers":[{"level":2,"title":"摘要","slug":"摘要","link":"#摘要","children":[]},{"level":2,"title":"目录","slug":"目录","link":"#目录","children":[]},{"level":2,"title":"T‑LoRA：单图像扩散模型快速定制，无训练也不卡精度","slug":"t‐lora-单图像扩散模型快速定制-无训练也不卡精度","link":"#t‐lora-单图像扩散模型快速定制-无训练也不卡精度","children":[]},{"level":2,"title":"MemOS：面向 LLM 的记忆操作系统","slug":"memos-面向-llm-的记忆操作系统","link":"#memos-面向-llm-的记忆操作系统","children":[]},{"level":2,"title":"VLV‑AutoEncoder（Vision‑Language‑Vision Auto‑Encoder）：无监督扩散蒸馏视觉语言模型","slug":"vlv‐autoencoder-vision‐language‐vision-auto‐encoder-无监督扩散蒸馏视觉语言模型","link":"#vlv‐autoencoder-vision‐language‐vision-auto‐encoder-无监督扩散蒸馏视觉语言模型","children":[]},{"level":2,"title":"4KAgent：通用图像到4K超分辨率的智能代理系统","slug":"_4kagent-通用图像到4k超分辨率的智能代理系统","link":"#_4kagent-通用图像到4k超分辨率的智能代理系统","children":[]},{"level":2,"title":"OmniPart：可编辑语义部件驱动的 3D 对象生成框架","slug":"omnipart-可编辑语义部件驱动的-3d-对象生成框架","link":"#omnipart-可编辑语义部件驱动的-3d-对象生成框架","children":[]},{"level":2,"title":"FM‑Vision‑Evals：评测多模态模型的视觉理解能力基准平台","slug":"fm‐vision‐evals-评测多模态模型的视觉理解能力基准平台","link":"#fm‐vision‐evals-评测多模态模型的视觉理解能力基准平台","children":[{"level":3,"title":"参考链接","slug":"参考链接","link":"#参考链接","children":[]}]}],"readingTime":{"minutes":6.67,"words":2002},"filePathRelative":"zh/posts/ai-weekly/046.md","excerpt":"\\n<figure><img src=\\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bc7e4820-82c0-4d95-a196-9627d8cb4578/original=true,quality=90/00003-2892726208.jpeg\\" alt=\\"\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption></figcaption></figure>\\n<h2>摘要</h2>\\n<p>本周亮点：MemOS 推出首个大模型记忆操作系统，T‑LoRA 实现单图扩散微调，OmniPart 支持可控 3D 生成，FM‑Vision‑Evals 建立多模态视觉评测基准。详见正文，参考链接见文末。</p>","autoDesc":true}')}}]);