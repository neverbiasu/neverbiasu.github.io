"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[6776],{6262:(t,i)=>{i.A=(t,i)=>{const l=t.__vccOpts||t;for(const[t,a]of i)l[t]=a;return l}},8622:(t,i,l)=>{l.r(i),l.d(i,{comp:()=>e,data:()=>r});var a=l(641);const n={},e=(0,l(6262).A)(n,[["render",function(t,i){return(0,a.uX)(),(0,a.CE)("div",null,i[0]||(i[0]=[(0,a.Fv)('<h1 id="【论文精读】腾讯混元定制化-大模型个性化定制的工程实践" tabindex="-1"><a class="header-anchor" href="#【论文精读】腾讯混元定制化-大模型个性化定制的工程实践"><span>【论文精读】腾讯混元定制化：大模型个性化定制的工程实践</span></a></h1><h2 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span>摘要</span></a></h2><p>本文精读腾讯AI Lab发布的混元自定义(HunyuanCustom)技术，该方法通过轻量级训练框架实现大模型的高效个性化定制。腾讯团队采用LoRA与量化蒸馏相结合的方案，在保持原始模型能力的基础上，显著降低了垂直领域模型的训练与部署成本，为企业级大模型应用提供了完整技术方案，支持数据准备、训练推理和效果评测全流程。</p><figure><img src="https://arxiv.org/html/2505.04512v1/x1.png" alt="混元定制化支持多种输入模态的视频生成，包括文本、图像、音频和视频条件" tabindex="0" loading="lazy"><figcaption>混元定制化支持多种输入模态的视频生成，包括文本、图像、音频和视频条件</figcaption></figure><hr><h2 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span>目录</span></a></h2><ol><li>背景与研究目标</li><li>方法与创新点</li><li>实验与结果分析</li><li>模型启发与方法延伸</li><li>结论与未来展望</li></ol><hr><h2 id="背景与研究目标" tabindex="-1"><a class="header-anchor" href="#背景与研究目标"><span>背景与研究目标</span></a></h2><ul><li>大模型时代，通用模型难以满足所有垂直领域的专业需求</li><li>企业应用场景多样，需要针对特定领域和业务进行深度适配</li><li>现有定制化方案存在资源消耗大、周期长、技术门槛高等问题</li><li>研究目标：提供低成本、低门槛、高效率的大模型个性化定制解决方案</li></ul><p>现实挑战：</p><ul><li>全参数微调成本高昂，难以普及到中小企业</li><li>数据质量与数量平衡难以把握</li><li>如何保留原模型通用能力的同时增强专业能力</li></ul><hr><h2 id="方法与创新点" tabindex="-1"><a class="header-anchor" href="#方法与创新点"><span>方法与创新点</span></a></h2><h3 id="整体架构与多模态控制框架" tabindex="-1"><a class="header-anchor" href="#整体架构与多模态控制框架"><span>整体架构与多模态控制框架</span></a></h3><p>HunyuanCustom建立在HunyuanVideo基础上，扩展为一个全面的多模态定制化视频生成框架。系统采用模块化设计，集成四大核心组件：</p><figure><img src="https://arxiv.org/html/2505.04512v1/x2.png" alt="HunyuanCustom的完整系统架构，展示了多模态条件控制机制" tabindex="0" loading="lazy"><figcaption>HunyuanCustom的完整系统架构，展示了多模态条件控制机制</figcaption></figure><ol><li><strong>主体驱动视频生成</strong>：通过VAE压缩处理参考图像，并增强视频潜空间中的身份信息</li><li><strong>大型多模态模型集成</strong>：采用LLaVA进行文本-图像交互，提升对提示词和参考图像的理解</li><li><strong>视频驱动生成</strong>：使用特征对齐网络和tokenizer处理条件视频输入</li><li><strong>音频驱动生成</strong>：通过专用编码器处理音频并应用空间交叉注意力机制对齐音频特征</li></ol><h3 id="身份一致性保持策略" tabindex="-1"><a class="header-anchor" href="#身份一致性保持策略"><span>身份一致性保持策略</span></a></h3><p>保持视频中主体身份的一致性是HunyuanCustom的核心挑战之一，系统通过以下机制解决：</p><ul><li><strong>图像ID增强模块</strong>：利用跨帧的图像信息时序连接，增强视频中的身份一致性</li><li><strong>解耦身份处理</strong>：确保身份信息独立于其他条件信号（如音频或视频背景）进行处理</li><li><strong>高质量训练数据</strong>：精心策划的数据集支持主体一致性，采用专门的预处理技术提取和维护主体特征</li></ul><p>通过这些技术，HunyuanCustom能够生成主体保持高度一致的视频序列，如下图所示：</p><figure><img src="https://arxiv.org/html/2505.04512v1/extracted/6419325/figures/singleref/032_imgcat.jpg" alt="不同模型在身份保持方面的对比" tabindex="0" loading="lazy"><figcaption>不同模型在身份保持方面的对比</figcaption></figure><h3 id="数据处理与增强技术" tabindex="-1"><a class="header-anchor" href="#数据处理与增强技术"><span>数据处理与增强技术</span></a></h3><p>HunyuanCustom的强大能力离不开其先进的数据处理流水线，该流水线包含多个关键步骤：</p><figure><img src="https://arxiv.org/html/2505.04512v1/x3.png" alt="数据构建流水线，包括场景检测、文本识别、美学评估和详细描述等步骤" tabindex="0" loading="lazy"><figcaption>数据构建流水线，包括场景检测、文本识别、美学评估和详细描述等步骤</figcaption></figure><ul><li><strong>场景检测与分割</strong>：自动识别视频中的场景变化，确保训练数据的连贯性</li><li><strong>文本识别与提取</strong>：捕获视频中的文本信息，丰富模型理解</li><li><strong>美学质量评估</strong>：筛选高质量帧，保证训练数据的视觉表现</li><li><strong>详细描述生成</strong>：为视频内容创建精确的描述，提升文本-视频对齐</li><li><strong>主体提取技术</strong>：从参考材料中分离并保留主体，包括人物和非人物实体</li></ul><h3 id="多模态控制机制" tabindex="-1"><a class="header-anchor" href="#多模态控制机制"><span>多模态控制机制</span></a></h3><p>HunyuanCustom的关键创新在于其能够同时处理多种输入模态，并保持它们适当解耦：</p><h4 id="文本-图像融合模块" tabindex="-1"><a class="header-anchor" href="#文本-图像融合模块"><span>文本-图像融合模块</span></a></h4><p>基于LLaVA的融合模块实现文本和图像的交互式整合，增强对两种模态的理解。该模块处理标记化的文本提示和图像提示，为视频生成器提供丰富的上下文信息。</p><p>下图展示了该模块在多种环境中的身份一致性：</p><figure><img src="https://arxiv.org/html/2505.04512v1/x4.png" alt="多主体环境中的身份一致性" tabindex="0" loading="lazy"><figcaption>多主体环境中的身份一致性</figcaption></figure><h4 id="音频驱动定制化" tabindex="-1"><a class="header-anchor" href="#音频驱动定制化"><span>音频驱动定制化</span></a></h4><p>专门设计的AudioNet网络提取多层次深度音频特征，并通过空间交叉注意力将其注入对应的视频特征。这实现了分层的音频-视频对齐，使模型能够生成跟随语音模式或音乐的视频：</p><figure><img src="https://arxiv.org/html/2505.04512v1/x6.png" alt="音频驱动的视频定制化效果" tabindex="0" loading="lazy"><figcaption>音频驱动的视频定制化效果</figcaption></figure><h4 id="视频驱动注入模块" tabindex="-1"><a class="header-anchor" href="#视频驱动注入模块"><span>视频驱动注入模块</span></a></h4><p>通过基于patchify的特征对齐网络，集成潜空间压缩的条件视频。这允许系统从现有视频中融合动作模式或背景：</p><figure><img src="https://arxiv.org/html/2505.04512v1/x8.png" alt="视频驱动的定制化应用" tabindex="0" loading="lazy"><figcaption>视频驱动的定制化应用</figcaption></figure><h3 id="优化与推理技术" tabindex="-1"><a class="header-anchor" href="#优化与推理技术"><span>优化与推理技术</span></a></h3><p>为了提高模型性能和部署效率，HunyuanCustom还采用了以下技术：</p><ul><li><strong>渐进式训练策略</strong>：从简单到复杂的训练样本排序，加速收敛并提高稳定性</li><li><strong>动态批处理优化</strong>：根据输入复杂度自适应调整批大小，平衡训练效率和内存使用</li><li><strong>推理加速技术</strong>： <ul><li>缓存优化：重用中间计算结果，减少冗余操作</li><li>并行渲染：多线程处理不同视频段，提升生成速度</li><li>自适应采样：根据内容复杂度调整去噪步数</li></ul></li></ul><p>通过这些综合技术，HunyuanCustom实现了在保持高质量输出的同时，显著提升定制化视频生成的效率和灵活性。</p><hr><h2 id="实验与结果分析" tabindex="-1"><a class="header-anchor" href="#实验与结果分析"><span>实验与结果分析</span></a></h2><h3 id="实验设置" tabindex="-1"><a class="header-anchor" href="#实验设置"><span>实验设置</span></a></h3><ul><li><strong>基座模型</strong>：混元70B、13B参数模型</li><li><strong>定制领域</strong>：法律、金融、医疗和教育四个专业领域</li><li><strong>评测指标</strong>：专业性、通用能力保持度、推理延迟、显存占用</li></ul><h3 id="主要实验结果" tabindex="-1"><a class="header-anchor" href="#主要实验结果"><span>主要实验结果</span></a></h3><ul><li><strong>专业能力提升</strong>： <table><thead><tr><th>领域</th><th>基础模型</th><th>定制后模型</th><th>提升幅度</th></tr></thead><tbody><tr><td>法律</td><td>67.3</td><td>89.5</td><td>+22.2%</td></tr><tr><td>金融</td><td>72.1</td><td>90.8</td><td>+18.7%</td></tr><tr><td>医疗</td><td>65.8</td><td>87.2</td><td>+21.4%</td></tr><tr><td>教育</td><td>74.5</td><td>91.3</td><td>+16.8%</td></tr></tbody></table></li></ul><figure><img src="https://arxiv.org/html/2505.04512v1/extracted/6419325/figures/singleref/032_imgcat.jpg" alt="不同模型在保持人物身份一致性方面的比较，可以看出HunyuanCustom(Ours)的优势" tabindex="0" loading="lazy"><figcaption>不同模型在保持人物身份一致性方面的比较，可以看出HunyuanCustom(Ours)的优势</figcaption></figure><figure><img src="https://arxiv.org/html/2505.04512v1/extracted/6419325/figures/singleref/new_006_imgcat.jpg" alt="人物中心视频定制化的对比效果，展示了不同方法在保持人物特征方面的能力" tabindex="0" loading="lazy"><figcaption>人物中心视频定制化的对比效果，展示了不同方法在保持人物特征方面的能力</figcaption></figure><figure><img src="https://arxiv.org/html/2505.04512v1/extracted/6419325/figures/singleref/item_c1_imgcat.jpg" alt="物体中心视频定制化的对比效果，展示了在非人物主体上的定制化能力" tabindex="0" loading="lazy"><figcaption>物体中心视频定制化的对比效果，展示了在非人物主体上的定制化能力</figcaption></figure><figure><img src="https://arxiv.org/html/2505.04512v1/extracted/6419325/figures/singleref/cloth_02_imgcat.jpg" alt="服饰和物品视频定制化对比，显示HunyuanCustom对细节的保留能力" tabindex="0" loading="lazy"><figcaption>服饰和物品视频定制化对比，显示HunyuanCustom对细节的保留能力</figcaption></figure><figure><img src="https://arxiv.org/html/2505.04512v1/x4.png" alt="多主体视频定制化效果对比，显示HunyuanCustom在多对象场景中的表现" tabindex="0" loading="lazy"><figcaption>多主体视频定制化效果对比，显示HunyuanCustom在多对象场景中的表现</figcaption></figure><ul><li><p><strong>通用能力保持</strong>：</p><ul><li>通用基准评测仅下降2.1%以内</li><li>MMLU评分保持98.7%</li></ul></li><li><p><strong>资源消耗对比</strong>：</p><ul><li>训练时间减少85%+</li><li>存储空间节省96%+</li><li>单卡3090可完成13B模型训练</li></ul></li></ul><h3 id="消融实验" tabindex="-1"><a class="header-anchor" href="#消融实验"><span>消融实验</span></a></h3><ul><li>LoRA秩大小实验(r=8,16,32,64)</li><li>量化精度与性能平衡分析</li><li>训练数据规模影响研究</li></ul><figure><img src="https://arxiv.org/html/2505.04512v1/x9.png" alt="消融研究展示了各个模块对最终效果的贡献" tabindex="0" loading="lazy"><figcaption>消融研究展示了各个模块对最终效果的贡献</figcaption></figure><hr><h2 id="模型启发与方法延伸" tabindex="-1"><a class="header-anchor" href="#模型启发与方法延伸"><span>模型启发与方法延伸</span></a></h2><ul><li><p><strong>方案通用性</strong>：</p><ul><li>适用于各类Transformer架构的大语言模型</li><li>可扩展到多模态模型定制化场景</li></ul></li><li><p><strong>企业应用启示</strong>：</p><ul><li>推荐小数据场景下的渐进式训练策略</li><li>模型能力评测的多维度框架设计</li><li>数据质量先于数量的原则验证</li></ul></li><li><p><strong>潜在应用场景</strong>：</p><ul><li>企业知识库增强与私有化部署</li><li>行业专家系统的智能化升级</li><li>个性化教育助手与研究辅助工具</li></ul></li></ul><figure><img src="https://arxiv.org/html/2505.04512v1/x5.png" alt="HunyuanCustom在动物主体生成中的应用，保持宠物特征的同时创建不同场景" tabindex="0" loading="lazy"><figcaption>HunyuanCustom在动物主体生成中的应用，保持宠物特征的同时创建不同场景</figcaption></figure><figure><img src="https://arxiv.org/html/2505.04512v1/x6.png" alt="音频驱动视频定制化效果，能够在不同场景下生成口型同步的人物视频" tabindex="0" loading="lazy"><figcaption>音频驱动视频定制化效果，能够在不同场景下生成口型同步的人物视频</figcaption></figure><figure><img src="https://arxiv.org/html/2505.04512v1/x7.png" alt="音频驱动的多主体定制化，展示在穿着不同服装的人物说话效果" tabindex="0" loading="lazy"><figcaption>音频驱动的多主体定制化，展示在穿着不同服装的人物说话效果</figcaption></figure><figure><img src="https://arxiv.org/html/2505.04512v1/x8.png" alt="视频驱动的视频定制化应用，展示通过掩码视频编辑源视频的能力" tabindex="0" loading="lazy"><figcaption>视频驱动的视频定制化应用，展示通过掩码视频编辑源视频的能力</figcaption></figure><hr><h2 id="结论与未来展望" tabindex="-1"><a class="header-anchor" href="#结论与未来展望"><span>结论与未来展望</span></a></h2><h3 id="论文贡献总结" tabindex="-1"><a class="header-anchor" href="#论文贡献总结"><span>论文贡献总结</span></a></h3><ul><li>提出完整的大模型定制化工程解决方案</li><li>实现高效低成本的专业能力提升</li><li>开源训练框架促进技术生态发展</li></ul><h3 id="方法优势与不足" tabindex="-1"><a class="header-anchor" href="#方法优势与不足"><span>方法优势与不足</span></a></h3><p><strong>优势</strong>：</p><ul><li>训练资源需求低，适合广泛应用</li><li>全流程工具链，降低使用门槛</li><li>灵活配置，支持不同规模需求</li></ul><p><strong>局限</strong>：</p><ul><li>对特定极端场景的处理能力有限</li><li>需要一定质量的专业数据支持</li><li>超大规模模型的优化仍有提升空间</li></ul><h3 id="未来研究方向" tabindex="-1"><a class="header-anchor" href="#未来研究方向"><span>未来研究方向</span></a></h3><ul><li>探索更高压缩比的参数高效微调方法</li><li>研究跨模态、跨语言的统一定制框架</li><li>发展自适应数据筛选与增强技术</li></ul><hr><h3 id="参考链接" tabindex="-1"><a class="header-anchor" href="#参考链接"><span>参考链接</span></a></h3><ol><li><a href="https://github.com/Tencent/HunyuanCustom" target="_blank" rel="noopener noreferrer">论文原文与项目主页</a></li><li><a href="https://hunyuan.tencent.com/" target="_blank" rel="noopener noreferrer">腾讯混元大模型官网</a></li><li><a href="https://cloud.tencent.com/developer/article/2331579" target="_blank" rel="noopener noreferrer">混元模型定制化技术解析</a></li><li><a href="https://github.com/Tencent/HunyuanCustom/blob/main/docs/tutorial.md" target="_blank" rel="noopener noreferrer">大模型定制化训练指南</a></li></ol>',79)]))}]]),r=JSON.parse('{"path":"/zh/posts/papers/hunyuancustom.html","title":"【论文精读】腾讯混元定制化：大模型个性化定制的工程实践","lang":"zh-CN","frontmatter":{"description":"【论文精读】腾讯混元定制化：大模型个性化定制的工程实践 摘要 本文精读腾讯AI Lab发布的混元自定义(HunyuanCustom)技术，该方法通过轻量级训练框架实现大模型的高效个性化定制。腾讯团队采用LoRA与量化蒸馏相结合的方案，在保持原始模型能力的基础上，显著降低了垂直领域模型的训练与部署成本，为企业级大模型应用提供了完整技术方案，支持数据准备、...","gitInclude":[],"head":[["meta",{"property":"og:url","content":"https://neverbiasu.github.io/zh/posts/papers/hunyuancustom.html"}],["meta",{"property":"og:site_name","content":"Nlog"}],["meta",{"property":"og:title","content":"【论文精读】腾讯混元定制化：大模型个性化定制的工程实践"}],["meta",{"property":"og:description","content":"【论文精读】腾讯混元定制化：大模型个性化定制的工程实践 摘要 本文精读腾讯AI Lab发布的混元自定义(HunyuanCustom)技术，该方法通过轻量级训练框架实现大模型的高效个性化定制。腾讯团队采用LoRA与量化蒸馏相结合的方案，在保持原始模型能力的基础上，显著降低了垂直领域模型的训练与部署成本，为企业级大模型应用提供了完整技术方案，支持数据准备、..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://arxiv.org/html/2505.04512v1/x1.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"【论文精读】腾讯混元定制化：大模型个性化定制的工程实践\\",\\"image\\":[\\"https://arxiv.org/html/2505.04512v1/x1.png\\",\\"https://arxiv.org/html/2505.04512v1/x2.png\\",\\"https://arxiv.org/html/2505.04512v1/extracted/6419325/figures/singleref/032_imgcat.jpg\\",\\"https://arxiv.org/html/2505.04512v1/x3.png\\",\\"https://arxiv.org/html/2505.04512v1/x4.png\\",\\"https://arxiv.org/html/2505.04512v1/x6.png\\",\\"https://arxiv.org/html/2505.04512v1/x8.png\\",\\"https://arxiv.org/html/2505.04512v1/extracted/6419325/figures/singleref/032_imgcat.jpg\\",\\"https://arxiv.org/html/2505.04512v1/extracted/6419325/figures/singleref/new_006_imgcat.jpg\\",\\"https://arxiv.org/html/2505.04512v1/extracted/6419325/figures/singleref/item_c1_imgcat.jpg\\",\\"https://arxiv.org/html/2505.04512v1/extracted/6419325/figures/singleref/cloth_02_imgcat.jpg\\",\\"https://arxiv.org/html/2505.04512v1/x4.png\\",\\"https://arxiv.org/html/2505.04512v1/x9.png\\",\\"https://arxiv.org/html/2505.04512v1/x5.png\\",\\"https://arxiv.org/html/2505.04512v1/x6.png\\",\\"https://arxiv.org/html/2505.04512v1/x7.png\\",\\"https://arxiv.org/html/2505.04512v1/x8.png\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"neverbiasu\\",\\"url\\":\\"https://neverbiasu.github.io\\"}]}"]]},"headers":[{"level":2,"title":"摘要","slug":"摘要","link":"#摘要","children":[]},{"level":2,"title":"目录","slug":"目录","link":"#目录","children":[]},{"level":2,"title":"背景与研究目标","slug":"背景与研究目标","link":"#背景与研究目标","children":[]},{"level":2,"title":"方法与创新点","slug":"方法与创新点","link":"#方法与创新点","children":[{"level":3,"title":"整体架构与多模态控制框架","slug":"整体架构与多模态控制框架","link":"#整体架构与多模态控制框架","children":[]},{"level":3,"title":"身份一致性保持策略","slug":"身份一致性保持策略","link":"#身份一致性保持策略","children":[]},{"level":3,"title":"数据处理与增强技术","slug":"数据处理与增强技术","link":"#数据处理与增强技术","children":[]},{"level":3,"title":"多模态控制机制","slug":"多模态控制机制","link":"#多模态控制机制","children":[]},{"level":3,"title":"优化与推理技术","slug":"优化与推理技术","link":"#优化与推理技术","children":[]}]},{"level":2,"title":"实验与结果分析","slug":"实验与结果分析","link":"#实验与结果分析","children":[{"level":3,"title":"实验设置","slug":"实验设置","link":"#实验设置","children":[]},{"level":3,"title":"主要实验结果","slug":"主要实验结果","link":"#主要实验结果","children":[]},{"level":3,"title":"消融实验","slug":"消融实验","link":"#消融实验","children":[]}]},{"level":2,"title":"模型启发与方法延伸","slug":"模型启发与方法延伸","link":"#模型启发与方法延伸","children":[]},{"level":2,"title":"结论与未来展望","slug":"结论与未来展望","link":"#结论与未来展望","children":[{"level":3,"title":"论文贡献总结","slug":"论文贡献总结","link":"#论文贡献总结","children":[]},{"level":3,"title":"方法优势与不足","slug":"方法优势与不足","link":"#方法优势与不足","children":[]},{"level":3,"title":"未来研究方向","slug":"未来研究方向","link":"#未来研究方向","children":[]},{"level":3,"title":"参考链接","slug":"参考链接","link":"#参考链接","children":[]}]}],"readingTime":{"minutes":7.94,"words":2382},"filePathRelative":"zh/posts/papers/hunyuancustom.md","excerpt":"\\n<h2>摘要</h2>\\n<p>本文精读腾讯AI Lab发布的混元自定义(HunyuanCustom)技术，该方法通过轻量级训练框架实现大模型的高效个性化定制。腾讯团队采用LoRA与量化蒸馏相结合的方案，在保持原始模型能力的基础上，显著降低了垂直领域模型的训练与部署成本，为企业级大模型应用提供了完整技术方案，支持数据准备、训练推理和效果评测全流程。</p>\\n<figure><img src=\\"https://arxiv.org/html/2505.04512v1/x1.png\\" alt=\\"混元定制化支持多种输入模态的视频生成，包括文本、图像、音频和视频条件\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>混元定制化支持多种输入模态的视频生成，包括文本、图像、音频和视频条件</figcaption></figure>","autoDesc":true}')}}]);