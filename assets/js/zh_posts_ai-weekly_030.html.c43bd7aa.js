"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[5483],{6262:(e,r)=>{r.A=(e,r)=>{const t=e.__vccOpts||e;for(const[e,i]of r)t[e]=i;return t}},840:(e,r,t)=>{t.r(r),t.d(r,{comp:()=>n,data:()=>s});var i=t(641);const a={},n=(0,t(6262).A)(a,[["render",function(e,r){return(0,i.uX)(),(0,i.CE)("div",null,r[0]||(r[0]=[(0,i.Fv)('<h1 id="recammaster重塑视频视角-pladis优化diffusion推理-impossible-videos探索反现实【ai周报】" tabindex="-1"><a class="header-anchor" href="#recammaster重塑视频视角-pladis优化diffusion推理-impossible-videos探索反现实【ai周报】"><span>ReCamMaster重塑视频视角 | PLADIS优化Diffusion推理 | Impossible Videos探索反现实【AI周报】</span></a></h1><figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0f0f3d34-216b-4954-bede-82cc10657d8d/original=true,quality=90/00178-3302738830-masterpiece, best quality, good quality, very aesthetic, absurdres, newest, 8K, depth of field, focused subject, dynamic ange, w.jpeg" alt="封面源自C站作者Koal2" tabindex="0" loading="lazy"><figcaption>封面源自C站作者Koal2</figcaption></figure><h2 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span>摘要</span></a></h2><p>本周亮点：ReCamMaster通过摄像机轨迹调整实现视频再渲染；PLADIS采用稀疏注意力优化扩散推理；Impossible Videos提出IPV-Bench评估体系，探索反现实视频生成；Hunyuan3D2.0高效生成高精度3D资产。</p><hr><h2 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span>目录</span></a></h2><ol><li><a href="#recammaster%E4%BB%8E%E5%8D%95%E4%B8%AA%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90%E6%96%B0%E8%A7%86%E8%A7%92%E5%92%8C%E8%BF%90%E5%8A%A8%E8%BD%A8%E8%BF%B9%E8%A7%86%E9%A2%91%E7%9A%84%E6%A1%86%E6%9E%B6">ReCamMaster：从单个视频生成新视角和运动轨迹视频的框架</a></li><li><a href="#pladis%E5%88%A9%E7%94%A8%E7%A8%80%E7%96%8F%E6%80%A7%E5%9C%A8%E6%8E%A8%E7%90%86%E9%98%B6%E6%AE%B5%E7%AA%81%E7%A0%B4diffusion%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E9%99%90%E5%88%B6">PLADIS：利用稀疏性在推理阶段突破Diffusion模型中的注意力限制</a></li><li><a href="#personalize-anything%E5%9F%BA%E4%BA%8Ediffusion-transformer%E7%9A%84%E4%B8%AA%E6%80%A7%E5%8C%96%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90">Personalize Anything：基于Diffusion Transformer的个性化图像生成</a></li><li><a href="#impossible-videos%E6%8E%A2%E7%B4%A2%E5%8F%8D%E4%BA%8B%E5%AE%9E%E4%B8%8E%E5%8F%8D%E7%8E%B0%E5%AE%9E%E8%A7%86%E9%A2%91%E7%9A%84%E7%94%9F%E6%88%90%E4%B8%8E%E7%90%86%E8%A7%A3">Impossible Videos：探索反事实与反现实视频的生成与理解</a></li><li><a href="#hunyuan3d-20%E8%85%BE%E8%AE%AF%E6%8E%A8%E5%87%BA%E7%9A%84%E9%AB%98%E7%B2%BE%E5%BA%A63d%E8%B5%84%E4%BA%A7%E7%94%9F%E6%88%90%E7%B3%BB%E7%BB%9F">Hunyuan3D 2.0：腾讯推出的高精度3D资产生成系统</a></li><li><a href="#starvector%E4%BB%8E%E5%9B%BE%E5%83%8F%E5%92%8C%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E5%8F%AF%E7%BC%A9%E6%94%BE%E7%9F%A2%E9%87%8F%E5%9B%BE%E5%BD%A2%E4%BB%A3%E7%A0%81">StarVector：从图像和文本生成可缩放矢量图形代码</a></li></ol><hr><h2 id="recammaster-从单个视频生成新视角和运动轨迹视频的框架" tabindex="-1"><a class="header-anchor" href="#recammaster-从单个视频生成新视角和运动轨迹视频的框架"><span>ReCamMaster：从单个视频生成新视角和运动轨迹视频的框架</span></a></h2><figure><img src="https://jianhongbai.github.io/ReCamMaster/pics/fig_pipe.png" alt="ReCamMaster Pipeline 图" tabindex="0" loading="lazy"><figcaption>ReCamMaster Pipeline 图</figcaption></figure><p><strong>概要</strong>：<strong>ReCamMaster</strong> 是由 <strong>浙江大学</strong>、<strong>快手科技</strong>、<strong>香港中文大学</strong> 和 <strong>华中科技大学</strong> 联合开发的创新框架，旨在从单个视频生成具有新视角和运动轨迹的视频内容。该框架利用预训练的文本到视频生成模型，并通过精心设计的视频条件机制，实现高质量的视频重渲染。其主要功能包括相机轨迹控制（如平移、旋转、缩放等）、高质量视频生成以及支持大规模数据集。ReCamMaster 可应用于视频稳定化、视频超分辨率、自动驾驶和机器人视觉，以及视频创作和后期制作等领域。</p><p><strong>标签</strong>：#视频生成 #新视角 #相机轨迹控制 #视频重渲染 #多视角数据增强</p><hr><h2 id="pladis-利用稀疏性在推理阶段突破diffusion模型中的注意力限制" tabindex="-1"><a class="header-anchor" href="#pladis-利用稀疏性在推理阶段突破diffusion模型中的注意力限制"><span>PLADIS：利用稀疏性在推理阶段突破Diffusion模型中的注意力限制</span></a></h2><figure><img src="https://cubeyoung.github.io/pladis-proejct/main_1.jpg" alt="PLADIS Comparison 图" tabindex="0" loading="lazy"><figcaption>PLADIS Comparison 图</figcaption></figure><p><strong>概要</strong>：<strong>PLADIS</strong> 是由 <strong>三星研究院</strong> 提出的一种创新方法，旨在通过在推理阶段利用稀疏注意力机制，提升预训练Diffusion模型（如 U-Net/Transformer）的性能。具体而言，PLADIS 在推理过程中，对交叉注意力层中的查询-键相关性进行外推，无需额外训练或增加神经函数评估（NFEs）。通过利用稀疏注意力的抗噪性，PLADIS 释放了文本到图像Diffusion模型的潜力，使其在之前表现欠佳的领域取得显著效果。该方法可无缝集成到现有的引导技术中，包括引导蒸馏模型。大量实验表明，PLADIS 在文本对齐和人类偏好方面取得了显著改进，提供了一种高效且普遍适用的解决方案。</p><p><strong>标签</strong>：#Diffusion模型 #稀疏注意力 #推理优化 #文本到图像生成 #模型增强</p><hr><h2 id="personalize-anything-基于diffusion-transformer的个性化图像生成" tabindex="-1"><a class="header-anchor" href="#personalize-anything-基于diffusion-transformer的个性化图像生成"><span>Personalize Anything：基于Diffusion Transformer的个性化图像生成</span></a></h2><figure><img src="https://fenghora.github.io/Personalize-Anything-Page/images/teaser.png" alt="Personalize Anything Teaser 图" tabindex="0" loading="lazy"><figcaption>Personalize Anything Teaser 图</figcaption></figure><p><strong>概要</strong>：<strong>Personalize Anything</strong> 是由 <strong>清华大学</strong>、<strong>北京航空航天大学</strong> 和 <strong>中国人民大学</strong> 等机构联合推出的创新框架，旨在利用Diffusion Transformer（DiT）实现个性化的图像生成。该方法通过在DiT中引入时间步自适应的标记替换策略和补丁扰动技术，在无需训练的情况下，实现了对特定主体的高保真图像生成。这一框架支持布局引导生成、多主体个性化以及掩码控制编辑等多种应用场景，展现了在身份保持和多样性方面的卓越性能。</p><p><strong>标签</strong>：#Personalize Anything #Diffusion Transformer #无训练框架 #标记替换 #补丁扰动</p><hr><h2 id="impossible-videos-探索反事实与反现实视频的生成与理解" tabindex="-1"><a class="header-anchor" href="#impossible-videos-探索反事实与反现实视频的生成与理解"><span>Impossible Videos：探索反事实与反现实视频的生成与理解</span></a></h2><figure><img src="https://arxiv.org/html/2503.14378v1/x1.png" alt="Impossible Videos Examples 图" tabindex="0" loading="lazy"><figcaption>Impossible Videos Examples 图</figcaption></figure><p><strong>概要</strong>：<strong>Impossible Videos</strong> 是由 <strong>新加坡国立大学 Show Lab</strong> 提出的创新研究，旨在探索生成和理解违反物理、生物、地理或社会规律的反事实与反现实视频内容。研究团队构建了一个名为 <strong>IPV-Bench</strong> 的基准，包括涵盖4个领域、14个类别的分类体系，以及用于评估视频生成模型的提示集和用于评估视频理解模型的视频基准。通过对现有视频生成和理解模型的综合评估，研究揭示了这些模型在处理不可能视频内容时的局限性，并为未来的视频模型研究指明了方向。</p><p><strong>标签</strong>：#Show lab #视频生成 #视频理解 #IPV-Bench #反事实</p><hr><h2 id="hunyuan3d-2-0-腾讯推出的高精度3d资产生成系统" tabindex="-1"><a class="header-anchor" href="#hunyuan3d-2-0-腾讯推出的高精度3d资产生成系统"><span>Hunyuan3D 2.0：腾讯推出的高精度3D资产生成系统</span></a></h2><figure><img src="https://github.com/Tencent/Hunyuan3D-2/raw/main/assets/images/arch.jpg" alt="Hunyuan3D 2.0 Architecture 图" tabindex="0" loading="lazy"><figcaption>Hunyuan3D 2.0 Architecture 图</figcaption></figure><p><strong>概要</strong>：<strong>Hunyuan3D 2.0</strong> 是由 <strong>腾讯</strong> 推出的开源3D生成大模型，采用几何与纹理分离的两阶段架构，专注于从文本和图像高效生成高分辨率3D模型。 该系统首先生成无纹理的几何模型，然后合成高分辨率纹理贴图，有效提升了3D生成的精度与效率。其性能在几何细节、条件对齐和纹理质量等方面表现出色，超越了现有的开源和闭源模型。</p><p><strong>标签</strong>：#3D生成 #开源模型 #几何与纹理分离 #高分辨率 #腾讯</p><hr><h2 id="starvector-从图像和文本生成可缩放矢量图形代码" tabindex="-1"><a class="header-anchor" href="#starvector-从图像和文本生成可缩放矢量图形代码"><span>StarVector：从图像和文本生成可缩放矢量图形代码</span></a></h2><figure><img src="https://starvector.github.io/static/images/starvector-teaser.png" alt="StarVector 示例图" tabindex="0" loading="lazy"><figcaption>StarVector 示例图</figcaption></figure><p><strong>概要</strong>：<strong>StarVector</strong> 是由 <strong>Mila – 魁北克人工智能研究所</strong> 等机构提出的一种多模态大型语言模型，旨在从图像和文本生成可缩放矢量图形（SVG）代码。该模型利用 CLIP 图像编码器提取视觉表示，通过适配器模块将其转换为视觉标记，并结合 StarCoder 模型生成精确的 SVG 代码。为训练 StarVector，研究团队构建了包含 200 万个样本的多样化数据集 SVG-Stack，使模型能够广泛泛化于矢量化任务，并精确使用椭圆、多边形和文本等 SVG 基元。实验结果表明，StarVector 在视觉质量和复杂性处理方面实现了最新性能，生成的 SVG 更加紧凑且语义丰富。</p><h2 id="标签-svg生成-多模态模型-大型语言模型-图像矢量化-视觉质量" tabindex="-1"><a class="header-anchor" href="#标签-svg生成-多模态模型-大型语言模型-图像矢量化-视觉质量"><span><strong>标签</strong>：#SVG生成 #多模态模型 #大型语言模型 #图像矢量化 #视觉质量</span></a></h2><h3 id="参考链接" tabindex="-1"><a class="header-anchor" href="#参考链接"><span><strong>参考链接</strong></span></a></h3><ol><li><a href="https://jianhongbai.github.io/ReCamMaster/" target="_blank" rel="noopener noreferrer">ReCamMaster 官网</a></li><li><a href="https://github.com/KwaiVGI/ReCamMaster" target="_blank" rel="noopener noreferrer">ReCamMaster GitHub</a></li><li><a href="https://arxiv.org/html/2503.11647v1" target="_blank" rel="noopener noreferrer">ReCamMaster 论文</a></li><li><a href="https://cubeyoung.github.io/pladis-proejct/" target="_blank" rel="noopener noreferrer">PLADIS 官网</a></li><li><a href="https://github.com/cubeyoung/PLADIS" target="_blank" rel="noopener noreferrer">PLADIS GitHub</a></li><li><a href="https://arxiv.org/html/2503.07677v2" target="_blank" rel="noopener noreferrer">PLADIS 论文</a></li><li><a href="https://fenghora.github.io/Personalize-Anything-Page/" target="_blank" rel="noopener noreferrer">Personalize Anything 官网</a></li><li><a href="https://github.com/fenghora/personalize-anything" target="_blank" rel="noopener noreferrer">Personalize Anything GitHub</a></li><li><a href="https://arxiv.org/html/2503.12590v1" target="_blank" rel="noopener noreferrer">Personalize Anything 论文</a></li><li><a href="https://showlab.github.io/Impossible-Videos/" target="_blank" rel="noopener noreferrer">Impossible Videos 官网</a></li><li><a href="https://github.com/showlab/Impossible-Videos" target="_blank" rel="noopener noreferrer">Impossible Videos GitHub</a></li><li><a href="https://arxiv.org/html/2503.14378v1" target="_blank" rel="noopener noreferrer">Impossible Videos 论文</a></li><li><a href="https://bytedance.github.io/InfiniteYou/" target="_blank" rel="noopener noreferrer">InfiniteYou 官网</a></li><li><a href="https://github.com/bytedance/InfiniteYou" target="_blank" rel="noopener noreferrer">InfiniteYou GitHub</a></li><li><a href="https://arxiv.org/html/2503.16418v1" target="_blank" rel="noopener noreferrer">InfiniteYou 论文</a></li><li><a href="https://3d.hunyuan.tencent.com/" target="_blank" rel="noopener noreferrer">Hunyuan3D 2.0 官网</a></li><li><a href="https://github.com/Tencent/Hunyuan3D-2" target="_blank" rel="noopener noreferrer">Hunyuan3D 2.0 GitHub</a></li><li><a href="https://starvector.github.io/" target="_blank" rel="noopener noreferrer">StarVector 官网</a></li><li><a href="https://github.com/joanrod/star-vector" target="_blank" rel="noopener noreferrer">StarVector GitHub</a></li><li><a href="https://arxiv.org/html/2312.11556v3" target="_blank" rel="noopener noreferrer">StarVector 论文</a></li></ol>',39)]))}]]),s=JSON.parse('{"path":"/zh/posts/ai-weekly/030.html","title":"ReCamMaster重塑视频视角 | PLADIS优化Diffusion推理 | Impossible Videos探索反现实【AI周报】","lang":"zh-CN","frontmatter":{"description":"ReCamMaster重塑视频视角 | PLADIS优化Diffusion推理 | Impossible Videos探索反现实【AI周报】 封面源自C站作者Koal2封面源自C站作者Koal2 摘要 本周亮点：ReCamMaster通过摄像机轨迹调整实现视频再渲染；PLADIS采用稀疏注意力优化扩散推理；Impossible Videos提出IPV-...","gitInclude":[],"head":[["meta",{"property":"og:url","content":"https://neverbiasu.github.io/zh/posts/ai-weekly/030.html"}],["meta",{"property":"og:site_name","content":"Nlog"}],["meta",{"property":"og:title","content":"ReCamMaster重塑视频视角 | PLADIS优化Diffusion推理 | Impossible Videos探索反现实【AI周报】"}],["meta",{"property":"og:description","content":"ReCamMaster重塑视频视角 | PLADIS优化Diffusion推理 | Impossible Videos探索反现实【AI周报】 封面源自C站作者Koal2封面源自C站作者Koal2 摘要 本周亮点：ReCamMaster通过摄像机轨迹调整实现视频再渲染；PLADIS采用稀疏注意力优化扩散推理；Impossible Videos提出IPV-..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0f0f3d34-216b-4954-bede-82cc10657d8d/original=true,quality=90/00178-3302738830-masterpiece,%20best%20quality,%20good%20quality,%20very%20aesthetic,%20absurdres,%20newest,%208K,%20depth%20of%20field,%20focused%20subject,%20dynamic%20ange,%20w.jpeg"}],["meta",{"property":"og:locale","content":"zh-CN"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"ReCamMaster重塑视频视角 | PLADIS优化Diffusion推理 | Impossible Videos探索反现实【AI周报】\\",\\"image\\":[\\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0f0f3d34-216b-4954-bede-82cc10657d8d/original=true,quality=90/00178-3302738830-masterpiece,%20best%20quality,%20good%20quality,%20very%20aesthetic,%20absurdres,%20newest,%208K,%20depth%20of%20field,%20focused%20subject,%20dynamic%20ange,%20w.jpeg\\",\\"https://jianhongbai.github.io/ReCamMaster/pics/fig_pipe.png\\",\\"https://cubeyoung.github.io/pladis-proejct/main_1.jpg\\",\\"https://fenghora.github.io/Personalize-Anything-Page/images/teaser.png\\",\\"https://arxiv.org/html/2503.14378v1/x1.png\\",\\"https://github.com/Tencent/Hunyuan3D-2/raw/main/assets/images/arch.jpg\\",\\"https://starvector.github.io/static/images/starvector-teaser.png\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"neverbiasu\\",\\"url\\":\\"https://neverbiasu.github.io\\"}]}"]]},"headers":[{"level":2,"title":"摘要","slug":"摘要","link":"#摘要","children":[]},{"level":2,"title":"目录","slug":"目录","link":"#目录","children":[]},{"level":2,"title":"ReCamMaster：从单个视频生成新视角和运动轨迹视频的框架","slug":"recammaster-从单个视频生成新视角和运动轨迹视频的框架","link":"#recammaster-从单个视频生成新视角和运动轨迹视频的框架","children":[]},{"level":2,"title":"PLADIS：利用稀疏性在推理阶段突破Diffusion模型中的注意力限制","slug":"pladis-利用稀疏性在推理阶段突破diffusion模型中的注意力限制","link":"#pladis-利用稀疏性在推理阶段突破diffusion模型中的注意力限制","children":[]},{"level":2,"title":"Personalize Anything：基于Diffusion Transformer的个性化图像生成","slug":"personalize-anything-基于diffusion-transformer的个性化图像生成","link":"#personalize-anything-基于diffusion-transformer的个性化图像生成","children":[]},{"level":2,"title":"Impossible Videos：探索反事实与反现实视频的生成与理解","slug":"impossible-videos-探索反事实与反现实视频的生成与理解","link":"#impossible-videos-探索反事实与反现实视频的生成与理解","children":[]},{"level":2,"title":"Hunyuan3D 2.0：腾讯推出的高精度3D资产生成系统","slug":"hunyuan3d-2-0-腾讯推出的高精度3d资产生成系统","link":"#hunyuan3d-2-0-腾讯推出的高精度3d资产生成系统","children":[]},{"level":2,"title":"StarVector：从图像和文本生成可缩放矢量图形代码","slug":"starvector-从图像和文本生成可缩放矢量图形代码","link":"#starvector-从图像和文本生成可缩放矢量图形代码","children":[]},{"level":2,"title":"标签：#SVG生成 #多模态模型 #大型语言模型 #图像矢量化 #视觉质量","slug":"标签-svg生成-多模态模型-大型语言模型-图像矢量化-视觉质量","link":"#标签-svg生成-多模态模型-大型语言模型-图像矢量化-视觉质量","children":[{"level":3,"title":"参考链接","slug":"参考链接","link":"#参考链接","children":[]}]}],"readingTime":{"minutes":6.14,"words":1841},"filePathRelative":"zh/posts/ai-weekly/030.md","excerpt":"\\n<figure><img src=\\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0f0f3d34-216b-4954-bede-82cc10657d8d/original=true,quality=90/00178-3302738830-masterpiece, best quality, good quality, very aesthetic, absurdres, newest, 8K, depth of field, focused subject, dynamic ange, w.jpeg\\" alt=\\"封面源自C站作者Koal2\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>封面源自C站作者Koal2</figcaption></figure>","autoDesc":true}')}}]);