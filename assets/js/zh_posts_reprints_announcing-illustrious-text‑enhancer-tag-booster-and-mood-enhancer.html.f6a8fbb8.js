"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[5731],{66262:(t,o)=>{o.A=(t,o)=>{const r=t.__vccOpts||t;for(const[t,e]of o)r[t]=e;return r}},86269:(t,o,r)=>{r.r(o),r.d(o,{comp:()=>s,data:()=>a});var e=r(20641);const n={},s=(0,r(66262).A)(n,[["render",function(t,o){const r=(0,e.g2)("center");return(0,e.uX)(),(0,e.CE)("div",null,[o[2]||(o[2]=(0,e.Fv)('<h1 id="发布-illustrious-text‐enhancer-tag-booster-和-mood-enhancer" tabindex="-1"><a class="header-anchor" href="#发布-illustrious-text‐enhancer-tag-booster-和-mood-enhancer"><span>发布 Illustrious Text‑Enhancer：Tag Booster 和 Mood Enhancer</span></a></h1><p>Illustrious 用户经常问：&quot;<em>如何在不编写冗长 Prompt 的情况下获得更好的结果？</em>&quot; 今天，我们很兴奋地通过 <strong>Text‑Enhancer</strong> 来回答这个问题，这是一个新系统，可以显著<strong>丰富用户 Prompt</strong>，用于我们的图像生成平台。</p><p>Text‑Enhancer 包含<strong>两个智能组件</strong>协同工作：</p><ol><li><strong>Tag Booster：</strong> 基于我们的 TIPO（Text-to-Image Prompt Optimization）框架构建的 Prompt 增强工具。它<strong>扩展短或稀疏的 Prompt</strong>（无论是标签还是纯文本），通过将它们与我们模型训练数据中看到的分布对齐。结果是更高保真度的图像和更紧密的 Prompt-图像对齐。</li><li><strong>Mood Enhancer：</strong> 基于自定义 LLM 的管道，<strong>将最少的输入转换为详细、引人注目的图像 Prompt</strong>。通过利用固定的系统 Prompt 和少量示例（配合先进的 KV 缓存策略），它可以从稀疏输入生成丰富的描述，<strong>成本和延迟仅为通常 LLM 的一小部分</strong>。</li></ol><p>Together, Tag Booster 和 Mood Enhancer <strong>减轻了创作者</strong>手工制作冗长 Prompt 的负担，同时<strong>持续产生更高质量、更符合目标的生成结果</strong>。在这篇文章中，我们将深入探讨每个组件的工作原理、底层的技术创新（从<strong>多任务 Prompt 模型</strong>到 <strong>LLM KV 缓存</strong>），以及为什么这对 Illustrious 用户来说是一个游戏规则改变者。</p><hr><h2 id="从稀疏到丰富-tag-booster-如何通过-tipo-丰富-prompt" tabindex="-1"><a class="header-anchor" href="#从稀疏到丰富-tag-booster-如何通过-tipo-丰富-prompt"><span>从稀疏到丰富：Tag Booster 如何通过 TIPO 丰富 Prompt</span></a></h2><p>从一行 Prompt 创建生动的图像是具有挑战性的——像 Illustrious XL 这样的扩散模型是在 Prompt/说明具有一定丰富性和多样性的数据集上训练的。<strong>Tag Booster</strong> 通过<strong>自动扩展和优化您的 Prompt</strong> 使其更像训练分布中的那些来弥补这一差距。它由我们内部的 <strong>TIPO 框架</strong>提供支持，这是一个专为 Prompt 优化而构建的轻量级多任务语言模型。</p><figure><img src="https://neverbiasu.github.io/assets/images/reprints/illustrious/tag-enhancer/tipo-architecture.png" alt="TIPO Architecture" tabindex="0" loading="lazy"><figcaption>TIPO Architecture</figcaption></figure><h3 id="什么是-tipo" tabindex="-1"><a class="header-anchor" href="#什么是-tipo"><span>什么是 TIPO？</span></a></h3><p>TIPO 代表 <strong>Text-to-Image Prompt Optimization</strong>——一种与多模态模型的杰出外部研究人员合作开发的新方法。与强力 Prompt 工程或昂贵的大语言模型方法不同，TIPO 使用一个<strong>小型、高效的模型</strong>（数亿参数，而不是数百亿）在 <strong>Prompt 对上训练</strong>。本质上，它学会了接受简单的 Prompt 并输出更丰富的 Prompt。从概念上讲，它&quot;<strong>从 Prompt 空间的目标子分布中采样精炼的 Prompt</strong>&quot;，这意味着它添加了我们扩散模型期望的细节类型，<strong>在保持原始意图的同时</strong>。与使用原始 Prompt 相比，这产生了<em>显著改善的视觉质量、连贯性和细节</em>。</p><h3 id="联合任务训练-tags-↔-text" tabindex="-1"><a class="header-anchor" href="#联合任务训练-tags-↔-text"><span>联合任务训练（Tags ↔ Text）</span></a></h3><p>Tag Booster 的 TIPO 模型的一个关键创新是它是<strong>联合任务</strong>的——它可以处理<strong>标签列表和自然语言</strong>并将一个转换为另一个。在训练期间，我们给 TIPO 两种任务： <strong>&quot;标签到文本&quot;</strong> （例如，取一系列简洁的标签并产生完整的描述性句子）和 <strong>&quot;文本到标签&quot;</strong> （取一个短句并预测重要的标签或关键词）。通过学习两个方向，模型发展了对 Prompt 语义的灵活理解。在实践中，这意味着 <strong>Tag Booster 可以解释您的输入格式</strong> 并适当地丰富它：</p><ol><li>如果您提供标签列表或几个词，它将<strong>添加高影响力的视觉标签</strong>，这些标签在训练数据中与这些概念在统计上相关。</li><li>如果您提供短句，它将<strong>用额外的描述符或风格关键词扩展它</strong>，有效地将自由形式的文本翻译成增强的富标签 Prompt。</li></ol><p>例如，想象您只输入 <strong>&quot;an autumn forest&quot;</strong> 。这很短，可能产生一般性的结果。Tag Booster 可能将其丰富为：</p><ol><li><strong>输入：</strong> an autumn forest</li><li><strong>Tag Booster 输出：</strong> an autumn forest, golden sunlight, falling leaves, high detail, masterpiece, warm colors</li></ol><figure><img src="https://neverbiasu.github.io/assets/images/reprints/illustrious/tag-enhancer/tag-booster-compare.jpg" alt="Tag Booster Example Comparison" tabindex="0" loading="lazy"><figcaption>Tag Booster Example Comparison</figcaption></figure><p>通过添加细节（&quot;golden sunlight&quot;、&quot;falling leaves&quot;）和风格标签（&quot;high detail, masterpiece&quot;），Prompt 现在更好地匹配我们模型的训练内容。这些额外的提示帮助扩散模型<strong>专注于预期的场景和美学</strong>。在内部测试中，这种方法在<strong>图像质量方面取得了显著提升</strong>——我们的评估者看到了<em>更生动的色彩、更少的伪影，以及与 Prompt 意图更紧密对齐的构图</em>。这与 TIPO 研究的发现相呼应，该研究报告了使用此类 Prompt 优化时&quot;<em>美学质量的显著改善、视觉伪影的显著减少，以及与目标分布的增强对齐</em>&quot;。</p><p>更重要的是，Tag Booster 运行<strong>极其快速</strong>。因为 TIPO 非常轻量级，添加这一步不会以任何明显的方式减慢生成速度——丰富 Prompt 只需几分之一秒。与仅仅附加固定&quot;魔法关键词&quot;集合的启发式方法不同，Tag Booster 是<strong>上下文感知的</strong>：它根据<strong>您的特定 Prompt</strong> 内容定制添加内容。增强的 Prompt 仍然感觉像是您想要的自然延伸，只是有更多细节和清晰度。最终结果是<strong>用户以最少的额外努力获得更高保真度的图像</strong>，让即使是一个词的 Prompt 也能闪耀，就像它们被精心设计的一样。</p><hr><h2 id="用更少努力创造生动叙述-mood-enhancer-和-llm-驱动的扩展" tabindex="-1"><a class="header-anchor" href="#用更少努力创造生动叙述-mood-enhancer-和-llm-驱动的扩展"><span>用更少努力创造生动叙述：Mood Enhancer 和 LLM 驱动的扩展</span></a></h2><p>虽然 Tag Booster 擅长<strong>添加相关关键词和标签</strong>，我们也想帮助那些喜欢<strong>自然语言 Prompt</strong> 或对其图像有特定<em>氛围或故事</em>想法的用户。这就是 <strong>Mood Enhancer</strong> 发挥作用的地方。Mood Enhancer 使用<strong>自定义大语言模型 (LLM) 管道</strong>将<strong>简短想法转换为丰富、有氛围的 Prompt</strong>。如果 Tag Booster 关注<strong>精确性和保真度</strong>，Mood Enhancer 关注<strong>创造力和故事叙述</strong>，为 Prompt 注入生动的场景描述、背景和情感基调。</p><h3 id="工作原理" tabindex="-1"><a class="header-anchor" href="#工作原理"><span>工作原理</span></a></h3><p>我们为 LLM 制作了一个特殊的<strong>系统 prompt</strong>，配合一组<strong>少样本示例</strong>，让它学习理想 Illustrious prompt 的风格。例如，系统 prompt 可能说 <em>&quot;You are an art assistant that transforms short prompts into detailed visual descriptions. Include imaginative details and create atmosphere.&quot;</em> 然后我们提供一些转换示例（就像向模型展示 prompt 的前后对比）。有了这个固定的 prompt 模板，当用户提供输入时，LLM 将按照这些示例生成<strong>详细的 prompt</strong>。</p><p>考虑用户输入：<strong>&quot;futuristic city at night&quot;</strong>。这是一个很酷的概念，但相当高层次。Mood Enhancer 会将其转换为：</p><blockquote><p>&quot;A sprawling futuristic cityscape at night, with neon-lit skyscrapers and flying vehicles weaving between the buildings. The streets below are illuminated by holographic billboards and reflected lights. Rain-soaked atmosphere and puddles reflecting neon signs add a cyberpunk mood.&quot;</p></blockquote><p>注意稀疏的想法如何变成<strong>迷你故事</strong>：它保留了核心（&quot;futuristic city at night&quot;），但添加了具体的视觉元素（霓虹灯、摩天大楼、全息广告牌）和氛围（雨天、赛博朋克氛围）。这种丰富的 prompt 可以引导扩散模型生成感觉像科幻电影画面的图像，而不是普通的城市。<strong>氛围的天赋</strong>和<strong>具体细节</strong>正是 Mood Enhancer 设计注入的。</p><figure><img src="https://neverbiasu.github.io/assets/images/reprints/illustrious/tag-enhancer/mood-enhancer-compare.jpg" alt="Mood Enhancer Comparison" tabindex="0" loading="lazy"><figcaption>Mood Enhancer Comparison</figcaption></figure><hr><h2 id="kv-缓存-超级增强-llm-效率" tabindex="-1"><a class="header-anchor" href="#kv-缓存-超级增强-llm-效率"><span>KV 缓存：超级增强 LLM 效率</span></a></h2><p>使用 LLM 扩展 prompt 引起了一个担忧：<strong>成本和速度</strong>。高质量的 LLM（具有大参数数量）运行可能缓慢或昂贵，特别是如果每次都要提供长系统 prompt 和示例。我们通过一个巧妙的优化解决了这个挑战：<strong>Key-Value 缓存重用</strong>用于 LLM 的 prompt。这种技术受到 LLM 部署的最新进展启发（甚至 Anthropic 的 Claude API 也引入了类似的 <em>prompt 缓存</em> 功能来减少多达 90% 的成本）。</p><figure><img src="https://neverbiasu.github.io/assets/images/reprints/illustrious/tag-enhancer/kv-caching2.jpg" alt="KV Caching Efficiency" tabindex="0" loading="lazy"><figcaption>KV Caching Efficiency</figcaption></figure><h3 id="什么是-kv-缓存" tabindex="-1"><a class="header-anchor" href="#什么是-kv-缓存"><span>什么是 KV 缓存？</span></a></h3><p>在自回归生成期间，LLM 构建内部 <strong>Key</strong> 和 <strong>Value</strong> 张量（自注意力机制的&quot;记忆&quot;），当它们消费 prompt token 时。通常，如果每次都重新生成，您需要为每个请求支付所有 prompt token 的计算成本。但是如果 prompt 的大部分<strong>总是相同的</strong>（在我们的情况下，Mood Enhancer 的系统消息和少样本示例是固定的），我们可以<strong>缓存其 KV 状态</strong>一次并重复使用。在实践中，我们通过静态 prompt 部分运行 LLM <strong>一次</strong>（每会话或服务器预热），并存储每个 transformer 层的结果键值对。然后对于每个新用户输入，我们 <em>用这个缓存的 KV 初始化 LLM 的状态</em> 并从前缀末尾开始生成，就好像模型&quot;已经看到了&quot;系统 prompt 和示例。</p><p>这产生了<strong>巨大的效率提升</strong>。Mood Enhancer 的<strong>固定 prompt</strong> 可能相当长（比如说，500 个指令和示例 token 来确保高质量输出）。使用 KV 缓存，这 500 个 token 只处理一次；后续 prompt 只产生新用户输入（可能 5-50 个 token）加上输出 token 的计算。在我们的测试中，这将<strong>LLM 推理成本降至</strong>每次生成朴素成本的约 20%——有效地减少了 80% 的成本和显著的加速，而输出质量没有任何损失。这些数字与行业报告一致，prompt 缓存在某些场景中可以减少 <em>多达 90%</em> 的输入成本。</p><h3 id="技术洞察-使其工作" tabindex="-1"><a class="header-anchor" href="#技术洞察-使其工作"><span>技术洞察 - 使其工作</span></a></h3><p>以稳健的方式实现 KV 缓存需要处理一些 <strong>LLM 内部机制</strong>。现代 transformer 模型（包括我们用于 Mood Enhancer 的模型）经常对 token 使用<strong>旋转位置嵌入</strong>。这种相对定位方案对于处理长上下文很好，但我们必须确保我们的缓存机制<strong>保持位置一致性</strong>。简单来说，当我们缓存前缀时，模型已经为这些 token 分配了某些位置相位；当我们稍后附加用户的 token 时，我们必须<strong>无缝地继续位置编码</strong>，以便模型将其视为一个连续序列。我们通过在生成期间仔细管理位置索引来解决这个问题——本质上，模型在前缀和用户输入之间永远不会&quot;重置&quot;，因此没有错位的机会。</p><p>另一个挑战是处理标准生成管道中的<strong>基于前缀的限制</strong>。现成的 API 或库通常假设您一次提供整个 prompt；它们不是为让您注入预计算前缀而设计的。为了克服这一点，我们集成了低级支持，允许在生成时将缓存的键和值反馈到模型中。我们的解决方案类似于最新 LLM API 现在提供的 prompt 缓存，但我们为我们的管道定制构建了它。我们还小心地锁定前缀的确切<strong>分词</strong>，以便用户输入中的任何内容都不会无意中改变 prompt 的解析方式（这是一个罕见的边缘情况，但我们彻底验证了）。通过这些工程修复，Mood Enhancer 可以在许多生成中安全地重用其 prompt 上下文。</p><p>结果？Mood Enhancer 转换的<strong>显著更低延迟和成本</strong>，使我们能够向用户提供此功能<strong>而没有明显的延迟</strong>。您实际上免费获得大模型 prompt 头脑风暴的好处，因为繁重的工作被摊销了。</p><hr><h2 id="text‐enhancer-实际应用-以最少努力获得更好的图像" tabindex="-1"><a class="header-anchor" href="#text‐enhancer-实际应用-以最少努力获得更好的图像"><span>Text‑Enhancer 实际应用：以最少努力获得更好的图像</span></a></h2><p>通过结合 Tag Booster 和 Mood Enhancer，Illustrious 的 Text‑Enhancer 系统确保<strong>任何用户输入，无论多么简单，都能发展成用于图像生成的强大 prompt</strong>。这一切都在幕后完成——您可以开启这些增强器，输入几个词，并获得精美详细的 prompt 和令人惊艳的图像。</p><p>让我们通过一个假设的例子来看看端到端的效果：</p><ol><li><strong>用户输入：</strong> a lonely castle on a hill <em>只是一个简单的描述——富有感染力，但稀疏。用户没有指定风格、照明或周围细节。</em></li><li><strong>经过 Tag Booster：</strong> a lonely castle on a hill, medieval fortress, stormy sky, dusk, high resolution, epic scale <em>Tag Booster 识别了主题并添加了关键视觉标签：城堡被识别为中世纪堡垒，添加了可能的设置（黄昏阴云天空）以营造氛围，以及与我们戏剧性风景训练数据对齐的风格标签如&quot;高分辨率，史诗级规模&quot;。</em></li><li><strong>经过 Mood Enhancer：</strong> &quot;A <strong>lonely medieval castle</strong> perches atop a mist-shrouded hill beneath a <strong>stormy dusk sky</strong>. The ancient stone fortress is illuminated by the last rays of twilight, its silhouette standing in <strong>epic scale</strong> against the darkening valley below. <strong>Dramatic clouds</strong> roil overhead while wisps of fog cling to the ground, evoking a sense of <strong>mystery and grandeur</strong>.&quot;</li></ol><p><em>Mood Enhancer 将标签编织成丰富的叙述。它保留了所有关键元素（城堡、山丘、阴云黄昏）并增强了它们：我们现在可以<strong>感受到氛围</strong>并在脑海中看到场景。</em></p><p>现在想象将最终增强的 prompt 输入 Illustrious XL。输出的差异是天壤之别。事实上，我们内部测试了这一点：</p><ol><li>没有 Text‑Enhancer，prompt &quot;a lonely castle on a hill&quot; 产生了一个非常普通的城堡图像，天空平淡。</li><li><strong>使用 Text‑Enhancer，生成的图像要戏剧性和详细得多</strong>——城堡有复杂的建筑，天空充满被日落照亮的阴郁云彩，整体构图匹配我们追求的 <strong>&quot;雄伟氛围&quot;</strong>。</li></ol><figure><img src="https://neverbiasu.github.io/assets/images/reprints/illustrious/tag-enhancer/compare-tag-booster.png" alt="TagBooster MoodBooster Comparison" tabindex="0" loading="lazy"><figcaption>TagBooster MoodBooster Comparison</figcaption></figure>',48)),(0,e.bF)(r,null,{default:(0,e.k6)((()=>o[0]||(o[0]=[(0,e.Lk)("em",null,"左侧显示从原始 prompt 生成的图像，右侧显示 Text-Enhancer 增强后的图像。氛围和细节的改善是显而易见的",-1)]))),_:1}),o[3]||(o[3]=(0,e.Lk)("br",null,null,-1)),(0,e.bF)(r,null,{default:(0,e.k6)((()=>o[1]||(o[1]=[(0,e.Lk)("em",null,"(原始 prompt : 1girl, red hair, dress, space, sola, 1boy, yellow hair, moon)",-1)]))),_:1}),o[4]||(o[4]=(0,e.Lk)("hr",null,null,-1)),o[5]||(o[5]=(0,e.Lk)("h2",{id:"结论",tabindex:"-1"},[(0,e.Lk)("a",{class:"header-anchor",href:"#结论"},[(0,e.Lk)("span",null,"结论")])],-1)),o[6]||(o[6]=(0,e.Lk)("p",null,"Illustrious Text‑Enhancer（Tag Booster + Mood Enhancer）代表了在自然人类输入和高质量图像生成所需的最佳 prompt 之间架起桥梁的重大飞跃。通过利用先进的 NLP 技术——从专门的 prompt 优化模型（TIPO）到成本高效的 LLM 管道——我们的系统实时处理 prompt 工程的繁重工作。这意味着艺术家和创作者可以专注于他们的创作愿景，而不会陷入找出关键词或描述符的完美组合的困扰中。",-1)),o[7]||(o[7]=(0,e.Lk)("p",null,"从技术角度来看，我们为这些组件如何相互补充感到自豪。Tag Booster 确保 prompt 涵盖所有关键视觉提示并与我们扩散模型的训练数据对齐，提高保真度。Mood Enhancer 通过注入富有想象力的细节和氛围进一步发展，产生讲述故事的输出。由于 KV 缓存等优化，我们在不引入延迟或过高计算成本的情况下实现了这些收益——对用户和平台来说都是双赢。",-1)),o[8]||(o[8]=(0,e.Lk)("p",null,"我们相信这将赋能 Illustrious 的新手和高级用户。新手可以用最少的输入获得出色的结果，专家在充实他们的想法时可以节省时间。这是让 AI 图像生成更直观、更符合您创作意图的又一步。",-1)),o[9]||(o[9]=(0,e.Lk)("p",null,"Text‑Enhancer 功能现在在 Illustrious 中已上线：试试看吧！从一个简单的想法开始，启用 Tag Booster 和 Mood Enhancer，看着您谦逊的 prompt 转变为杰作级的描述。您将获得一张不仅反映您想象的图像，而且其细节和质量水平可能会让您惊喜。",-1)),o[10]||(o[10]=(0,e.Lk)("p",null,"愉快的 prompting，一如既往，让我们知道您的反馈。我们很兴奋看到您用 Tag Booster 和 Mood Enhancer 增强您的想象力所创造的作品！",-1))])}]]),a=JSON.parse('{"path":"/zh/posts/reprints/announcing-illustrious-text%E2%80%91enhancer-tag-booster-and-mood-enhancer.html","title":"发布 Illustrious Text‑Enhancer：Tag Booster 和 Mood Enhancer","lang":"zh-CN","frontmatter":{"title":"发布 Illustrious Text‑Enhancer：Tag Booster 和 Mood Enhancer","cover":"https://neverbiasu.github.io/assets/images/reprints/illustrious/tag-enhancer/cover.jpg","date":"2025-05-23T00:00:00.000Z","author":"LivBigStar","excerpt":"Illustrious 推出 Text‑Enhancer，包含 Tag Booster 和 Mood Enhancer。前者基于 TIPO 框架扩展稀疏 prompt，后者通过 LLM 生成氛围描述，显著提升图像质量。","description":"发布 Illustrious Text‑Enhancer：Tag Booster 和 Mood Enhancer Illustrious 用户经常问：\\"如何在不编写冗长 Prompt 的情况下获得更好的结果？\\" 今天，我们很兴奋地通过 Text‑Enhancer 来回答这个问题，这是一个新系统，可以显著丰富用户 Prompt，用于我们的图像生成平台。 ...","gitInclude":[],"head":[["link",{"rel":"alternate","hreflang":"en-us","href":"https://neverbiasu.github.io/posts/reprints/announcing-illustrious-text%E2%80%91enhancer-tag-booster-and-mood-enhancer.html"}],["meta",{"property":"og:url","content":"https://neverbiasu.github.io/zh/posts/reprints/announcing-illustrious-text%E2%80%91enhancer-tag-booster-and-mood-enhancer.html"}],["meta",{"property":"og:site_name","content":"Nlog"}],["meta",{"property":"og:title","content":"发布 Illustrious Text‑Enhancer：Tag Booster 和 Mood Enhancer"}],["meta",{"property":"og:description","content":"发布 Illustrious Text‑Enhancer：Tag Booster 和 Mood Enhancer Illustrious 用户经常问：\\"如何在不编写冗长 Prompt 的情况下获得更好的结果？\\" 今天，我们很兴奋地通过 Text‑Enhancer 来回答这个问题，这是一个新系统，可以显著丰富用户 Prompt，用于我们的图像生成平台。 ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://neverbiasu.github.io/assets/images/reprints/illustrious/tag-enhancer/cover.jpg"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:locale:alternate","content":"en-US"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:src","content":"https://neverbiasu.github.io/assets/images/reprints/illustrious/tag-enhancer/cover.jpg"}],["meta",{"name":"twitter:image:alt","content":"发布 Illustrious Text‑Enhancer：Tag Booster 和 Mood Enhancer"}],["meta",{"property":"article:author","content":"LivBigStar"}],["meta",{"property":"article:published_time","content":"2025-05-23T00:00:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"发布 Illustrious Text‑Enhancer：Tag Booster 和 Mood Enhancer\\",\\"image\\":[\\"https://neverbiasu.github.io/assets/images/reprints/illustrious/tag-enhancer/tipo-architecture.png\\",\\"https://neverbiasu.github.io/assets/images/reprints/illustrious/tag-enhancer/tag-booster-compare.jpg\\",\\"https://neverbiasu.github.io/assets/images/reprints/illustrious/tag-enhancer/mood-enhancer-compare.jpg\\",\\"https://neverbiasu.github.io/assets/images/reprints/illustrious/tag-enhancer/kv-caching2.jpg\\",\\"https://neverbiasu.github.io/assets/images/reprints/illustrious/tag-enhancer/compare-tag-booster.png\\"],\\"datePublished\\":\\"2025-05-23T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"LivBigStar\\"}]}"]]},"headers":[{"level":2,"title":"从稀疏到丰富：Tag Booster 如何通过 TIPO 丰富 Prompt","slug":"从稀疏到丰富-tag-booster-如何通过-tipo-丰富-prompt","link":"#从稀疏到丰富-tag-booster-如何通过-tipo-丰富-prompt","children":[{"level":3,"title":"什么是 TIPO？","slug":"什么是-tipo","link":"#什么是-tipo","children":[]},{"level":3,"title":"联合任务训练（Tags ↔ Text）","slug":"联合任务训练-tags-↔-text","link":"#联合任务训练-tags-↔-text","children":[]}]},{"level":2,"title":"用更少努力创造生动叙述：Mood Enhancer 和 LLM 驱动的扩展","slug":"用更少努力创造生动叙述-mood-enhancer-和-llm-驱动的扩展","link":"#用更少努力创造生动叙述-mood-enhancer-和-llm-驱动的扩展","children":[{"level":3,"title":"工作原理","slug":"工作原理","link":"#工作原理","children":[]}]},{"level":2,"title":"KV 缓存：超级增强 LLM 效率","slug":"kv-缓存-超级增强-llm-效率","link":"#kv-缓存-超级增强-llm-效率","children":[{"level":3,"title":"什么是 KV 缓存？","slug":"什么是-kv-缓存","link":"#什么是-kv-缓存","children":[]},{"level":3,"title":"技术洞察 - 使其工作","slug":"技术洞察-使其工作","link":"#技术洞察-使其工作","children":[]}]},{"level":2,"title":"Text‑Enhancer 实际应用：以最少努力获得更好的图像","slug":"text‐enhancer-实际应用-以最少努力获得更好的图像","link":"#text‐enhancer-实际应用-以最少努力获得更好的图像","children":[]},{"level":2,"title":"结论","slug":"结论","link":"#结论","children":[]}],"readingTime":{"minutes":13.34,"words":4002},"filePathRelative":"zh/posts/reprints/announcing-illustrious-text‑enhancer-tag-booster-and-mood-enhancer.md","localizedDate":"2025年5月23日","autoDesc":true}')}}]);