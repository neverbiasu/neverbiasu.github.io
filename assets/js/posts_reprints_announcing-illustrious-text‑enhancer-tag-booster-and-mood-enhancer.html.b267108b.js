"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[3232],{6262:(e,t)=>{t.A=(e,t)=>{const n=e.__vccOpts||e;for(const[e,i]of t)n[e]=i;return n}},8692:(e,t,n)=>{n.r(t),n.d(t,{comp:()=>a,data:()=>s});var i=n(641);const o={},a=(0,n(6262).A)(o,[["render",function(e,t){const n=(0,i.g2)("center");return(0,i.uX)(),(0,i.CE)("div",null,[t[2]||(t[2]=(0,i.Fv)('<h1 id="announcing-illustrious-text‐enhancer-tag-booster-mood-enhancer" tabindex="-1"><a class="header-anchor" href="#announcing-illustrious-text‐enhancer-tag-booster-mood-enhancer"><span>Announcing Illustrious Text‑Enhancer: Tag Booster &amp; Mood Enhancer</span></a></h1><p>Illustrious users often ask: <em>“How can I get better results without writing long prompts?”</em> Today, we’re excited to answer that with <strong>Text‑Enhancer</strong>, a new system that dramatically <strong>enriches user prompts</strong> for our image generation platform.</p><p>Text‑Enhancer actually comprises <strong>two intelligent components</strong> working together:</p><ol><li><strong>Tag Booster:</strong> A prompt enrichment tool built on our TIPO (Text-to-Image Prompt Optimization) framework. It <strong>expands short or sparse prompts</strong> (whether tags or plain text) by aligning them with the distributions seen in our model’s training data. The result is higher fidelity images and tighter prompt–image alignment.</li><li><strong>Mood Enhancer:</strong> A custom LLM-based pipeline that <strong>transforms minimal input into detailed, evocative image prompts</strong>. By leveraging a fixed system prompt and few-shot examples (with an advanced KV caching strategy), it can generate rich descriptions from sparse input <strong>at a fraction of the usual LLM cost</strong> and latency.</li></ol><p>Together, Tag Booster and Mood Enhancer <strong>reduce the burden on creators</strong> to hand-craft lengthy prompts, while <strong>consistently yielding higher-quality, on-target generations</strong>. In this post, we’ll dive into how each component works, the technical innovations under the hood (from <strong>multi-task prompt models</strong> to <strong>LLM KV caching</strong>), and why this is a game-changer for Illustrious users.</p><hr><h2 id="from-sparse-to-rich-how-tag-booster-enriches-prompts-with-tipo" tabindex="-1"><a class="header-anchor" href="#from-sparse-to-rich-how-tag-booster-enriches-prompts-with-tipo"><span>From Sparse to Rich: How Tag Booster Enriches Prompts with TIPO</span></a></h2><p>Creating a vivid image from a one-liner prompt is challenging – diffusion models like Illustrious XL were trained on datasets where prompts/captions have a certain richness and variety. <strong>Tag Booster</strong> bridges this gap by <strong>automatically expanding and refining your prompt</strong> to look more like those in the training distribution. It’s powered by our in-house <strong>TIPO framework</strong>, a lightweight multi-task language model purpose-built for prompt optimization.</p><figure><img src="/assets/images/reprints/illustrious/tag-enhancer/tipo-architecture.png" alt="TIPO Architecture" tabindex="0" loading="lazy"><figcaption>TIPO Architecture</figcaption></figure><h3 id="what-is-tipo" tabindex="-1"><a class="header-anchor" href="#what-is-tipo"><span>What is TIPO?</span></a></h3><p>TIPO stands for <strong>Text-to-Image Prompt Optimization</strong> – a novel approach that was co-developed by collaborating with a bright external researcher of multimodal model. Unlike brute-force prompt engineering or expensive large language model methods, TIPO uses a <strong>small, efficient model</strong> (hundreds of millions of parameters, rather than tens of billions) that was <strong>trained on prompt pairs</strong>. Essentially, it learned to take a simple prompt and output a richer one. Conceptually, it “<strong>samples refined prompts from a targeted sub-distribution</strong>” of the prompt space, which means it adds the kinds of details our diffusion model expects, <strong>while preserving the original intent</strong>. This yields <em>significantly improved visual quality, coherence, and detail</em> compared to using the raw prompt.</p><h3 id="joint-task-training-tags-↔-text" tabindex="-1"><a class="header-anchor" href="#joint-task-training-tags-↔-text"><span>Joint-task Training (Tags ↔ Text)</span></a></h3><p>A key innovation in Tag Booster’s TIPO model is that it’s <strong>joint-task</strong> – it can handle both <strong>tag lists and natural language</strong> and convert one to the other. During training, we gave TIPO two kinds of tasks: <strong>“tag-to-text”</strong> (e.g. take a list of terse tags and produce a full descriptive sentence) and <strong>“text-to-tag”</strong> (take a short sentence and predict important tags or keywords). By learning both directions, the model developed a flexible understanding of prompt semantics. In practice, this means <strong>Tag Booster can interpret your input format</strong> and enrich it appropriately:</p><ol><li>If you provide a list of tags or a few words, it will <strong>add high-impact visual tags</strong> that are statistically correlated with those concepts in the training data.</li><li>If you provide a short sentence, it will <strong>expand it with additional descriptors or stylistic keywords</strong>, effectively translating free-form text into an enhanced tag-rich prompt.</li></ol><p>For example, imagine you input just <strong>“an autumn forest”</strong>. This is short and might produce a generic result. Tag Booster might enrich this to something like:</p><ol><li><strong>Input:</strong> autumn forest</li><li><strong>Tag Booster Output:</strong> autumn forest, golden sunlight, falling leaves, high detail, masterpiece, warm color palette</li></ol><figure><img src="/assets/images/reprints/illustrious/tag-enhancer/tag-booster-compare.jpg" alt="Tag Booster Example Comparison" tabindex="0" loading="lazy"><figcaption>Tag Booster Example Comparison</figcaption></figure><p>By adding details (“golden sunlight”, “falling leaves”) and style tags (“high detail, masterpiece”), the prompt now better matches what our model was trained on. These extra cues help the diffusion model <strong>focus on the intended scene and aesthetic</strong>. In internal tests, this approach yielded <strong>notable gains in image quality</strong> – our evaluators saw <em>more vivid colors, fewer artifacts, and compositions that aligned more closely with the prompt intention</em>. This echoes findings from the TIPO research, which reported <em>“substantial improvements in aesthetic quality, significant reduction of visual artifacts, and enhanced alignment with target distributions”</em> when using such prompt optimization.</p><p>More importantly, Tag Booster operates <strong>lightning-fast</strong>. Because TIPO is so lightweight, adding this step doesn’t slow down generation in any noticeable way – it’s a fraction of a second to enrich the prompt. And unlike heuristics that simply append a fixed set of “magic keywords”, Tag Booster is <strong>context-aware</strong>: it tailors the additions to <strong>your specific prompt</strong> content. The enriched prompt still feels like a natural extension of what you wanted, just with more detail and clarity. The end result is that <strong>users get higher-fidelity images with minimal extra effort</strong>, allowing even one-word prompts to shine as if they were carefully engineered.</p><hr><h2 id="vivid-narratives-with-less-effort-mood-enhancer-and-llm-powered-expansion" tabindex="-1"><a class="header-anchor" href="#vivid-narratives-with-less-effort-mood-enhancer-and-llm-powered-expansion"><span>Vivid Narratives with Less Effort: Mood Enhancer and LLM-Powered Expansion</span></a></h2><p>While Tag Booster excels at <strong>adding relevant keywords and tags</strong>, we also wanted to help users who prefer <strong>natural language prompts</strong> or who have a certain <em>mood or story</em> in mind for their image. This is where <strong>Mood Enhancer</strong> comes into play. Mood Enhancer uses a <strong>custom Large Language Model (LLM) pipeline</strong> to <strong>transform a brief idea into a rich, atmospheric prompt</strong>. If Tag Booster is about <strong>precision and fidelity</strong>, Mood Enhancer is about <strong>creativity and storytelling</strong> infusing prompts with vivid scene descriptions, context, and emotional tone.</p><h3 id="how-it-works" tabindex="-1"><a class="header-anchor" href="#how-it-works"><span>How it Works</span></a></h3><p>We crafted a special <strong>system prompt</strong> for an LLM along with a set of <strong>few-shot examples</strong> so that it learns the style of an ideal Illustrious prompt. For instance, the system prompt might say something like <em>“You are an artist assistant that turns short prompts into detailed visual descriptions. Include imaginative details and set the mood.”</em> Then we provide a few examples of transformations (just like showing the model a before-and-after of prompts). With this fixed prompt template, when the user provides their input, the LLM will generate an <strong>elaborated prompt</strong> following those examples.</p><p>Consider a user input: <strong>“futuristic city at night”</strong>. That’s a cool concept but fairly high-level. Mood Enhancer would turn this into something like:</p><blockquote><p><em>“A sprawling</em><strong><em>futuristic city</em></strong><em>skyline at night, with</em><strong><em>neon-lit skyscrapers</em></strong><em>and flying vehicles weaving between the buildings. The streets below glow with</em><strong><em>holographic billboards</em></strong><em>and reflected lights. A sense of</em><strong><em>rainy ambiance</em></strong><em>with puddles reflecting the vibrant neon signs adds a</em><strong><em>cyberpunk</em></strong><em>mood.”</em></p></blockquote><p>Notice how the sparse idea became a <strong>mini story</strong>: it preserved the core (“futuristic city at night”) but added concrete visual elements (neon lights, skyscrapers, holographic billboards) and mood (rainy, cyberpunk vibe). This kind of rich prompt can guide the diffusion model to generate an image that feels like a frame from a sci-fi film, rather than a generic city. The <strong>atmospheric flair</strong> and <strong>specific details</strong> are exactly what Mood Enhancer is designed to inject.</p><figure><img src="/assets/images/reprints/illustrious/tag-enhancer/mood-enhancer-compare.jpg" alt="Mood Enhancer Comparison" tabindex="0" loading="lazy"><figcaption>Mood Enhancer Comparison</figcaption></figure><hr><h2 id="kv-caching-supercharging-llm-efficiency-under-the-hood" tabindex="-1"><a class="header-anchor" href="#kv-caching-supercharging-llm-efficiency-under-the-hood"><span>KV Caching: Supercharging LLM Efficiency Under the Hood</span></a></h2><p>Using an LLM to expand prompts raises a concern: <strong>cost and speed</strong>. High-quality LLMs (with large parameter counts) can be slow or expensive to run, especially if you feed a long system prompt and examples each time. We tackled this challenge with a clever optimization: <strong>Key-Value cache reuse</strong> for the LLM’s prompts. This technique is inspired by recent advances in LLM deployment (even Anthropic’s Claude API introduced a similar <em>prompt caching</em> feature to cut costs by up to 90%).</p><figure><img src="/assets/images/reprints/illustrious/tag-enhancer/kv-caching2.jpg" alt="KV Caching Efficiency" tabindex="0" loading="lazy"><figcaption>KV Caching Efficiency</figcaption></figure><h3 id="what-is-kv-caching" tabindex="-1"><a class="header-anchor" href="#what-is-kv-caching"><span>What is KV caching?</span></a></h3><p>During autoregressive generation, LLMs build up internal <strong>Key</strong> and <strong>Value</strong> tensors (the “memory” of the self-attention mechanism) as they consume the prompt tokens. Normally, if you generate fresh each time, you pay the compute cost for all prompt tokens for each request. But if a large portion of the prompt is <strong>always the same</strong> (in our case, the system message and few-shot examples are fixed for Mood Enhancer), we can <strong>cache its KV state</strong> once and reuse it. In practice, we run the LLM through the static prompt portion <strong>one time</strong> (per session or server warm-up), and store the resulting key-value pairs from each transformer layer. Then for each new user input, we <em>initialize the LLM’s state with this cached KV</em> and start generation from the end of the prefix, as if the model had “already seen” the system prompt and examples.</p><p>This yields <strong>massive efficiency gains</strong>. The <strong>fixed prompt</strong> for Mood Enhancer can be quite lengthy (it might be, say, 500 tokens of instructions and examples to ensure high-quality output). With KV caching, those 500 tokens are processed just once; subsequent prompts only incur compute for the new user input (maybe 5–50 tokens) plus the output tokens. In our tests, this brought the <strong>LLM inference cost down to ~20%</strong> of the naïve cost per generation – effectively an 80% reduction in cost and a significant speedup, without any loss in output quality. These numbers line up with industry reports that prompt caching can reduce input costs by <em>up to 90%</em> in some scenarios.</p><h3 id="technical-insight-making-it-work" tabindex="-1"><a class="header-anchor" href="#technical-insight-making-it-work"><span>Technical insight - making it work</span></a></h3><p>Implementing KV caching in a robust way required navigating some <strong>LLM internals</strong>. Modern transformer models (including the one we use for Mood Enhancer) often employ <strong>rotary positional embeddings</strong> for tokens. This relative positioning scheme is great for handling long contexts, but we had to ensure that our caching mechanism <strong>preserves positional consistency</strong>. In simple terms, when we cache the prefix, the model has assigned certain positional phases to those tokens; when we later append the user’s tokens, we must <strong>continue the positional encoding seamlessly</strong> so that the model treats it as one continuous sequence. We addressed this by carefully managing the position indices during generation – essentially, the model is never “reset” between the prefix and user input, so there’s no chance for misalignment.</p><p>Another challenge was dealing with <strong>prefix-based limitations</strong> in standard generation pipelines. Off-the-shelf APIs or libraries typically assume you feed the entire prompt at once; they weren’t designed to let you inject a pre-computed prefix. To overcome this, we integrated low-level support that allows feeding the cached keys and values back into the model at generation time. Our solution is akin to what the latest LLM APIs now offer with prompt caching, but we custom-built it for our pipeline. We also took care to lock in the exact <strong>tokenization</strong> of the prefix so that nothing in the user input could inadvertently change how the prompt is parsed (a rare edge-case, but something we verified thoroughly). With these engineering fixes, Mood Enhancer can reuse its prompt context safely across many generations.</p><p>The result? <strong>Dramatically lower latency and cost</strong> for Mood Enhancer’s transformations, enabling us to offer this feature to users <strong>without noticeable delays</strong>. You get the benefit of a large-model prompt brainstorm for free, effectively, as the heavy lifting is amortized.</p><hr><h2 id="text‐enhancer-in-action-better-images-with-minimal-effort" tabindex="-1"><a class="header-anchor" href="#text‐enhancer-in-action-better-images-with-minimal-effort"><span>Text‑Enhancer in Action: Better Images with Minimal Effort</span></a></h2><p>By combining Tag Booster and Mood Enhancer, Illustrious’s Text‑Enhancer system ensures that <strong>any user input, no matter how simple, can evolve into a powerful prompt</strong> for image generation. This is all done behind the scenes – you can toggle these enhancers on, enter a few words, and get back a beautifully detailed prompt and a stunning image.</p><p>Let’s walk through a hypothetical example to see the end-to-end effect:</p><ol><li><strong>User Input:</strong> a lone castle on a hill <em>Just a simple description — evocative, but sparse. The user hasn’t specified style, lighting, or surrounding details.</em></li><li><strong>After Tag Booster:</strong> lone castle on a hill, medieval fortress, cloudy sky, twilight, high-resolution, epic scale <em>Tag Booster recognized the theme and added key visual tags: the castle is identified as a medieval fortress, a likely setting (cloudy sky at twilight) is added for mood, and stylistic tags like “high-resolution, epic scale” align with our training data for dramatic scenery.</em></li><li><strong>After Mood Enhancer:</strong><em>“A</em><strong><em>lone medieval castle</em></strong><em>stands atop a misty hill under a</em><strong><em>cloud-laden twilight sky</em></strong><em>. The ancient stone fortress is illuminated by the last light of dusk, its silhouette towering with</em><strong><em>epic scale</em></strong><em>over the darkening valley.</em><strong><em>Dramatic clouds</em></strong><em>swirl above, and a faint mist clings to the ground, evoking a</em><strong><em>mysterious, majestic atmosphere</em></strong><em>.”</em><em>Mood Enhancer wove the tags into a rich narrative. It preserved all the key elements (castle, hill, cloudy twilight) and enhanced them: we can now</em><strong><em>feel the atmosphere</em></strong><em>and see the scene in our mind’s eye.</em></li></ol><p>Now imagine feeding the final enhanced prompt into Illustrious XL. The difference in the output is night and day. In fact, we tested this internally:</p><ol><li>Without Text‑Enhancer, the prompt “a lone castle on a hill” yielded a very generic castle image with a plain sky.</li><li><strong>With Text‑Enhancer, the generated image was far more dramatic and detailed</strong> – the castle had intricate architecture, the sky was filled with brooding clouds lit by the sunset, and the overall composition matched that <strong>“majestic atmosphere”</strong> we were aiming for.</li></ol><figure><img src="/assets/images/reprints/illustrious/tag-enhancer/compare-tag-booster.png" alt="TagBooster Comparison" tabindex="0" loading="lazy"><figcaption>TagBooster Comparison</figcaption></figure>',47)),(0,i.bF)(n,null,{default:(0,i.k6)((()=>t[0]||(t[0]=[(0,i.Lk)("em",null,"the left side shows the image generated from the original prompt, and the right side shows the image after Text-Enhancer enrichment. The improvement in mood and detail is evident",-1)]))),_:1}),t[3]||(t[3]=(0,i.Lk)("br",null,null,-1)),(0,i.bF)(n,null,{default:(0,i.k6)((()=>t[1]||(t[1]=[(0,i.Lk)("em",null,"(original prompt : 1girl, red hair, dress, space, sola, 1boy, yellow hair, moon)",-1)]))),_:1}),t[4]||(t[4]=(0,i.Lk)("hr",null,null,-1)),t[5]||(t[5]=(0,i.Lk)("h2",{id:"conclusion",tabindex:"-1"},[(0,i.Lk)("a",{class:"header-anchor",href:"#conclusion"},[(0,i.Lk)("span",null,"Conclusion")])],-1)),t[6]||(t[6]=(0,i.Lk)("p",null,"The Illustrious Text‑Enhancer (Tag Booster + Mood Enhancer) represents a significant leap forward in bridging natural human input and the optimal prompts needed for high‑quality image generation. By leveraging advanced NLP techniques from a specialized prompt optimizing model (TIPO) to a cost‑efficient LLM pipeline our system handles the heavy lifting of prompt engineering in real‑time. This means artists and creators can focus on their creative vision, without getting bogged down in figuring out the perfect combination of keywords or descriptors.",-1)),t[7]||(t[7]=(0,i.Lk)("p",null,"From a technical perspective, we’re proud of how these components complement each other. Tag Booster ensures the prompt covers all the critical visual cues and aligns with our diffusion model’s training data, improving fidelity. Mood Enhancer takes it further by infusing the prompt with imaginative detail and atmosphere, yielding outputs that tell a story. And thanks to optimizations like KV caching, we achieve these gains without introducing lag or exorbitant compute costs a win-win for users and the platform.",-1)),t[8]||(t[8]=(0,i.Lk)("p",null,"We believe this will empower both newcomers and power users of Illustrious. Novices can get great results with minimal input, and experts can save time when fleshing out their ideas. It’s another step toward making AI image generation more intuitive and aligned with your creative intent.",-1)),t[9]||(t[9]=(0,i.Lk)("p",null,"The Text‑Enhancer features are live now in Illustrious : give them a spin! Start with a simple idea, enable Tag Booster and Mood Enhancer, and watch as your humble prompt transforms into a masterpiece‑worthy description. You’ll be greeted with an image that not only reflects what you imagined, but does so with a level of detail and quality that might just surprise you.",-1)),t[10]||(t[10]=(0,i.Lk)("p",null,"Happy prompting, and as always, let us know your feedback. We’re excited to see what you create with Tag Booster and Mood Enhancer supercharging your imaginations!",-1))])}]]),s=JSON.parse('{"path":"/posts/reprints/announcing-illustrious-text%E2%80%91enhancer-tag-booster-and-mood-enhancer.html","title":"Announcing Illustrious Text‑Enhancer: Tag Booster & Mood Enhancer","lang":"en-US","frontmatter":{"title":"Announcing Illustrious Text‑Enhancer: Tag Booster & Mood Enhancer","cover":"/assets/images/reprints/illustrious/tag-enhancer/cover.jpg","date":"2025-05-23T00:00:00.000Z","author":"LivBigStar","description":"Announcing Illustrious Text‑Enhancer: Tag Booster & Mood Enhancer Illustrious users often ask: “How can I get better results without writing long prompts?” Today, we’re excited ...","gitInclude":[],"head":[["link",{"rel":"alternate","hreflang":"zh-cn","href":"https://neverbiasu.github.io/zh/posts/reprints/announcing-illustrious-text%E2%80%91enhancer-tag-booster-and-mood-enhancer.html"}],["meta",{"property":"og:url","content":"https://neverbiasu.github.io/posts/reprints/announcing-illustrious-text%E2%80%91enhancer-tag-booster-and-mood-enhancer.html"}],["meta",{"property":"og:site_name","content":"Nlog"}],["meta",{"property":"og:title","content":"Announcing Illustrious Text‑Enhancer: Tag Booster & Mood Enhancer"}],["meta",{"property":"og:description","content":"Announcing Illustrious Text‑Enhancer: Tag Booster & Mood Enhancer Illustrious users often ask: “How can I get better results without writing long prompts?” Today, we’re excited ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://neverbiasu.github.io/assets/images/reprints/illustrious/tag-enhancer/cover.jpg"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:locale:alternate","content":"zh-CN"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:src","content":"https://neverbiasu.github.io/assets/images/reprints/illustrious/tag-enhancer/cover.jpg"}],["meta",{"name":"twitter:image:alt","content":"Announcing Illustrious Text‑Enhancer: Tag Booster & Mood Enhancer"}],["meta",{"property":"article:author","content":"LivBigStar"}],["meta",{"property":"article:published_time","content":"2025-05-23T00:00:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Announcing Illustrious Text‑Enhancer: Tag Booster & Mood Enhancer\\",\\"image\\":[\\"https://neverbiasu.github.io/assets/images/reprints/illustrious/tag-enhancer/tipo-architecture.png\\",\\"https://neverbiasu.github.io/assets/images/reprints/illustrious/tag-enhancer/tag-booster-compare.jpg\\",\\"https://neverbiasu.github.io/assets/images/reprints/illustrious/tag-enhancer/mood-enhancer-compare.jpg\\",\\"https://neverbiasu.github.io/assets/images/reprints/illustrious/tag-enhancer/kv-caching2.jpg\\",\\"https://neverbiasu.github.io/assets/images/reprints/illustrious/tag-enhancer/compare-tag-booster.png\\"],\\"datePublished\\":\\"2025-05-23T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"LivBigStar\\"}]}"]]},"headers":[{"level":2,"title":"From Sparse to Rich: How Tag Booster Enriches Prompts with TIPO","slug":"from-sparse-to-rich-how-tag-booster-enriches-prompts-with-tipo","link":"#from-sparse-to-rich-how-tag-booster-enriches-prompts-with-tipo","children":[{"level":3,"title":"What is TIPO?","slug":"what-is-tipo","link":"#what-is-tipo","children":[]},{"level":3,"title":"Joint-task Training (Tags ↔ Text)","slug":"joint-task-training-tags-↔-text","link":"#joint-task-training-tags-↔-text","children":[]}]},{"level":2,"title":"Vivid Narratives with Less Effort: Mood Enhancer and LLM-Powered Expansion","slug":"vivid-narratives-with-less-effort-mood-enhancer-and-llm-powered-expansion","link":"#vivid-narratives-with-less-effort-mood-enhancer-and-llm-powered-expansion","children":[{"level":3,"title":"How it Works","slug":"how-it-works","link":"#how-it-works","children":[]}]},{"level":2,"title":"KV Caching: Supercharging LLM Efficiency Under the Hood","slug":"kv-caching-supercharging-llm-efficiency-under-the-hood","link":"#kv-caching-supercharging-llm-efficiency-under-the-hood","children":[{"level":3,"title":"What is KV caching?","slug":"what-is-kv-caching","link":"#what-is-kv-caching","children":[]},{"level":3,"title":"Technical insight - making it work","slug":"technical-insight-making-it-work","link":"#technical-insight-making-it-work","children":[]}]},{"level":2,"title":"Text‑Enhancer in Action: Better Images with Minimal Effort","slug":"text‐enhancer-in-action-better-images-with-minimal-effort","link":"#text‐enhancer-in-action-better-images-with-minimal-effort","children":[]},{"level":2,"title":"Conclusion","slug":"conclusion","link":"#conclusion","children":[]}],"readingTime":{"minutes":8.75,"words":2626},"filePathRelative":"posts/reprints/announcing-illustrious-text‑enhancer-tag-booster-and-mood-enhancer.md","localizedDate":"May 23, 2025","excerpt":"\\n<p>Illustrious users often ask: <em>“How can I get better results without writing long prompts?”</em> Today, we’re excited to answer that with <strong>Text‑Enhancer</strong>, a new system that dramatically <strong>enriches user prompts</strong> for our image generation platform.</p>\\n<p>Text‑Enhancer actually comprises <strong>two intelligent components</strong> working together:</p>","autoDesc":true}')}}]);