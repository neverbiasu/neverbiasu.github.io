"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[5519],{6262:(e,r)=>{r.A=(e,r)=>{const a=e.__vccOpts||e;for(const[e,t]of r)a[e]=t;return a}},7643:(e,r,a)=>{a.r(r),a.d(r,{comp:()=>o,data:()=>i});var t=a(641);const n={},o=(0,a(6262).A)(n,[["render",function(e,r){return(0,t.uX)(),(0,t.CE)("div",null,r[0]||(r[0]=[(0,t.Fv)('<h1 id="tango赋能数字人-add-it重构图像编辑-mikudance动漫角色舞蹈动画【ai周报】" tabindex="-1"><a class="header-anchor" href="#tango赋能数字人-add-it重构图像编辑-mikudance动漫角色舞蹈动画【ai周报】"><span><strong>TANGO赋能数字人|ADD-IT重构图像编辑|MikuDance动漫角色舞蹈动画【AI周报】</strong></span></a></h1><figure><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/021ded55-a224-419c-939c-70c6888912f7/d1a9dc14-03bb-4a6d-9bde-08c809989d52/微信logo.png" alt="微信logo.png" tabindex="0" loading="lazy"><figcaption>微信logo.png</figcaption></figure><h2 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span><strong>摘要</strong></span></a></h2><p>本周聚焦多模态AI发展：TANGO创新语音驱动手势视频；StoryTeller支持长视频剧情生成；ADD-IT无训练对象插入；MikuDance合成动漫角色舞蹈；LLaMA-Mesh统一3D网格与语言模型。其余详见正文。</p><h2 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span><strong>目录</strong></span></a></h2><ol><li><a href="notion://www.notion.so/faych/657f0864717c46feb4e178340c835a83?v=8c227af762f84d858c18dea07fc3f9a6&amp;p=1415f3c4a13980978baddb4d6e464cba&amp;pm=s#tango-%E8%81%94%E5%90%88%E8%AF%AD%E9%9F%B3%E9%A9%B1%E5%8A%A8%E7%9A%84%E6%89%8B%E5%8A%BF%E9%87%8D%E6%BC%94%E6%A8%A1%E5%9E%8B" target="_blank" rel="noopener noreferrer">TANGO: 联合语音驱动的手势重演模型</a></li><li><a href="notion://www.notion.so/faych/657f0864717c46feb4e178340c835a83?v=8c227af762f84d858c18dea07fc3f9a6&amp;p=1415f3c4a13980978baddb4d6e464cba&amp;pm=s#storyteller-%E9%95%BF%E8%A7%86%E9%A2%91%E6%8F%8F%E8%BF%B0%E4%B8%8E%E8%A7%92%E8%89%B2%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B" target="_blank" rel="noopener noreferrer">StoryTeller: 长视频描述与角色识别模型</a></li><li><a href="notion://www.notion.so/faych/657f0864717c46feb4e178340c835a83?v=8c227af762f84d858c18dea07fc3f9a6&amp;p=1415f3c4a13980978baddb4d6e464cba&amp;pm=s#add-it-%E6%97%A0%E9%9C%80%E8%AE%AD%E7%BB%83%E7%9A%84%E5%9B%BE%E5%83%8F%E5%AF%B9%E8%B1%A1%E6%8F%92%E5%85%A5%E6%96%B9%E6%B3%95" target="_blank" rel="noopener noreferrer">ADD-IT: 无需训练的图像对象插入方法</a></li><li><a href="notion://www.notion.so/faych/657f0864717c46feb4e178340c835a83?v=8c227af762f84d858c18dea07fc3f9a6&amp;p=1415f3c4a13980978baddb4d6e464cba&amp;pm=s#mikudance-%E5%9F%BA%E4%BA%8Ediffusion%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8D%A1%E9%80%9A%E8%A7%92%E8%89%B2%E5%8A%A8%E7%94%BB%E7%94%9F%E6%88%90" target="_blank" rel="noopener noreferrer">MikuDance: 基于Diffusion模型的卡通角色动画生成</a></li><li><a href="notion://www.notion.so/faych/657f0864717c46feb4e178340c835a83?v=8c227af762f84d858c18dea07fc3f9a6&amp;p=1415f3c4a13980978baddb4d6e464cba&amp;pm=s#magicquill-%E6%99%BA%E8%83%BD%E4%BA%A4%E4%BA%92%E5%BC%8F%E5%9B%BE%E5%83%8F%E7%BC%96%E8%BE%91%E7%B3%BB%E7%BB%9F" target="_blank" rel="noopener noreferrer">MagicQuill: 智能交互式图像编辑系统</a></li><li><a href="notion://www.notion.so/faych/657f0864717c46feb4e178340c835a83?v=8c227af762f84d858c18dea07fc3f9a6&amp;p=1415f3c4a13980978baddb4d6e464cba&amp;pm=s#llama-mesh-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%A9%B1%E5%8A%A8%E7%9A%84-3d-mesh%E7%94%9F%E6%88%90" target="_blank" rel="noopener noreferrer">LLaMA-Mesh: 大模型驱动的 3D Mesh生成</a></li></ol><hr><h2 id="tango-联合语音驱动的手势重演模型" tabindex="-1"><a class="header-anchor" href="#tango-联合语音驱动的手势重演模型"><span><strong>TANGO: 联合语音驱动的手势重演模型</strong></span></a></h2><p>!https://arxiv.org/html/2410.04221v1/x1.png</p><p>TANGO Teaser 图</p><p><strong>概要</strong>: <strong>TANGO</strong> 是 <strong>东京大学</strong> 提出的一种生成与语音同步身体手势视频的新算法。它通过改进手势视频重现（GVR）技术解决了音频-动作不同步和GAN生成过渡帧中的视觉伪影问题。TANGO利用基于潜特征距离的手势检索来提高跨模态对齐，并采用名为AuMoCLIP的层次联合嵌入空间。此外，TANGO引入了基于Diffusion模型的外观一致插值（ACInterp）来生成平滑过渡帧，确保生成视频与参考视频之间的一致性。通过这些改进，TANGO能够生成更加自然流畅、与音频高度同步的视频内容。</p><p><strong>标签</strong>: #手势视频生成 #音频-动作同步 #Diffusion模型 #跨模态对齐 #视频过渡帧</p><hr><h2 id="storyteller-长视频描述与角色识别模型" tabindex="-1"><a class="header-anchor" href="#storyteller-长视频描述与角色识别模型"><span><strong>StoryTeller: 长视频描述与角色识别模型</strong></span></a></h2><p>!https://arxiv.org/html/2411.07076v1/x1.png</p><p>StoryTeller Pipeline 图</p><p><strong>概要</strong>: <strong>StoryTeller</strong> 是由 <strong>浙江大学</strong> 和 <strong>阿里巴巴达摩院</strong> 合作开发的一个长时段视频描述生成系统。该系统利用了多模态大型语言模型 (LVLM)，集成了视觉、音频和文本模态，通过音视频角色识别 (Audio-Visual Character Identification)提高剧情描述的连贯性和准确性。StoryTeller 能够处理分钟级别的长视频片段，并引入了 <strong>MovieStory101</strong> 数据集，专门用于评估模型在剧情描述任务中的表现。实验显示，该系统在 MovieQA 测试中，比现有的最强Baseline模型提升了 9.5% 的准确率，并在用户评估中表现出明显优势。</p><p><strong>标签</strong>: #视频描述 #多模态模型 #角色识别 #电影分析 #长视频处理</p><hr><h2 id="add-it-无需训练的图像对象插入方法" tabindex="-1"><a class="header-anchor" href="#add-it-无需训练的图像对象插入方法"><span><strong>ADD-IT :无需训练的图像对象插入方法</strong></span></a></h2><p>!https://research.nvidia.com/labs/par/addit/static/images/Architecture.png</p><p>ADD-IT Architecture 图</p><p><strong>概要</strong>: <strong>ADD-IT</strong> 是由 <strong>NVIDIA</strong> 和 <strong>Tel Aviv University</strong> 联合开发的一种无需训练的图像对象插入方法。ADD-IT 基于预训练的Diffusion模型，能够从文本提示中插入新对象到图像中，无需进行额外的微调训练。其创新在于加权扩展注意力机制 (Weighted Extended-Attention Mechanism)，结合了来自原始场景图像、文本提示和生成图像的信息。这一方法通过结构传递 (Structure Transfer)和主体引导潜变量融合 (Subject Guided Latent Blending)，确保插入对象与背景的结构一致性和细节保留。</p><p><strong>标签</strong>: #图像编辑 #对象插入 #Diffusion模型 #NVIDIA #结构一致性</p><hr><h2 id="mikudance-基于diffusion模型的卡通角色动画生成" tabindex="-1"><a class="header-anchor" href="#mikudance-基于diffusion模型的卡通角色动画生成"><span><strong>MikuDance: 基于Diffusion模型的卡通角色动画生成</strong></span></a></h2><p>!https://kebii.github.io/MikuDance/static/images/method_overview.png</p><p>MikuDance Overview 图</p><p><strong>概要</strong>: <strong>MikuDance</strong> 是一个由 <strong>武汉大学</strong>、<strong>阶跃星辰</strong> 和 <strong>字节跳动</strong> 联合提出的 <strong>Diffusion模型驱动的动画生成系统</strong>，专为卡通化角色和个性化角色艺术动画设计。该系统的核心创新包括 <strong>Mixed Motion Modeling</strong> 和 <strong>Mixed-Control Diffusion</strong> 两大模块，旨在解决角色动画中的高动态运动和参考引导错位等挑战。项目采用了 <strong>Scene Motion Tracking</strong> 技术，实现了角色与场景的统一动态建模，并通过 <strong>Motion-Adaptive Normalization</strong> 模块，灵活控制本地和全局的运动细节。</p><p><strong>标签</strong>: #Diffusion模型 #动画合成 #3D动画 #卡通艺术 #虚拟偶像</p><hr><h2 id="magicquill-智能交互式图像编辑系统" tabindex="-1"><a class="header-anchor" href="#magicquill-智能交互式图像编辑系统"><span><strong>MagicQuill: 智能交互式图像编辑系统</strong></span></a></h2><p>!https://magicquill.art/demo/gallery/mona%20lisa%20cat.gif</p><p>MagicQuill Demo 图</p><p><strong>概要</strong>: <strong>MagicQuill</strong> 是 <strong>港科技</strong>、<strong>蚂蚁集团</strong>、<strong>浙大</strong> 和 <strong>港大</strong> 发布一个智能交互式图像编辑算法，它能够高效实现创意想法。该系统拥有简洁而功能强大的界面，用户可以通过最少的输入完成复杂的编辑操作，如插入元素、擦除物体和改变颜色等。系统采用多模态大语言模型(MLLM)实时预测用户的编辑意图，无需明确输入指令。为了精确处理编辑请求，MagicQuill 使用了一个经过精心训练的双分支插件模块增强的强效Diffusion先验。实验结果表明，MagicQuill 能够实现高质量的图像编辑效果。</p><p><strong>标签</strong>: #MagicQuill #交互式图像编辑 #多模态大语言模型 #Diffusion先验 #图像处理</p><hr><h2 id="llama-mesh-大模型驱动的-3d-mesh生成" tabindex="-1"><a class="header-anchor" href="#llama-mesh-大模型驱动的-3d-mesh生成"><span><strong>LLaMA-Mesh: 大模型驱动的 3D Mesh生成</strong></span></a></h2><p>!https://arxiv.org/html/2411.09595v1/x1.png</p><p>LLaMA-Mesh Illustration 图</p><p><strong>概要</strong>: <strong>LLaMA-Mesh</strong> 是由 <strong>NVIDIA Toronto AI Lab</strong>推出的一个创新框架，旨在扩展大型语言模型 (LLM) 的能力，使其能够生成 3D Mesh。LLaMA-Mesh 利用了预训练 LLM 中的空间知识，并通过将 3D Mesh的顶点坐标和面定义表示为纯文本，解决了 3D 数据标记化的挑战。这种表示方式允许 3D 数据与 LLM 无缝集成，且无需扩展模型的词汇表。</p><p>该项目提出了一种监督微调数据集，支持预训练的 LLM (如 LLaMA) 执行以下任务：(1) 根据文本提示生成 3D Mesh；(2) 生成交错的文本和 3D Mesh输出；(3) 理解并解释 3D Mesh结构。实验表明，LLaMA-Mesh 在生成质量上达到了与从头训练的 3D 模型相当的效果，同时仍保持了强大的文本生成能力。</p><p><strong>标签</strong>: #LLM #3D生成 #Mesh表示 #NVIDIA #多模态集成</p><hr><h3 id="参考链接" tabindex="-1"><a class="header-anchor" href="#参考链接"><span><strong>参考链接</strong></span></a></h3><ol><li><a href="https://pantomatrix.github.io/TANGO/" target="_blank" rel="noopener noreferrer">TANGO 项目主页</a></li><li><a href="https://github.com/CyberAgentAILab/TANGO" target="_blank" rel="noopener noreferrer">TANGO GitHub 仓库</a></li><li><a href="https://arxiv.org/pdf/2410.04221" target="_blank" rel="noopener noreferrer">TANGO 论文</a></li><li><a href="https://github.com/hyc2026/StoryTeller" target="_blank" rel="noopener noreferrer">StoryTeller GitHub 仓库</a></li><li><a href="https://arxiv.org/pdf/2411.07076" target="_blank" rel="noopener noreferrer">StoryTeller 论文</a></li><li><a href="https://research.nvidia.com/labs/par/addit/" target="_blank" rel="noopener noreferrer">ADD-IT 项目主页</a></li><li><a href="https://github.com/nvlabs/addit" target="_blank" rel="noopener noreferrer">ADD-IT GitHub 仓库</a></li><li><a href="https://arxiv.org/pdf/2411.07232" target="_blank" rel="noopener noreferrer">ADD-IT 论文</a></li><li><a href="https://kebii.github.io/MikuDance/" target="_blank" rel="noopener noreferrer">MikuDance 项目主页</a></li><li><a href="https://github.com/Kebii/MikuDance" target="_blank" rel="noopener noreferrer">MikuDance GitHub 仓库</a></li><li><a href="https://arxiv.org/pdf/2411.08656" target="_blank" rel="noopener noreferrer">MikuDance 论文</a></li><li><a href="https://magicquill.art/demo/" target="_blank" rel="noopener noreferrer">MagicQuill 演示页面</a></li><li><a href="https://github.com/magic-quill/magicquill" target="_blank" rel="noopener noreferrer">MagicQuill GitHub 仓库</a></li><li><a href="https://arxiv.org/pdf/2411.09703" target="_blank" rel="noopener noreferrer">MagicQuill 论文</a></li><li><a href="https://research.nvidia.com/labs/toronto-ai/LLaMA-Mesh/" target="_blank" rel="noopener noreferrer">LLaMA-Mesh 项目主页</a></li><li><a href="https://github.com/nv-tlabs/LLaMa-Mesh" target="_blank" rel="noopener noreferrer">LLaMA-Mesh GitHub 仓库</a></li></ol>',46)]))}]]),i=JSON.parse('{"path":"/zh/posts/ai-weekly/012.html","title":"TANGO赋能数字人|ADD-IT重构图像编辑|MikuDance动漫角色舞蹈动画【AI周报】","lang":"zh-CN","frontmatter":{"description":"TANGO赋能数字人|ADD-IT重构图像编辑|MikuDance动漫角色舞蹈动画【AI周报】 微信logo.png微信logo.png 摘要 本周聚焦多模态AI发展：TANGO创新语音驱动手势视频；StoryTeller支持长视频剧情生成；ADD-IT无训练对象插入；MikuDance合成动漫角色舞蹈；LLaMA-Mesh统一3D网格与语言模型。其余...","gitInclude":[],"head":[["meta",{"property":"og:url","content":"https://neverbiasu.github.io/zh/posts/ai-weekly/012.html"}],["meta",{"property":"og:site_name","content":"Nlog"}],["meta",{"property":"og:title","content":"TANGO赋能数字人|ADD-IT重构图像编辑|MikuDance动漫角色舞蹈动画【AI周报】"}],["meta",{"property":"og:description","content":"TANGO赋能数字人|ADD-IT重构图像编辑|MikuDance动漫角色舞蹈动画【AI周报】 微信logo.png微信logo.png 摘要 本周聚焦多模态AI发展：TANGO创新语音驱动手势视频；StoryTeller支持长视频剧情生成；ADD-IT无训练对象插入；MikuDance合成动漫角色舞蹈；LLaMA-Mesh统一3D网格与语言模型。其余..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://prod-files-secure.s3.us-west-2.amazonaws.com/021ded55-a224-419c-939c-70c6888912f7/d1a9dc14-03bb-4a6d-9bde-08c809989d52/%E5%BE%AE%E4%BF%A1logo.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"TANGO赋能数字人|ADD-IT重构图像编辑|MikuDance动漫角色舞蹈动画【AI周报】\\",\\"image\\":[\\"https://prod-files-secure.s3.us-west-2.amazonaws.com/021ded55-a224-419c-939c-70c6888912f7/d1a9dc14-03bb-4a6d-9bde-08c809989d52/%E5%BE%AE%E4%BF%A1logo.png\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"neverbiasu\\",\\"url\\":\\"https://mister-hope.com\\"}]}"]]},"headers":[{"level":2,"title":"摘要","slug":"摘要","link":"#摘要","children":[]},{"level":2,"title":"目录","slug":"目录","link":"#目录","children":[]},{"level":2,"title":"TANGO: 联合语音驱动的手势重演模型","slug":"tango-联合语音驱动的手势重演模型","link":"#tango-联合语音驱动的手势重演模型","children":[]},{"level":2,"title":"StoryTeller: 长视频描述与角色识别模型","slug":"storyteller-长视频描述与角色识别模型","link":"#storyteller-长视频描述与角色识别模型","children":[]},{"level":2,"title":"ADD-IT :无需训练的图像对象插入方法","slug":"add-it-无需训练的图像对象插入方法","link":"#add-it-无需训练的图像对象插入方法","children":[]},{"level":2,"title":"MikuDance: 基于Diffusion模型的卡通角色动画生成","slug":"mikudance-基于diffusion模型的卡通角色动画生成","link":"#mikudance-基于diffusion模型的卡通角色动画生成","children":[]},{"level":2,"title":"MagicQuill: 智能交互式图像编辑系统","slug":"magicquill-智能交互式图像编辑系统","link":"#magicquill-智能交互式图像编辑系统","children":[]},{"level":2,"title":"LLaMA-Mesh: 大模型驱动的 3D Mesh生成","slug":"llama-mesh-大模型驱动的-3d-mesh生成","link":"#llama-mesh-大模型驱动的-3d-mesh生成","children":[{"level":3,"title":"参考链接","slug":"参考链接","link":"#参考链接","children":[]}]}],"readingTime":{"minutes":6.38,"words":1915},"filePathRelative":"zh/posts/ai-weekly/012.md","excerpt":"\\n<figure><img src=\\"https://prod-files-secure.s3.us-west-2.amazonaws.com/021ded55-a224-419c-939c-70c6888912f7/d1a9dc14-03bb-4a6d-9bde-08c809989d52/微信logo.png\\" alt=\\"微信logo.png\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>微信logo.png</figcaption></figure>\\n<h2><strong>摘要</strong></h2>\\n<p>本周聚焦多模态AI发展：TANGO创新语音驱动手势视频；StoryTeller支持长视频剧情生成；ADD-IT无训练对象插入；MikuDance合成动漫角色舞蹈；LLaMA-Mesh统一3D网格与语言模型。其余详见正文。</p>","autoDesc":true}')}}]);