"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[6193],{66262:(n,a)=>{a.A=(n,a)=>{const e=n.__vccOpts||n;for(const[n,i]of a)e[n]=i;return e}},6807:(n,a,e)=>{e.r(a),e.d(a,{comp:()=>t,data:()=>o});var i=e(20641);const r={},t=(0,e(66262).A)(r,[["render",function(n,a){return(0,i.uX)(),(0,i.CE)("div",null,a[0]||(a[0]=[(0,i.Fv)('<h1 id="wan2-1-fusionx视频生成升级-hunyuan3d-2-1高保真3d创作-show-o2统一多模态架构【ai周报】" tabindex="-1"><a class="header-anchor" href="#wan2-1-fusionx视频生成升级-hunyuan3d-2-1高保真3d创作-show-o2统一多模态架构【ai周报】"><span>Wan2.1 FusionX视频生成升级 | Hunyuan3D-2.1高保真3D创作 | Show-o2统一多模态架构【AI周报】</span></a></h1><figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bc7e4820-82c0-4d95-a196-9627d8cb4578/original=true,quality=90/00003-2892726208.jpeg" alt="封面源自C站作者Koal2" tabindex="0" loading="lazy"><figcaption>封面源自C站作者Koal2</figcaption></figure><h2 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span>摘要</span></a></h2><p>本周亮点：Wan2.1-FusionX视频生成提速25%；Hunyuan3D-2.1生产级PBR材质3D生成；Show-o2统一多模态架构；MiniMax-M1百万级上下文推理；PartPacker零件级3D生成；其余详见正文。</p><hr><h2 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span>目录</span></a></h2><ol><li><a href="#only-style-pp%E8%81%9A%E7%84%A6%E9%A3%8E%E6%A0%BC%E7%B2%BE%E7%B2%B9%E7%9A%84%E5%9B%BE%E5%83%8F%E8%BF%81%E7%A7%BB%E6%8A%80%E6%9C%AF">Only-Style-PP：聚焦风格精粹的图像迁移技术</a></li><li><a href="#ming%E2%80%91omni%E9%A6%96%E4%B8%AA%E5%85%A8%E6%A8%A1%E6%80%81%E7%BB%9F%E4%B8%80%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88%E8%AF%AD%E9%9F%B3%E4%B8%8E%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E5%8A%9F%E8%83%BD">Ming‑Omni：首个全模态统一模型，融合语音与图像生成功能</a></li><li><a href="#partpacker%E9%AB%98%E6%95%88%E9%9B%B6%E4%BB%B6%E7%BA%A7-3d-%E5%AF%B9%E8%B1%A1%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B">PartPacker：高效零件级 3D 对象生成模型</a></li><li><a href="#hunyuan3d%E2%80%9121%E5%8F%AF%E7%94%9F%E6%88%90%E9%AB%98%E4%BF%9D%E7%9C%9Fpbr%E6%9D%90%E8%B4%A8%E7%9A%84%E5%8D%95%E5%9B%BE3d%E8%B5%84%E4%BA%A7%E7%B3%BB%E7%BB%9F">Hunyuan3D‑2.1：可生成高保真PBR材质的单图3D资产系统</a></li><li><a href="#wan2.1-fusionix%E7%A4%BE%E5%8C%BA%E9%A9%B1%E5%8A%A8%E7%9A%84%E9%AB%98%E6%80%A7%E8%83%BD%E5%BC%80%E6%BA%90%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B">Wan2.1-FusionX：社区驱动的高性能开源视频生成模型</a></li><li><a href="#minimax-m1%E5%85%A8%E7%90%83%E9%A6%96%E4%B8%AA%E7%99%BE%E4%B8%87%E7%BA%A7%E4%B8%8A%E4%B8%8B%E6%96%87%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B">MiniMax-M1：全球首个百万级上下文混合专家推理模型</a></li><li><a href="#show-o2%E5%8E%9F%E7%94%9F%E5%A2%9E%E5%BC%BA%E7%BB%9F%E4%B8%80%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B">Show-o2：原生增强统一多模态模型</a></li></ol><hr><h2 id="only-style-pp-聚焦风格精粹的图像迁移技术" tabindex="-1"><a class="header-anchor" href="#only-style-pp-聚焦风格精粹的图像迁移技术"><span>Only-Style-PP：聚焦风格精粹的图像迁移技术</span></a></h2><figure><img src="https://arxiv.org/html/2506.09916v1/x1.png" alt="Only-Style-PP Overview 图" tabindex="0" loading="lazy"><figcaption>Only-Style-PP Overview 图</figcaption></figure><p><strong>概要</strong>：<strong>Only‑Style‑PP</strong> 是由 <strong>雅典国家技术大学</strong> 团队提出的一种专注于“仅提取并迁移风格”的图像风格迁移方法。它通过创新的 Filter-and-Paste-Patch 流程，从源图像中精确提取风格，然后将风格信息转移到目标图像的内容区域，而有效避免内容特征的干扰。该方法在细节保真度和风格一致性方面表现突出，尤其适用于需要保持内容清晰而只改变风格的场景。</p><p><strong>标签</strong>：#图像风格迁移 #风格保留 #FilterAndPastePatch #高保真</p><hr><h2 id="ming‐omni-首个全模态统一模型-融合语音与图像生成功能" tabindex="-1"><a class="header-anchor" href="#ming‐omni-首个全模态统一模型-融合语音与图像生成功能"><span>Ming‑Omni：首个全模态统一模型，融合语音与图像生成功能</span></a></h2><figure><img src="https://lucaria-academy.github.io/Ming-Omni/static/images/teaser.jpg" alt="Ming‑Omni Teaser 图" tabindex="0" loading="lazy"><figcaption>Ming‑Omni Teaser 图</figcaption></figure><p><strong>概要</strong>：<strong>Ming‑Omni</strong> 是由 <strong>Inclusion AI 与 Ant Group</strong> 联合推出的全新统一多模态模型，覆盖图像、文本、音频和视频的输入和生成能力。其核心架构采用多专家混合（MoE）设计，配备模态专用编码器与路由器（Ling），实现无缝模态融合。通过集成高质量音频解码器与图像生成模块（Ming‑Lite‑Uni），该模型能够进行上下文感知对话、文字转语音、图像生成与多模态编辑。Ming‑Lite‑Omni 版本仅启用 2.8B 参数却在图像、音频、视频与文字任务中的多项基准超越 Qwen 或 Gemini 等大型闭源模型，在跨模态表现上与 GPT‑4o 不相上下，是首个公开匹配其模态能力的开源模型 。</p><p><strong>标签</strong>：#多模态模型 #统一感知生成 #MoE架构 #音频生成 #图像生成</p><hr><h2 id="partpacker-高效零件级-3d-对象生成模型" tabindex="-1"><a class="header-anchor" href="#partpacker-高效零件级-3d-对象生成模型"><span>PartPacker：高效零件级 3D 对象生成模型</span></a></h2><figure><img src="https://research.nvidia.com/labs/dir/partpacker/media/teaser.png" alt="PartPacker Teaser 图" tabindex="0" loading="lazy"><figcaption>PartPacker Teaser 图</figcaption></figure><p><strong>概要</strong>：<strong>PartPacker</strong> 是由 <strong>NVIDIA Research</strong>、<strong>北京大学</strong> 和 <strong>斯坦福大学</strong> 合作推出的首个端到端单视图零件级 3D 对象生成框架。不同于常见的融合式网格，该方法通过“双体素封装”策略，将生成任务划分为两个互补体素结构，支持任意数量的语义独立部件生成。系统基于扩散 Transformer（DiT）架构，无需预分割，通过独特的体素打包机制，实现对每个部件的并行推理和高效生成。在 Objaverse‑XL 数据集上表现卓越，生成速度从数分钟缩短至 30 秒，且在质量、多样性和泛化能力上全面优于现有图像到 3D 零件生成方法 。项目已在 GitHub 和 Hugging Face Spaces 上开源，包含完整代码、预训练模型、演示接口和交互式体验，极大推动了可编辑 3D 内容自动化生成的研究进展。</p><p><strong>标签</strong>：#3D生成 #零件级网格 #扩散Transformer #双体素封装 #可编辑</p><hr><h2 id="hunyuan3d‐2-1-可生成高保真pbr材质的单图3d资产系统" tabindex="-1"><a class="header-anchor" href="#hunyuan3d‐2-1-可生成高保真pbr材质的单图3d资产系统"><span>Hunyuan3D‑2.1：可生成高保真PBR材质的单图3D资产系统</span></a></h2><figure><img src="https://3d-models.hunyuan.tencent.com/public/65f2dca1c28fd8b846ea.webp" alt="Hunyuan3D‑2.1 Architecture 图" tabindex="0" loading="lazy"><figcaption>Hunyuan3D‑2.1 Architecture 图</figcaption></figure><p><strong>概要</strong>：<strong>Hunyuan3D‑2.1</strong> 是由 腾讯混元 团队开发的先进 3D 生成与纹理合成系统，面向游戏、影视、工业设计等生产级场景。该系统包括两个核心模块：<strong>Hunyuan3D‑DiT</strong>（形状生成）和 <strong>Hunyuan3D‑Paint</strong>（PBR 材质纹理合成），分别负责从单张图像生成高保真网格和物理基础渲染纹理。整个流程是模块化、可灵活选配多视角建模或仅形状输出，支持模型微调与真实部署。官方于 6 月 13 日全面开源，包括训练代码、权重和 demo，以及 Hugging Face Space 在线演示 。实验验证显示 Hunyuan3D‑2.1 在几何质量与纹理一致性上全面超越现有开源及闭源模型，生成速度从分钟级降至几十秒级，真正实现“生产级”3D 内容自动化。</p><p><strong>标签</strong>：#3D生成 #PBR材质 #单图网格 #高保真 #模块化流程</p><hr><h2 id="wan2-1-fusionx-社区驱动的高性能开源视频生成模型" tabindex="-1"><a class="header-anchor" href="#wan2-1-fusionx-社区驱动的高性能开源视频生成模型"><span>Wan2.1-FusionX：社区驱动的高性能开源视频生成模型</span></a></h2><figure><img src="https://huggingface.co/vrgamedevgirl84/Wan14BT2VFusioniX/resolve/main/videos/FusionX_00020.gif" alt="Wan2.1-FunsionX Demo 图" tabindex="0" loading="lazy"><figcaption>Wan2.1-FunsionX Demo 图</figcaption></figure><p><strong>概要</strong>：<strong>Wan2.1 FusionX</strong> 是社区贡献者（vrgamedevgirl84）基于 <strong>WAN 2.1 14B</strong> 模型打造的开源文本/图像驱动视频生成基础模型。它集成了多个研究型组件（如 CausVid、AccVideo、MoviiGen1.1、MPS Reward LoRA 等），显著提升生成流程中的动态流畅度、场景一致性与细节表现腰。该模型对 ComfyUI 极度友好，仅需 6–8 步即可生成高品质视频，且生成速度较原始 WAN 模型提升约 25%。最新版本还支持 LoRA 插件化，同时兼容 GGUF 格式，极大增强部署灵活性和社区模型融入能力。</p><p><strong>标签</strong>：#视频生成 #文本生成视频 #社区贡献 #ComfyUI #LoRA</p><hr><h2 id="minimax-m1-全球首个百万级上下文混合专家推理模型" tabindex="-1"><a class="header-anchor" href="#minimax-m1-全球首个百万级上下文混合专家推理模型"><span>MiniMax-M1：全球首个百万级上下文混合专家推理模型</span></a></h2><figure><img src="https://github.com/MiniMax-AI/MiniMax-M1/raw/main/figures/TextBench.png" alt="MiniMax-M1 Benchmark 图" tabindex="0" loading="lazy"><figcaption>MiniMax-M1 Benchmark 图</figcaption></figure><p><strong>概要</strong>：<strong>MiniMax-M1</strong> 是由中国上海 MiniMax 团队推出的开源混合专家推理模型，具备混合稀疏 MoE 架构和高效 lightning attention 技术，支持长达 100 万 token 的上下文处理，相较 DeepSeek-R1 模型达到 8 倍上下文长度。该模型通过 CISPO 强化学习算法实现高效训练，仅耗时三周完成全量训练，成本低至约 $534,700。MiniMax-M1 在长文本推理、编程任务和复杂工具调用等方面表现出色，在 LiveCodeBench、GPQA 等基准中达到或超越 Qwen3-235B 和 DeepSeek-R1。</p><p><strong>标签</strong>：#推理模型 #混合专家 #百万上下文 #强化学习 #高效推理</p><hr><h2 id="show-o2-原生增强统一多模态模型" tabindex="-1"><a class="header-anchor" href="#show-o2-原生增强统一多模态模型"><span>Show-o2：原生增强统一多模态模型</span></a></h2><figure><img src="https://arxiv.org/html/2506.15564v1/x1.png" alt="Show-o2 Teaser 图" tabindex="0" loading="lazy"><figcaption>Show-o2 Teaser 图</figcaption></figure><p><strong>概要</strong>：<strong>Show-o2</strong> 是由 <strong>新加玻国立大学 Show Lab</strong> 与 <strong>字节跳动</strong> 联合推出的 Show-o 改进版本，采用单一 Transformer 架构融合自回归和流匹配机制，实现文本、图像、视频的统一理解与生成。该模型通过 3D 因果变分自编码器空间与双路径空间-时序融合结构，在语言 head 使用自回归，在图像/视频 head 应用流匹配（flow matching），有效统一多模态能力。Show-o2 支持视觉问答、图像生成、视频生成、引导修复/补全等任务，通过两阶段训练策略提升大尺度处理能力，在内容生成和理解任务中均达到或超过当前最佳水平。</p><p><strong>标签</strong>：#统一多模态 #Transformer #自回归+流匹配 #3D VAE #图像视频生成</p><hr><h3 id="参考链接" tabindex="-1"><a class="header-anchor" href="#参考链接"><span><strong>参考链接</strong></span></a></h3><ol><li><a href="https://tilemahosaravanis.github.io/Only-Style-PP/" target="_blank" rel="noopener noreferrer">Only-Style-PP 项目页面</a></li><li><a href="https://github.com/TilemahosAravanis/Only-Style" target="_blank" rel="noopener noreferrer">Only-Style-PP Github 仓库</a></li><li><a href="https://arxiv.org/html/2506.09916v1" target="_blank" rel="noopener noreferrer">Only-Style-PP 论文</a></li><li><a href="https://lucaria-academy.github.io/Ming-Omni/" target="_blank" rel="noopener noreferrer">Ming-Omni 项目页面</a></li><li><a href="https://github.com/inclusionai/ming" target="_blank" rel="noopener noreferrer">Ming-Omni Github 仓库</a></li><li><a href="https://arxiv.org/html/2506.09344v1" target="_blank" rel="noopener noreferrer">Ming-Omni 论文</a></li><li><a href="https://research.nvidia.com/labs/dir/partpacker/" target="_blank" rel="noopener noreferrer">PartPacker 项目页面</a></li><li><a href="https://github.com/nvlabs/partpacker" target="_blank" rel="noopener noreferrer">PartPacker Github 仓库</a></li><li><a href="https://arxiv.org/html/2506.09980v1" target="_blank" rel="noopener noreferrer">PartPacker 论文</a></li><li><a href="https://3d-models.hunyuan.tencent.com/" target="_blank" rel="noopener noreferrer">Hunyuan3D-2.1 项目页面</a></li><li><a href="https://github.com/Tencent-Hunyuan/Hunyuan3D-2.1" target="_blank" rel="noopener noreferrer">Hunyuan3D-2.1 Github 仓库</a></li><li><a href="https://arxiv.org/html/2506.15442v1" target="_blank" rel="noopener noreferrer">Hunyuan3D-2.1 论文</a></li><li><a href="https://huggingface.co/vrgamedevgirl84/Wan14BT2VFusioniX" target="_blank" rel="noopener noreferrer">Wan14BT2VFusioniX Hugging Face</a></li><li><a href="https://civitai.com/models/1681541?modelVersionId=1903407" target="_blank" rel="noopener noreferrer">Wan14BT2VFusioniX Civitai</a></li><li><a href="https://www.minimax.io/" target="_blank" rel="noopener noreferrer">MiniMax-M1 官网</a></li><li><a href="https://github.com/MiniMax-AI/MiniMax-M1" target="_blank" rel="noopener noreferrer">MiniMax-M1 Github 仓库</a></li><li><a href="https://arxiv.org/html/2506.13585" target="_blank" rel="noopener noreferrer">MiniMax-M1 论文</a></li><li><a href="https://github.com/showlab/Show-o" target="_blank" rel="noopener noreferrer">Show-o2 Github 仓库</a></li><li><a href="https://arxiv.org/html/2506.15564v1" target="_blank" rel="noopener noreferrer">Show-o2 论文</a></li></ol>',45)]))}]]),o=JSON.parse('{"path":"/zh/posts/ai-weekly/043.html","title":"Wan2.1 FusionX视频生成升级 | Hunyuan3D-2.1高保真3D创作 | Show-o2统一多模态架构【AI周报】","lang":"zh-CN","frontmatter":{"description":"Wan2.1 FusionX视频生成升级 | Hunyuan3D-2.1高保真3D创作 | Show-o2统一多模态架构【AI周报】 封面源自C站作者Koal2封面源自C站作者Koal2 摘要 本周亮点：Wan2.1-FusionX视频生成提速25%；Hunyuan3D-2.1生产级PBR材质3D生成；Show-o2统一多模态架构；MiniMax-M1...","gitInclude":[],"head":[["meta",{"property":"og:url","content":"https://neverbiasu.github.io/zh/posts/ai-weekly/043.html"}],["meta",{"property":"og:site_name","content":"Nlog"}],["meta",{"property":"og:title","content":"Wan2.1 FusionX视频生成升级 | Hunyuan3D-2.1高保真3D创作 | Show-o2统一多模态架构【AI周报】"}],["meta",{"property":"og:description","content":"Wan2.1 FusionX视频生成升级 | Hunyuan3D-2.1高保真3D创作 | Show-o2统一多模态架构【AI周报】 封面源自C站作者Koal2封面源自C站作者Koal2 摘要 本周亮点：Wan2.1-FusionX视频生成提速25%；Hunyuan3D-2.1生产级PBR材质3D生成；Show-o2统一多模态架构；MiniMax-M1..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bc7e4820-82c0-4d95-a196-9627d8cb4578/original=true,quality=90/00003-2892726208.jpeg"}],["meta",{"property":"og:locale","content":"zh-CN"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Wan2.1 FusionX视频生成升级 | Hunyuan3D-2.1高保真3D创作 | Show-o2统一多模态架构【AI周报】\\",\\"image\\":[\\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bc7e4820-82c0-4d95-a196-9627d8cb4578/original=true,quality=90/00003-2892726208.jpeg\\",\\"https://arxiv.org/html/2506.09916v1/x1.png\\",\\"https://lucaria-academy.github.io/Ming-Omni/static/images/teaser.jpg\\",\\"https://research.nvidia.com/labs/dir/partpacker/media/teaser.png\\",\\"https://3d-models.hunyuan.tencent.com/public/65f2dca1c28fd8b846ea.webp\\",\\"https://huggingface.co/vrgamedevgirl84/Wan14BT2VFusioniX/resolve/main/videos/FusionX_00020.gif\\",\\"https://github.com/MiniMax-AI/MiniMax-M1/raw/main/figures/TextBench.png\\",\\"https://arxiv.org/html/2506.15564v1/x1.png\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"neverbiasu\\",\\"url\\":\\"https://neverbiasu.github.io\\"}]}"]]},"headers":[{"level":2,"title":"摘要","slug":"摘要","link":"#摘要","children":[]},{"level":2,"title":"目录","slug":"目录","link":"#目录","children":[]},{"level":2,"title":"Only-Style-PP：聚焦风格精粹的图像迁移技术","slug":"only-style-pp-聚焦风格精粹的图像迁移技术","link":"#only-style-pp-聚焦风格精粹的图像迁移技术","children":[]},{"level":2,"title":"Ming‑Omni：首个全模态统一模型，融合语音与图像生成功能","slug":"ming‐omni-首个全模态统一模型-融合语音与图像生成功能","link":"#ming‐omni-首个全模态统一模型-融合语音与图像生成功能","children":[]},{"level":2,"title":"PartPacker：高效零件级 3D 对象生成模型","slug":"partpacker-高效零件级-3d-对象生成模型","link":"#partpacker-高效零件级-3d-对象生成模型","children":[]},{"level":2,"title":"Hunyuan3D‑2.1：可生成高保真PBR材质的单图3D资产系统","slug":"hunyuan3d‐2-1-可生成高保真pbr材质的单图3d资产系统","link":"#hunyuan3d‐2-1-可生成高保真pbr材质的单图3d资产系统","children":[]},{"level":2,"title":"Wan2.1-FusionX：社区驱动的高性能开源视频生成模型","slug":"wan2-1-fusionx-社区驱动的高性能开源视频生成模型","link":"#wan2-1-fusionx-社区驱动的高性能开源视频生成模型","children":[]},{"level":2,"title":"MiniMax-M1：全球首个百万级上下文混合专家推理模型","slug":"minimax-m1-全球首个百万级上下文混合专家推理模型","link":"#minimax-m1-全球首个百万级上下文混合专家推理模型","children":[]},{"level":2,"title":"Show-o2：原生增强统一多模态模型","slug":"show-o2-原生增强统一多模态模型","link":"#show-o2-原生增强统一多模态模型","children":[{"level":3,"title":"参考链接","slug":"参考链接","link":"#参考链接","children":[]}]}],"readingTime":{"minutes":7.12,"words":2135},"filePathRelative":"zh/posts/ai-weekly/043.md","excerpt":"\\n<figure><img src=\\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bc7e4820-82c0-4d95-a196-9627d8cb4578/original=true,quality=90/00003-2892726208.jpeg\\" alt=\\"封面源自C站作者Koal2\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>封面源自C站作者Koal2</figcaption></figure>\\n<h2>摘要</h2>\\n<p>本周亮点：Wan2.1-FusionX视频生成提速25%；Hunyuan3D-2.1生产级PBR材质3D生成；Show-o2统一多模态架构；MiniMax-M1百万级上下文推理；PartPacker零件级3D生成；其余详见正文。</p>","autoDesc":true}')}}]);