"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[5317],{66262:(e,a)=>{a.A=(e,a)=>{const i=e.__vccOpts||e;for(const[e,t]of a)i[e]=t;return i}},7050:(e,a,i)=>{i.r(a),i.d(a,{comp:()=>s,data:()=>r});var t=i(20641);const n={},s=(0,i(66262).A)(n,[["render",function(e,a){return(0,t.uX)(),(0,t.CE)("div",null,a[0]||(a[0]=[(0,t.Fv)('<h1 id="how-to-create-an-original-character-lora-sdxl-training-sdxl-character-training" tabindex="-1"><a class="header-anchor" href="#how-to-create-an-original-character-lora-sdxl-training-sdxl-character-training"><span>How to create an original character LoRA [SDXL Training] SDXL Character Training</span></a></h1><figure><img src="http://digitalcreativeai.net/_next/image?url=https%3A%2F%2Fdca.data-hub-center.com%2Fcontent%2Fuploads%2F2025%2F05%2Feye_catch_original-character-lora-sdxl-character-training-en.jpg&amp;w=3840&amp;q=80" alt="How to create an original character LoRA [SDXL Training] SDXL Character Training featured Image" tabindex="0" loading="lazy"><figcaption>How to create an original character LoRA [SDXL Training] SDXL Character Training featured Image</figcaption></figure><h2 id="table-of-contents" tabindex="-1"><a class="header-anchor" href="#table-of-contents"><span>Table of Contents</span></a></h2><ol><li><a href="#compatibility-of-sdxls-pretrained-model">Compatibility of SDXL’s Pretrained model</a><br> 1.1. <a href="#compatibility-test-generation">Compatibility test generation</a></li><li><a href="#training-with-default-parameters-in-kohya-ss-gui">Training with default parameters in Kohya ss GUI</a><br> 2.1. <a href="#dataset">Dataset</a><br> 2.2. <a href="#default-parameters">Default Parameters</a><br> 2.3. <a href="#test-generation-using-trained-lora">Test generation using trained LoRA</a></li><li><a href="#parameters-used-in-this-train">Parameters used in this train</a><br> 3.1. <a href="#lr-scheduler">LR Scheduler</a><br> 3.2. <a href="#optimizer">Optimizer</a><br> 3.3. <a href="#other-parameters">Other parameters</a></li><li><a href="#training-results">Training Results</a><br> 4.1. <a href="#combination-with-other-loras">Combination with other LoRAs</a><br> 4.2. <a href="#apply-to-checkpoint-models-of-the-same-lineage">Apply to checkpoint models of the same lineage</a></li><li><a href="#conclusion">Conclusion</a></li></ol><hr><h2 id="compatibility-of-sdxl-s-pretrained-model" tabindex="-1"><a class="header-anchor" href="#compatibility-of-sdxl-s-pretrained-model"><span>Compatibility of SDXL’s Pretrained model</span></a></h2><p>LoRA in SDXL is less versatile than in SD1.5. The checkpoint models that LoRA can be applied to are limited depending on the pretrained model lineage. When generated, LoRA application within the same lineage can be used without problems, but when applied to checkpoint models outside the lineage, LoRA cannot be successfully applied. Most common SDXL illustration base model lineages are as follows:</p><ul><li><strong>SDXL-base-1.0 series</strong>: Fundamental model of SDXL. This model is not so suitable for illustration generation.</li><li><strong>animagineXL V3 series</strong>: This illustration AI model was popular until the arrival of PDXL (PonyV6). <em>LoRA trained in V3 cannot be used in V4.</em></li><li><strong>ponyDiffusionV6XL series</strong>: This popular model has quickly dominated the scene since its introduction. However, NSFW images are often generated and need to be adjusted with negative prompts.</li><li><strong>illustriousXL01 series</strong>: The model on which kohaku-xl-beta5 is used as a base model. At the time of writing, it is the most vibrant model and produces high-quality illustrations. As with animagineXL, compatibility between different versions is not good.</li><li><strong>NoobAI-XL series</strong>: Illustrious-xl-early-release-v0 is used as the base model, so it may belong to the illustriousXL series, but this is also a popular illustration AI model.</li></ul><p>In SDXL’s LoRA training, it is important to determine which lineage model the LoRA will be trained on.</p><h3 id="compatibility-test-generation" tabindex="-1"><a class="header-anchor" href="#compatibility-test-generation"><span>Compatibility test generation</span></a></h3><p>To make it easier to understand the compatibility, let’s look at the comparison images generated by each model. The LoRAs to be compared are <code>[SDXL-base-1.0VAEFix / animagineXLV31_v31 / ponyDiffusionV6XL_v6StartWithThisOne / illustriousXL_v01 / noobaiXLNAIXL_epsilonPred 1.1-Version]</code>. These are specified as pretrained models and trained with default parameters.</p><p><strong>Training Parameters</strong></p><div class="language-plaintext line-numbers-mode" data-highlighter="shiki" data-ext="plaintext" data-title="plaintext" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>Number of training images: 100</span></span>\n<span class="line"><span>Repeats: 5</span></span>\n<span class="line"><span>Train batch size: 1</span></span>\n<span class="line"><span>Epoch: 1</span></span>\n<span class="line"><span>Max train steps: 1600</span></span>\n<span class="line"><span>Seed: 123</span></span>\n<span class="line"><span>LR Scheduler: cosine</span></span>\n<span class="line"><span>Optimizer: AdamW8bit</span></span>\n<span class="line"><span>Learning rate: 0.0001 (1e-4)</span></span>\n<span class="line"><span>Unet learning rate: 0.0001 (1e-4)</span></span>\n<span class="line"><span>Text Encoder learning rate: 0.00005 (5e-5)</span></span>\n<span class="line"><span>Network Rank (Dimension): 8</span></span>\n<span class="line"><span>Network Alpha: 1</span></span>\n<span class="line"><span>clip_skip: 0 *In SDXL, Clip skip is disabled.</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>A1111 WebUI generation parameters</strong></p><p><strong>Prompt:</strong></p><div class="language-plaintext line-numbers-mode" data-highlighter="shiki" data-ext="plaintext" data-title="plaintext" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>dcai-girl, 1girl, looking at viewer, solo, short hair, orange hair, brown eyes, animal ears, dress, masterpiece, meadow, sky, day &lt;lora:DCAI_Girl_SDXL_Def_sdxl-base:1&gt;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><strong>Negative Prompt:</strong></p><div class="language-plaintext line-numbers-mode" data-highlighter="shiki" data-ext="plaintext" data-title="plaintext" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>worst quality, low quality, bad anatomy, realistic, lips, inaccurate limb, extra digit, fewer digits, six fingers, monochrome, nsfw</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><strong>Parameters</strong></p><div class="language-plaintext line-numbers-mode" data-highlighter="shiki" data-ext="plaintext" data-title="plaintext" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>Steps: 20</span></span>\n<span class="line"><span>Sampler: DPM++ SDE</span></span>\n<span class="line"><span>Schedule type: Karras</span></span>\n<span class="line"><span>CFG scale: 6</span></span>\n<span class="line"><span>Seed: 3156195032</span></span>\n<span class="line"><span>Size: 1024x1024</span></span>\n<span class="line"><span>VAE: sdxl.vae.safetensors</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><hr><p><strong>SDXL-base-1.0</strong> The first comparison image is generated using &quot;SDXL-base-1.0&quot;. The rightmost image is the generated result before LoRA adaptation.</p><figure><img src="https://dca.data-hub-center.com/content/uploads/2025/05/compare-sdxl-base-model-base1.jpg" alt="LoRA comparison generated by SDXL-base-1.0 model" tabindex="0" loading="lazy"><figcaption>LoRA comparison generated by SDXL-base-1.0 model</figcaption></figure><p>Far right: the SDXL-base LoRA has trained reasonably well. You can also see that the other LoRAs are slightly affected by the costumes.</p><p><strong>animagineXLV31_v31</strong> The next comparison image is with &quot;animagineXLV31_v31&quot;.</p><figure><img src="https://dca.data-hub-center.com/content/uploads/2025/05/compare-sdxl-base-model-anima3.jpg" alt="LoRA comparison generated by animagineXLV31_v31" tabindex="0" loading="lazy"><figcaption>LoRA comparison generated by animagineXLV31_v31</figcaption></figure><p>2nd from right: animagineXLV3.1 LoRA has been reproduced better. You can see that the other LoRAs also affected the costumes a little.</p><p><strong>ponyDiffusionV6XL_v6StartWithThisOne</strong> This is a comparison image using &quot;ponyDiffusionV6XL_v6StartWithThisOne&quot;. *The quality modifiers &quot;score_9, score_8_up, score_7_up&quot; specific to PonyDiffusionV6XL and &quot;score_6, score_5, score_4&quot; for negative prompts are added for generation.</p><figure><img src="https://dca.data-hub-center.com/content/uploads/2025/05/compare-sdxl-base-model-pony6.jpg" alt="LoRA comparison generated by ponyDiffusionV6XL_v6StartWithThisOne" tabindex="0" loading="lazy"><figcaption>LoRA comparison generated by ponyDiffusionV6XL_v6StartWithThisOne</figcaption></figure><p>3rd from the right: you can see that almost nothing is affected except the LoRA of ponyDiffusionV6XL.</p><p><strong>illustriousXL_v01</strong> This is a comparison image using &quot;illustriousXL_v01&quot;.</p><figure><img src="https://dca.data-hub-center.com/content/uploads/2025/05/compare-sdxl-base-model-illusxl.jpg" alt="LoRA comparison generated by illustriousXL_v01" tabindex="0" loading="lazy"><figcaption>LoRA comparison generated by illustriousXL_v01</figcaption></figure><p>4th from right: illustriousXL&#39;s LoRA is reasonably well learned except for the color of the costume. The other LoRAs can be seen to have little effect.</p><p><strong>noobaiXLNAIXL_epsilonPred 1.1-Version</strong> This is a comparison image using &quot;noobaiXLNAIXL_epsilonPred 1.1-Version&quot;. *The main model is &quot;NOOBAI XL-VPred 1.0&quot;, but V-prediction is only available in the development version for A1111WebUI. In this case, the Epsilon-prediction version is used.</p><figure><img src="https://dca.data-hub-center.com/content/uploads/2025/05/compare-sdxl-base-model-noobai.jpg" alt="LoRA comparison generated by noobaiXLNAIXL_epsilonPred 1.1-Version" tabindex="0" loading="lazy"><figcaption>LoRA comparison generated by noobaiXLNAIXL_epsilonPred 1.1-Version</figcaption></figure><p>5th from right: noobaiXLNAIXL_epsilonPred 1.1-Version of LoRA was able to reproduce the face but not the outfit. You can also see a slight influence on illustriousXL.</p><p>The above comparison images show that SDXL&#39;s LoRA is not compatible.</p><h2 id="training-with-default-parameters-in-kohya-ss-gui" tabindex="-1"><a class="header-anchor" href="#training-with-default-parameters-in-kohya-ss-gui"><span>Training with default parameters in Kohya ss GUI</span></a></h2><p>Now that you understand SDXL compatibility, let&#39;s train with &quot;animagineXLV31_v30Base&quot;. If you train LoRA on this model, you can use it as a checkpoint model for animagineXL V3 series. Note that the LoRA of animagineXL V3 cannot be used for animagineXL V4. Let&#39;s compare the images generated by Animagine XL 4.0 Opt with the previous comparison image.</p><figure><img src="https://dca.data-hub-center.com/content/uploads/2025/05/compare-sdxl-base-model-anima3.jpg" alt="LoRA comparison generated by animagineXLV31_v31" tabindex="0" loading="lazy"><figcaption>LoRA comparison generated by animagineXLV31_v31</figcaption></figure><figure><img src="https://dca.data-hub-center.com/content/uploads/2025/05/compare-sdxl-base-model-anima4.jpg" alt="LoRA comparison generated by Animagine XL 4.0 Opt" tabindex="0" loading="lazy"><figcaption>LoRA comparison generated by Animagine XL 4.0 Opt</figcaption></figure><p>2nd from right: Costume affected a little, but generated less reproduction.</p><h3 id="dataset" tabindex="-1"><a class="header-anchor" href="#dataset"><span>Dataset</span></a></h3><p>First, let&#39;s train with default parameters. The dataset for training source is based on the data created in &quot;How to create an original character LoRA [Dataset] Making a training image and caption&quot;. If you want to train with the same dataset, it is available on Patreon, but only paid supporters can download it.</p><figure><img src="https://dca.data-hub-center.com/content/uploads/2025/03/finished-dataset-images.jpg" alt="Dataset Image Sample List" tabindex="0" loading="lazy"><figcaption>Dataset Image Sample List</figcaption></figure><h3 id="default-parameters" tabindex="-1"><a class="header-anchor" href="#default-parameters"><span>Default Parameters</span></a></h3><p>Once the dataset is ready, we start by training with the default values, slightly modified for the trained illustration of the SDXL model. Areas that need to be entered or changed are noted in red text.</p><ul><li><strong>Pretrained model name or path:</strong> animagineXLV31_v30Base.safetensors</li><li><strong>Trained Model output name:</strong> DCAI_Girl_SDXL_Def_anima3 *Output name of the model</li><li><strong>Instance prompt:</strong> dcai-girl *The caption method used in this case ignores this value, but if you do not enter it, an error will occur.</li><li><strong>Class prompt:</strong> 1girl *Entered for the same reason as above.</li><li><strong>Repeats:</strong> 5 [Default: 40] *This is because the training source has 100 images and we want to make the total number of images 500.</li><li><strong>Presets:</strong> none</li><li><strong>LoRA type:</strong> Standard</li><li><strong>Train batch size:</strong> 1</li><li><strong>Epoch:</strong> 1</li><li><strong>Max train epoch:</strong> 0</li><li><strong>Max train steps:</strong> 1600</li><li><strong>Save every N epochs:</strong> 1</li><li><strong>Seed:</strong> 123 [Default: 0 = random] *Insert the appropriate number to control the parameter.</li><li><strong>LR Scheduler:</strong> cosine</li><li><strong>Optimizer:</strong> AdamW8bit</li><li><strong>Learning rate:</strong> 0.0001 (1e-4)</li><li><strong>Text Encoder learning rate:</strong> 0.00005 (5e-5) [Default: 0.0001 (1e-4)] *Changed to the recommended defaults in the official documentation.</li><li><strong>Unet learning rate:</strong> 0.0001 (1e-4)</li><li><strong>LR warmup (% of total steps):</strong> 10</li><li><strong>Network Rank (Dimension):</strong> 8</li><li><strong>Network Alpha:</strong> 1</li><li><strong>clip_skip:</strong> 0 [Default: 1] *Because Clip skip is disabled in SDXL</li></ul><h3 id="test-generation-using-trained-lora" tabindex="-1"><a class="header-anchor" href="#test-generation-using-trained-lora"><span>Test generation using trained LoRA</span></a></h3><p>The trained LoRA was generated using the A1111 WebUI, resulting in the figure below. The &quot;animagineXLV31_v31&quot; was used to generate the LoRA. The image below is before LoRA was applied.</p><figure><img src="https://dca.data-hub-center.com/content/uploads/2025/05/sdxl-train-anima3-def.jpg" alt="Default parameter results" tabindex="0" loading="lazy"><figcaption>Default parameter results</figcaption></figure><figure><img src="https://dca.data-hub-center.com/content/uploads/2025/05/sdxl-train-anima3-def-no-lora.jpg" alt="Results without LoRA" tabindex="0" loading="lazy"><figcaption>Results without LoRA</figcaption></figure><p>It is highly reproducible, but it is like a winning Seed Gacha, and other Seeds produced unstable generation. The generation parameters are almost the same as in the previous comparison image, but with a few prompts changed for AnimagineV3.1.</p><p><strong>Prompt:</strong></p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>dcai-girl, 1girl, looking at viewer, solo, short hair, orange hair, brown eyes, animal ears, dress, meadow, sky, day, newest, masterpiece, best quality, very aesthetic, absurdres &lt;lora:DCAI_Girl_SDXL_Def_anima3:1&gt;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><strong>Negative Prompt:</strong></p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>worst quality, low quality, bad anatomy, realistic, lips, inaccurate limb, extra digit, fewer digits, six fingers, monochrome, nsfw</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><strong>Parameters:</strong></p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>Steps: 30</span></span>\n<span class="line"><span>Sampler: DPM++ SDE</span></span>\n<span class="line"><span>Schedule type: Karras</span></span>\n<span class="line"><span>CFG scale: 6</span></span>\n<span class="line"><span>Seed: 3156195032</span></span>\n<span class="line"><span>Size: 1344x768</span></span>\n<span class="line"><span>VAE: sdxl.vae.safetensors</span></span>\n<span class="line"><span>Hires.fix: True</span></span>\n<span class="line"><span>ADetailer: True</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="parameters-used-in-this-train" tabindex="-1"><a class="header-anchor" href="#parameters-used-in-this-train"><span>Parameters used in this train</span></a></h2><p>Since this is an SDXL train, it is set up to run relatively lightweight, but with no more than 16-24 GB of VRAM.</p><p>Different versions of Kohya ss, PyTorch or CUDA will give different results, so the settings I have presented will not guarantee that you will get the same results. There is currently no best setting that can train a high quality LoRA on every dataset and caption, so keep improving the quality through trial and error. For this training, I used the latest version of Kohya ss GUI v25.0.3 at the time of writing and RunPod&#39;s ubuntu22.04.</p><p>The environment of RunPod is as follows:</p><ul><li><strong>POD Template:</strong> RunPod Pytorch 2.2.0</li><li><strong>GPU:</strong> 1 x RTX 4090 *RTX 5090 cannot be used for now because xformars does not meet the requirements. If you really want to use it, you need to uninstall xformars by yourself and use Torch&#39;s sdpa for cross-attention.</li><li><strong>OS:</strong> ubuntu22.04</li><li><strong>Torch:</strong> 2.5.0+cu124</li><li><strong>Python:</strong> 3.10.12</li><li><strong>CUDA:</strong> 12.4</li><li><strong>cuDNN:</strong> 90100</li><li><strong>Kohya_ss GUI:</strong> 25.0.3</li></ul><h3 id="lr-scheduler" tabindex="-1"><a class="header-anchor" href="#lr-scheduler"><span>LR Scheduler</span></a></h3><p>cosine_with_restarts is one of the LR Scheduler to train while resetting cosine at specified intervals. The number of resets is specified by LR # cycles.</p><p>Take a look at the comparison image with the default below.</p><figure><img src="https://dca.data-hub-center.com/content/uploads/2025/05/compare-scheduler-restart.jpg" alt="Comparison of cosine_with_restarts" tabindex="0" loading="lazy"><figcaption>Comparison of cosine_with_restarts</figcaption></figure><p>The color of the clothes has changed, but the reproduction has been slightly improved.</p><figure><img src="https://dca.data-hub-center.com/content/uploads/2025/05/cosin-restart-tb-sample.jpg" alt="TB sample for cosine_with_restarts" tabindex="0" loading="lazy"><figcaption>TB sample for cosine_with_restarts</figcaption></figure><p>TensorBoard example; cyan:cosine_with_restarts-2LR#cycles pink:cosine *0-200 on X axis is LR warmup.</p><h3 id="optimizer" tabindex="-1"><a class="header-anchor" href="#optimizer"><span>Optimizer</span></a></h3><p>The official documentation recommends Adafactor. Also, AdamW8bit, which was used in the default settings mentioned earlier, does not seem to be recommended. If the number of training images is small or simple, Prodigy is recommended, but let&#39;s train with &quot;AdamW&quot; this time, using Optimizer extra arguments and changing the settings a little.</p><p>In the PyTorch documentation, the default class for AdamW is as follows:</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.optim.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">AdamW</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(params, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">lr</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.001</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">betas</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.9</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.999</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">), </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">eps</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1e-08</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">weight_decay</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.01</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">amsgrad</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">False</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, *, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">maximize</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">False</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">foreach</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">capturable</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">False</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">differentiable</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">False</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">fused</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>The two AdamW parameters to be changed this time are as follows:</p><h4 id="betas" tabindex="-1"><a class="header-anchor" href="#betas"><span>betas</span></a></h4><p>The coefficients used to compute the average of the gradients for convergence of the train. The coefficients used to calculate the average of the gradient toward convergence are (beta1, beta2), where beta1 controls how much weight is given to past gradients and beta2 controls how much weight is given to the magnitude of the gradient (the degree of variability).</p><p>In this case, I will use beta2 lowered from 0.999 to <code>0.99</code>. Lowering the beta2 value makes it more responsive to recent gradient fluctuations and more sensitive to adjustments in the train rate.</p><h4 id="weight-decay" tabindex="-1"><a class="header-anchor" href="#weight-decay"><span>weight_decay</span></a></h4><p>weight_decay is a regularization technique that prevents the weights in a model from becoming too large. It effectively simplifies the model and increases its versatility.</p><p>In this case, we will use <code>0.05</code>, up from the default of 0.01. This will increase stability and versatility.</p><h3 id="other-parameters" tabindex="-1"><a class="header-anchor" href="#other-parameters"><span>Other parameters</span></a></h3><p>Basically, there is little change from the previous SD1.5, but the difference is that Scale weight norms and Min SNR gamma are not used. The reason for this is that Scale weight norms is not necessary because the AdamW weight_decay is set to be stronger, and Min SNR gamma is not used because it did not have much effect in this setting.</p><p>Now let&#39;s look at the study settings after the change:</p><ul><li><strong>Pretrained model name or path:</strong> animagineXLV31_v30Base.safetensors</li><li><strong>Trained Model output name:</strong> DCAI_Girl_SDXL_Anima3 *Output name of the model</li><li><strong>Instance prompt:</strong> dcai-girl</li><li><strong>Class prompt:</strong> 1girl</li><li><strong>Repeats:</strong> 5 [Default: 40]</li><li><strong>Presets:</strong> none</li><li><strong>LoRA type:</strong> Standard</li><li><strong>Train batch size:</strong> 1</li><li><strong>Epoch:</strong> 4 [Default: 1] *To adjust total steps in Epoch</li><li><strong>Max train epoch:</strong> 0</li><li><strong>Max train steps:</strong> 0 [Default: 1600] *To adjust total steps in Epoch</li><li><strong>Save every N epochs:</strong> 0 [Default: 1] *No need to see progress</li><li><strong>Seed:</strong> 123 [Default: 0 = random]</li><li><strong>LR Scheduler:</strong> cosine_with_restarts [Default: cosine]</li><li><strong>Optimizer:</strong> AdamW [Default: AdamW8bit]</li><li><strong>Optimizer extra arguments:</strong> betas=0.9,0.99 weight_decay=0.05</li><li><strong>Learning rate:</strong> 0.0004 (4e-4) [Default: 0.0001]</li><li><strong>Text Encoder learning rate:</strong> 0.00005 (5e-5) [Default: 0.0001 (1e-4)]</li><li><strong>Unet learning rate:</strong> 0.0004 (4e-4) [Default: 0.0001]</li><li><strong>LR warmup (% of total steps):</strong> 10</li><li><strong>LR # cycles:</strong> 2 [Default: 1]</li><li><strong>Network Rank (Dimension):</strong> 32 [Default: 8]</li><li><strong>Network Alpha:</strong> 16 [Default: 1]</li><li><strong>Keep n tokens:</strong> 8 [Default: 0] *Number of instance and class tokens</li><li><strong>clip_skip:</strong> 0 [Default: 1]</li><li><strong>Shuffle caption:</strong> true [Default: false]</li><li><strong>CrossAttention:</strong> sdpa [Default: xformers]</li></ul><p>If your VRAM is less than 16 GB, use gradient checkpointing. Although the learning time will increase, VRAM consumption can be reduced. If VRAM is still insufficient, change the Optimizer to &quot;Adafactor&quot;.</p><h2 id="training-results" tabindex="-1"><a class="header-anchor" href="#training-results"><span>Training Results</span></a></h2><p>The A1111 WebUI settings were the same settings used to generate the previous test generation.</p><figure><img src="https://dca.data-hub-center.com/content/uploads/2025/05/sdxl-train-anima3-final.jpg" alt="Final results of the training" tabindex="0" loading="lazy"><figcaption>Final results of the training</figcaption></figure><h3 id="combination-with-other-loras" tabindex="-1"><a class="header-anchor" href="#combination-with-other-loras"><span>Combination with other LoRAs</span></a></h3><p>When using with other LoRAs, different weight scales may not apply well. The following is an adaptation of &quot;xl_more_art-full / xl_real / Enhancer&quot; at 1.0 with the same generation settings.</p><figure><img src="https://dca.data-hub-center.com/content/uploads/2025/05/sdxl-train-anima3-final-more_art-full.jpg" alt="Results in combination with other LoRA" tabindex="0" loading="lazy"><figcaption>Results in combination with other LoRA</figcaption></figure><p>The background has changed, but the characters themselves have adapted without much change.</p><h3 id="apply-to-checkpoint-models-of-the-same-lineage" tabindex="-1"><a class="header-anchor" href="#apply-to-checkpoint-models-of-the-same-lineage"><span>Apply to checkpoint models of the same lineage</span></a></h3><p>In this case, it was trained with AnimagineV3.1, so it can be used with a checkpoint model of the same lineage. Everything is generated with the same settings as for test generation.</p><figure><img src="https://dca.data-hub-center.com/content/uploads/2025/05/sdxl-train-anima3-final-animapencilxl_v500.jpg" alt="Generated result for animaPencilXL_v500" tabindex="0" loading="lazy"><figcaption>Generated result for animaPencilXL_v500</figcaption></figure><p>animaPencilXL_v500</p><figure><img src="https://dca.data-hub-center.com/content/uploads/2025/05/sdxl-train-anima3-final-anythingxl_xl.jpg" alt="Generated result for AnythingXL_xl" tabindex="0" loading="lazy"><figcaption>Generated result for AnythingXL_xl</figcaption></figure><p>AnythingXL_xl</p><figure><img src="https://dca.data-hub-center.com/content/uploads/2025/05/sdxl-train-anima3-final-chenkinanimeImpastobased.jpg" alt="Generated result for chenkinAnimeImpastoBased_v10" tabindex="0" loading="lazy"><figcaption>Generated result for chenkinAnimeImpastoBased_v10</figcaption></figure><p>chenkinAnimeImpastoBased_v10</p><figure><img src="https://dca.data-hub-center.com/content/uploads/2025/05/sdxl-train-anima3-final-lizmix_versionx.jpg" alt="Generated result for lizmix_versionX" tabindex="0" loading="lazy"><figcaption>Generated result for lizmix_versionX</figcaption></figure><p>lizmix_versionX</p><figure><img src="https://dca.data-hub-center.com/content/uploads/2025/05/sdxl-train-anima3-final-ranimexlbaseonanimagine_v10.jpg" alt="Generated result for ranimeXLBaseOnAnimagine_v10" tabindex="0" loading="lazy"><figcaption>Generated result for ranimeXLBaseOnAnimagine_v10</figcaption></figure><p>ranimeXLBaseOnAnimagine_v10</p><figure><img src="https://dca.data-hub-center.com/content/uploads/2025/05/sdxl-train-anima3-final-realAnimagineXL_v10.jpg" alt="Generated result for realAnimagineXL_v10" tabindex="0" loading="lazy"><figcaption>Generated result for realAnimagineXL_v10</figcaption></figure><p>realAnimagineXL_v10</p><p>As shown above, LoRA can be applied if the merge models includes AnimagineV3.1.</p><h2 id="conclusion" tabindex="-1"><a class="header-anchor" href="#conclusion"><span>Conclusion</span></a></h2><p>In this article, I have explained LoRA training for SDXL. Compared to the previous SD1.5, the training time is longer and requires a certain level of PC specs, so trial and error is quite a challenge. However, compared to SD1.5, I think we were able to train LoRA characters with more detail due to the increased resolution. I would like to explain the other lineage (ponyDiffusionV6XL, illustriousXL01, NoobAI-XL) in the near future. I would also like to explain how to use RunPod in DCAI article.</p>',111)]))}]]),r=JSON.parse('{"path":"/posts/reprints/original-character-lora-sdxl-character-training.html","title":"How to create an original character LoRA [SDXL Training] SDXL Character Training","lang":"en-US","frontmatter":{"title":"How to create an original character LoRA [SDXL Training] SDXL Character Training","date":"2025-05-12T07:01:40.000Z","tags":["Kohya SS GUI","LoRA","SDXL"],"categories":["Advanced"],"description":"How to create an original character LoRA [SDXL Training] SDXL Character Training How to create an original character LoRA [SDXL Training] SDXL Character Training featured ImageH...","gitInclude":[],"head":[["link",{"rel":"alternate","hreflang":"zh-cn","href":"https://neverbiasu.github.io/zh/posts/reprints/original-character-lora-sdxl-character-training.html"}],["meta",{"property":"og:url","content":"https://neverbiasu.github.io/posts/reprints/original-character-lora-sdxl-character-training.html"}],["meta",{"property":"og:site_name","content":"Nlog"}],["meta",{"property":"og:title","content":"How to create an original character LoRA [SDXL Training] SDXL Character Training"}],["meta",{"property":"og:description","content":"How to create an original character LoRA [SDXL Training] SDXL Character Training How to create an original character LoRA [SDXL Training] SDXL Character Training featured ImageH..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"http://digitalcreativeai.net/_next/image?url=https%3A%2F%2Fdca.data-hub-center.com%2Fcontent%2Fuploads%2F2025%2F05%2Feye_catch_original-character-lora-sdxl-character-training-en.jpg&w=3840&q=80"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:locale:alternate","content":"zh-CN"}],["meta",{"property":"article:tag","content":"Kohya SS GUI"}],["meta",{"property":"article:tag","content":"LoRA"}],["meta",{"property":"article:tag","content":"SDXL"}],["meta",{"property":"article:published_time","content":"2025-05-12T07:01:40.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"How to create an original character LoRA [SDXL Training] SDXL Character Training\\",\\"image\\":[\\"http://digitalcreativeai.net/_next/image?url=https%3A%2F%2Fdca.data-hub-center.com%2Fcontent%2Fuploads%2F2025%2F05%2Feye_catch_original-character-lora-sdxl-character-training-en.jpg&w=3840&q=80\\",\\"https://dca.data-hub-center.com/content/uploads/2025/05/compare-sdxl-base-model-base1.jpg\\",\\"https://dca.data-hub-center.com/content/uploads/2025/05/compare-sdxl-base-model-anima3.jpg\\",\\"https://dca.data-hub-center.com/content/uploads/2025/05/compare-sdxl-base-model-pony6.jpg\\",\\"https://dca.data-hub-center.com/content/uploads/2025/05/compare-sdxl-base-model-illusxl.jpg\\",\\"https://dca.data-hub-center.com/content/uploads/2025/05/compare-sdxl-base-model-noobai.jpg\\",\\"https://dca.data-hub-center.com/content/uploads/2025/05/compare-sdxl-base-model-anima3.jpg\\",\\"https://dca.data-hub-center.com/content/uploads/2025/05/compare-sdxl-base-model-anima4.jpg\\",\\"https://dca.data-hub-center.com/content/uploads/2025/03/finished-dataset-images.jpg\\",\\"https://dca.data-hub-center.com/content/uploads/2025/05/sdxl-train-anima3-def.jpg\\",\\"https://dca.data-hub-center.com/content/uploads/2025/05/sdxl-train-anima3-def-no-lora.jpg\\",\\"https://dca.data-hub-center.com/content/uploads/2025/05/compare-scheduler-restart.jpg\\",\\"https://dca.data-hub-center.com/content/uploads/2025/05/cosin-restart-tb-sample.jpg\\",\\"https://dca.data-hub-center.com/content/uploads/2025/05/sdxl-train-anima3-final.jpg\\",\\"https://dca.data-hub-center.com/content/uploads/2025/05/sdxl-train-anima3-final-more_art-full.jpg\\",\\"https://dca.data-hub-center.com/content/uploads/2025/05/sdxl-train-anima3-final-animapencilxl_v500.jpg\\",\\"https://dca.data-hub-center.com/content/uploads/2025/05/sdxl-train-anima3-final-anythingxl_xl.jpg\\",\\"https://dca.data-hub-center.com/content/uploads/2025/05/sdxl-train-anima3-final-chenkinanimeImpastobased.jpg\\",\\"https://dca.data-hub-center.com/content/uploads/2025/05/sdxl-train-anima3-final-lizmix_versionx.jpg\\",\\"https://dca.data-hub-center.com/content/uploads/2025/05/sdxl-train-anima3-final-ranimexlbaseonanimagine_v10.jpg\\",\\"https://dca.data-hub-center.com/content/uploads/2025/05/sdxl-train-anima3-final-realAnimagineXL_v10.jpg\\"],\\"datePublished\\":\\"2025-05-12T07:01:40.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"neverbiasu\\",\\"url\\":\\"https://neverbiasu.github.io\\"}]}"]]},"headers":[{"level":2,"title":"Table of Contents","slug":"table-of-contents","link":"#table-of-contents","children":[]},{"level":2,"title":"Compatibility of SDXL’s Pretrained model","slug":"compatibility-of-sdxl-s-pretrained-model","link":"#compatibility-of-sdxl-s-pretrained-model","children":[{"level":3,"title":"Compatibility test generation","slug":"compatibility-test-generation","link":"#compatibility-test-generation","children":[]}]},{"level":2,"title":"Training with default parameters in Kohya ss GUI","slug":"training-with-default-parameters-in-kohya-ss-gui","link":"#training-with-default-parameters-in-kohya-ss-gui","children":[{"level":3,"title":"Dataset","slug":"dataset","link":"#dataset","children":[]},{"level":3,"title":"Default Parameters","slug":"default-parameters","link":"#default-parameters","children":[]},{"level":3,"title":"Test generation using trained LoRA","slug":"test-generation-using-trained-lora","link":"#test-generation-using-trained-lora","children":[]}]},{"level":2,"title":"Parameters used in this train","slug":"parameters-used-in-this-train","link":"#parameters-used-in-this-train","children":[{"level":3,"title":"LR Scheduler","slug":"lr-scheduler","link":"#lr-scheduler","children":[]},{"level":3,"title":"Optimizer","slug":"optimizer","link":"#optimizer","children":[]},{"level":3,"title":"Other parameters","slug":"other-parameters","link":"#other-parameters","children":[]}]},{"level":2,"title":"Training Results","slug":"training-results","link":"#training-results","children":[{"level":3,"title":"Combination with other LoRAs","slug":"combination-with-other-loras","link":"#combination-with-other-loras","children":[]},{"level":3,"title":"Apply to checkpoint models of the same lineage","slug":"apply-to-checkpoint-models-of-the-same-lineage","link":"#apply-to-checkpoint-models-of-the-same-lineage","children":[]}]},{"level":2,"title":"Conclusion","slug":"conclusion","link":"#conclusion","children":[]}],"readingTime":{"minutes":8.54,"words":2561},"filePathRelative":"posts/reprints/original-character-lora-sdxl-character-training.md","localizedDate":"May 12, 2025","excerpt":"\\n<figure><img src=\\"http://digitalcreativeai.net/_next/image?url=https%3A%2F%2Fdca.data-hub-center.com%2Fcontent%2Fuploads%2F2025%2F05%2Feye_catch_original-character-lora-sdxl-character-training-en.jpg&amp;w=3840&amp;q=80\\" alt=\\"How to create an original character LoRA [SDXL Training] SDXL Character Training featured Image\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>How to create an original character LoRA [SDXL Training] SDXL Character Training featured Image</figcaption></figure>","autoDesc":true}')}}]);