"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[9682],{6262:(e,i)=>{i.A=(e,i)=>{const n=e.__vccOpts||e;for(const[e,r]of i)n[e]=r;return n}},737:(e,i,n)=>{n.r(i),n.d(i,{comp:()=>a,data:()=>s});var r=n(641);const t={},a=(0,n(6262).A)(t,[["render",function(e,i){return(0,r.uX)(),(0,r.CE)("div",null,i[0]||(i[0]=[(0,r.Fv)('<h1 id="meta-发布-movie-gen-开启-ai-生成视频新时代-yolov11-引领目标检测革新-华盛顿大学-inverse-painting-重构绘画过程【ai-周报】" tabindex="-1"><a class="header-anchor" href="#meta-发布-movie-gen-开启-ai-生成视频新时代-yolov11-引领目标检测革新-华盛顿大学-inverse-painting-重构绘画过程【ai-周报】"><span><strong>Meta 发布 Movie Gen 开启 AI 生成视频新时代 | YOLOv11 引领目标检测革新 | 华盛顿大学 Inverse Painting 重构绘画过程【AI 周报】</strong></span></a></h1><h2 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span><strong>摘要</strong></span></a></h2><p>本周 AI 周报聚焦生成模型与视觉技术突破：Meta 发布 Movie Gen，推动文本到视频的生成新模式；Ultralytics 推出 YOLOv11，优化目标检测与图像分类性能；华盛顿大学的 Inverse Painting 模型重现艺术创作过程。此外，Illustrious XL 与 FabricDiffusion 等模型在插画生成和 3D 服装纹理迁移上也带来显著提升，进一步拓展了 AI 在多领域的应用潜力。</p><h2 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span><strong>目录</strong></span></a></h2><ol><li><a href="#inverse-painting-%E5%9F%BA%E4%BA%8E-diffusion-%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%BB%98%E7%94%BB%E9%87%8D%E6%9E%84">Inverse Painting: 基于 Diffusion 模型的绘画过程重构</a></li><li><a href="#illustrious-xl-%E4%B8%93%E4%B8%BA%E6%8F%92%E7%94%BB%E8%AE%BE%E8%AE%A1%E7%9A%84%E8%89%BA%E6%9C%AF%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B">Illustrious XL: 专为插画设计的艺术生成模型</a></li><li><a href="#comfygen-%E5%9F%BA%E4%BA%8E-llm-%E7%9A%84%E8%87%AA%E9%80%82%E5%BA%94%E7%94%9F%E6%88%90%E5%B7%A5%E4%BD%9C%E6%B5%81">ComfyGen: 基于 LLM 的自适应生成 ComfyUI 工作流</a></li><li><a href="#fabricdiffusion-%E9%AB%98%E4%BF%9D%E7%9C%9F-3d-%E6%9C%8D%E8%A3%85%E7%BA%B9%E7%90%86%E8%BF%81%E7%A7%BB">FabricDiffusion: 高保真 3D 服装纹理迁移</a></li><li><a href="#training-free-image-style-transfer-%E5%88%A9%E7%94%A8-latent-diffusion-%E8%BF%9B%E8%A1%8C%E6%97%A0%E8%AE%AD%E7%BB%83%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB">STRDP: 利用 Latent Diffusion 进行无训练风格迁移</a></li><li><a href="#movie-gen-metas-ai%E9%A9%B1%E5%8A%A8%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90">Movie Gen: Meta&#39;s AI 驱动视频生成</a></li><li><a href="#yolov11-%E6%96%B0%E4%B8%80%E4%BB%A3%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B">YOLOv11: 新一代目标检测与分类模型</a></li></ol><h2 id="inverse-painting-基于-diffusion-模型的绘画过程重构" tabindex="-1"><a class="header-anchor" href="#inverse-painting-基于-diffusion-模型的绘画过程重构"><span><strong>Inverse Painting: 基于 Diffusion 模型的绘画过程重构</strong></span></a></h2><p>!https://inversepainting.github.io/static/images/teaser.png</p><p>Inverse Painting Teaser 图</p><p><strong>概要</strong>: Inverse Painting[1][2][3] 是由华盛顿大学团队提出的一种基于 Diffusion 模型的创新方法，用于生成绘画过程的时间推移视频。该方法通过训练模型学习真实艺术家的绘画方式，逐步从空白画布到完整图像进行迭代更新。该系统还结合文本与区域理解，以自动生成绘画“指令”，并通过扩散渲染器来复现绘画过程，能够适应多种艺术风格。</p><p><strong>标签</strong>: #逆向绘画 #Diffusion 模型 #艺术生成 #时序视频 #华盛顿大学</p><hr><h2 id="illustrious-xl-专为插画设计的艺术生成模型" tabindex="-1"><a class="header-anchor" href="#illustrious-xl-专为插画设计的艺术生成模型"><span><strong>Illustrious XL: 专为插画设计的艺术生成模型</strong></span></a></h2><p>!https://arxiv.org/html/2409.19946v1/extracted/5888078/figures/illustrious_comparison.jpg</p><p>Illustrious XL Comparison 图</p><p><strong>概要</strong>: Illustrious XL[4][5] 是 OnomaAI 基于 Stable Diffusion XL 并微调 Danbooru 数据集的艺术生成模型，特别适用于插画和动漫人物设计。模型分为基础版和带安全控制的版本，能够生成符合用户需求的高质量艺术图像。未来将进一步推出不同风格的微调模型，增强生成的多样性和控制力，适用于非商业化的艺术创作领域。</p><p><strong>标签</strong>: #Stable Diffusion #插画生成 #Danbooru #动漫设计 #安全控制</p><hr><h2 id="comfygen-基于-llm-的自适应生成-comfyui-工作流" tabindex="-1"><a class="header-anchor" href="#comfygen-基于-llm-的自适应生成-comfyui-工作流"><span><strong>ComfyGen: 基于 LLM 的自适应生成 ComfyUI 工作流</strong></span></a></h2><p>!https://comfygen-paper.github.io/static/images/teaser/teaser.jpg</p><p>ComfyGen Teaser 图</p><p><strong>概要</strong>: ComfyGen[6][7] 由特拉维夫大学与 NVIDIA 合作推出，使用 LLM 分析生成提示，并根据不同提示自动匹配最佳的  <strong>ComfyUI</strong>  生成流程。该框架能够灵活组合多种图像生成组件，大幅提升文本到图像生成的灵活性与质量。通过自适应的工作流机制，ComfyGen 在多个生成任务中展现了显著优于传统方法的性能。</p><p><strong>标签</strong>: #ComfyUI #文本到图像 #自适应工作流 #生成模型 #NVIDIA</p><hr><h2 id="fabricdiffusion-高保真-3d-服装纹理迁移" tabindex="-1"><a class="header-anchor" href="#fabricdiffusion-高保真-3d-服装纹理迁移"><span><strong>FabricDiffusion: 高保真 3D 服装纹理迁移</strong></span></a></h2><p>!https://humansensinglab.github.io/fabric-diffusion/fabric-diffusion/static/images/main.png</p><p>FabricDiffusion Overview 图</p><p><strong>概要</strong>: FabricDiffusion[8][9] 由卡内基梅隆大学和 Google AR 合作开发，能够从 2D 图片中高效提取服装纹理，并将其准确转移到 3D 服装模型上。该模型使用 Denoising Diffusion 生成高精度的物理渲染级纹理（PBR），在服装设计、虚拟时尚等领域具有广泛应用，提升了服装的光照、纹理和逼真度。</p><p><strong>标签</strong>: #服装生成 #3D 纹理迁移 #PBR 渲染 #Diffusion 模型 #虚拟时尚</p><hr><h2 id="strdp-利用-latent-diffusion-进行无训练风格迁移" tabindex="-1"><a class="header-anchor" href="#strdp-利用-latent-diffusion-进行无训练风格迁移"><span><strong>STRDP: 利用 Latent Diffusion 进行无训练风格迁移</strong></span></a></h2><p>!https://arxiv.org/html/2410.01366v1/x2.png</p><p>STRDP Overview 图</p><p><strong>概要</strong>: 本研究提出了一种新颖的图像风格迁移 STRDP[10] 算法，利用 Latent Diffusion Model（LDM）进行训练自由的风格迁移。通过引入自适应实例归一化（AdaIN）与风格追踪反向扩散过程（STRDP），该方法在无需额外训练的情况下，实现了内容与风格的高效融合。实验结果表明，算法不仅具有优异的风格迁移能力，还兼具计算效率和跨模型兼容性。</p><p><strong>标签</strong>: #风格迁移 #LatentDiffusion #AdaIN #无训练 #高效生成</p><hr><h2 id="movie-gen-meta-s-ai-驱动视频生成" tabindex="-1"><a class="header-anchor" href="#movie-gen-meta-s-ai-驱动视频生成"><span><strong>Movie Gen: Meta&#39;s AI 驱动视频生成</strong></span></a></h2><p>!https://fastly.jsdelivr.net/gh/bucketio/img6@main/2024/10/06/1728144426607-2b09d57f-c8c2-4192-acb0-9c783d2128b2.png</p><p>Movie Gen Overview 图</p><p><strong>概要</strong>: Movie Gen[11][12] 是 Meta 最新推出的生成式 AI 工具，能够将文本提示转化为个性化高质量视频。用户不仅可以生成从文本到视频的内容，还能通过文本进行视频编辑和特效添加。此外，Movie Gen 支持音频生成和背景音乐制作，实现了视觉与音频内容的同步创作。此技术为内容创作者提供了全新的灵活性和创意控制能力。</p><p><strong>标签</strong>: #视频生成 #文本编辑 #音频生成 #MetaAI #个性化视频</p><hr><h2 id="yolov11-新一代目标检测与分类模型" tabindex="-1"><a class="header-anchor" href="#yolov11-新一代目标检测与分类模型"><span><strong>YOLOv11: 新一代目标检测与分类模型</strong></span></a></h2><p>!https://fastly.jsdelivr.net/gh/bucketio/img17@main/2024/10/05/1728142021342-d57486a1-3ff4-410d-92c8-44a8941bd932.png</p><p>YOLOv11 Performance 图</p><p><strong>概要</strong>: YOLOv11[13] 是 Ultralytics 最新推出的目标检测模型，构建在此前 YOLO 系列的成功基础上。它在速度、准确性和灵活性上做出重大改进，适用于对象检测、实例分割、图像分类和姿态估计等任务。YOLOv11 支持多种模式和任务类型，且易于训练和部署，提供了极高的性能和可扩展性，是下一代计算机视觉任务的首选工具。</p><p><strong>标签</strong>: #YOLOv11 #目标检测 #实例分割 #图像分类 #姿态估计</p><hr><h3 id="参考链接" tabindex="-1"><a class="header-anchor" href="#参考链接"><span><strong>参考链接</strong></span></a></h3><h1 id="meta-发布-movie-gen-开启-ai-生成视频新时代-yolov11-引领目标检测革新-华盛顿大学-inverse-painting-重构绘画过程【ai-周报】-1" tabindex="-1"><a class="header-anchor" href="#meta-发布-movie-gen-开启-ai-生成视频新时代-yolov11-引领目标检测革新-华盛顿大学-inverse-painting-重构绘画过程【ai-周报】-1"><span><strong>Meta 发布 Movie Gen 开启 AI 生成视频新时代 | YOLOv11 引领目标检测革新 | 华盛顿大学 Inverse Painting 重构绘画过程【AI 周报】</strong></span></a></h1><h2 id="摘要-1" tabindex="-1"><a class="header-anchor" href="#摘要-1"><span><strong>摘要</strong></span></a></h2><p>本周 AI 周报聚焦生成模型与视觉技术突破：Meta 发布 Movie Gen，推动文本到视频的生成新模式；Ultralytics 推出 YOLOv11，优化目标检测与图像分类性能；华盛顿大学的 Inverse Painting 模型重现艺术创作过程。此外，Illustrious XL 与 FabricDiffusion 等模型在插画生成和 3D 服装纹理迁移上也带来显著提升，进一步拓展了 AI 在多领域的应用潜力。</p><h2 id="目录-1" tabindex="-1"><a class="header-anchor" href="#目录-1"><span><strong>目录</strong></span></a></h2><ol><li>1. Inverse Painting: 基于 Diffusion 模型的绘画过程重构</li><li>2. Illustrious XL: 专为插画设计的艺术生成模型</li><li>3. ComfyGen: 基于 LLM 的自适应生成 ComfyUI 工作流</li><li>4. FabricDiffusion: 高保真 3D 服装纹理迁移</li><li>5. STRDP: 利用 Latent Diffusion 进行无训练风格迁移</li><li>6. Movie Gen: Meta&#39;s AI 驱动视频生成</li><li>7. YOLOv11: 新一代目标检测与分类模型</li></ol><h2 id="inverse-painting-基于-diffusion-模型的绘画过程重构-1" tabindex="-1"><a class="header-anchor" href="#inverse-painting-基于-diffusion-模型的绘画过程重构-1"><span><strong>Inverse Painting: 基于 Diffusion 模型的绘画过程重构</strong></span></a></h2><p>!https://inversepainting.github.io/static/images/teaser.png</p><p>Inverse Painting Teaser 图</p><p><strong>概要</strong>: Inverse Painting[1][2][3] 是由华盛顿大学团队提出的一种基于 Diffusion 模型的创新方法，用于生成绘画过程的时间推移视频。该方法通过训练模型学习真实艺术家的绘画方式，逐步从空白画布到完整图像进行迭代更新。该系统还结合文本与区域理解，以自动生成绘画“指令”，并通过扩散渲染器来复现绘画过程，能够适应多种艺术风格。</p><p><strong>标签</strong>: #逆向绘画 #Diffusion 模型 #艺术生成 #时序视频 #华盛顿大学</p><hr><h2 id="illustrious-xl-专为插画设计的艺术生成模型-1" tabindex="-1"><a class="header-anchor" href="#illustrious-xl-专为插画设计的艺术生成模型-1"><span><strong>Illustrious XL: 专为插画设计的艺术生成模型</strong></span></a></h2><p>!https://arxiv.org/html/2409.19946v1/extracted/5888078/figures/illustrious_comparison.jpg</p><p>Illustrious XL Comparison 图</p><p><strong>概要</strong>: Illustrious XL[4][5] 是 OnomaAI 基于 Stable Diffusion XL 并微调 Danbooru 数据集的艺术生成模型，特别适用于插画和动漫人物设计。模型分为基础版和带安全控制的版本，能够生成符合用户需求的高质量艺术图像。未来将进一步推出不同风格的微调模型，增强生成的多样性和控制力，适用于非商业化的艺术创作领域。</p><p><strong>标签</strong>: #Stable Diffusion #插画生成 #Danbooru #动漫设计 #安全控制</p><hr><h2 id="comfygen-基于-llm-的自适应生成-comfyui-工作流-1" tabindex="-1"><a class="header-anchor" href="#comfygen-基于-llm-的自适应生成-comfyui-工作流-1"><span><strong>ComfyGen: 基于 LLM 的自适应生成 ComfyUI 工作流</strong></span></a></h2><p>!https://comfygen-paper.github.io/static/images/teaser/teaser.jpg</p><p>ComfyGen Teaser 图</p><p><strong>概要</strong>: ComfyGen[6][7] 由特拉维夫大学与 NVIDIA 合作推出，使用 LLM 分析生成提示，并根据不同提示自动匹配最佳的  <strong>ComfyUI</strong>  生成流程。该框架能够灵活组合多种图像生成组件，大幅提升文本到图像生成的灵活性与质量。通过自适应的工作流机制，ComfyGen 在多个生成任务中展现了显著优于传统方法的性能。</p><p><strong>标签</strong>: #ComfyUI #文本到图像 #自适应工作流 #生成模型 #NVIDIA</p><hr><h2 id="fabricdiffusion-高保真-3d-服装纹理迁移-1" tabindex="-1"><a class="header-anchor" href="#fabricdiffusion-高保真-3d-服装纹理迁移-1"><span><strong>FabricDiffusion: 高保真 3D 服装纹理迁移</strong></span></a></h2><p>!https://humansensinglab.github.io/fabric-diffusion/fabric-diffusion/static/images/main.png</p><p>FabricDiffusion Overview 图</p><p><strong>概要</strong>: FabricDiffusion[8][9] 由卡内基梅隆大学和 Google AR 合作开发，能够从 2D 图片中高效提取服装纹理，并将其准确转移到 3D 服装模型上。该模型使用 Denoising Diffusion 生成高精度的物理渲染级纹理（PBR），在服装设计、虚拟时尚等领域具有广泛应用，提升了服装的光照、纹理和逼真度。</p><p><strong>标签</strong>: #服装生成 #3D 纹理迁移 #PBR 渲染 #Diffusion 模型 #虚拟时尚</p><hr><h2 id="strdp-利用-latent-diffusion-进行无训练风格迁移-1" tabindex="-1"><a class="header-anchor" href="#strdp-利用-latent-diffusion-进行无训练风格迁移-1"><span><strong>STRDP: 利用 Latent Diffusion 进行无训练风格迁移</strong></span></a></h2><p>!https://arxiv.org/html/2410.01366v1/x2.png</p><p>STRDP Overview 图</p><p><strong>概要</strong>: 本研究提出了一种新颖的图像风格迁移 STRDP[10] 算法，利用 Latent Diffusion Model（LDM）进行训练自由的风格迁移。通过引入自适应实例归一化（AdaIN）与风格追踪反向扩散过程（STRDP），该方法在无需额外训练的情况下，实现了内容与风格的高效融合。实验结果表明，算法不仅具有优异的风格迁移能力，还兼具计算效率和跨模型兼容性。</p><p><strong>标签</strong>: #风格迁移 #LatentDiffusion #AdaIN #无训练 #高效生成</p><hr><h2 id="movie-gen-meta-s-ai-驱动视频生成-1" tabindex="-1"><a class="header-anchor" href="#movie-gen-meta-s-ai-驱动视频生成-1"><span><strong>Movie Gen: Meta&#39;s AI 驱动视频生成</strong></span></a></h2><p>!https://fastly.jsdelivr.net/gh/bucketio/img6@main/2024/10/06/1728144426607-2b09d57f-c8c2-4192-acb0-9c783d2128b2.png</p><p>Movie Gen Overview 图</p><p><strong>概要</strong>: Movie Gen[11][12] 是 Meta 最新推出的生成式 AI 工具，能够将文本提示转化为个性化高质量视频。用户不仅可以生成从文本到视频的内容，还能通过文本进行视频编辑和特效添加。此外，Movie Gen 支持音频生成和背景音乐制作，实现了视觉与音频内容的同步创作。此技术为内容创作者提供了全新的灵活性和创意控制能力。</p><p><strong>标签</strong>: #视频生成 #文本编辑 #音频生成 #MetaAI #个性化视频</p><hr><h2 id="yolov11-新一代目标检测与分类模型-1" tabindex="-1"><a class="header-anchor" href="#yolov11-新一代目标检测与分类模型-1"><span><strong>YOLOv11: 新一代目标检测与分类模型</strong></span></a></h2><p>!https://fastly.jsdelivr.net/gh/bucketio/img17@main/2024/10/05/1728142021342-d57486a1-3ff4-410d-92c8-44a8941bd932.png</p><p>YOLOv11 Performance 图</p><p><strong>概要</strong>: YOLOv11[13] 是 Ultralytics 最新推出的目标检测模型，构建在此前 YOLO 系列的成功基础上。它在速度、准确性和灵活性上做出重大改进，适用于对象检测、实例分割、图像分类和姿态估计等任务。YOLOv11 支持多种模式和任务类型，且易于训练和部署，提供了极高的性能和可扩展性，是下一代计算机视觉任务的首选工具。</p><p><strong>标签</strong>: #YOLOv11 #目标检测 #实例分割 #图像分类 #姿态估计</p><hr><h3 id="参考链接-1" tabindex="-1"><a class="header-anchor" href="#参考链接-1"><span><strong>参考链接</strong></span></a></h3><ol><li><a href="https://inversepainting.github.io/" target="_blank" rel="noopener noreferrer">Inverse Painting 项目主页</a></li><li><a href="https://github.com/ArmastusChen/inverse_painting" target="_blank" rel="noopener noreferrer">Inverse Painting GitHub</a></li><li><a href="https://arxiv.org/pdf/2409.20556" target="_blank" rel="noopener noreferrer">Inverse Painting 论文</a></li><li><a href="https://huggingface.co/OnomaAIResearch/Illustrious-xl-early-release-v0" target="_blank" rel="noopener noreferrer">Illustrious XL 模型主页</a></li><li><a href="https://arxiv.org/pdf/2409.19946" target="_blank" rel="noopener noreferrer">Illustrious XL 论文</a></li><li><a href="https://comfygen-paper.github.io/" target="_blank" rel="noopener noreferrer">ComfyGen 项目主页</a></li><li><a href="https://arxiv.org/pdf/2410.01731" target="_blank" rel="noopener noreferrer">ComfyGen 论文</a></li><li><a href="https://humansensinglab.github.io/fabric-diffusion/" target="_blank" rel="noopener noreferrer">FabricDiffusion 项目主页</a></li><li><a href="https://arxiv.org/pdf/2410.01801" target="_blank" rel="noopener noreferrer">FabricDiffusion 论文</a></li><li><a href="https://github.com/humansensinglab/fabric-diffusion" target="_blank" rel="noopener noreferrer">FabricDiffusion GitHub</a></li><li><a href="https://arxiv.org/pdf/2410.01366" target="_blank" rel="noopener noreferrer">Training-Free Image Style Transfer 论文</a></li><li><a href="https://ai.meta.com/research/movie-gen/?ref=producthunt" target="_blank" rel="noopener noreferrer">Movie Gen 项目主页</a></li><li><a href="https://ai.meta.com/static-resource/movie-gen-research-paper" target="_blank" rel="noopener noreferrer">Movie Gen 研究论文</a></li><li><a href="https://github.com/ultralytics/ultralytics" target="_blank" rel="noopener noreferrer">Ultralytics YOLOv11 GitHub</a></li></ol>',97)]))}]]),s=JSON.parse('{"path":"/zh/posts/ai-weekly/006.html","title":"Meta 发布 Movie Gen 开启 AI 生成视频新时代 | YOLOv11 引领目标检测革新 | 华盛顿大学 Inverse Painting 重构绘画过程【AI 周报】","lang":"zh-CN","frontmatter":{"description":"Meta 发布 Movie Gen 开启 AI 生成视频新时代 | YOLOv11 引领目标检测革新 | 华盛顿大学 Inverse Painting 重构绘画过程【AI 周报】 摘要 本周 AI 周报聚焦生成模型与视觉技术突破：Meta 发布 Movie Gen，推动文本到视频的生成新模式；Ultralytics 推出 YOLOv11，优化目标检测与...","gitInclude":[],"head":[["meta",{"property":"og:url","content":"https://neverbiasu.github.io/zh/posts/ai-weekly/006.html"}],["meta",{"property":"og:site_name","content":"Nlog"}],["meta",{"property":"og:title","content":"Meta 发布 Movie Gen 开启 AI 生成视频新时代 | YOLOv11 引领目标检测革新 | 华盛顿大学 Inverse Painting 重构绘画过程【AI 周报】"}],["meta",{"property":"og:description","content":"Meta 发布 Movie Gen 开启 AI 生成视频新时代 | YOLOv11 引领目标检测革新 | 华盛顿大学 Inverse Painting 重构绘画过程【AI 周报】 摘要 本周 AI 周报聚焦生成模型与视觉技术突破：Meta 发布 Movie Gen，推动文本到视频的生成新模式；Ultralytics 推出 YOLOv11，优化目标检测与..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Meta 发布 Movie Gen 开启 AI 生成视频新时代 | YOLOv11 引领目标检测革新 | 华盛顿大学 Inverse Painting 重构绘画过程【AI 周报】\\",\\"image\\":[\\"\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"neverbiasu\\",\\"url\\":\\"https://neverbiasu.github.io\\"}]}"]]},"headers":[{"level":2,"title":"摘要","slug":"摘要","link":"#摘要","children":[]},{"level":2,"title":"目录","slug":"目录","link":"#目录","children":[]},{"level":2,"title":"Inverse Painting: 基于 Diffusion 模型的绘画过程重构","slug":"inverse-painting-基于-diffusion-模型的绘画过程重构","link":"#inverse-painting-基于-diffusion-模型的绘画过程重构","children":[]},{"level":2,"title":"Illustrious XL: 专为插画设计的艺术生成模型","slug":"illustrious-xl-专为插画设计的艺术生成模型","link":"#illustrious-xl-专为插画设计的艺术生成模型","children":[]},{"level":2,"title":"ComfyGen: 基于 LLM 的自适应生成 ComfyUI 工作流","slug":"comfygen-基于-llm-的自适应生成-comfyui-工作流","link":"#comfygen-基于-llm-的自适应生成-comfyui-工作流","children":[]},{"level":2,"title":"FabricDiffusion: 高保真 3D 服装纹理迁移","slug":"fabricdiffusion-高保真-3d-服装纹理迁移","link":"#fabricdiffusion-高保真-3d-服装纹理迁移","children":[]},{"level":2,"title":"STRDP: 利用 Latent Diffusion 进行无训练风格迁移","slug":"strdp-利用-latent-diffusion-进行无训练风格迁移","link":"#strdp-利用-latent-diffusion-进行无训练风格迁移","children":[]},{"level":2,"title":"Movie Gen: Meta\'s AI 驱动视频生成","slug":"movie-gen-meta-s-ai-驱动视频生成","link":"#movie-gen-meta-s-ai-驱动视频生成","children":[]},{"level":2,"title":"YOLOv11: 新一代目标检测与分类模型","slug":"yolov11-新一代目标检测与分类模型","link":"#yolov11-新一代目标检测与分类模型","children":[{"level":3,"title":"参考链接","slug":"参考链接","link":"#参考链接","children":[]}]},{"level":2,"title":"摘要","slug":"摘要-1","link":"#摘要-1","children":[]},{"level":2,"title":"目录","slug":"目录-1","link":"#目录-1","children":[]},{"level":2,"title":"Inverse Painting: 基于 Diffusion 模型的绘画过程重构","slug":"inverse-painting-基于-diffusion-模型的绘画过程重构-1","link":"#inverse-painting-基于-diffusion-模型的绘画过程重构-1","children":[]},{"level":2,"title":"Illustrious XL: 专为插画设计的艺术生成模型","slug":"illustrious-xl-专为插画设计的艺术生成模型-1","link":"#illustrious-xl-专为插画设计的艺术生成模型-1","children":[]},{"level":2,"title":"ComfyGen: 基于 LLM 的自适应生成 ComfyUI 工作流","slug":"comfygen-基于-llm-的自适应生成-comfyui-工作流-1","link":"#comfygen-基于-llm-的自适应生成-comfyui-工作流-1","children":[]},{"level":2,"title":"FabricDiffusion: 高保真 3D 服装纹理迁移","slug":"fabricdiffusion-高保真-3d-服装纹理迁移-1","link":"#fabricdiffusion-高保真-3d-服装纹理迁移-1","children":[]},{"level":2,"title":"STRDP: 利用 Latent Diffusion 进行无训练风格迁移","slug":"strdp-利用-latent-diffusion-进行无训练风格迁移-1","link":"#strdp-利用-latent-diffusion-进行无训练风格迁移-1","children":[]},{"level":2,"title":"Movie Gen: Meta\'s AI 驱动视频生成","slug":"movie-gen-meta-s-ai-驱动视频生成-1","link":"#movie-gen-meta-s-ai-驱动视频生成-1","children":[]},{"level":2,"title":"YOLOv11: 新一代目标检测与分类模型","slug":"yolov11-新一代目标检测与分类模型-1","link":"#yolov11-新一代目标检测与分类模型-1","children":[{"level":3,"title":"参考链接","slug":"参考链接-1","link":"#参考链接-1","children":[]}]}],"readingTime":{"minutes":9.95,"words":2984},"filePathRelative":"zh/posts/ai-weekly/006.md","excerpt":"\\n<h2><strong>摘要</strong></h2>\\n<p>本周 AI 周报聚焦生成模型与视觉技术突破：Meta 发布 Movie Gen，推动文本到视频的生成新模式；Ultralytics 推出 YOLOv11，优化目标检测与图像分类性能；华盛顿大学的 Inverse Painting 模型重现艺术创作过程。此外，Illustrious XL 与 FabricDiffusion 等模型在插画生成和 3D 服装纹理迁移上也带来显著提升，进一步拓展了 AI 在多领域的应用潜力。</p>\\n<h2><strong>目录</strong></h2>\\n<ol>\\n<li><a href=\\"#inverse-painting-%E5%9F%BA%E4%BA%8E-diffusion-%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%BB%98%E7%94%BB%E9%87%8D%E6%9E%84\\">Inverse Painting: 基于 Diffusion 模型的绘画过程重构</a></li>\\n<li><a href=\\"#illustrious-xl-%E4%B8%93%E4%B8%BA%E6%8F%92%E7%94%BB%E8%AE%BE%E8%AE%A1%E7%9A%84%E8%89%BA%E6%9C%AF%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B\\">Illustrious XL: 专为插画设计的艺术生成模型</a></li>\\n<li><a href=\\"#comfygen-%E5%9F%BA%E4%BA%8E-llm-%E7%9A%84%E8%87%AA%E9%80%82%E5%BA%94%E7%94%9F%E6%88%90%E5%B7%A5%E4%BD%9C%E6%B5%81\\">ComfyGen: 基于 LLM 的自适应生成 ComfyUI 工作流</a></li>\\n<li><a href=\\"#fabricdiffusion-%E9%AB%98%E4%BF%9D%E7%9C%9F-3d-%E6%9C%8D%E8%A3%85%E7%BA%B9%E7%90%86%E8%BF%81%E7%A7%BB\\">FabricDiffusion: 高保真 3D 服装纹理迁移</a></li>\\n<li><a href=\\"#training-free-image-style-transfer-%E5%88%A9%E7%94%A8-latent-diffusion-%E8%BF%9B%E8%A1%8C%E6%97%A0%E8%AE%AD%E7%BB%83%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB\\">STRDP: 利用 Latent Diffusion 进行无训练风格迁移</a></li>\\n<li><a href=\\"#movie-gen-metas-ai%E9%A9%B1%E5%8A%A8%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90\\">Movie Gen: Meta\'s AI 驱动视频生成</a></li>\\n<li><a href=\\"#yolov11-%E6%96%B0%E4%B8%80%E4%BB%A3%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B\\">YOLOv11: 新一代目标检测与分类模型</a></li>\\n</ol>","autoDesc":true}')}}]);