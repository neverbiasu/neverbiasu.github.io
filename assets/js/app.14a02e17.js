"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[3524],{1709:(e,t,a)=>{a.d(t,{l:()=>n});const n={category:{"/":{path:"/category/",map:{Guide:{path:"/category/guide/",indexes:[0,1,2,3,4,5]},Explainer:{path:"/category/explainer/",indexes:[6]},"Generative AI":{path:"/category/generative-ai/",indexes:[6]},Reprints:{path:"/category/reprints/",indexes:[7]},"Model Development":{path:"/category/model-development/",indexes:[8,9,10]},reprint:{path:"/category/reprint/",indexes:[11,8,12]},"Model Training":{path:"/category/model-training/",indexes:[9,10]},"Image Generation":{path:"/category/image-generation/",indexes:[9,10]},"Anime Style":{path:"/category/anime-style/",indexes:[9,10]},reprints:{path:"/category/reprints/",indexes:[13,14]}}},"/zh/":{path:"/zh/category/",map:{使用指南:{path:"/zh/category/%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/",indexes:[15,16,17,18,19]},指南:{path:"/zh/category/%E6%8C%87%E5%8D%97/",indexes:[20]},日记:{path:"/zh/category/%E6%97%A5%E8%AE%B0/",indexes:[21,22]},视频生成:{path:"/zh/category/%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90/",indexes:[23]},论文精读:{path:"/zh/category/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/",indexes:[23]},张吕敏:{path:"/zh/category/%E5%BC%A0%E5%90%95%E6%95%8F/",indexes:[23]},Explainer:{path:"/zh/category/explainer/",indexes:[24]},"Generative AI":{path:"/zh/category/generative-ai/",indexes:[24]},转载:{path:"/zh/category/%E8%BD%AC%E8%BD%BD/",indexes:[25,26,27]},模型开发:{path:"/zh/category/%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91/",indexes:[25]},"Model Development":{path:"/zh/category/model-development/",indexes:[28]},"Model Training":{path:"/zh/category/model-training/",indexes:[28]},"Image Generation":{path:"/zh/category/image-generation/",indexes:[28]},"Anime Style":{path:"/zh/category/anime-style/",indexes:[28]},模型研发:{path:"/zh/category/%E6%A8%A1%E5%9E%8B%E7%A0%94%E5%8F%91/",indexes:[29]},模型训练:{path:"/zh/category/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/",indexes:[29]},图像生成:{path:"/zh/category/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/",indexes:[29]},动漫风格:{path:"/zh/category/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%A0%BC/",indexes:[29]},reprints:{path:"/zh/category/reprints/",indexes:[30,31]},reprint:{path:"/zh/category/reprint/",indexes:[32]},思考:{path:"/zh/category/%E6%80%9D%E8%80%83/",indexes:[33]}}}},tag:{"/":{path:"/tag/",map:{disable:{path:"/tag/disable/",indexes:[2]},encryption:{path:"/tag/encryption/",indexes:[3]},Layout:{path:"/tag/layout/",indexes:[4]},Markdown:{path:"/tag/markdown/",indexes:[5]},"Page config":{path:"/tag/page-config/",indexes:[0]},Guide:{path:"/tag/guide/",indexes:[0]},"resource guide":{path:"/tag/resource-guide/",indexes:[34]},script:{path:"/tag/script/",indexes:[34]},"stable diffusion":{path:"/tag/stable-diffusion/",indexes:[34]},merge:{path:"/tag/merge/",indexes:[34]},model:{path:"/tag/model/",indexes:[34]},editor:{path:"/tag/editor/",indexes:[35]},"Model Context Protocol":{path:"/tag/model-context-protocol/",indexes:[35]},tech:{path:"/tag/tech/",indexes:[35]},"Artificial Intelligence":{path:"/tag/artificial-intelligence/",indexes:[6]},Inference:{path:"/tag/inference/",indexes:[6]},"Generative AI":{path:"/tag/generative-ai/",indexes:[7]},"Game Development":{path:"/tag/game-development/",indexes:[7]},"Stable Diffusion":{path:"/tag/stable-diffusion/",indexes:[7]},"Image Generation":{path:"/tag/image-generation/",indexes:[8,7]},AWS:{path:"/tag/aws/",indexes:[7]},"Amazon Bedrock":{path:"/tag/amazon-bedrock/",indexes:[7]},Illustrious:{path:"/tag/illustrious/",indexes:[8,9,10]},LU:{path:"/tag/lu/",indexes:[8]},Lumina:{path:"/tag/lumina/",indexes:[8]},"AI Model":{path:"/tag/ai-model/",indexes:[8]},Training:{path:"/tag/training/",indexes:[8]},SDXL:{path:"/tag/sdxl/",indexes:[9,10]},"2048 Resolution":{path:"/tag/2048-resolution/",indexes:[9]},vpred:{path:"/tag/vpred/",indexes:[9]},"epsilon prediction":{path:"/tag/epsilon-prediction/",indexes:[9]},Anime:{path:"/tag/anime/",indexes:[10]},"Base model":{path:"/tag/base-model/",indexes:[10]},"Image generation":{path:"/tag/image-generation/",indexes:[10]},AI:{path:"/tag/ai/",indexes:[12,36,37,38]},LLM:{path:"/tag/llm/",indexes:[12]},Protocol:{path:"/tag/protocol/",indexes:[12]},Debate:{path:"/tag/debate/",indexes:[12]},StableDiffusion:{path:"/tag/stablediffusion/",indexes:[36,37,38]},ModelMerge:{path:"/tag/modelmerge/",indexes:[37,38]},AUTOMATIC1111:{path:"/tag/automatic1111/",indexes:[36,37,38]},Art:{path:"/tag/art/",indexes:[13,14]},Drawing:{path:"/tag/drawing/",indexes:[13,14]},Fundamentals:{path:"/tag/fundamentals/",indexes:[13,14]},niji:{path:"/tag/niji/",indexes:[13,14]},Qwen:{path:"/tag/qwen/",indexes:[11]},Qwen3:{path:"/tag/qwen3/",indexes:[11]},"Alibaba AI research":{path:"/tag/alibaba-ai-research/",indexes:[11]},"Alibaba AI":{path:"/tag/alibaba-ai/",indexes:[11]},"large language models":{path:"/tag/large-language-models/",indexes:[11]},LLMs:{path:"/tag/llms/",indexes:[11]},"LLM benchmarks":{path:"/tag/llm-benchmarks/",indexes:[11]},"Multilingual AI":{path:"/tag/multilingual-ai/",indexes:[11]},"Multimodal AI":{path:"/tag/multimodal-ai/",indexes:[11]},"AI reasoning":{path:"/tag/ai-reasoning/",indexes:[11]},MCP:{path:"/tag/mcp/",indexes:[11]},ModelMerging:{path:"/tag/modelmerging/",indexes:[36]}}},"/zh/":{path:"/zh/tag/",map:{禁用:{path:"/zh/tag/%E7%A6%81%E7%94%A8/",indexes:[17]},加密:{path:"/zh/tag/%E5%8A%A0%E5%AF%86/",indexes:[18]},布局:{path:"/zh/tag/%E5%B8%83%E5%B1%80/",indexes:[20]},Markdown:{path:"/zh/tag/markdown/",indexes:[19]},页面配置:{path:"/zh/tag/%E9%A1%B5%E9%9D%A2%E9%85%8D%E7%BD%AE/",indexes:[15]},使用指南:{path:"/zh/tag/%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/",indexes:[15]},随想:{path:"/zh/tag/%E9%9A%8F%E6%83%B3/",indexes:[21,22]},开源:{path:"/zh/tag/%E5%BC%80%E6%BA%90/",indexes:[22]},大会:{path:"/zh/tag/%E5%A4%A7%E4%BC%9A/",indexes:[22]},实习:{path:"/zh/tag/%E5%AE%9E%E4%B9%A0/",indexes:[22]},做饭:{path:"/zh/tag/%E5%81%9A%E9%A5%AD/",indexes:[21]},公众号:{path:"/zh/tag/%E5%85%AC%E4%BC%97%E5%8F%B7/",indexes:[21]},FramePack:{path:"/zh/tag/framepack/",indexes:[23]},视频生成:{path:"/zh/tag/%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90/",indexes:[23]},扩散模型:{path:"/zh/tag/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/",indexes:[23]},输入预处理:{path:"/zh/tag/%E8%BE%93%E5%85%A5%E9%A2%84%E5%A4%84%E7%90%86/",indexes:[23]},"resource guide":{path:"/zh/tag/resource-guide/",indexes:[39]},script:{path:"/zh/tag/script/",indexes:[39]},"stable diffusion":{path:"/zh/tag/stable-diffusion/",indexes:[39]},merge:{path:"/zh/tag/merge/",indexes:[39]},model:{path:"/zh/tag/model/",indexes:[39]},编辑器:{path:"/zh/tag/%E7%BC%96%E8%BE%91%E5%99%A8/",indexes:[40]},模型上下文协议:{path:"/zh/tag/%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE/",indexes:[40]},技术:{path:"/zh/tag/%E6%8A%80%E6%9C%AF/",indexes:[40]},"Artificial Intelligence":{path:"/zh/tag/artificial-intelligence/",indexes:[24]},Inference:{path:"/zh/tag/inference/",indexes:[24]},生成式AI:{path:"/zh/tag/%E7%94%9F%E6%88%90%E5%BC%8Fai/",indexes:[26]},游戏开发:{path:"/zh/tag/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/",indexes:[26]},"Stable Diffusion":{path:"/zh/tag/stable-diffusion/",indexes:[26]},图像生成:{path:"/zh/tag/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/",indexes:[25,26,29]},AWS:{path:"/zh/tag/aws/",indexes:[26]},"Amazon Bedrock":{path:"/zh/tag/amazon-bedrock/",indexes:[26]},Illustrious:{path:"/zh/tag/illustrious/",indexes:[25,28,29]},LU:{path:"/zh/tag/lu/",indexes:[25]},Lumina:{path:"/zh/tag/lumina/",indexes:[25]},AI模型:{path:"/zh/tag/ai%E6%A8%A1%E5%9E%8B/",indexes:[25]},训练:{path:"/zh/tag/%E8%AE%AD%E7%BB%83/",indexes:[25]},SDXL:{path:"/zh/tag/sdxl/",indexes:[28,29]},"2048分辨率":{path:"/zh/tag/2048%E5%88%86%E8%BE%A8%E7%8E%87/",indexes:[28]},vpred:{path:"/zh/tag/vpred/",indexes:[28]},epsilon预测:{path:"/zh/tag/epsilon%E9%A2%84%E6%B5%8B/",indexes:[28]},动漫:{path:"/zh/tag/%E5%8A%A8%E6%BC%AB/",indexes:[29]},基础模型:{path:"/zh/tag/%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B/",indexes:[29]},AI:{path:"/zh/tag/ai/",indexes:[27]},LLM:{path:"/zh/tag/llm/",indexes:[27]},协议:{path:"/zh/tag/%E5%8D%8F%E8%AE%AE/",indexes:[27]},辩论:{path:"/zh/tag/%E8%BE%A9%E8%AE%BA/",indexes:[27]},Art:{path:"/zh/tag/art/",indexes:[30,31]},Drawing:{path:"/zh/tag/drawing/",indexes:[30,31]},Fundamentals:{path:"/zh/tag/fundamentals/",indexes:[30,31]},niji:{path:"/zh/tag/niji/",indexes:[30,31]},Qwen:{path:"/zh/tag/qwen/",indexes:[32]},Qwen3:{path:"/zh/tag/qwen3/",indexes:[32]},阿里巴巴AI研究:{path:"/zh/tag/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4ai%E7%A0%94%E7%A9%B6/",indexes:[32]},阿里巴巴AI:{path:"/zh/tag/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4ai/",indexes:[32]},大语言模型:{path:"/zh/tag/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/",indexes:[32]},LLMs:{path:"/zh/tag/llms/",indexes:[32]},LLM基准测试:{path:"/zh/tag/llm%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95/",indexes:[32]},多语言AI:{path:"/zh/tag/%E5%A4%9A%E8%AF%AD%E8%A8%80ai/",indexes:[32]},多模态AI:{path:"/zh/tag/%E5%A4%9A%E6%A8%A1%E6%80%81ai/",indexes:[32]},AI推理:{path:"/zh/tag/ai%E6%8E%A8%E7%90%86/",indexes:[32]},MCP:{path:"/zh/tag/mcp/",indexes:[32]},平台:{path:"/zh/tag/%E5%B9%B3%E5%8F%B0/",indexes:[33]},运营:{path:"/zh/tag/%E8%BF%90%E8%90%A5/",indexes:[33]},内容:{path:"/zh/tag/%E5%86%85%E5%AE%B9/",indexes:[33]},创新:{path:"/zh/tag/%E5%88%9B%E6%96%B0/",indexes:[33]}}}}}},4776:(e,t,a)=>{a.d(t,{M:()=>n});const n=["/demo/page.html","/demo/","/demo/disable.html","/demo/encrypt.html","/demo/layout.html","/demo/markdown.html","/posts/reprints/explaining-tokens-the-language-and-currency-of-ai-nvidia-blog.html","/posts/reprints/generative-ai-powered-design.html","/posts/reprints/illustrious-lu-v0.03.html","/posts/reprints/illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language.html","/posts/reprints/illustrious-xl-v2.0-the-best-training-base-model-in-1536-age.html","/posts/reprints/qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html","/posts/reprints/mcp-flash-in-the-pan-or-future-standard.html","/posts/reprints/niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything.html","/posts/reprints/niji-study-1-measuring-with-your-eyes.html","/zh/demo/page.html","/zh/demo/","/zh/demo/disable.html","/zh/demo/encrypt.html","/zh/demo/markdown.html","/zh/demo/layout.html","/zh/posts/dairys/250223.html","/zh/posts/dairys/250222.html","/zh/posts/papers/framepack.html","/zh/posts/reprints/explaining-tokens-the-language-and-currency-of-ai-nvidia-blog.html","/zh/posts/reprints/illustrious-lu-v0.03.html","/zh/posts/reprints/generative-ai-powered-design.html","/zh/posts/reprints/mcp-flash-in-the-pan-or-future-standard.html","/zh/posts/reprints/illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language.html","/zh/posts/reprints/illustrious-xl-v2.0-the-best-training-base-model-in-1536-age.html","/zh/posts/reprints/niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything.html","/zh/posts/reprints/niji-study-1-measuring-with-your-eyes.html","/zh/posts/reprints/qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html","/zh/posts/thoughts/platform-operation-thoughts-after-comfycon.html","/posts/reprints/crody's-model-merge-guide.html","/posts/reprints/experimenting-with-mcp-using-github-copilot.html","/posts/reprints/what-is-block-merging.html","/posts/reprints/model-block-merge-1.html","/posts/reprints/model-block-merge-2.html","/zh/posts/reprints/crody's-model-merge-guide.html","/zh/posts/reprints/experiments-with-mcp-using-github-copilot.html","/posts/reprints/ai-art-newsletter-jan-25.html","/posts/reprints/model-block-merge.html","/zh/posts/ai-impls/yolov9.html","/zh/posts/ai-weekly/001.html","/zh/posts/ai-weekly/002.html","/zh/posts/ai-weekly/003.html","/zh/posts/ai-weekly/004.html","/zh/posts/ai-weekly/005.html","/zh/posts/ai-weekly/006.html","/zh/posts/ai-weekly/007.html","/zh/posts/ai-weekly/008.html","/zh/posts/ai-weekly/009.html","/zh/posts/ai-weekly/010.html","/zh/posts/ai-weekly/011.html","/zh/posts/ai-weekly/012.html","/zh/posts/ai-weekly/013.html","/zh/posts/ai-weekly/014.html","/zh/posts/ai-weekly/015.html","/zh/posts/ai-weekly/016.html","/zh/posts/ai-weekly/017.html","/zh/posts/ai-weekly/018.html","/zh/posts/ai-weekly/019.html","/zh/posts/ai-weekly/020.html","/zh/posts/ai-weekly/021.html","/zh/posts/ai-weekly/022.html","/zh/posts/ai-weekly/023.html","/zh/posts/ai-weekly/024.html","/zh/posts/ai-weekly/025.html","/zh/posts/ai-weekly/026.html","/zh/posts/ai-weekly/027.html","/zh/posts/ai-weekly/028.html","/zh/posts/ai-weekly/029.html","/zh/posts/ai-weekly/030.html","/zh/posts/ai-weekly/031.html","/zh/posts/ai-weekly/032.html","/zh/posts/ai-weekly/033.html","/zh/posts/ai-weekly/034.html","/zh/posts/ai-weekly/035.html","/zh/posts/ai-weekly/036.html","/zh/posts/ai-weekly/037.html","/zh/posts/ai-weekly/X01.html","/zh/posts/papers/3steps-paper-reading.html","/zh/posts/papers/alexnet.html","/zh/posts/papers/colorizediffusion.html","/zh/posts/papers/hunyuancustom.html","/zh/posts/papers/icedit.html","/zh/posts/papers/reptext.html","/zh/posts/papers/resnet.html","/zh/posts/papers/transformer.html","/zh/posts/reprints/ai-art-newsletter-jan-25.html","/zh/posts/templates/papers.html","/zh/posts/web/vue-1.html"]},3781:(e,t,a)=>{a.d(t,{U:()=>n});const n={article:{"/":{path:"/article/",indexes:[0,11,8,9,7,35,6,10,34,12,13,14,36,37,38,1,2,3,4,5,41,42]},"/zh/":{path:"/zh/article/",indexes:[21,22,15,32,23,25,33,28,26,40,24,29,39,27,30,31,16,17,18,20,19,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92]}},star:{"/":{path:"/star/",indexes:[0]},"/zh/":{path:"/zh/star/",indexes:[33,21,22,15]}},timeline:{"/":{path:"/timeline/",indexes:[11,8,9,7,35,6,10,34,12,13,14,36,37,38,0]},"/zh/":{path:"/zh/timeline/",indexes:[32,23,25,33,28,26,40,24,29,39,21,22,27,30,31,15]}}}},711:(e,t,a)=>{a.d(t,{B:()=>X});var n={};a.r(n);var i={};a.r(i);var o={};a.r(o),a.d(o,{default:()=>b});var r={};a.r(r);var l={};a.r(l),a.d(l,{default:()=>I});var s={};a.r(s),a.d(s,{default:()=>D});var d={};a.r(d),a.d(d,{default:()=>j});var h={};a.r(h),a.d(h,{default:()=>R});var p=a(2402),g=a(3073),m=a(9403),c=a(596),u=a(8831);const b={enhance:({app:e})=>{(0,p.L4)("FontIcon")||e.component("FontIcon",m.A),(0,p.L4)("Badge")||e.component("Badge",c.A),(0,p.L4)("VPCard")||e.component("VPCard",u.A)},setup:()=>{(0,g.r9V)("https://cdn.jsdelivr.net/npm/iconify-icon@1")},rootComponents:[]};var f=a(6358),E=a(3827),A=a(355),y=a(1599),w=a(8913),x=a(457),z=a(3349),B=a(1781),v=a(9212);const I={enhance:({app:e})=>{e.component("CodeTabs",B.S),e.component("Tabs",v.t)}};var k=a(8031),C=a(3027);const D={enhance:({app:e})=>{e.component("CodeDemo",k.A),e.component("MdDemo",C.A)}};var T=a(5753),M=a(5054),F=a(9672),L=a(8465),q=a(641),S=a(9288),G=a(3974);(0,L.M_)((e=>{const t=e.t,a=!1!==e.I,n=e.i;return a?{title:t,content:n?()=>[(0,q.h)(F.GB,{icon:n}),t]:null,order:e.O,index:e.I}:null}));const j={enhance:({app:e,router:t})=>{const{scrollBehavior:a}=t.options;t.options.scrollBehavior=async(...e)=>(await F.lE.wait(),a(...e)),(0,F.fk)(e),e.component("HopeIcon",F.GB),e.component("BloggerInfo",S.tI),e.component("SocialMedias",S.rS),e.component("GlobalEncrypt",G.J),e.component("LocalEncrypt",G.n)},setup:()=>{(0,F.PV)(),(0,F.i$)(),(0,S.su)()},layouts:{Layout:F.PE,NotFound:F.Mk,BlogCategory:S.Pn,BlogHome:S.qX,BlogType:S.z7,Timeline:S.Kf}};var P=a(3456),O=a(953),N=a(1974),H=a(2330),W=a(7388),_=a(2581);const K={class:"theme-hope-content"},V=(0,q.pM)({__name:"MyPostLayout",setup:e=>(e,t)=>{const a=(0,q.g2)("Share");return(0,q.uX)(),(0,q.CE)(q.FK,null,[(0,q.bF)((0,O.R1)(W.A)),(0,q.bF)((0,O.R1)(N.A),null,{default:(0,q.k6)((()=>[(0,q.bF)((0,O.R1)(_.N),null,{default:(0,q.k6)((()=>[(0,q.bF)((0,O.R1)(H.A),null,{contentAfter:(0,q.k6)((()=>[(0,q.Lk)("div",K,[(0,q.bF)(a,{colorful:"",services:"email,facebook,line,linkedin,messenger,qrcode,reddit,telegram,twitter"})])])),_:1})])),_:1})])),_:1})],64)}}),R=(0,P.re)({enhance:({app:e})=>{},layouts:{Layout:V,Origin:F.PE}}),X=[n,i,o,f,E,A,y,w,x,z,r,l,s,T,M,d,h].map((e=>e.default)).filter(Boolean)},8164:(e,t,a)=>{a.d(t,{J:()=>i,c:()=>n});const n=JSON.parse("{}"),i=Object.fromEntries([["/home.html",{loader:()=>a.e(9759).then(a.bind(a,5936)),meta:{t:"Blog Home",i:"home"}}],["/",{loader:()=>a.e(4470).then(a.bind(a,9908)),meta:{t:"Blog Home",i:"home"}}],["/intro.html",{loader:()=>a.e(3912).then(a.bind(a,2058)),meta:{t:"Intro Page",i:"circle-info"}}],["/demo/",{loader:()=>a.e(3320).then(a.bind(a,5351)),meta:{c:["Guide"],r:{minutes:.04,words:12},t:"Features demo",i:"laptop-code",y:"a"}}],["/demo/disable.html",{loader:()=>a.e(2756).then(a.bind(a,2411)),meta:{c:["Guide"],g:["disable"],e:"<p>You can disable some function and layout on the page by setting the Frontmatter of the page.</p>\n",r:{minutes:.28,words:83},t:"Disabling layout and features",i:"gears",O:4,y:"a"}}],["/demo/encrypt.html",{loader:()=>a.e(2581).then(a.bind(a,1280)),meta:{c:["Guide"],g:["encryption"],n:!0,r:{minutes:.3,words:90},t:"Encryption Article",i:"lock",y:"a"}}],["/demo/layout.html",{loader:()=>a.e(6216).then(a.bind(a,1804)),meta:{c:["Guide"],g:["Layout"],e:'<p>The layout contains:</p>\n<ul>\n<li><a href="https://theme-hope.vuejs.press/guide/layout/navbar.html" target="_blank" rel="noopener noreferrer">Navbar</a></li>\n<li><a href="https://theme-hope.vuejs.press/guide/layout/sidebar.html" target="_blank" rel="noopener noreferrer">Sidebar</a></li>\n<li><a href="https://theme-hope.vuejs.press/guide/layout/footer.html" target="_blank" rel="noopener noreferrer">Footer</a></li>\n</ul>',r:{minutes:.35,words:105},t:"Layout",i:"object-group",O:2,y:"a"}}],["/demo/markdown.html",{loader:()=>a.e(8711).then(a.bind(a,3947)),meta:{c:["Guide"],g:["Markdown"],e:"<p>VuePress basically generate pages from Markdown files. So you can use it to generate documentation or blog sites easily.</p>\n<p>You should create and write Markdown files, so that VuePress can convert them to different pages according to file structure.</p>\n",r:{minutes:2.63,words:789},t:"Markdown Enhance",i:"fab fa-markdown",O:2,y:"a"}}],["/demo/page.html",{loader:()=>a.e(645).then(a.bind(a,5397)),meta:{a:"Ms.Hope",d:15778368e5,l:"January 1, 2020",c:["Guide"],g:["Page config","Guide"],u:!0,e:"<p>Content before <code>more</code> comment is regarded as page excerpt.</p>\n",r:{minutes:1.14,words:341},t:"Page Config",i:"file",O:3,y:"a"}}],["/zh/home.html",{loader:()=>a.e(3090).then(a.bind(a,6072)),meta:{t:"Blog Home",i:"home"}}],["/zh/",{loader:()=>a.e(433).then(a.bind(a,5762)),meta:{t:"Blog Home",i:"home"}}],["/zh/intro.html",{loader:()=>a.e(787).then(a.bind(a,2414)),meta:{t:"Intro Page",i:"circle-info"}}],["/posts/reprints/ai-art-newsletter-jan-25.html",{loader:()=>a.e(4772).then(a.bind(a,7940)),meta:{e:"\n<h3>First issue 🎉</h3>\n<p>The AI space is moving so fast it’s hard to believe that a year ago we still struggled to generate people with the correct amount of fingers 😂.</p>\n<p>The last couple of years have been pivotal for open source models and tools for artistic usage.\nAI tools for creative expression have never been more accessible, and we’re only scratching the surface.\nJoin us as we look back at the key milestones, tools, and breakthroughs in AI &amp; Arts from 2024,\nand forward for what’s to come in 2025.</p>",r:{minutes:7.56,words:2269},t:"The AI tools for Art Newsletter - Issue 1",y:"a"}}],["/posts/reprints/crody's-model-merge-guide.html",{loader:()=>a.e(1041).then(a.bind(a,6470)),meta:{a:"Crody",d:17419104e5,l:"March 14, 2025",g:["resource guide","script","stable diffusion","merge","model"],v:"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2d3f67d3-4906-46b0-b27c-63ba7376cca7/width=1320/00000_2500974118.jpeg",e:"<p>Hi this is Crody from Team-C: creator of Nova Series</p>\n<p>In this article, I'll write down what kind of merge I use with some knowledge about SDXL models\nFor how I do, please read Merge Scripter Guide first</p>\n<h2>1. Weighted Sum / Sum Twice</h2>\n<p>Weighted Sum (WS) merges 2 models, Sum Twice (ST) merges first 2 and 1 model (which means doing WS twice)\nYou can use Block Merge as well\nUsing alpha (and beta) to determine how much similarity the result have\nHigher value means the results would be similar to latter model</p>",r:{minutes:5.18,words:1553},t:"Crody's Model Merge Guide // Team-C",y:"a"}}],["/posts/reprints/experimenting-with-mcp-using-github-copilot.html",{loader:()=>a.e(9839).then(a.bind(a,4360)),meta:{a:"kcon",d:1742256e6,l:"March 18, 2025",g:["editor","Model Context Protocol","tech"],e:'\n<h2>Overview</h2>\n<p>This article describes how to install the "Copilot MCP" extension in VS Code and use GitHub Copilot with MCP to fetch information from GitHub for testing purposes.<br>\nNote: Since the official GitHub Copilot implementation also seems to support MCP, this extension might become unnecessary once the feature is released.</p>',r:{minutes:1.6,words:480},t:"Experimenting with MCP using GitHub Copilot",y:"a"}}],["/posts/reprints/explaining-tokens-the-language-and-currency-of-ai-nvidia-blog.html",{loader:()=>a.e(8637).then(a.bind(a,6576)),meta:{a:"Dave Salvator",d:17421696e5,l:"March 17, 2025",c:["Explainer","Generative AI"],g:["Artificial Intelligence","Inference"],v:"https://blogs.nvidia.com/wp-content/uploads/2025/03/llm-blog-data-curator-2847806-1280x680-1.png",e:'\n<figure><img src="https://blogs.nvidia.com/wp-content/uploads/2025/03/llm-blog-data-curator-2847806-1280x680-1.png" alt="Image 1: Depiction of a large language model processing data" tabindex="0" loading="lazy"><figcaption>Image 1: Depiction of a large language model processing data</figcaption></figure>',r:{minutes:5.44,words:1632},t:"Explaining Tokens — the Language and Currency of AI",y:"a"}}],["/posts/reprints/generative-ai-powered-design.html",{loader:()=>a.e(5391).then(a.bind(a,1414)),meta:{a:"Isha Dua & Parth Patel",d:17423424e5,l:"March 19, 2025",c:["Reprints"],g:["Generative AI","Game Development","Stable Diffusion","Image Generation","AWS","Amazon Bedrock"],u:!1,v:"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/03/19/Picture1-11.jpg",e:"<p>In the competitive world of game development, staying ahead of technological advancements is crucial. Generative AI has emerged as a game changer, offering unprecedented opportunities for game designers to push boundaries and create immersive virtual worlds. At the forefront of this revolution is Stability AI’s cutting-edge text-to-image AI model, Stable Diffusion 3.5 Large (SD3.5 Large), which is transforming the way we approach game environment creation.</p>",r:{minutes:4.68,words:1405},t:"Generative AI-Powered Design: Creating Game Environments with SD3.5 Large",i:"openmoji:video-game",O:1,y:"a"}}],["/posts/reprints/illustrious-lu-v0.03.html",{loader:()=>a.e(843).then(a.bind(a,9082)),meta:{a:"Angelbottomless",d:17449344e5,l:"April 18, 2025",c:["Model Development","reprint"],g:["Illustrious","LU","Lumina","AI Model","Image Generation","Training"],v:"https://illustrious-prod.s3.ap-northeast-2.amazonaws.com/blog/2025-04-11T07:16:56.712Z/2025-04-11%20Thumbnail.png",e:'\n<p>SD XL has been suffering from CLIP – I think this is true, at least partially. Recent models have shown some potential related to natural language, like understanding "left is red, right is blue". However, since CLIP was not trained with natural language sentences, base SD XL and its finetuned variants were significantly limited regarding processing it.</p>',r:{minutes:2.56,words:768},t:"Illustrious-LU v0.03",i:"fa-solid:microscope",y:"a"}}],["/posts/reprints/illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language.html",{loader:()=>a.e(2296).then(a.bind(a,9134)),meta:{a:"Angelbottomless",d:17426016e5,l:"March 22, 2025",c:["Model Development","Model Training","Image Generation","Anime Style"],g:["SDXL","2048 Resolution","Illustrious","vpred","epsilon prediction"],v:"/assets/images/reprints/illustrious/v3.0-3.5/thumbnail.webp",e:"\n<p>Illustrious XL 3.0–3.5-vpred represents a major advancement in Stable Diffusion XL (SD XL) modeling, notably supporting resolutions ranging seamlessly from 256 up to 2048. The v3.5-vpred variant particularly emphasizes robust natural language understanding capabilities, comparable in sophistication to miniaturized large language models (LLMs), achieved through extensive simultaneous training of both CLIP and UNet components.</p>",r:{minutes:8.56,words:2568},t:"Illustrious XL 3.0-3.5-vpred: 2048 Resolution and Natural Language",i:"mdi:paint-outline",y:"a"}}],["/posts/reprints/illustrious-xl-v2.0-the-best-training-base-model-in-1536-age.html",{loader:()=>a.e(6959).then(a.bind(a,7246)),meta:{a:"Angelbottomless",d:17419968e5,l:"March 15, 2025",c:["Model Development","Model Training","Image Generation","Anime Style"],g:["SDXL","Anime","Illustrious","Base model","Image generation"],v:"/assets/images/reprints/illustrious/v2.0-2.0a/thumbnail.webp",e:"\n<h2>Introduction</h2>\n<p>Illustrious XL 1.0-2.0 series aims to stabilize native generation at 1536 resolution while significantly improving natural language understanding capabilities.</p>\n<p>While users sometimes observed successful 1024x1536 resolution generations, these were not stable. Similarly, 512x512 generations occasionally produced unwanted artifacts.</p>",r:{minutes:3.66,words:1097},t:"Illustrious XL v2.0—The best training base model in 1536 age",i:"mdi:paint-outline",y:"a"}}],["/posts/reprints/mcp-flash-in-the-pan-or-future-standard.html",{loader:()=>a.e(157).then(a.bind(a,4e3)),meta:{a:"Harrison Chase & Nuno Campos",d:17145216e5,l:"May 1, 2024",c:["reprint"],g:["AI","LLM","Protocol","Debate"],u:!1,v:"/assets/images/reprint/mcp-debate-cover.jpeg",e:"\n<p>Model Context Protocol (MCP) has stirred up quite a storm on Twitter—but is it actually useful, or just noise? In this debate, Harrison Chase (LangChain CEO) and Nuno Campos (Head of LangGraph) discuss whether MCP lives up to the hype.</p>\n<h2>Harrison's Take: MCP Is Actually Useful</h2>\n<p>I started skeptical about MCP, but I've begun to see its value. Essentially: <strong>MCP is useful when you want to add tools to an agent you don't control</strong>.</p>",r:{minutes:4.36,words:1309},t:"MCP: Flash in the Pan or Future Standard?",i:"openmoji:code-editor",O:1,y:"a"}}],["/posts/reprints/model-block-merge-1.html",{loader:()=>a.e(7532).then(a.bind(a,3605)),meta:{a:"bbcmc",d:1671812821e3,l:"December 23, 2022",g:["StableDiffusion","ModelMerge","AUTOMATIC1111","AI"],e:'\n<figure><img src="https://assets.st-note.com/production/uploads/images/93960055/rectangle_large_type_2_0e16ed0e2b288d1ab93dbd822ca17a46.png?width=1200" alt="Header image" tabindex="0" loading="lazy"><figcaption>Header image</figcaption></figure>\n\n<ol>\n<li>Introduction</li>\n<li>Experiment Overview</li>\n<li>Experiment 1</li>\n<li>Analysis 1</li>\n<li>Experiment 2</li>\n<li>Analysis 2</li>\n<li>Side Note 1</li>\n<li>Experiment 2 Setup</li>\n<li>Experiment 2: Results and Analysis</li>\n<li>Analysis Approach and Reminders (to me)</li>\n</ol>',r:{minutes:6.85,words:2056},t:"[Experiment Report] Investigating the Influence of Each U-Net Layer with Model Block Merge #1",y:"a"}}],["/posts/reprints/model-block-merge-2.html",{loader:()=>a.e(3329).then(a.bind(a,2250)),meta:{a:"bbcmc",d:1671812821e3,l:"December 23, 2022",g:["StableDiffusion","ModelMerge","AUTOMATIC1111","AI"],e:'\n<figure><img src="https://assets.st-note.com/production/uploads/images/93960055/rectangle_large_type_2_0e16ed0e2b288d1ab93dbd822ca17a46.png?width=1200" alt="Header image" tabindex="0" loading="lazy"><figcaption>Header image</figcaption></figure>\n',r:{minutes:6.68,words:2004},t:"[Experiment Report] Investigating the Influence of Each U-Net Layer with Model Block Merge #1",y:"a"}}],["/posts/reprints/model-block-merge.html",{loader:()=>a.e(3722).then(a.bind(a,5940)),meta:{t:"",y:"a"}}],["/posts/reprints/niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything.html",{loader:()=>a.e(5109).then(a.bind(a,8838)),meta:{a:"niji・journey",d:16898976e5,l:"July 21, 2023",c:["reprints"],g:["Art","Drawing","Fundamentals","niji"],u:!1,v:"/assets/images/reprints/nijijourney/lesson1/thumb.webp",e:'\n<p>In this class, instead of focusing on how to draw specific subjects, we\'ll be teaching you how to teach yourself, with some help from niji.</p>\n<p>For the exercise attached to this lesson, see <a href="https://nijijourney.com/blog/niji-study-1-Measuring-With-Your-Eyes" target="_blank" rel="noopener noreferrer">📏 Study 1: Measuring With Your Eyes.</a></p>',r:{minutes:6.14,words:1843},t:"Lesson 1: Fundamentals of Measurement and Abstraction: The Theory of (How to Draw) Everything",i:"palette",O:1,y:"a"}}],["/posts/reprints/niji-study-1-measuring-with-your-eyes.html",{loader:()=>a.e(8904).then(a.bind(a,9355)),meta:{a:"niji・journey",d:16898976e5,l:"July 21, 2023",c:["reprints"],g:["Art","Drawing","Fundamentals","niji"],u:!1,v:"/assets/images/reprints/nijijourney/study1/thumb.webp",e:'\n<p><a href="/posts/reprints/niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything">Previous Lesson 1: Fundamentals of Measurement and Abstraction: The Theory of (How to Draw) Everything</a> | <a href="https://nijijourney.com/blog/niji-study-2-notan" target="_blank" rel="noopener noreferrer">Next Study 2: Notan</a></p>',r:{minutes:3.3,words:991},t:"Study 1: Measuring With Your Eyes",i:"ruler",O:2,y:"a"}}],["/posts/reprints/qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html",{loader:()=>a.e(8467).then(a.bind(a,9194)),meta:{a:"Jainil Prajapati",d:17458848e5,l:"April 29, 2025",c:["reprint"],g:["Qwen","Qwen3","Alibaba AI research","Alibaba AI","large language models","LLMs","LLM benchmarks","Multilingual AI","Multimodal AI","AI reasoning","MCP"],u:!1,v:"https://altctrlai.com/content/images/size/w2000/2025/04/834B968B-9CED-4EF4-B81F-845F8241AC0A.webp",e:'\n<figure><img src="https://altctrlai.com/content/images/size/w2000/2025/04/834B968B-9CED-4EF4-B81F-845F8241AC0A.webp" alt="Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 Overview" tabindex="0" loading="lazy"><figcaption>Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 Overview</figcaption></figure>',r:{minutes:6.03,words:1808},t:"Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 Overview",i:"fa-solid:robot",y:"a"}}],["/posts/reprints/what-is-block-merging.html",{loader:()=>a.e(8573).then(a.bind(a,7083)),meta:{a:"researchanon",d:16740864e5,l:"January 19, 2023",g:["StableDiffusion","ModelMerging","AUTOMATIC1111","AI"],e:'\n<div class="hint-container warning">\n<p class="hint-container-title">NOTE</p>\n<p>This guide is still work in progress. Any and all feedback is highly appreciated, it doesn\'t have to be suggestions, even questions regarding things you didn\'t understand can help me figure out what to refine.</p>\n</div>',r:{minutes:12.88,words:3865},t:"What is Block Merging?",y:"a"}}],["/zh/demo/",{loader:()=>a.e(1145).then(a.bind(a,782)),meta:{c:["使用指南"],r:{minutes:.07,words:22},t:"主要功能与配置演示",i:"laptop-code",y:"a"}}],["/zh/demo/disable.html",{loader:()=>a.e(6297).then(a.bind(a,7891)),meta:{c:["使用指南"],g:["禁用"],e:"<p>你可以通过设置页面的 Frontmatter，在页面禁用功能与布局。</p>\n",r:{minutes:.43,words:128},t:"布局与功能禁用",i:"gears",O:4,y:"a"}}],["/zh/demo/encrypt.html",{loader:()=>a.e(4344).then(a.bind(a,1321)),meta:{c:["使用指南"],g:["加密"],n:!0,r:{minutes:.51,words:154},t:"密码加密的文章",i:"lock",y:"a"}}],["/zh/demo/layout.html",{loader:()=>a.e(7119).then(a.bind(a,4191)),meta:{c:["指南"],g:["布局"],e:'<p>布局包括:</p>\n<ul>\n<li><a href="https://theme-hope.vuejs.press/zh/guide/layout/navbar.html" target="_blank" rel="noopener noreferrer">导航栏</a></li>\n<li><a href="https://theme-hope.vuejs.press/zh/guide/layout/sidebar.html" target="_blank" rel="noopener noreferrer">侧边栏</a></li>\n<li><a href="https://theme-hope.vuejs.press/zh/guide/layout/footer.html" target="_blank" rel="noopener noreferrer">页脚</a></li>\n</ul>',r:{minutes:.53,words:159},t:"布局",i:"object-group",O:2,y:"a"}}],["/zh/demo/markdown.html",{loader:()=>a.e(7584).then(a.bind(a,6732)),meta:{c:["使用指南"],g:["Markdown"],e:"<p>VuePress 主要从 Markdown 文件生成页面。因此，你可以使用它轻松生成文档或博客站点。</p>\n<p>你需要创建并编写 Markdown，以便 VuePress 可以根据文件结构将它们转换为不同的页面。</p>\n",r:{minutes:3.47,words:1041},t:"Markdown 展示",i:"fab fa-markdown",O:2,y:"a"}}],["/zh/demo/page.html",{loader:()=>a.e(6590).then(a.bind(a,8604)),meta:{a:"Ms.Hope",d:15778368e5,l:"2020年1月1日",c:["使用指南"],g:["页面配置","使用指南"],u:!0,v:"/assets/images/cover1.jpg",e:"<p><code>more</code> 注释之前的内容被视为文章摘要。</p>\n",r:{minutes:1.76,words:529},t:"页面配置",i:"file",O:3,y:"a"}}],["/zh/posts/ai-impls/yolov9.html",{loader:()=>a.e(1668).then(a.bind(a,3160)),meta:{e:'\n<h2>导航</h2>\n<ul>\n<li><a href="notion://www.notion.so/Blog1-YOLOv9-5bfb1b8d97844ba99c6f081ed667721d?pvs=12#%E5%BC%95%E8%A8%80" target="_blank" rel="noopener noreferrer">引言</a>\n<ul>\n<li><a href="notion://www.notion.so/Blog1-YOLOv9-5bfb1b8d97844ba99c6f081ed667721d?pvs=12#YOLOv9%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0" target="_blank" rel="noopener noreferrer">YOLOv9 模型概述</a>\n<ul>\n<li><a href="notion://www.notion.so/Blog1-YOLOv9-5bfb1b8d97844ba99c6f081ed667721d?pvs=12#%E6%A8%A1%E5%9E%8B%E6%A1%86%E6%9E%B6%E5%9B%BE" target="_blank" rel="noopener noreferrer">模型框架图</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href="notion://www.notion.so/Blog1-YOLOv9-5bfb1b8d97844ba99c6f081ed667721d?pvs=12#%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E5%8F%8A%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86" target="_blank" rel="noopener noreferrer">环境搭建及训练推理</a>\n<ul>\n<li><a href="notion://www.notion.so/Blog1-YOLOv9-5bfb1b8d97844ba99c6f081ed667721d?pvs=12#%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE" target="_blank" rel="noopener noreferrer">环境配置</a></li>\n<li><a href="notion://www.notion.so/Blog1-YOLOv9-5bfb1b8d97844ba99c6f081ed667721d?pvs=12#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%87%86%E5%A4%87" target="_blank" rel="noopener noreferrer">数据集准备</a></li>\n<li><a href="notion://www.notion.so/Blog1-YOLOv9-5bfb1b8d97844ba99c6f081ed667721d?pvs=12#%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B" target="_blank" rel="noopener noreferrer">训练过程</a></li>\n<li><a href="notion://www.notion.so/Blog1-YOLOv9-5bfb1b8d97844ba99c6f081ed667721d?pvs=12#%E6%B5%8B%E8%AF%95%E5%92%8C%E8%AF%84%E4%BC%B0" target="_blank" rel="noopener noreferrer">测试和评估</a></li>\n<li><a href="notion://www.notion.so/Blog1-YOLOv9-5bfb1b8d97844ba99c6f081ed667721d?pvs=12#%E5%AE%9E%E8%B7%B5%E5%BA%94%E7%94%A8" target="_blank" rel="noopener noreferrer">实践应用</a></li>\n</ul>\n</li>\n<li><a href="notion://www.notion.so/Blog1-YOLOv9-5bfb1b8d97844ba99c6f081ed667721d?pvs=12#%E6%8A%A5%E9%94%99%E4%BF%AE%E5%A4%8D" target="_blank" rel="noopener noreferrer">报错修复</a></li>\n<li><a href="notion://www.notion.so/Blog1-YOLOv9-5bfb1b8d97844ba99c6f081ed667721d?pvs=12#%E6%80%BB%E7%BB%93%E5%92%8C%E5%B1%95%E6%9C%9B" target="_blank" rel="noopener noreferrer">总结和展望</a></li>\n<li><a href="notion://www.notion.so/Blog1-YOLOv9-5bfb1b8d97844ba99c6f081ed667721d?pvs=12#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5" target="_blank" rel="noopener noreferrer">参考链接</a></li>\n</ul>',r:{minutes:6.16,words:1847},t:"YOLOv9 代码复现",y:"a"}}],["/zh/posts/ai-weekly/001.html",{loader:()=>a.e(1583).then(a.bind(a,7903)),meta:{e:'\n<h2>目录</h2>\n<ol>\n<li><a href="notion://www.notion.so/657f0864717c46feb4e178340c835a83?v=b369a7ce1cdd4ec185a435fc80bf1dc1&amp;p=d3052cfc27554302961952cc405f6431&amp;pm=s#show-o-%E7%BB%9F%E4%B8%80%E5%A4%9A%E6%A8%A1%E6%80%81%E7%90%86%E8%A7%A3%E4%B8%8E%E7%94%9F%E6%88%90%E7%9A%84transformer" target="_blank" rel="noopener noreferrer">Show-o: 统一多模态理解与生成的 Transformer</a></li>\n<li><a href="notion://www.notion.so/657f0864717c46feb4e178340c835a83?v=b369a7ce1cdd4ec185a435fc80bf1dc1&amp;p=d3052cfc27554302961952cc405f6431&amp;pm=s#csgo-%E5%9F%BA%E4%BA%8E%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB%E4%B8%8E%E7%94%9F%E6%88%90" target="_blank" rel="noopener noreferrer">CSGO: 基于扩散模型的风格迁移与生成</a></li>\n<li><a href="notion://www.notion.so/657f0864717c46feb4e178340c835a83?v=b369a7ce1cdd4ec185a435fc80bf1dc1&amp;p=d3052cfc27554302961952cc405f6431&amp;pm=s#instantstyle-plus-%E4%BC%98%E5%8C%96%E5%86%85%E5%AE%B9%E4%BF%9D%E7%95%99%E4%B8%8E%E9%A3%8E%E6%A0%BC%E5%A2%9E%E5%BC%BA%E7%9A%84%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB%E6%96%B9%E6%B3%95" target="_blank" rel="noopener noreferrer">InstantStyle-Plus: 优化内容保留与风格增强的风格迁移方法</a></li>\n<li><a href="notion://www.notion.so/657f0864717c46feb4e178340c835a83?v=b369a7ce1cdd4ec185a435fc80bf1dc1&amp;p=d3052cfc27554302961952cc405f6431&amp;pm=s#swiftbrush-v2-%E4%B8%8B%E4%B8%80%E4%BB%A3%E9%AB%98%E6%95%88ai%E7%BB%98%E7%94%BB%E5%B7%A5%E5%85%B7" target="_blank" rel="noopener noreferrer">SwiftBrush V2: 下一代高效 AI 绘画工具</a></li>\n<li><a href="notion://www.notion.so/657f0864717c46feb4e178340c835a83?v=b369a7ce1cdd4ec185a435fc80bf1dc1&amp;p=d3052cfc27554302961952cc405f6431&amp;pm=s#kotaemon-%E9%AB%98%E6%95%88%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA" target="_blank" rel="noopener noreferrer">Kotaemon: 高效的多模态聊天机器人</a></li>\n<li><a href="notion://www.notion.so/657f0864717c46feb4e178340c835a83?v=b369a7ce1cdd4ec185a435fc80bf1dc1&amp;p=d3052cfc27554302961952cc405f6431&amp;pm=s#linly-dubbing-%E5%9F%BA%E4%BA%8Eai%E7%9A%84%E9%AB%98%E6%95%88%E9%85%8D%E9%9F%B3%E5%B7%A5%E5%85%B7" target="_blank" rel="noopener noreferrer">Linly-Dubbing: 基于 AI 的高效配音工具</a></li>\n<li><a href="notion://www.notion.so/657f0864717c46feb4e178340c835a83?v=b369a7ce1cdd4ec185a435fc80bf1dc1&amp;p=d3052cfc27554302961952cc405f6431&amp;pm=s#hivisionidphotos-%E5%9F%BA%E4%BA%8Eai%E7%9A%84%E8%AF%81%E4%BB%B6%E7%85%A7%E7%94%9F%E6%88%90%E5%B7%A5%E5%85%B7" target="_blank" rel="noopener noreferrer">HivisionIDPhotos: 基于 AI 的证件照生成工具</a></li>\n</ol>',r:{minutes:6.63,words:1990},t:"AI 证件照生成工具 HivisionIDPhotos 引爆社交媒体 | Show-o 探索多模态未来 | 小红书 InstantX 团队提出风格迁移新方法 CSGO【AI 周报】",y:"a"}}],["/zh/posts/ai-weekly/002.html",{loader:()=>a.e(2486).then(a.bind(a,6963)),meta:{e:"\n<p>https://mmbiz.qpic.cn/sz_mmbiz_png/NM6DecUSXYtWYIE9aUXFP1YiaWE4UoQCz0MUrkqRNap6WlMeYABdXSgmxsnKAibk0GwZicjt1HX0nCTjVO6HYpzAQ/0?wx_fmt=png&amp;from=appmsg</p>\n<h2><strong>目录</strong></h2>\n<ol>\n<li>DepthCrafter: 为开放世界视频生成一致的长深度序列</li>\n<li>LinFusion: 高效生成 16K 图像的新方法</li>\n<li>Mini-Omni: 实时语音对话模型</li>\n<li>StyleTokenizer: 控制 Diffusion 模型的图像风格生成</li>\n<li>HiPrompt: 强化提示词优化框架</li>\n<li>Geometry Image Diffusion: 基于图像的高效文本生成 3D 模型</li>\n<li>Guide-and-Rescale: 实现无调优高效图像编辑的自引导机制</li>\n</ol>",r:{minutes:4.53,words:1359},t:"Unity 自研 3D 材质生成大模型 | 支付宝推出 Style Tokenizer|LinFusion 高效生成 16K 图像【AI 周报】",y:"a"}}],["/zh/posts/ai-weekly/003.html",{loader:()=>a.e(9437).then(a.bind(a,4012)),meta:{e:'\n<h2></h2>\n<figure><img src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/NM6DecUSXYsGhqP9NJy88No01ZhhQgNN0Kyx6ZYST4ZKicnDJXLVEnvKfDRicYzhc1hJ7UW0tibP5X0VZG02voBvQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>\n<h2><strong>概要</strong></h2>',r:{minutes:4.98,words:1494},t:"SaRA 高效微调 Diffusion 模型|Fish-Speech 更新多语种语音生成|IFAdapter 提升图像特征控制【AI 周报】",y:"a"}}],["/zh/posts/ai-weekly/004.html",{loader:()=>a.e(9092).then(a.bind(a,7950)),meta:{e:"\n<h2>摘要</h2>\n<p>本期周报涵盖 Qwen 2.5 Coder 的代码生成进展、InstantDrag 的交互式图像生成工具、以及 Omnigen 的多模态生成研究。此外，还介绍了 Diffusion-e2e-ft 扩散模型优化、LVCD 的线稿视频上色方法和 MoCoop 多模态合作学习。</p>\n<h2>目录</h2>\n<ol>\n<li>Qwen 2.5 Coder: 代码生成的最新突破</li>\n<li>InstantDrag: 交互式图像拖拽生成新工具</li>\n<li>Diffusion-e2e-ft: 自监督扩散模型优化</li>\n<li>Omnigen: 灵活生成模型的研究进展</li>\n<li>LVCD: 基于扩散模型的线稿视频上色</li>\n<li>MoCoop: 多模态合作学习的新方法</li>\n</ol>",r:{minutes:4.26,words:1278},t:"Qwen 2.5 Coder: 多语言代码生成新高度，InstantDrag 实时交互式图像生成，Omnigen 多模态生成研究进展【AI 周报】",y:"a"}}],["/zh/posts/ai-weekly/005.html",{loader:()=>a.e(7307).then(a.bind(a,7816)),meta:{e:"\n<h2><strong>摘要</strong></h2>\n<p>本周 AI 周报聚焦最新图像生成技术：Imagine yourself 无需调优即可生成个性化图像，NovelAI DiffusionV3 提升了生成效率与质量，智源研究院发布的多模态模型 Emu3 展现跨模态生成强大潜力，为 AI 发展带来更多创新可能。</p>\n<h2><strong>目录</strong></h2>\n<ol>\n<li>Imagine yourself：无需调优的个性化图像生成</li>\n<li>NovelAI Diffusion V3 中对 SDXL 的改进</li>\n<li>Make Pixels Dance: 扩散模型中的动态图像生成</li>\n<li>Molecular Modeling AI Initiative by Allen Institute</li>\n<li>MIMO: Vision Transformer with Multimodal Input</li>\n<li>Emu: BAAI 的多模态大模型项目</li>\n<li>PromptSliders: 基于滑动条的提示优化模型</li>\n</ol>",r:{minutes:7.62,words:2287},t:"Imagine yourself 无调优图像生成亮相 | NovelAI Diffusion V3 提升生成效率 | BAAI 推出多模态模型 Emu3【AI 周报】",y:"a"}}],["/zh/posts/ai-weekly/006.html",{loader:()=>a.e(9682).then(a.bind(a,737)),meta:{e:'\n<h2><strong>摘要</strong></h2>\n<p>本周 AI 周报聚焦生成模型与视觉技术突破：Meta 发布 Movie Gen，推动文本到视频的生成新模式；Ultralytics 推出 YOLOv11，优化目标检测与图像分类性能；华盛顿大学的 Inverse Painting 模型重现艺术创作过程。此外，Illustrious XL 与 FabricDiffusion 等模型在插画生成和 3D 服装纹理迁移上也带来显著提升，进一步拓展了 AI 在多领域的应用潜力。</p>\n<h2><strong>目录</strong></h2>\n<ol>\n<li><a href="#inverse-painting-%E5%9F%BA%E4%BA%8E-diffusion-%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%BB%98%E7%94%BB%E9%87%8D%E6%9E%84">Inverse Painting: 基于 Diffusion 模型的绘画过程重构</a></li>\n<li><a href="#illustrious-xl-%E4%B8%93%E4%B8%BA%E6%8F%92%E7%94%BB%E8%AE%BE%E8%AE%A1%E7%9A%84%E8%89%BA%E6%9C%AF%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B">Illustrious XL: 专为插画设计的艺术生成模型</a></li>\n<li><a href="#comfygen-%E5%9F%BA%E4%BA%8E-llm-%E7%9A%84%E8%87%AA%E9%80%82%E5%BA%94%E7%94%9F%E6%88%90%E5%B7%A5%E4%BD%9C%E6%B5%81">ComfyGen: 基于 LLM 的自适应生成 ComfyUI 工作流</a></li>\n<li><a href="#fabricdiffusion-%E9%AB%98%E4%BF%9D%E7%9C%9F-3d-%E6%9C%8D%E8%A3%85%E7%BA%B9%E7%90%86%E8%BF%81%E7%A7%BB">FabricDiffusion: 高保真 3D 服装纹理迁移</a></li>\n<li><a href="#training-free-image-style-transfer-%E5%88%A9%E7%94%A8-latent-diffusion-%E8%BF%9B%E8%A1%8C%E6%97%A0%E8%AE%AD%E7%BB%83%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB">STRDP: 利用 Latent Diffusion 进行无训练风格迁移</a></li>\n<li><a href="#movie-gen-metas-ai%E9%A9%B1%E5%8A%A8%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90">Movie Gen: Meta\'s AI 驱动视频生成</a></li>\n<li><a href="#yolov11-%E6%96%B0%E4%B8%80%E4%BB%A3%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B">YOLOv11: 新一代目标检测与分类模型</a></li>\n</ol>',r:{minutes:9.95,words:2984},t:"Meta 发布 Movie Gen 开启 AI 生成视频新时代 | YOLOv11 引领目标检测革新 | 华盛顿大学 Inverse Painting 重构绘画过程【AI 周报】",y:"a"}}],["/zh/posts/ai-weekly/007.html",{loader:()=>a.e(5961).then(a.bind(a,9464)),meta:{e:"\n<p>!https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3a0efd56-5a31-4661-910b-55d91f9f82b0/width=450/33654117.jpeg</p>\n<h2>摘要</h2>\n<p>本期汇总展示了六个前沿AI项目，涵盖从图像、视频生成的创新。CtrlX提供无损图像编辑，PixelShuffler实现自监督图像去噪，TextToon推动漫画生成技术，HybridBooth聚焦个性化头像生成，其余论文及项目详见正文。</p>\n<h2>目录</h2>\n<ol>\n<li>CtrlX: 可控图像编辑框架</li>\n<li>PixelShuffler: 高效的自监督图像去噪</li>\n<li>TextToon: 文本驱动的实时漫画化头像生成</li>\n<li>HybridBooth: 高效的个性化生成模型</li>\n<li>Pyramid-Flow: 高效的分层可逆生成模型</li>\n<li>Aria: 开源多模态专家模型</li>\n</ol>",r:{minutes:5.02,words:1506},t:"英伟达发布可控图像编辑框架|字节跳动TextToon实时漫画化头像生成|Vivo推出HybridBooth个性化生成【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/008.html",{loader:()=>a.e(8784).then(a.bind(a,4274)),meta:{e:'\n<figure><img src="https://fastly.jsdelivr.net/gh/bucketio/img12@main/2024/10/20/1729433178592-bd22ef03-8cac-448b-9ab1-3f2dcddac6c3.jpeg" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>\n<h2><strong>摘要</strong></h2>\n<p>本周AI周报关注几项前沿生成模型：ZeroComp在3D合成领域开辟新路径，CtrLoRA实现可控图像生成的高效框架，F5-TTS通过流匹配技术提升语音生成效果，HyperDreamBooth加快个性化文本到图像的速度。其余成果详见正文。</p>',r:{minutes:4.36,words:1309},t:"阿里开源Animate-X革新AI角色动画|ZeroComp实现创新3D对象合成|F5-TTS提升TTS语音的自然度【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/009.html",{loader:()=>a.e(9383).then(a.bind(a,8565)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/4e3f1d8a-beb1-4b84-bbdf-b3f61b4b2d3f/width=450/35854696.jpeg" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>\n<h2><strong>摘要</strong></h2>\n<p>本周，Stability AI的Stable Diffusion 3.5提升图像生成精度，Hugging Face推出无代码AutoTrain Advanced平台降低机器学习门槛，MagicTailor则在图像个性化编辑上实现更高控制度。</p>',r:{minutes:6.76,words:2027},t:"Stable Diffusion3.5革新生成精度|AutoTrain高效炼丹|MagicTailor个性化图像编辑【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/010.html",{loader:()=>a.e(1005).then(a.bind(a,8781)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c1d5f4ea-9cad-4e0b-8923-492d97bfce0e/width=450/1941-(img_1018CR210), Hack Forums scrapped-flux1-dev-fp8-compact-99638172.jpeg" alt="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c1d5f4ea-9cad-4e0b-8923-492d97bfce0e/width=450/1941-(img_1018CR210),%20Hack%20Forums%20scrapped-flux1-dev-fp8-compact-99638172.jpeg" tabindex="0" loading="lazy"><figcaption>https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c1d5f4ea-9cad-4e0b-8923-492d97bfce0e/width=450/1941-(img_1018CR210),%20Hack%20Forums%20scrapped-flux1-dev-fp8-compact-99638172.jpeg</figcaption></figure>',r:{minutes:5.96,words:1788},t:"FaceChain更新人脸转换引领个性生成|GenArtist多模态艺术生成系统|AutoKaggle竞赛助手革新【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/011.html",{loader:()=>a.e(4246).then(a.bind(a,8738)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bb18d643-4bac-439b-a647-35b9355aee31/width=450/38613991.jpeg" alt="封面" tabindex="0" loading="lazy"><figcaption>封面</figcaption></figure>\n<h2>摘要</h2>\n<p>本周聚焦视觉与生成领域突破：腾讯混元3D 推出高效3D重建工具，支持实时场景重建；MVPaint提升3D材质一致性，实现高质量多视角纹理生成；PromptFix利用Diffusion模型进行多任务图像修复，覆盖上色、去雾等。其余详见正文。</p>',r:{minutes:6.53,words:1959},t:"腾讯Hunyuan3D重塑3D重建|MVPaint多视角提升3D材质一致性|PromptFix实现高质量图像修复【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/012.html",{loader:()=>a.e(5519).then(a.bind(a,7643)),meta:{e:'\n<figure><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/021ded55-a224-419c-939c-70c6888912f7/d1a9dc14-03bb-4a6d-9bde-08c809989d52/微信logo.png" alt="微信logo.png" tabindex="0" loading="lazy"><figcaption>微信logo.png</figcaption></figure>\n<h2><strong>摘要</strong></h2>\n<p>本周聚焦多模态AI发展：TANGO创新语音驱动手势视频；StoryTeller支持长视频剧情生成；ADD-IT无训练对象插入；MikuDance合成动漫角色舞蹈；LLaMA-Mesh统一3D网格与语言模型。其余详见正文。</p>',r:{minutes:6.38,words:1915},t:"TANGO赋能数字人|ADD-IT重构图像编辑|MikuDance动漫角色舞蹈动画【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/013.html",{loader:()=>a.e(1944).then(a.bind(a,8276)),meta:{e:'\n<figure><img src="https://fastly.jsdelivr.net/gh/bucketio/img18@main/2024/11/24/1732457006798-1774d1ab-5764-437c-a50e-f922f2198952.png" alt="封面" tabindex="0" loading="lazy"><figcaption>封面</figcaption></figure>\n<h2><strong>摘要</strong></h2>\n<p>本周生成与检测技术亮点：JoyVASA 利用扩散模型实现音频驱动动画生成，支持人像与动物；DINO-X 面向开放世界目标检测，通过多模态提示提升长尾检测表现；StyleCodes 将图像风格编码为Base64格式，简化迁移过程并提升生成灵活性与质量。详情见正文。</p>',r:{minutes:5.1,words:1531},t:"JoyVASA突破多模态动画生成 | DINO-X定义开放世界检测 | StyleCodes实现风格编码迁移【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/014.html",{loader:()=>a.e(8617).then(a.bind(a,7801)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7ec38594-6a9f-469a-9515-cc2a8d4ae2f5/original=true,quality=90/42025535.jpeg" alt="封面源自C站作者Hannibal_Lecter" tabindex="0" loading="lazy"><figcaption>封面源自C站作者Hannibal_Lecter</figcaption></figure>\n<h2>摘要</h2>\n<p>本周聚焦生成式AI创新：MaterialAnything自动生成PBR材质；OminiControl为Diffusion模型提供通用轻量控制框架；FlipSketch生成草图动画。这些进步展示了生成式AI的迭代效率之高，其余内容详见正文。</p>',r:{minutes:7.46,words:2239},t:"MaterialAnything生成PBR材质|ConsisID优化ID视频生成|FlipSketch实现草图动画【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/015.html",{loader:()=>a.e(6226).then(a.bind(a,2958)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1c9c0f79-771e-4132-95a5-75f511af7850/width=450/43470959.jpeg" alt="封面源自C站作者navimixu" tabindex="0" loading="lazy"><figcaption>封面源自C站作者navimixu</figcaption></figure>\n<h2>摘要</h2>\n<p>本周聚焦生成式AI：TokenFlow提供多模态生成框架；NitroFusion实现一步图像生成；Imagine360支持全景内容创作；HunyuanVideo引领多模态视频生成；Art-Free-Diffusion打破风格限制。详见正文。</p>',r:{minutes:5.53,words:1660},t:"多模态理解与生成统一Token化框架|NitroFusion单步图像生成|Imagine360探索全景生成视频【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/016.html",{loader:()=>a.e(4171).then(a.bind(a,9182)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/49053226-463c-4b1a-ae6d-74e4079be9f0/width=450/44419355.jpeg" alt="封面源自C站作者tavoltennis837" tabindex="0" loading="lazy"><figcaption>封面源自C站作者tavoltennis837</figcaption></figure>\n<h2>摘要</h2>\n<p>本周聚焦生成与编辑：EasyRef 推出高效视频参考生成；SynCamMaster 实现多相机视角同步；StyleMaster 提供艺术风格视频转换；SwiftEdit 用单步扩散实现高速图像编辑，助力创意表达。详见正文。</p>',r:{minutes:4.48,words:1344},t:"EasyRef多模态高效图参考生成框架|SynCamMaster实现视角同步|SwiftEdit支持高速图像编辑【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/017.html",{loader:()=>a.e(2676).then(a.bind(a,2425)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/18c08401-31c6-4737-a8f6-cc937016cb91/original=true,quality=90/46150617.jpeg" alt="封面源自C站作者ShiroNekoAlpha" tabindex="0" loading="lazy"><figcaption>封面源自C站作者ShiroNekoAlpha</figcaption></figure>\n<h2>摘要</h2>\n<p>本周聚焦生成与编辑：AniDoc简化动画上色；ChatDiT聊天解决图像编辑；GenEx生成3D视频；DynamicControl加强图像生成控制，BrushEdit高效修复编辑图像。其余详见正文。</p>',r:{minutes:5.14,words:1543},t:"AniDoc简化动画上色||ChatDiT聊天解决图像编辑|GenEx生成3D视频【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/018.html",{loader:()=>a.e(9957).then(a.bind(a,7242)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b338b22c-394c-4ae0-88d2-2bf15fa83809/original=true,quality=90/47422369.jpeg" alt="封面源自C站作者Meower2024" tabindex="0" loading="lazy"><figcaption>封面源自C站作者Meower2024</figcaption></figure>\n<h2>摘要</h2>\n<p>本周聚焦大模型与多模态：Qwen2.5 优化预训练与后训练，定义多模态模型新标准；DeepSeek-V3 引入混合专家架构，提升训练效率；Mulberry 结合蒙特卡罗树搜索，增强推理与反思能力。详见正文。</p>',r:{minutes:6.01,words:1803},t:"Qwen2.5定义多模态模型新高度|DeepSeek-V3突破混合专家能力|Mulberry强化推理反思【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/019.html",{loader:()=>a.e(8078).then(a.bind(a,5072)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/151c21e5-8ab2-449b-a7b3-b315df75432e/original=true,quality=90/6GXND6WWA1T2KAEJE9AWEA47G0.jpeg" alt="封面源自C站作者Klasker2025" tabindex="0" loading="lazy"><figcaption>封面源自C站作者Klasker2025</figcaption></figure>\n<h2>摘要</h2>\n<p>本周重点：StoryWeaver提出Character Graph解决角色一致性与语义对齐问题；1.58bitFLUX极低比特量化FLUX；Orient-Anything实现零样本3D方向估计；Edicho推动一致性图像编辑。详情见正文。</p>',r:{minutes:5.45,words:1634},t:"StoryWeaver重塑视觉故事生成|Edicho实现一致性图像编辑|VideoAnyDoor增强视频对象插入【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/020.html",{loader:()=>a.e(3230).then(a.bind(a,3890)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/70d2b83a-dd62-4984-b15c-4150de0344ea/original=true,quality=90/49673554.jpeg" alt="封面源自C站作者martinffm_pg" tabindex="0" loading="lazy"><figcaption>封面源自C站作者martinffm_pg</figcaption></figure>\n<h2>摘要</h2>\n<p>本周亮点：AutoPresent提高幻灯片制作效率；ConceptMaster解耦多概念视频生成；Hallo3推动动态肖像动画；Cosmos引领物理AI开发；SPAR3D实现单图像3D重建；R3GAN推动GAN重回图像生成之巅。详情见正文。</p>',r:{minutes:5.84,words:1753},t:"AutoPresent提升幻灯片制作效率 | Hallo3实现动态肖像动画 | R3GAN媲美Diffusion模型【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/021.html",{loader:()=>a.e(277).then(a.bind(a,3749)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c6f924f2-97b3-45ab-94f6-0c29066798aa/anim=false,width=450/51311073.jpeg" alt="封面源自C站作者karlanan" tabindex="0" loading="lazy"><figcaption>封面源自C站作者karlanan</figcaption></figure>\n<h2>摘要</h2>\n<p>本周亮点：MiniMax-01采用Lightning Attention支持超长文本处理，提升多模态理解；Seaweed-APT通过对抗性后训练实现高分辨率视频的即时生成；AnyDressing利用定制化网络提供多服装虚拟试衣。详情见正文。</p>',r:{minutes:6.16,words:1848},t:"MiniMax-01扩展长文本处理|Seaweed-APT一步视频生成|AnyDressing个性化虚拟试衣【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/022.html",{loader:()=>a.e(4864).then(a.bind(a,6799)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5ea5d962-dcc2-4afe-983e-9b4eedb1f20d/original=true,quality=90/52768659.jpeg" alt="封面源自C站作者AIdaFONDA" tabindex="0" loading="lazy"><figcaption>封面源自C站作者AIdaFONDA</figcaption></figure>\n<h2>摘要</h2>\n<p>本周亮点：FilmAgent实现多智能体协作虚拟电影制作；DeepSeek-R1通过强化学习提升推理性能；EMO-2单图驱动数字人；PASA增强学术搜索效率；Textoon文本生成Live2D模型。详情见正文。</p>',r:{minutes:6.97,words:2092},t:"DeepSeek-R1定义强化学习推理|EMO2高效语音驱动数字|Textoon文本生成Live2D模型【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/023.html",{loader:()=>a.e(7959).then(a.bind(a,9527)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1b61e25e-d444-4ca5-9a95-4db03f2aafc8/anim=false,width=450/54073781.jpeg" alt="封面源自C站作者roxin282" tabindex="0" loading="lazy"><figcaption>封面源自C站作者roxin282</figcaption></figure>\n<h2>摘要</h2>\n<p>本周亮点：CatV2TON利用DiT统一视频虚拟试穿；Janus-Pro增强多模态理解生成；Baichuan-Omni-1.5开源全模态模型；Qwen2.5-1M突破128K长文本生成；AtlaAI提出小型语言模型评估器。详情见正文。</p>',r:{minutes:5.75,words:1724},t:"CatV2TON利用扩散Transformer实现虚拟试穿|Janus-Pro多模态理解与生成|Qwen2.5-1M扩展输入上限【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/024.html",{loader:()=>a.e(9098).then(a.bind(a,2525)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e958ef00-1183-47ee-91f5-c1f1023f08a3/anim=false,width=450/55557070.jpeg" alt="封面源自C站作者Clear_Note" tabindex="0" loading="lazy"><figcaption>封面源自C站作者Clear_Note</figcaption></figure>\n<h2>摘要</h2>\n<p>本周亮点：MILS展示了无需训练的多模态理解方法；LayerTracer通过DiT改进SVG生成；MakeAnything利用DiT优化程序化序列生成；OmniHuman生成高保真数字人视频；MatAnyone提供稳定的视频抠像方案；s1模型在推理任务中展现强劲实力。详情见正文。</p>',r:{minutes:5.75,words:1725},t:"MILS零训练多模态理解|LayerTracer优化SVG生成|OmniHuman高保真数字人【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/025.html",{loader:()=>a.e(1233).then(a.bind(a,5702)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f570fad2-1880-4978-a1cd-8f1e4e6e5494/original=true,quality=90/56995455.jpeg" alt="封面源自C站作者iviyaa" tabindex="0" loading="lazy"><figcaption>封面源自C站作者iviyaa</figcaption></figure>\n<h2>摘要</h2>\n<p>本周亮点：Whisk将概念嵌入场景并风格迁移；Zonos领先的开源文本转语音模型；Light-A-Video无需训练即可重光照视频；Goku 提供高效的视频生成方案；Data Formulator让数据可视化更智能。详情见正文。</p>',r:{minutes:5.84,words:1751},t:"Magic 1-For-1高效生成1分钟视频|Zonos最强开源文本转语音|Light-A-Video零样本重光照视频生成【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/026.html",{loader:()=>a.e(3500).then(a.bind(a,8624)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/caa2baeb-3ea6-4ff5-9cbb-24e61fc4157e/original=true,quality=90/58399173.jpeg" alt="封面源自C站作者PBtheCreator" tabindex="0" loading="lazy"><figcaption>封面源自C站作者PBtheCreator</figcaption></figure>\n<h2>摘要</h2>\n<p>本周亮点：Step-Video-T2V提升视频质量和一致性；YOLOv12在目标检测任务中提供更强推理能力和高精度；WHAM模型首次为游戏内容生成提供了创新性解决方案；Dynamic Concepts实现了跨模态的动态概念推理。详情见正文。</p>',r:{minutes:7.08,words:2125},t:"Step-Video-T2V文本到视频生成|YOLOv12目标检测优化|WHAM游戏内容生成【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/027.html",{loader:()=>a.e(1603).then(a.bind(a,6928)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9c4a95e1-b11d-4215-8948-5a4352700c60/original=true,quality=90/60618576.jpeg" alt="封面源自C站作者Koal2" tabindex="0" loading="lazy"><figcaption>封面源自C站作者Koal2</figcaption></figure>\n<h2>摘要</h2>\n<p>本周亮点：PhotoDoodle少样本艺术化图像编辑；Wan2.1优化资源高效生成视频；K-LoRA无训练融合增强风格适配；FractalGen利用分形生成复杂结构；KV-Edit精准保持背景编辑图像；GHOST 2.0提升头部替换保真度。</p>',r:{minutes:5.96,words:1788},t:"PhotoDoodle艺术化图像编辑|Wan2.1成为最新视频生成SOTA|FractalGen分形自回归生图【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/028.html",{loader:()=>a.e(7622).then(a.bind(a,4382)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ba745a8d-475e-4060-9590-870302076a56/original=true,quality=90/60528420.jpeg" alt="封面源自C站作者Qvoheu" tabindex="0" loading="lazy"><figcaption>封面源自C站作者Qvoheu</figcaption></figure>\n<h2>摘要</h2>\n<p>本周亮点：Attention Distillation基于扩散模型注意力机制实现精准风格迁移；微软Phi-4数学推理远超同类；EgoLife提出EgoGPT/EgoRAG，推进自我视角AI助手；HunyuanVideo-I2V优化图转视频。</p>',r:{minutes:5.85,words:1756},t:"Attention Distillation精准风格迁移 | Phi-4数学推理登顶 | EgoLife自我视角AI助手【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/029.html",{loader:()=>a.e(7549).then(a.bind(a,1242)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/271d5fc4-6d65-4e6d-ab43-30b3e253eb46/original=true,quality=90/00053-3724718039.jpeg" alt="封面源自C站作者AmberFog" tabindex="0" loading="lazy"><figcaption>封面源自C站作者AmberFog</figcaption></figure>\n<h2>摘要</h2>\n<p>本周亮点：YuE 基于 LLaMA2 架构，实现长篇 AI 音乐创作与风格转换；VACE 采用 Video Condition Unit，统一视频生成与编辑任务；VideoPainter 提出双分支框架，提升视频修复质量与身份一致性；ConsisLoRA 解决 LoRA 风格迁移中的一致性问题。</p>',r:{minutes:7.68,words:2305},t:"YuE赋能长篇AI音乐创作|VACE统一视频编辑|MagicInfinite无限制视频生成【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/030.html",{loader:()=>a.e(5483).then(a.bind(a,840)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0f0f3d34-216b-4954-bede-82cc10657d8d/original=true,quality=90/00178-3302738830-masterpiece, best quality, good quality, very aesthetic, absurdres, newest, 8K, depth of field, focused subject, dynamic ange, w.jpeg" alt="封面源自C站作者Koal2" tabindex="0" loading="lazy"><figcaption>封面源自C站作者Koal2</figcaption></figure>',r:{minutes:6.14,words:1841},t:"ReCamMaster重塑视频视角 | PLADIS优化Diffusion推理 | Impossible Videos探索反现实【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/031.html",{loader:()=>a.e(3668).then(a.bind(a,8609)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9469f5ed-e000-4aeb-ab93-4b40865a7c7b/original=true,quality=90/00320-919909395-1girl, hatsune_miku, lips, thin lips, parted lips, solo, looking at viewer, camisole, upper body, dark, underlightling, masterpi.jpeg" alt="封面源自C站作者Koal2" tabindex="0" loading="lazy"><figcaption>封面源自C站作者Koal2</figcaption></figure>',r:{minutes:7.57,words:2270},t:"Conceptrol精准概念控制 | ChatAnyone实时数字人|Lumina-Image 2.0突【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/032.html",{loader:()=>a.e(3161).then(a.bind(a,9307)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/43d1dfeb-a0bc-4d38-a7d5-2694070fac43/original=true,quality=90/00687-2746924664-vaporwave" alt="封面源自C站作者Koal2" tabindex="0" loading="lazy"><figcaption>封面源自C站作者Koal2</figcaption></figure>\n<h2>摘要</h2>\n<p>本周亮点：TextCrafter精准渲染文本；MoCha推出电影级角色合成；Any2Caption增强视频生成；AnimeGamer实现动漫生活模拟；ACTalker多模态音视频生成；OpenDeepSearch赋能搜索AI。其余详见正文。</p>',r:{minutes:7.34,words:2202},t:"TextCrafter精准文本渲染|MoCha电影级角色合成|AnimeGamer动漫生活模拟【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/033.html",{loader:()=>a.e(3842).then(a.bind(a,9444)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7ca09232-41e5-47f6-a2dc-39eb85b35853/original=true,quality=90/00883-3137192565-masterpiece" alt="封面源自C站作者Koal2" tabindex="0" loading="lazy"><figcaption>封面源自C站作者Koal2</figcaption></figure>\n<h2>摘要</h2>\n<p>本周亮点：OmniCaptioner实现跨视觉域语言描述；UNO统一个性化定制多主体生成；SPF-Portrait解决语义污染；FantasyTalking生成音频驱动数字人；SmolVLM2发布轻量级视频理解模型。其余详见正文。</p>',r:{minutes:7.48,words:2245},t:"OmniCaptioner统一视觉描述 | UNO多主体定制 | SPF-Portrait消除污染提升肖像定制【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/034.html",{loader:()=>a.e(1551).then(a.bind(a,3881)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/781e2f08-150f-4ce9-8cfe-0b9865785381/original=true,quality=90/00021-2797360292.jpeg" alt="封面源自C站作者Koal2" tabindex="0" loading="lazy"><figcaption>封面源自C站作者Koal2</figcaption></figure>\n<h2>摘要</h2>\n<p>本周亮点：HiDream-I1 发布17B参数基础模型，支持多风格图像生成；Cobra 引入稀疏DiT，支持200+图像指导漫画上色；InstantCharacter 结合视觉编码与适配器结构，实现灵活角色定制。其余详见正文。</p>',r:{minutes:6.32,words:1895},t:"HiDream-I1引领图像生成 | Cobra支持海量上色参考 | InstantCharacter高效定制角色【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/035.html",{loader:()=>a.e(6712).then(a.bind(a,6002)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cc9b2c75-69a4-4156-88c6-4a3ba910cff8/width=800,original=false/01145-1691900756-masterpiece,best quality,amazing quality,ultra high res,_kanna kamui,silver dragon horns,_bioluminescent scales,blue sailor unif.jpeg" alt="封面源自C站作者Koal2" tabindex="0" loading="lazy"><figcaption>封面源自C站作者Koal2</figcaption></figure>',r:{minutes:6.01,words:1802},t:"FramePack压缩加速视频生成 | Step1X-Edit开源高质量图像编辑 | DreamID高保真换脸【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/036.html",{loader:()=>a.e(5021).then(a.bind(a,745)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/44cb3616-4cff-4dea-bcb6-caeedb99ceeb/original=true,quality=90/73901561.jpeg" alt="封面源自C站作者Koal2" tabindex="0" loading="lazy"><figcaption>封面源自C站作者Koal2</figcaption></figure>\n<h2>摘要</h2>\n<p>本周亮点：ColorizeDiffusion v2 提升动漫草图上色质量；RepText 实现多语言文本渲染；ICEdit 多视角保持身份一致性编辑；Insert Anything 灵活插入任意物体；Nexus-Gen 融合 LLM 与扩散模型统一生成流程；X-Fusion 实现多任务图文对齐能力。</p>',r:{minutes:6.26,words:1878},t:"ColorizeDiffusion v2实现最强动漫草图上色 | RepText 多语言文本渲染 | Nexus-Gen 图像生成统一模型【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/037.html",{loader:()=>a.e(8566).then(a.bind(a,7551)),meta:{e:'\n<figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/44cb3616-4cff-4dea-bcb6-caeedb99ceeb/original=true,quality=90/73901561.jpeg" alt="封面源自C站作者Koal2" tabindex="0" loading="lazy"><figcaption>封面源自C站作者Koal2</figcaption></figure>\n<h2>摘要</h2>\n<p>本周亮点：PixelHacker引入语义结构引导，提升图像修复质量；Voila实现低延迟情感语音交互；LegoGPT从文本生成稳定LEGO结构；HunyuanCustom支持多模态视频定制；SOAP实现单图3D头像建模与动画控制。其余详见正文。</p>',r:{minutes:7.12,words:2136},t:"PixelHacker图像修复新突破 | Voila开源语音大模型 | LegoGPT生成可搭建乐高积木【AI周报】",y:"a"}}],["/zh/posts/ai-weekly/X01.html",{loader:()=>a.e(9959).then(a.bind(a,9256)),meta:{e:'\n<p><strong>作者</strong>：hzwer(黄哲威), DingXiaoH(丁霄汉)</p>\n<p><a href="https://drive.google.com/file/d/1hbQ8qvVPUndNRSwK2Hq6wLwh8sxapi95/view?usp=sharing" target="_blank" rel="noopener noreferrer">PDF 下载</a> | <a href="https://github.com/hzwer/AIPaperWriting" target="_blank" rel="noopener noreferrer">GitHub 页面</a> | 知乎讨论：<a href="https://zhuanlan.zhihu.com/p/593195527" target="_blank" rel="noopener noreferrer">1</a>-<a href="https://zhuanlan.zhihu.com/p/639732057" target="_blank" rel="noopener noreferrer">2</a>-<a href="https://zhuanlan.zhihu.com/p/627032371" target="_blank" rel="noopener noreferrer">3</a> ｜<a href="https://yuewen.cn/share/145749938443137024?utm_source=share&amp;utm_content=web_linkcopy&amp;version=2" target="_blank" rel="noopener noreferrer">跃问翻译</a> | <a href="https://www.doubao.com/chat/" target="_blank" rel="noopener noreferrer">豆包</a></p>',r:{minutes:15.36,words:4609},t:"AI 会议论文写作完全指南：从零开始构建高质量论文",y:"a"}}],["/zh/posts/dairys/250222.html",{loader:()=>a.e(5871).then(a.bind(a,3467)),meta:{a:"学生小陈",d:17401824e5,l:"2025年2月22日",c:["日记"],g:["随想","开源","大会","实习"],u:!0,v:"/assets/images/dairys/250222/GDC-Cover.jpeg",e:'<h2>介绍</h2>\n<p>今天去参加了在徐汇西岸召开的2025GDC大会（Global Developer Conference），中文名叫全球开发者先锋大会，TA的官方介绍如下：\n今年的主题是”模塑全球 无限可能“，围绕大模型，结合了<strong>算力</strong>、语料、基金等要素，聚焦具身智能、无人驾驶和科学智能等五大领域，及金融、医疗、智能制造等六大行业，做厚产业生态；以”社区的社区“为基础，打造高创新浓度、高创业热度、高人才密度的开发者生态。</p>\n<h2>内容</h2>\n<p><img src="/assets/images/dairys/250222/人形机器人.jpeg" alt="人形机器人" width="300" height="400" loading="lazy">\n<img src="/assets/images/dairys/250222/宇树机器人1.jpeg" alt="宇树机器人" width="300" height="400" loading="lazy">\n<img src="/assets/images/dairys/250222/智元机器人.jpeg" alt="智元机器人" width="300" height="400" loading="lazy"></p>',r:{minutes:9.03,words:2708},t:"参加GDC大会有感",i:"openmoji:code-editor",O:1,y:"a"}}],["/zh/posts/dairys/250223.html",{loader:()=>a.e(2360).then(a.bind(a,4656)),meta:{a:"非厨",d:17402688e5,l:"2025年2月23日",c:["日记"],g:["随想","做饭","公众号"],u:!0,v:"/assets/images/dairys/250223/食材.jpeg =400x300",e:'<h2>早上</h2>\n<p>9点多，自然醒吧，感觉现在睡7个小时就已经开始做梦了，非常浅的睡眠，于是就还是早起了点。起床之后的习惯还是不好，开始躺在床上刷短视频和打游戏。点了个叮咚买菜，玩到差不多11点多才下床拿我的菜。</p>\n<h2>中午</h2>\n<p><img src="/assets/images/dairys/250223/青椒丝.jpeg" alt="青椒丝" width="300" height="400" loading="lazy">\n<img src="/assets/images/dairys/250223/备菜.jpeg" alt="备菜" width="400" height="300" loading="lazy"></p>',r:{minutes:3.69,words:1108},t:"闲暇的周日",i:"twemoji:bell-pepper",O:2,y:"a"}}],["/zh/posts/papers/3steps-paper-reading.html",{loader:()=>a.e(887).then(a.bind(a,5814)),meta:{e:'\n<figure><img src="https://fastly.jsdelivr.net/gh/bucketio/img13@main/2025/01/15/1736921821494-d69f9ea8-0882-40c3-a3fa-70760d09dda5.png" alt="Teaser" tabindex="0" loading="lazy"><figcaption>Teaser</figcaption></figure>\n<h2>摘要</h2>\n<p>论文阅读是学术研究的核心技能。本文结合李沐与吴恩达的经验，详细总结了三步法读论文的技巧：快速筛选、全面了解、深入精读，帮助研究者高效筛选和深度理解文献内容，从而提升科研效率，掌握核心知识点。</p>',r:{minutes:3.43,words:1029},t:"【高效科研】李沐与吴恩达推荐的论文三步精读法",y:"a"}}],["/zh/posts/papers/alexnet.html",{loader:()=>a.e(9838).then(a.bind(a,9329)),meta:{e:'\n<figure><img src="https://faych.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F021ded55-a224-419c-939c-70c6888912f7%2F983b058d-48a2-4e90-8cf8-76d44a179591%2Fteaser.png?table=block&amp;id=1845f3c4-a139-8098-b059-d2ef2d3cd9f9&amp;spaceId=021ded55-a224-419c-939c-70c6888912f7&amp;width=1420&amp;userId=&amp;cache=v2" alt="teaser" tabindex="0" loading="lazy"><figcaption>teaser</figcaption></figure>',r:{minutes:6.25,words:1876},t:"【论文精读】AlexNet：ImageNet Classification with Deep Convolutional Neural Networks",y:"a"}}],["/zh/posts/papers/colorizediffusion.html",{loader:()=>a.e(2175).then(a.bind(a,5681)),meta:{e:'\n<figure><img src="https://arxiv.org/html/2401.01456v3/x1.png" alt="ColorizeDiffusion Teaser" tabindex="0" loading="lazy"><figcaption>ColorizeDiffusion Teaser</figcaption></figure>\n<h2>摘要</h2>\n<p>ColorizeDiffusion由东京工业大学研究团队提出，旨在解决草图上色中的"分布问题"——参考图像与草图结构的平衡困境。基于扩散模型，该方法通过三种创新训练策略和零样本文本调控，实现精确可控的上色效果，支持动漫/漫画风格创作。</p>',r:{minutes:8.33,words:2499},t:"【论文精读】ColorizeDiffusion：基于参考图像和文本的可调整草图上色方法",y:"a"}}],["/zh/posts/papers/framepack.html",{loader:()=>a.e(6645).then(a.bind(a,8700)),meta:{a:"Lvmin Zhang, Maneesh Agrawala",d:17456256e5,l:"2025年4月26日",c:["视频生成","论文精读","张吕敏"],g:["FramePack","视频生成","扩散模型","输入预处理"],v:"/assets/images/papers/framepack/teaser.png",e:'\n<p align="center">\n        <img src="https://lllyasviel.github.io/frame_pack_gitpage/img/logo.png" width="200">\n</p>\n<h2>摘要</h2>\n<p>FramePack由斯坦福大学张吕敏等提出，是一种输入预处理模块，可无缝集成到主流视频扩散模型（如混元视频模型），通过自适应帧压缩和反漂移采样，有效提升长时序一致性和生成质量，支持13B模型在6GB显存上流畅生成长视频，显著降低算力门槛。</p>\n<hr>\n<h2>目录</h2>\n<ol>\n<li><a href="#%E8%83%8C%E6%99%AF%E4%B8%8E%E7%A0%94%E7%A9%B6%E7%9B%AE%E6%A0%87">背景与研究目标</a></li>\n<li><a href="#%E6%96%B9%E6%B3%95%E4%B8%8E%E5%88%9B%E6%96%B0%E7%82%B9">方法与创新点</a></li>\n<li><a href="#%E5%AE%9E%E9%AA%8C%E4%B8%8E%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90">实验与结果分析</a></li>\n<li><a href="#%E6%A8%A1%E5%9E%8B%E5%90%AF%E5%8F%91%E4%B8%8E%E6%96%B9%E6%B3%95%E5%BB%B6%E4%BC%B8">模型启发与方法延伸</a></li>\n<li><a href="#%E7%BB%93%E8%AE%BA%E4%B8%8E%E6%9C%AA%E6%9D%A5%E5%B1%95%E6%9C%9B">结论与未来展望</a></li>\n</ol>',r:{minutes:6.22,words:1865},t:"【论文精读】FramePack：在下一帧预测视频生成模型中打包输入帧上下文",i:"material-symbols:screenshot-frame-2",y:"a"}}],["/zh/posts/papers/hunyuancustom.html",{loader:()=>a.e(6776).then(a.bind(a,9812)),meta:{e:'\n<h2>摘要</h2>\n<p>腾讯提出的HunyuanCustom框架解决视频定制化生成中的身份一致性问题，通过图像ID增强与文本-图像融合技术，实现多模态控制(文本、图像、音频、视频)下的身份保持，支持虚拟人物广告、试穿和视频编辑等多种应用场景。</p>\n<figure><img src="https://arxiv.org/html/2505.04512v1/x1.png" alt="混元定制化支持多种输入模态的视频生成，包括文本、图像、音频和视频条件" tabindex="0" loading="lazy"><figcaption>混元定制化支持多种输入模态的视频生成，包括文本、图像、音频和视频条件</figcaption></figure>',r:{minutes:7.38,words:2214},t:"【论文精读】HunyuanCustom：多模态驱动的定制视频生成架构",y:"a"}}],["/zh/posts/papers/icedit.html",{loader:()=>a.e(1001).then(a.bind(a,1450)),meta:{e:'\n<figure><img src="https://github.com/River-Zhang/ICEdit/raw/main/docs/images/teaser.png" alt="ICEdit多轮编辑示例" tabindex="0" loading="lazy"><figcaption>ICEdit多轮编辑示例</figcaption></figure>\n<h2>摘要</h2>\n<p>ICEdit 基于大规模 Diffusion Transformer，提出 in-context 编辑、LoRA-MoE 微调和 Early Filter 策略，实现高效高质的指令图像编辑。仅用极少数据和参数即超越 SOTA，具备强泛化与实际应用潜力。</p>',r:{minutes:5.99,words:1797},t:"【论文精读】ICEdit：In-Context Edit——大规模扩散Transformer的指令图像编辑新范式",y:"a"}}],["/zh/posts/papers/reptext.html",{loader:()=>a.e(121).then(a.bind(a,2584)),meta:{e:'\n<figure><img src="https://github.com/Shakker-Labs/RepText/raw/main/assets/teaser.png" alt="RepText Teaser" tabindex="0" loading="lazy"><figcaption>RepText Teaser</figcaption></figure>\n<h2>摘要</h2>\n<p>RepText 由 Shakker Labs 提出，通过“复制”视觉元素（glyph latent）实现多语言高质量文本渲染，无需语义理解。基于 ControlNet，支持灵活控制字体、颜色和位置，兼容性强，资源消耗低，效果接近闭源大模型。</p>',r:{minutes:6.36,words:1909},t:"【论文精读】RepText：通过复制实现视觉文本渲染",y:"a"}}],["/zh/posts/papers/resnet.html",{loader:()=>a.e(4960).then(a.bind(a,3716)),meta:{e:'\n<h2>摘要</h2>\n<p>ResNet 通过残差学习成功解决超深网络的训练难题，克服梯度消失与退化问题。在 ImageNet 分类任务中以 3.57% Top-5 错误率刷新纪录，并在目标检测、分割等任务中展现卓越性能。本文解析其核心设计、实验验证及影响。</p>\n<hr>\n<h2>目录</h2>\n<ol>\n<li><a href="#%E8%83%8C%E6%99%AF%E4%B8%8E%E7%A0%94%E7%A9%B6%E7%9B%AE%E6%A0%87">背景与研究目标</a></li>\n<li><a href="#%E6%96%B9%E6%B3%95%E4%B8%8E%E5%88%9B%E6%96%B0%E7%82%B9">方法与创新点</a></li>\n<li><a href="#%E5%AE%9E%E9%AA%8C%E4%B8%8E%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90">实验与结果分析</a></li>\n<li><a href="#%E6%A8%A1%E5%9E%8B%E5%90%AF%E5%8F%91%E4%B8%8E%E6%96%B9%E6%B3%95%E5%BB%B6%E4%BC%B8">模型启发与方法延伸</a></li>\n<li><a href="#%E7%BB%93%E8%AE%BA%E4%B8%8E%E6%9C%AA%E6%9D%A5%E5%B1%95%E6%9C%9B">结论与未来展望</a></li>\n</ol>',r:{minutes:6.51,words:1953},t:"【论文精读】ResNet：Deep Residual Learning for Image Recognition",y:"a"}}],["/zh/posts/papers/transformer.html",{loader:()=>a.e(5822).then(a.bind(a,3637)),meta:{e:'\n<h2>摘要</h2>\n<p>Transformer 由 Vaswani 等人于 2017 年提出，首次完全基于自注意力机制（Self-Attention）实现序列建模，摒弃了 RNN/CNN 结构。该模型极大提升了并行效率和长距离依赖建模能力，成为 NLP、CV 等多模态领域的基础架构。论文提出的多头注意力、位置编码等机制，推动了大模型和生成式 AI 的快速发展。</p>\n<hr>\n<h2>目录</h2>\n<ol>\n<li><a href="#%E8%83%8C%E6%99%AF%E4%B8%8E%E7%A0%94%E7%A9%B6%E7%9B%AE%E6%A0%87">背景与研究目标</a></li>\n<li><a href="#%E6%96%B9%E6%B3%95%E4%B8%8E%E5%88%9B%E6%96%B0%E7%82%B9">方法与创新点</a></li>\n<li><a href="#%E5%AE%9E%E9%AA%8C%E4%B8%8E%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90">实验与结果分析</a></li>\n<li><a href="#%E6%A8%A1%E5%9E%8B%E5%90%AF%E5%8F%91%E4%B8%8E%E6%96%B9%E6%B3%95%E5%BB%B6%E4%BC%B8">模型启发与方法延伸</a></li>\n<li><a href="#%E7%BB%93%E8%AE%BA%E4%B8%8E%E6%9C%AA%E6%9D%A5%E5%B1%95%E6%9C%9B">结论与未来展望</a></li>\n</ol>',r:{minutes:6.29,words:1887},t:"【论文精读】Transformer：Attention Is All You Need",y:"a"}}],["/zh/posts/reprints/ai-art-newsletter-jan-25.html",{loader:()=>a.e(9803).then(a.bind(a,7881)),meta:{e:'\n<h3>创刊号 🎉</h3>\n<p>AI 领域的发展速度令人惊叹，回想一年前我们还在为生成正确手指数量的人像而苦苦挣扎的场景，恍如隔世 😂。</p>\n<p>过去两年对开源模型和艺术创作工具而言具有里程碑意义。创意表达的 AI 工具从未像现在这般触手可及，然而这仅仅是冰山一角。让我们共同回顾 2024 年 AI 艺术领域的关键突破与创新工具，并展望 2025 年的发展趋势。</p>\n<h2>目录</h2>\n<ul>\n<li><a href="#2024-%E9%87%8D%E5%A4%A7%E5%8F%91%E5%B8%83">2024 重大发布</a></li>\n<li><a href="#%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90">图像生成</a>\n<ul>\n<li><a href="#%E6%96%87%E7%94%9F%E5%9B%BE">文生图</a></li>\n<li><a href="#%E4%B8%AA%E6%80%A7%E5%8C%96%E4%B8%8E%E9%A3%8E%E6%A0%BC%E5%8C%96">个性化与风格化</a></li>\n</ul>\n</li>\n<li><a href="#%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90">视频生成</a></li>\n<li><a href="#2024-%E9%97%AA%E8%80%80%E5%88%9B%E6%84%8F%E5%B7%A5%E5%85%B7">2024 闪耀创意工具</a></li>\n<li><a href="#2025-%E5%B9%B4-AI-%E8%89%BA%E6%9C%AF%E8%B6%8B%E5%8A%BF%E5%B1%95%E6%9C%9B">2025 年 AI 艺术趋势展望</a></li>\n<li><a href="#%E5%BC%BA%E5%8A%BF%E5%BC%80%E5%B1%80-2025-%E5%B9%B4-1-%E6%9C%88%E5%BC%80%E6%BA%90%E6%96%B0%E4%BD%9C">强势开局: 2025 年 1 月开源新作</a></li>\n</ul>',r:{minutes:8.03,words:2408},t:"AI艺术工具通讯 - 第1期",y:"a"}}],["/zh/posts/reprints/crody's-model-merge-guide.html",{loader:()=>a.e(312).then(a.bind(a,4416)),meta:{a:"Crody",d:17419104e5,l:"2025年3月14日",g:["resource guide","script","stable diffusion","merge","model"],v:"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2d3f67d3-4906-46b0-b27c-63ba7376cca7/width=1320/00000_2500974118.jpeg",e:"<p>Hi this is Crody from Team-C: creator of Nova Series</p>\n<p>In this article, I'll write down what kind of merge I use with some knowledge about SDXL models\nFor how I do, please read Merge Scripter Guide first</p>\n<h2>1. Weighted Sum / Sum Twice</h2>\n<p>Weighted Sum (WS) merges 2 models, Sum Twice (ST) merges first 2 and 1 model (which means doing WS twice)\nYou can use Block Merge as well\nUsing alpha (and beta) to determine how much similarity the result have\nHigher value means the results would be similar to latter model</p>",r:{minutes:5.58,words:1674},t:"Crody's Model Merge Guide // Team-C",y:"a"}}],["/zh/posts/reprints/experiments-with-mcp-using-github-copilot.html",{loader:()=>a.e(8275).then(a.bind(a,3865)),meta:{a:"kcon",d:1742256e6,l:"2025年3月18日",g:["编辑器","模型上下文协议","技术"],e:'\n<h2>概述</h2>\n<p>本文描述了如何在 VS Code 中安装 "Copilot MCP" 扩展，并结合 MCP 使用 GitHub Copilot 从 GitHub 获取信息进行测试。<br>\n注意：由于官方 GitHub Copilot 实现似乎也支持 MCP，一旦该功能发布，此扩展可能将不再必要。</p>\n<h2>测试环境</h2>\n<ul>\n<li>Windows 10 Pro</li>\n<li>VS Code</li>\n</ul>\n<h2>准备工作</h2>\n<p>请提前确保以下事项：</p>\n<ul>\n<li>安装 node.js\n<ul>\n<li>必须可以使用 <code>npm</code> 和 <code>npx</code> 命令</li>\n</ul>\n</li>\n<li>创建 GitHub 账户</li>\n</ul>',r:{minutes:2.24,words:672},t:"使用 GitHub Copilot 进行 MCP 实验",y:"a"}}],["/zh/posts/reprints/explaining-tokens-the-language-and-currency-of-ai-nvidia-blog.html",{loader:()=>a.e(2592).then(a.bind(a,5431)),meta:{a:"Dave Salvator",d:17421696e5,l:"2025年3月17日",c:["Explainer","Generative AI"],g:["Artificial Intelligence","Inference"],v:"https://blogs.nvidia.com/wp-content/uploads/2025/03/llm-blog-data-curator-2847806-1280x680-1.png",e:'\n<figure><img src="https://blogs.nvidia.com/wp-content/uploads/2025/03/llm-blog-data-curator-2847806-1280x680-1.png" alt="图1：大型语言模型处理数据的描述" tabindex="0" loading="lazy"><figcaption>图1：大型语言模型处理数据的描述</figcaption></figure>\n<p>在每个AI应用程序的底层，都有算法在以自己的语言处理数据，这种语言基于token词汇。</p>\n<p>token是通过分解更大信息块而来的微小数据单元。AI模型处理token以学习它们之间的关系，并解锁包括预测、生成和推理在内的能力。token处理得越快，模型学习和响应的速度就越快。</p>',r:{minutes:8.16,words:2449},t:"解释token— AI的语言和货币 | NVIDIA博客",y:"a"}}],["/zh/posts/reprints/generative-ai-powered-design.html",{loader:()=>a.e(16).then(a.bind(a,6636)),meta:{a:"Isha Dua & Parth Patel",d:17423424e5,l:"2025年3月19日",c:["转载"],g:["生成式AI","游戏开发","Stable Diffusion","图像生成","AWS","Amazon Bedrock"],u:!1,v:"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/03/19/Picture1-11.jpg",e:"<p>在竞争激烈的游戏开发世界中，紧跟技术进步至关重要。生成式AI已经成为游戏规则的改变者，为游戏设计师提供了前所未有的机会，使他们能够突破界限并创造身临其境的虚拟世界。在这场革命的前沿是Stability AI的尖端文本到图像AI模型——Stable Diffusion 3.5 Large (SD3.5 Large)，它正在彻底改变我们创建游戏环境的方式。</p>\n<p>SD3.5 Large可在Amazon Bedrock上使用，是Stability AI迄今为止最先进的文本到图像模型。拥有81亿参数，该模型擅长从文本描述生成高质量的百万像素图像，具有卓越的提示符合性，使其成为快速创建详细游戏环境的理想选择。其改进的架构基于多模态扩散变换器(MMDiT)，结合多个预训练文本编码器以增强文本理解能力，并使用QK归一化来提高训练稳定性。</p>",r:{minutes:7.64,words:2291},t:"生成式AI驱动的设计：使用SD3.5 Large创建游戏环境",i:"openmoji:video-game",O:1,y:"a"}}],["/zh/posts/reprints/illustrious-lu-v0.03.html",{loader:()=>a.e(8808).then(a.bind(a,540)),meta:{a:"Angelbottomless",d:17449344e5,l:"2025年4月18日",c:["模型开发","转载"],g:["Illustrious","LU","Lumina","AI模型","图像生成","训练"],v:"https://illustrious-prod.s3.ap-northeast-2.amazonaws.com/blog/2025-04-11T07:16:56.712Z/2025-04-11%20Thumbnail.png",e:'\n<p>SD XL 一直受到 CLIP 的困扰--我认为至少这部分是事实。最近的模型在自然语言方面显示出一些潜力，比如理解"左边是红色，右边是蓝色"。然而，由于CLIP没有使用自然语言句子进行训练，基础SD XL及其微调变体在处理自然语言方面受到了显著限制。</p>\n<p>Flux和SD3等DiT模型与T5结合表现出更好的能力。特别是，已经证明T5在处理自然语言信息以正确生成文本或组合方面非常重要。然而，T5 非常大而且仍然有限，因此有人尝试直接使用 LLM 作为文本编码器。此外，DiT模型也非常庞大。即使没有T5，12B参数的模型也不太实用，这一点与SD XL非常相似。</p>\n<p>流匹配（Flow matching）也很有趣。然而，DiT 的直观结构似乎不可避免地促成了许多有用的研究。不幸的是，与SD XL结合的流匹配并未显示支持这一点的证据；相反，它引发了更多关于SD XL的VAE问题的疑问。</p>',r:{minutes:4.08,words:1225},t:"Illustrious-LU v0.03",i:"fa-solid:microscope",y:"a"}}],["/zh/posts/reprints/illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language.html",{loader:()=>a.e(4829).then(a.bind(a,1118)),meta:{a:"Angelbottomless",d:17426016e5,l:"2025年3月22日",c:["Model Development","Model Training","Image Generation","Anime Style"],g:["SDXL","2048分辨率","Illustrious","vpred","epsilon预测"],v:"/assets/images/reprints/illustrious/v3.0-3.5/thumbnail.webp",e:'\n<p>Illustrious XL 3.0-3.5-vpred 标志着 Stable Diffusion XL（SD XL）模型的一项重大进展，显著支持从 256 到 2048 分辨率的无缝扩展。特别是 v3.5-vpred 变体，在自然语言理解能力上达到了类似于迷你大型语言模型（LLMs）的精细程度，这是通过对 CLIP 与 UNet 组件的广泛同时训练实现的。</p>\n<h2>训练目标与概述：eps 与 vpred</h2>\n<p>Illustrious v3.0-v3.5 系列设计了两种不同的训练目标以探索行为差异：</p>\n<ul>\n<li>\n<p><strong>V3.0-epsilon</strong> 使用 epsilon 预测（噪声预测），确立了作为未来训练任务（尤其是与 LoRA 训练兼容）稳定"基底"模型的地位。该模型在默认状态下输出的风格较 vpred 变体更具特色，在某些美学评分中有时表现最佳。</p>\n</li>\n<li>\n<p><strong>V3.0-vpred</strong> 则采用 velocity 预测（v 参数化），展示出更强的组合理解能力，但最初伴随着严重问题，包括灾难性遗忘、领域偏移、颜色过饱和以及因零终端 SNR（Zero Terminal SNR）实现失误而导致的色板崩溃。</p>\n</li>\n<li>\n<p><strong>V3.5-vpred</strong> 则在实验性设置下训练，试图缓解上述问题。该模型显示出颜色更稳定，但并不天然生成鲜艳色彩，其功能已转移至特定的控制令牌（controlling tokens）。</p>\n</li>\n</ul>',r:{minutes:13.4,words:4019},t:"Illustrious XL 3.0-3.5-vpred: 2048分辨率与自然语言",i:"mdi:paint-outline",y:"a"}}],["/zh/posts/reprints/illustrious-xl-v2.0-the-best-training-base-model-in-1536-age.html",{loader:()=>a.e(5404).then(a.bind(a,4602)),meta:{a:"Angelbottomless",d:17419968e5,l:"2025年3月15日",c:["模型研发","模型训练","图像生成","动漫风格"],g:["SDXL","动漫","Illustrious","基础模型","图像生成"],v:"/assets/images/reprints/illustrious/v2.0-2.0a/thumbnail.webp",e:'\n<h2>简介</h2>\n<p>Illustrious XL 1.0-2.0系列旨在稳定1536分辨率的原生生成，同时显著提高自然语言理解能力。</p>\n<p>虽然用户有时会观察到在1024x1536分辨率下能成功生成，但这些并不稳定。同样，512x512分辨率的生成偶尔也会产生不必要的伪影。</p>\n<h2>早期版本为何不稳定？</h2>\n<p>这些不一致的根本原因很简单：模型未在这些分辨率上进行有效泛化或训练。使用小数据集填补这些空白往往会导致在某些分辨率上过拟合。这意味着模型会将特定分辨率与特定概念关联起来，使其在多样化生成时变得不可靠。</p>\n<p>一个有用的比喻是"广角效果"。如果数据集通常包含广角镜头，当给定广角分辨率时，模型自然会生成更小的人物，因为这是它学习泛化的方式。</p>',r:{minutes:5.3,words:1589},t:"Illustrious XL v2.0：1536分辨率时代最佳的训练基础模型",i:"mdi:paint-outline",y:"a"}}],["/zh/posts/reprints/mcp-flash-in-the-pan-or-future-standard.html",{loader:()=>a.e(1008).then(a.bind(a,7822)),meta:{a:"Harrison Chase & Nuno Campos",d:17145216e5,l:"2024年5月1日",c:["转载"],g:["AI","LLM","协议","辩论"],u:!1,v:"/assets/images/reprint/mcp-debate-cover.jpeg",e:"\n<p>Model Context Protocol (MCP) 在Twitter上引起了轩然大波——但它真的有用，还是只是噪音？在这场辩论中，Harrison Chase（LangChain CEO）和Nuno Campos（LangGraph负责人）讨论了MCP是否名副其实。</p>\n<h2>Harrison的观点：MCP确实有用</h2>\n<p>我一开始对MCP持怀疑态度，但我已经开始看到它的价值。本质上：<strong>当你想为自己无法控制的agent添加工具时，MCP就很有用</strong>。</p>\n<p>举个例子。对于Claude Desktop、Cursor、Windsurf这些应用，作为用户，我无法控制底层agent。这些agent默认只能访问几个内置工具。</p>",r:{minutes:6.47,words:1942},t:"MCP：昙花一现还是未来标准？",i:"openmoji:code-editor",O:1,y:"a"}}],["/zh/posts/reprints/niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything.html",{loader:()=>a.e(2869).then(a.bind(a,4037)),meta:{a:"niji・journey",d:16898976e5,l:"2023年7月21日",c:["reprints"],g:["Art","Drawing","Fundamentals","niji"],u:!1,v:"/assets/images/reprints/nijijourney/lesson1/thumb.webp",e:'\n<p>在本课程中，我们不会专注于如何绘制特定主题，而是教你如何在niji的帮助下自学成才。</p>\n<p>相关练习请参见 <a href="https://nijijourney.com/blog/niji-study-1-Measuring-With-Your-Eyes" target="_blank" rel="noopener noreferrer">📏 练习1：用眼睛测量</a>。</p>\n<h2>美的理论基础</h2>\n<p>我人生的大部分时间都困在这两类图像之间的鸿沟里。</p>\n<figure><img src="/assets/images/reprints/nijijourney/lesson1/4942dc04-f4f6-415f-b85f-91ecf5703d9a.jpeg" alt="动漫风格的女孩" tabindex="0" loading="lazy"><figcaption>动漫风格的女孩</figcaption></figure>',r:{minutes:8.03,words:2410},t:"第一课：测量与抽象的基础：绘画的普遍理论",i:"palette",O:1,y:"a"}}],["/zh/posts/reprints/niji-study-1-measuring-with-your-eyes.html",{loader:()=>a.e(7597).then(a.bind(a,8102)),meta:{a:"niji・journey",d:16898976e5,l:"2023年7月21日",c:["reprints"],g:["Art","Drawing","Fundamentals","niji"],u:!1,v:"/assets/images/reprints/nijijourney/study1/thumb.webp",e:'\n<p><a href="/zh/posts/reprints/niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything">上一课：测量与抽象的基础：绘画的普遍理论</a> | <a href="https://nijijourney.com/blog/niji-study-2-notan" target="_blank" rel="noopener noreferrer">下一课：练习2：浓淡</a></p>\n<p>你知道可以通过 AI 来提高自己的绘画能力吗？Niji Academy 是一个实验性项目，旨在帮助你使用 Niji 更快地学习绘画。我们每周都有讲座，但我们也在这里发布练习，这样如果你不能参加讲座，也可以参考它们！理解图像的关键是用眼睛进行准确的测量。这是一个很好的练习，可以训练你的手眼协调能力，并加深对所绘主题的理解。</p>',r:{minutes:4.71,words:1412},t:"练习1：用眼睛测量",i:"ruler",O:2,y:"a"}}],["/zh/posts/reprints/qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html",{loader:()=>a.e(266).then(a.bind(a,8317)),meta:{a:"Jainil Prajapati",d:17458848e5,l:"2025年4月29日",c:["reprint"],g:["Qwen","Qwen3","阿里巴巴AI研究","阿里巴巴AI","大语言模型","LLMs","LLM基准测试","多语言AI","多模态AI","AI推理","MCP"],u:!1,v:"https://altctrlai.com/content/images/size/w2000/2025/04/834B968B-9CED-4EF4-B81F-845F8241AC0A.webp",e:'\n<figure><img src="https://altctrlai.com/content/images/size/w2000/2025/04/834B968B-9CED-4EF4-B81F-845F8241AC0A.webp" alt="Qwen3: 下一代具备混合思维和多语言精通能力的AI模型" tabindex="0" loading="lazy"><figcaption>Qwen3: 下一代具备混合思维和多语言精通能力的AI模型</figcaption></figure>\n<p>Qwen3代表了人工智能领域的重大进步，提供了改进的推理能力、多语言支持以及各种基准测试的增强性能。作为Qwen大语言模型家族的最新成员，这一版本引入了创新功能和架构改进，使其成为主要AI实验室领先模型的有力竞争者。以下全面分析探讨了Qwen3的能力、技术规格和实际应用。</p>',r:{minutes:9.81,words:2944},t:"Qwen3: 下一代具备混合思维和多语言精通能力的AI模型 | 2025年概览",i:"fa-solid:robot",y:"a"}}],["/zh/posts/templates/papers.html",{loader:()=>a.e(1998).then(a.bind(a,4523)),meta:{e:"\n<p>!可选：论文/方法相关图片或Logo</p>\n<h2>摘要</h2>\n<p>简要介绍论文背景、核心创新、主要贡献和实验亮点（100-120字，突出作者、模型/方法、适用场景等关键信息）。</p>\n<hr>\n<h2>目录</h2>\n<ol>\n<li>背景与研究目标</li>\n<li>方法与创新点</li>\n<li>实验与结果分析</li>\n<li>模型启发与方法延伸</li>\n<li>结论与未来展望</li>\n</ol>\n<hr>\n<h2>背景与研究目标</h2>\n<ul>\n<li>领域背景、任务定义、现有方法的局限性</li>\n<li>论文要解决的核心问题</li>\n</ul>\n<hr>",r:{minutes:1.5,words:449},t:"【论文精读】论文标题（中英文对照可选）",y:"a"}}],["/zh/posts/thoughts/platform-operation-thoughts-after-comfycon.html",{loader:()=>a.e(7316).then(a.bind(a,3797)),meta:{a:"Faych",d:17436384e5,l:"2025年4月3日",c:["思考"],g:["平台","运营","内容","创新"],u:!1,v:"https://faych.notion.site/image/attachment%3Ac369ffa5-3a8d-4efd-bf62-3811710bc286%3Aimage.png?table=block&id=1ca5f3c4-a139-8050-9757-ff079e04ea98&spaceId=021ded55-a224-419c-939c-70c6888912f7&width=2000&userId=&cache=v2",e:"\n<h2>一、引言：为何探究多平台运营？</h2>\n<p>在 ComfyCon 上，我见到了不少在不同平台上的领军人物，他们为什么能成为顶流，我可以吗？引发了我的思考：</p>\n<ol>\n<li>我的内容创作能力是否有待提升？</li>\n<li>为什么在数十个平台均运营近一年后，仍未能成为真正的“Top”？</li>\n</ol>\n<p>本文将基于我各平台的数据，直面问题，剖析优劣得失，并探索未来可执行的改进方向，为自己带来更明确的运营策略和目标。</p>\n<hr>\n<h2>二、平台分类与核心数据</h2>\n<table>\n<thead>\n<tr>\n<th>平台</th>\n<th>平台分类</th>\n<th>描述</th>\n<th>创作开始时间</th>\n<th>最近更新时间</th>\n<th>成就</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Bilibili</td>\n<td>内容传播</td>\n<td>国内长视频内容发布和互动平台</td>\n<td>Dec. 5, 2022</td>\n<td>Jan. 6, 2025</td>\n<td>孙笑川与邻居友好互动日版6.9万播放量，总播放21.4万，总获赞2593，粉丝34</td>\n</tr>\n<tr>\n<td>CivitAI</td>\n<td>AI 社区</td>\n<td>最大AI绘画模型社区</td>\n<td>Mar. 2, 2025</td>\n<td>Apr. 2, 2025</td>\n<td>FeMix_HassakuXL获得2.6K下载，35书签，138点赞，总下载2.7K，总获赞183，粉丝58；Leaderboard新创作者第14，Base Model Creators第16</td>\n</tr>\n<tr>\n<td>CodeWithGPU</td>\n<td>镜像</td>\n<td>autodl的算法镜像社区</td>\n<td>Jan. 1, 2024</td>\n<td>Mar. 3, 2025</td>\n<td>ChatTTS全站最高排名第49，总下载2.4K</td>\n</tr>\n<tr>\n<td>CompShare</td>\n<td>镜像</td>\n<td>CompShare的算法镜像社区</td>\n<td>Nov. 7, 2024</td>\n<td>Mar. 20, 2025</td>\n<td>lora-scripts全站最高排名第2</td>\n</tr>\n<tr>\n<td>GitHub</td>\n<td>代码</td>\n<td>代码开源平台</td>\n<td>Oct. 29, 2023</td>\n<td>Apr. 2, 2025</td>\n<td>ComfyUI-SAM2获144 Star，总Star233，开发者评级A</td>\n</tr>\n<tr>\n<td>Liblib</td>\n<td>AI 社区</td>\n<td>国内最大AI绘画模型/工作流平台</td>\n<td>Jan. 27, 2025</td>\n<td>Mar. 26, 2025</td>\n<td>总下载3.2K</td>\n</tr>\n<tr>\n<td>ModelScope</td>\n<td>AI 社区</td>\n<td>国内最大AI模型平台（huggingface平替）</td>\n<td>June 3, 2025</td>\n<td>Mar. 27, 2025</td>\n<td>总下载7945</td>\n</tr>\n<tr>\n<td>OpenArt</td>\n<td>AI 社区</td>\n<td>最大的AI工作流开源社区</td>\n<td>Mar. 3, 2025</td>\n<td>Mar. 7, 2025</td>\n<td>总下载441，观看1.5K</td>\n</tr>\n<tr>\n<td>微信公众号</td>\n<td>内容传播</td>\n<td>微信自带的信息发布和互动平台</td>\n<td>Sept. 1, 2025</td>\n<td>Mar. 31, 2025</td>\n<td>【高效科研】李沐和吴恩达推荐的论文散步精度法获517阅读，121转发，粉丝171</td>\n</tr>\n<tr>\n<td>知乎</td>\n<td>内容传播</td>\n<td>问答、专业知识分享和讨论平台</td>\n<td>Mar. 29, 2024</td>\n<td>Feb. 26, 2025</td>\n<td>总获赞447，被关注49</td>\n</tr>\n</tbody>\n</table>",r:{minutes:6.59,words:1977},t:"参加 ComfyCon 有感 —— 数据剖析与自我反思",i:"ic:round-published-with-changes",y:"a"}}],["/zh/posts/web/vue-1.html",{loader:()=>a.e(7710).then(a.bind(a,7319)),meta:{e:"\n",r:{minutes:.02,words:5},t:"Vue3 快速开始",y:"a"}}],["/404.html",{loader:()=>a.e(7490).then(a.bind(a,1489)),meta:{t:""}}],["/posts/reprints/",{loader:()=>a.e(7046).then(a.bind(a,4860)),meta:{t:"Reprints"}}],["/posts/",{loader:()=>a.e(8666).then(a.bind(a,8063)),meta:{t:"Posts"}}],["/zh/posts/ai-impls/",{loader:()=>a.e(5770).then(a.bind(a,1799)),meta:{t:"Ai Impls"}}],["/zh/posts/",{loader:()=>a.e(9773).then(a.bind(a,2269)),meta:{t:"Posts"}}],["/zh/posts/ai-weekly/",{loader:()=>a.e(7488).then(a.bind(a,785)),meta:{t:"Ai Weekly"}}],["/zh/posts/dairys/",{loader:()=>a.e(1426).then(a.bind(a,5355)),meta:{t:"Dairys"}}],["/zh/posts/papers/",{loader:()=>a.e(4601).then(a.bind(a,1332)),meta:{t:"Papers"}}],["/zh/posts/reprints/",{loader:()=>a.e(4423).then(a.bind(a,1060)),meta:{t:"Reprints"}}],["/zh/posts/templates/",{loader:()=>a.e(5313).then(a.bind(a,3913)),meta:{t:"Templates"}}],["/zh/posts/thoughts/",{loader:()=>a.e(6824).then(a.bind(a,9044)),meta:{t:"Thoughts"}}],["/zh/posts/web/",{loader:()=>a.e(5452).then(a.bind(a,9892)),meta:{t:"Web"}}],["/category/",{loader:()=>a.e(3583).then(a.bind(a,3233)),meta:{t:"Category",I:!1}}],["/category/guide/",{loader:()=>a.e(3468).then(a.bind(a,6487)),meta:{t:"Guide Category",I:!1}}],["/category/explainer/",{loader:()=>a.e(2580).then(a.bind(a,723)),meta:{t:"Explainer Category",I:!1}}],["/category/generative-ai/",{loader:()=>a.e(1367).then(a.bind(a,3719)),meta:{t:"Generative AI Category",I:!1}}],["/category/reprints/",{loader:()=>a.e(9609).then(a.bind(a,1828)),meta:{t:"Reprints Category",I:!1}}],["/category/model-development/",{loader:()=>a.e(1881).then(a.bind(a,5603)),meta:{t:"Model Development Category",I:!1}}],["/category/reprint/",{loader:()=>a.e(8688).then(a.bind(a,9829)),meta:{t:"reprint Category",I:!1}}],["/category/model-training/",{loader:()=>a.e(9986).then(a.bind(a,2772)),meta:{t:"Model Training Category",I:!1}}],["/category/image-generation/",{loader:()=>a.e(8390).then(a.bind(a,1654)),meta:{t:"Image Generation Category",I:!1}}],["/category/anime-style/",{loader:()=>a.e(1712).then(a.bind(a,9447)),meta:{t:"Anime Style Category",I:!1}}],["/category/reprints/",{loader:()=>a.e(9609).then(a.bind(a,1828)),meta:{t:"reprints Category",I:!1}}],["/zh/category/",{loader:()=>a.e(86).then(a.bind(a,888)),meta:{t:"分类",I:!1}}],["/zh/category/%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/",{loader:()=>a.e(1206).then(a.bind(a,1145)),meta:{t:"使用指南 分类",I:!1}}],["/zh/category/%E6%8C%87%E5%8D%97/",{loader:()=>a.e(8693).then(a.bind(a,4413)),meta:{t:"指南 分类",I:!1}}],["/zh/category/%E6%97%A5%E8%AE%B0/",{loader:()=>a.e(2830).then(a.bind(a,3193)),meta:{t:"日记 分类",I:!1}}],["/zh/category/%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90/",{loader:()=>a.e(2929).then(a.bind(a,591)),meta:{t:"视频生成 分类",I:!1}}],["/zh/category/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/",{loader:()=>a.e(3775).then(a.bind(a,5920)),meta:{t:"论文精读 分类",I:!1}}],["/zh/category/%E5%BC%A0%E5%90%95%E6%95%8F/",{loader:()=>a.e(9461).then(a.bind(a,2752)),meta:{t:"张吕敏 分类",I:!1}}],["/zh/category/explainer/",{loader:()=>a.e(5133).then(a.bind(a,2293)),meta:{t:"Explainer 分类",I:!1}}],["/zh/category/generative-ai/",{loader:()=>a.e(2778).then(a.bind(a,8899)),meta:{t:"Generative AI 分类",I:!1}}],["/zh/category/%E8%BD%AC%E8%BD%BD/",{loader:()=>a.e(420).then(a.bind(a,8389)),meta:{t:"转载 分类",I:!1}}],["/zh/category/%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91/",{loader:()=>a.e(5212).then(a.bind(a,6518)),meta:{t:"模型开发 分类",I:!1}}],["/zh/category/model-development/",{loader:()=>a.e(1628).then(a.bind(a,8760)),meta:{t:"Model Development 分类",I:!1}}],["/zh/category/model-training/",{loader:()=>a.e(2153).then(a.bind(a,5769)),meta:{t:"Model Training 分类",I:!1}}],["/zh/category/image-generation/",{loader:()=>a.e(1129).then(a.bind(a,8133)),meta:{t:"Image Generation 分类",I:!1}}],["/zh/category/anime-style/",{loader:()=>a.e(5421).then(a.bind(a,5967)),meta:{t:"Anime Style 分类",I:!1}}],["/zh/category/%E6%A8%A1%E5%9E%8B%E7%A0%94%E5%8F%91/",{loader:()=>a.e(9288).then(a.bind(a,4915)),meta:{t:"模型研发 分类",I:!1}}],["/zh/category/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/",{loader:()=>a.e(3935).then(a.bind(a,2900)),meta:{t:"模型训练 分类",I:!1}}],["/zh/category/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/",{loader:()=>a.e(2827).then(a.bind(a,5951)),meta:{t:"图像生成 分类",I:!1}}],["/zh/category/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%A0%BC/",{loader:()=>a.e(840).then(a.bind(a,3387)),meta:{t:"动漫风格 分类",I:!1}}],["/zh/category/reprints/",{loader:()=>a.e(4426).then(a.bind(a,4544)),meta:{t:"reprints 分类",I:!1}}],["/zh/category/reprint/",{loader:()=>a.e(1545).then(a.bind(a,8191)),meta:{t:"reprint 分类",I:!1}}],["/zh/category/%E6%80%9D%E8%80%83/",{loader:()=>a.e(6143).then(a.bind(a,5628)),meta:{t:"思考 分类",I:!1}}],["/tag/",{loader:()=>a.e(1797).then(a.bind(a,951)),meta:{t:"Tag",I:!1}}],["/tag/disable/",{loader:()=>a.e(702).then(a.bind(a,6216)),meta:{t:"Tag: disable",I:!1}}],["/tag/encryption/",{loader:()=>a.e(6803).then(a.bind(a,5476)),meta:{t:"Tag: encryption",I:!1}}],["/tag/layout/",{loader:()=>a.e(1180).then(a.bind(a,6413)),meta:{t:"Tag: Layout",I:!1}}],["/tag/markdown/",{loader:()=>a.e(7931).then(a.bind(a,8216)),meta:{t:"Tag: Markdown",I:!1}}],["/tag/page-config/",{loader:()=>a.e(8782).then(a.bind(a,5844)),meta:{t:"Tag: Page config",I:!1}}],["/tag/guide/",{loader:()=>a.e(6210).then(a.bind(a,2351)),meta:{t:"Tag: Guide",I:!1}}],["/tag/resource-guide/",{loader:()=>a.e(7451).then(a.bind(a,1474)),meta:{t:"Tag: resource guide",I:!1}}],["/tag/script/",{loader:()=>a.e(9969).then(a.bind(a,696)),meta:{t:"Tag: script",I:!1}}],["/tag/stable-diffusion/",{loader:()=>a.e(5175).then(a.bind(a,2149)),meta:{t:"Tag: stable diffusion",I:!1}}],["/tag/merge/",{loader:()=>a.e(7734).then(a.bind(a,9497)),meta:{t:"Tag: merge",I:!1}}],["/tag/model/",{loader:()=>a.e(1647).then(a.bind(a,4530)),meta:{t:"Tag: model",I:!1}}],["/tag/editor/",{loader:()=>a.e(619).then(a.bind(a,9427)),meta:{t:"Tag: editor",I:!1}}],["/tag/model-context-protocol/",{loader:()=>a.e(2808).then(a.bind(a,6562)),meta:{t:"Tag: Model Context Protocol",I:!1}}],["/tag/tech/",{loader:()=>a.e(2354).then(a.bind(a,6510)),meta:{t:"Tag: tech",I:!1}}],["/tag/artificial-intelligence/",{loader:()=>a.e(4498).then(a.bind(a,2735)),meta:{t:"Tag: Artificial Intelligence",I:!1}}],["/tag/inference/",{loader:()=>a.e(7461).then(a.bind(a,5371)),meta:{t:"Tag: Inference",I:!1}}],["/tag/generative-ai/",{loader:()=>a.e(2777).then(a.bind(a,649)),meta:{t:"Tag: Generative AI",I:!1}}],["/tag/game-development/",{loader:()=>a.e(6024).then(a.bind(a,5805)),meta:{t:"Tag: Game Development",I:!1}}],["/tag/stable-diffusion/",{loader:()=>a.e(5175).then(a.bind(a,2149)),meta:{t:"Tag: Stable Diffusion",I:!1}}],["/tag/image-generation/",{loader:()=>a.e(1988).then(a.bind(a,4200)),meta:{t:"Tag: Image Generation",I:!1}}],["/tag/aws/",{loader:()=>a.e(4079).then(a.bind(a,9317)),meta:{t:"Tag: AWS",I:!1}}],["/tag/amazon-bedrock/",{loader:()=>a.e(6641).then(a.bind(a,2305)),meta:{t:"Tag: Amazon Bedrock",I:!1}}],["/tag/illustrious/",{loader:()=>a.e(6815).then(a.bind(a,7442)),meta:{t:"Tag: Illustrious",I:!1}}],["/tag/lu/",{loader:()=>a.e(313).then(a.bind(a,3366)),meta:{t:"Tag: LU",I:!1}}],["/tag/lumina/",{loader:()=>a.e(9630).then(a.bind(a,903)),meta:{t:"Tag: Lumina",I:!1}}],["/tag/ai-model/",{loader:()=>a.e(1092).then(a.bind(a,4851)),meta:{t:"Tag: AI Model",I:!1}}],["/tag/training/",{loader:()=>a.e(1188).then(a.bind(a,718)),meta:{t:"Tag: Training",I:!1}}],["/tag/sdxl/",{loader:()=>a.e(1625).then(a.bind(a,2001)),meta:{t:"Tag: SDXL",I:!1}}],["/tag/2048-resolution/",{loader:()=>a.e(7057).then(a.bind(a,731)),meta:{t:"Tag: 2048 Resolution",I:!1}}],["/tag/vpred/",{loader:()=>a.e(5599).then(a.bind(a,2487)),meta:{t:"Tag: vpred",I:!1}}],["/tag/epsilon-prediction/",{loader:()=>a.e(1094).then(a.bind(a,2483)),meta:{t:"Tag: epsilon prediction",I:!1}}],["/tag/anime/",{loader:()=>a.e(8738).then(a.bind(a,4506)),meta:{t:"Tag: Anime",I:!1}}],["/tag/base-model/",{loader:()=>a.e(5503).then(a.bind(a,2486)),meta:{t:"Tag: Base model",I:!1}}],["/tag/image-generation/",{loader:()=>a.e(1988).then(a.bind(a,4200)),meta:{t:"Tag: Image generation",I:!1}}],["/tag/ai/",{loader:()=>a.e(5268).then(a.bind(a,6701)),meta:{t:"Tag: AI",I:!1}}],["/tag/llm/",{loader:()=>a.e(6725).then(a.bind(a,7412)),meta:{t:"Tag: LLM",I:!1}}],["/tag/protocol/",{loader:()=>a.e(9870).then(a.bind(a,9947)),meta:{t:"Tag: Protocol",I:!1}}],["/tag/debate/",{loader:()=>a.e(7763).then(a.bind(a,3376)),meta:{t:"Tag: Debate",I:!1}}],["/tag/stablediffusion/",{loader:()=>a.e(4168).then(a.bind(a,7004)),meta:{t:"Tag: StableDiffusion",I:!1}}],["/tag/modelmerge/",{loader:()=>a.e(2109).then(a.bind(a,6646)),meta:{t:"Tag: ModelMerge",I:!1}}],["/tag/automatic1111/",{loader:()=>a.e(7817).then(a.bind(a,4196)),meta:{t:"Tag: AUTOMATIC1111",I:!1}}],["/tag/art/",{loader:()=>a.e(7975).then(a.bind(a,149)),meta:{t:"Tag: Art",I:!1}}],["/tag/drawing/",{loader:()=>a.e(4236).then(a.bind(a,7157)),meta:{t:"Tag: Drawing",I:!1}}],["/tag/fundamentals/",{loader:()=>a.e(1286).then(a.bind(a,8782)),meta:{t:"Tag: Fundamentals",I:!1}}],["/tag/niji/",{loader:()=>a.e(6474).then(a.bind(a,6127)),meta:{t:"Tag: niji",I:!1}}],["/tag/qwen/",{loader:()=>a.e(2493).then(a.bind(a,8025)),meta:{t:"Tag: Qwen",I:!1}}],["/tag/qwen3/",{loader:()=>a.e(9606).then(a.bind(a,468)),meta:{t:"Tag: Qwen3",I:!1}}],["/tag/alibaba-ai-research/",{loader:()=>a.e(5043).then(a.bind(a,6647)),meta:{t:"Tag: Alibaba AI research",I:!1}}],["/tag/alibaba-ai/",{loader:()=>a.e(8779).then(a.bind(a,2374)),meta:{t:"Tag: Alibaba AI",I:!1}}],["/tag/large-language-models/",{loader:()=>a.e(811).then(a.bind(a,6982)),meta:{t:"Tag: large language models",I:!1}}],["/tag/llms/",{loader:()=>a.e(5406).then(a.bind(a,3768)),meta:{t:"Tag: LLMs",I:!1}}],["/tag/llm-benchmarks/",{loader:()=>a.e(1016).then(a.bind(a,5495)),meta:{t:"Tag: LLM benchmarks",I:!1}}],["/tag/multilingual-ai/",{loader:()=>a.e(3220).then(a.bind(a,8673)),meta:{t:"Tag: Multilingual AI",I:!1}}],["/tag/multimodal-ai/",{loader:()=>a.e(6585).then(a.bind(a,700)),meta:{t:"Tag: Multimodal AI",I:!1}}],["/tag/ai-reasoning/",{loader:()=>a.e(1441).then(a.bind(a,6644)),meta:{t:"Tag: AI reasoning",I:!1}}],["/tag/mcp/",{loader:()=>a.e(6294).then(a.bind(a,6883)),meta:{t:"Tag: MCP",I:!1}}],["/tag/modelmerging/",{loader:()=>a.e(810).then(a.bind(a,3977)),meta:{t:"Tag: ModelMerging",I:!1}}],["/zh/tag/",{loader:()=>a.e(5230).then(a.bind(a,683)),meta:{t:"标签",I:!1}}],["/zh/tag/%E7%A6%81%E7%94%A8/",{loader:()=>a.e(4210).then(a.bind(a,7770)),meta:{t:"标签: 禁用",I:!1}}],["/zh/tag/%E5%8A%A0%E5%AF%86/",{loader:()=>a.e(8773).then(a.bind(a,4722)),meta:{t:"标签: 加密",I:!1}}],["/zh/tag/%E5%B8%83%E5%B1%80/",{loader:()=>a.e(400).then(a.bind(a,6657)),meta:{t:"标签: 布局",I:!1}}],["/zh/tag/markdown/",{loader:()=>a.e(8754).then(a.bind(a,6411)),meta:{t:"标签: Markdown",I:!1}}],["/zh/tag/%E9%A1%B5%E9%9D%A2%E9%85%8D%E7%BD%AE/",{loader:()=>a.e(627).then(a.bind(a,4927)),meta:{t:"标签: 页面配置",I:!1}}],["/zh/tag/%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/",{loader:()=>a.e(7249).then(a.bind(a,6747)),meta:{t:"标签: 使用指南",I:!1}}],["/zh/tag/%E9%9A%8F%E6%83%B3/",{loader:()=>a.e(6209).then(a.bind(a,5924)),meta:{t:"标签: 随想",I:!1}}],["/zh/tag/%E5%BC%80%E6%BA%90/",{loader:()=>a.e(8131).then(a.bind(a,8972)),meta:{t:"标签: 开源",I:!1}}],["/zh/tag/%E5%A4%A7%E4%BC%9A/",{loader:()=>a.e(1562).then(a.bind(a,4442)),meta:{t:"标签: 大会",I:!1}}],["/zh/tag/%E5%AE%9E%E4%B9%A0/",{loader:()=>a.e(285).then(a.bind(a,2424)),meta:{t:"标签: 实习",I:!1}}],["/zh/tag/%E5%81%9A%E9%A5%AD/",{loader:()=>a.e(8614).then(a.bind(a,9412)),meta:{t:"标签: 做饭",I:!1}}],["/zh/tag/%E5%85%AC%E4%BC%97%E5%8F%B7/",{loader:()=>a.e(1775).then(a.bind(a,3344)),meta:{t:"标签: 公众号",I:!1}}],["/zh/tag/framepack/",{loader:()=>a.e(4297).then(a.bind(a,7227)),meta:{t:"标签: FramePack",I:!1}}],["/zh/tag/%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90/",{loader:()=>a.e(7945).then(a.bind(a,9800)),meta:{t:"标签: 视频生成",I:!1}}],["/zh/tag/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/",{loader:()=>a.e(5099).then(a.bind(a,3002)),meta:{t:"标签: 扩散模型",I:!1}}],["/zh/tag/%E8%BE%93%E5%85%A5%E9%A2%84%E5%A4%84%E7%90%86/",{loader:()=>a.e(9039).then(a.bind(a,2090)),meta:{t:"标签: 输入预处理",I:!1}}],["/zh/tag/resource-guide/",{loader:()=>a.e(2678).then(a.bind(a,7645)),meta:{t:"标签: resource guide",I:!1}}],["/zh/tag/script/",{loader:()=>a.e(8052).then(a.bind(a,9772)),meta:{t:"标签: script",I:!1}}],["/zh/tag/stable-diffusion/",{loader:()=>a.e(9102).then(a.bind(a,2983)),meta:{t:"标签: stable diffusion",I:!1}}],["/zh/tag/merge/",{loader:()=>a.e(8721).then(a.bind(a,4539)),meta:{t:"标签: merge",I:!1}}],["/zh/tag/model/",{loader:()=>a.e(1300).then(a.bind(a,7003)),meta:{t:"标签: model",I:!1}}],["/zh/tag/%E7%BC%96%E8%BE%91%E5%99%A8/",{loader:()=>a.e(8438).then(a.bind(a,5226)),meta:{t:"标签: 编辑器",I:!1}}],["/zh/tag/%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE/",{loader:()=>a.e(2404).then(a.bind(a,3921)),meta:{t:"标签: 模型上下文协议",I:!1}}],["/zh/tag/%E6%8A%80%E6%9C%AF/",{loader:()=>a.e(7366).then(a.bind(a,827)),meta:{t:"标签: 技术",I:!1}}],["/zh/tag/artificial-intelligence/",{loader:()=>a.e(7077).then(a.bind(a,7239)),meta:{t:"标签: Artificial Intelligence",I:!1}}],["/zh/tag/inference/",{loader:()=>a.e(1706).then(a.bind(a,1063)),meta:{t:"标签: Inference",I:!1}}],["/zh/tag/%E7%94%9F%E6%88%90%E5%BC%8Fai/",{loader:()=>a.e(8255).then(a.bind(a,7576)),meta:{t:"标签: 生成式AI",I:!1}}],["/zh/tag/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/",{loader:()=>a.e(1061).then(a.bind(a,6184)),meta:{t:"标签: 游戏开发",I:!1}}],["/zh/tag/stable-diffusion/",{loader:()=>a.e(9102).then(a.bind(a,2983)),meta:{t:"标签: Stable Diffusion",I:!1}}],["/zh/tag/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/",{loader:()=>a.e(7443).then(a.bind(a,7350)),meta:{t:"标签: 图像生成",I:!1}}],["/zh/tag/aws/",{loader:()=>a.e(1232).then(a.bind(a,7529)),meta:{t:"标签: AWS",I:!1}}],["/zh/tag/amazon-bedrock/",{loader:()=>a.e(1872).then(a.bind(a,2732)),meta:{t:"标签: Amazon Bedrock",I:!1}}],["/zh/tag/illustrious/",{loader:()=>a.e(9492).then(a.bind(a,3986)),meta:{t:"标签: Illustrious",I:!1}}],["/zh/tag/lu/",{loader:()=>a.e(4372).then(a.bind(a,8963)),meta:{t:"标签: LU",I:!1}}],["/zh/tag/lumina/",{loader:()=>a.e(9347).then(a.bind(a,9468)),meta:{t:"标签: Lumina",I:!1}}],["/zh/tag/ai%E6%A8%A1%E5%9E%8B/",{loader:()=>a.e(4749).then(a.bind(a,2422)),meta:{t:"标签: AI模型",I:!1}}],["/zh/tag/%E8%AE%AD%E7%BB%83/",{loader:()=>a.e(4967).then(a.bind(a,3120)),meta:{t:"标签: 训练",I:!1}}],["/zh/tag/sdxl/",{loader:()=>a.e(320).then(a.bind(a,5243)),meta:{t:"标签: SDXL",I:!1}}],["/zh/tag/2048%E5%88%86%E8%BE%A8%E7%8E%87/",{loader:()=>a.e(7848).then(a.bind(a,686)),meta:{t:"标签: 2048分辨率",I:!1}}],["/zh/tag/vpred/",{loader:()=>a.e(4996).then(a.bind(a,875)),meta:{t:"标签: vpred",I:!1}}],["/zh/tag/epsilon%E9%A2%84%E6%B5%8B/",{loader:()=>a.e(4198).then(a.bind(a,6556)),meta:{t:"标签: epsilon预测",I:!1}}],["/zh/tag/%E5%8A%A8%E6%BC%AB/",{loader:()=>a.e(506).then(a.bind(a,9923)),meta:{t:"标签: 动漫",I:!1}}],["/zh/tag/%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B/",{loader:()=>a.e(3621).then(a.bind(a,4355)),meta:{t:"标签: 基础模型",I:!1}}],["/zh/tag/ai/",{loader:()=>a.e(361).then(a.bind(a,235)),meta:{t:"标签: AI",I:!1}}],["/zh/tag/llm/",{loader:()=>a.e(8030).then(a.bind(a,7807)),meta:{t:"标签: LLM",I:!1}}],["/zh/tag/%E5%8D%8F%E8%AE%AE/",{loader:()=>a.e(1702).then(a.bind(a,1741)),meta:{t:"标签: 协议",I:!1}}],["/zh/tag/%E8%BE%A9%E8%AE%BA/",{loader:()=>a.e(1540).then(a.bind(a,547)),meta:{t:"标签: 辩论",I:!1}}],["/zh/tag/art/",{loader:()=>a.e(7012).then(a.bind(a,1134)),meta:{t:"标签: Art",I:!1}}],["/zh/tag/drawing/",{loader:()=>a.e(9147).then(a.bind(a,6962)),meta:{t:"标签: Drawing",I:!1}}],["/zh/tag/fundamentals/",{loader:()=>a.e(863).then(a.bind(a,7349)),meta:{t:"标签: Fundamentals",I:!1}}],["/zh/tag/niji/",{loader:()=>a.e(2643).then(a.bind(a,8370)),meta:{t:"标签: niji",I:!1}}],["/zh/tag/qwen/",{loader:()=>a.e(6016).then(a.bind(a,856)),meta:{t:"标签: Qwen",I:!1}}],["/zh/tag/qwen3/",{loader:()=>a.e(6937).then(a.bind(a,8614)),meta:{t:"标签: Qwen3",I:!1}}],["/zh/tag/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4ai%E7%A0%94%E7%A9%B6/",{loader:()=>a.e(220).then(a.bind(a,2375)),meta:{t:"标签: 阿里巴巴AI研究",I:!1}}],["/zh/tag/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4ai/",{loader:()=>a.e(7466).then(a.bind(a,3402)),meta:{t:"标签: 阿里巴巴AI",I:!1}}],["/zh/tag/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/",{loader:()=>a.e(5073).then(a.bind(a,8850)),meta:{t:"标签: 大语言模型",I:!1}}],["/zh/tag/llms/",{loader:()=>a.e(5047).then(a.bind(a,4814)),meta:{t:"标签: LLMs",I:!1}}],["/zh/tag/llm%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95/",{loader:()=>a.e(6322).then(a.bind(a,3357)),meta:{t:"标签: LLM基准测试",I:!1}}],["/zh/tag/%E5%A4%9A%E8%AF%AD%E8%A8%80ai/",{loader:()=>a.e(1992).then(a.bind(a,760)),meta:{t:"标签: 多语言AI",I:!1}}],["/zh/tag/%E5%A4%9A%E6%A8%A1%E6%80%81ai/",{loader:()=>a.e(3135).then(a.bind(a,6270)),meta:{t:"标签: 多模态AI",I:!1}}],["/zh/tag/ai%E6%8E%A8%E7%90%86/",{loader:()=>a.e(1823).then(a.bind(a,5981)),meta:{t:"标签: AI推理",I:!1}}],["/zh/tag/mcp/",{loader:()=>a.e(8669).then(a.bind(a,886)),meta:{t:"标签: MCP",I:!1}}],["/zh/tag/%E5%B9%B3%E5%8F%B0/",{loader:()=>a.e(6528).then(a.bind(a,7447)),meta:{t:"标签: 平台",I:!1}}],["/zh/tag/%E8%BF%90%E8%90%A5/",{loader:()=>a.e(5912).then(a.bind(a,8442)),meta:{t:"标签: 运营",I:!1}}],["/zh/tag/%E5%86%85%E5%AE%B9/",{loader:()=>a.e(8021).then(a.bind(a,481)),meta:{t:"标签: 内容",I:!1}}],["/zh/tag/%E5%88%9B%E6%96%B0/",{loader:()=>a.e(5416).then(a.bind(a,1284)),meta:{t:"标签: 创新",I:!1}}],["/article/",{loader:()=>a.e(7511).then(a.bind(a,391)),meta:{t:"Articles",I:!1}}],["/zh/article/",{loader:()=>a.e(716).then(a.bind(a,6654)),meta:{t:"文章",I:!1}}],["/star/",{loader:()=>a.e(7199).then(a.bind(a,353)),meta:{t:"Star",I:!1}}],["/zh/star/",{loader:()=>a.e(7774).then(a.bind(a,5588)),meta:{t:"星标",I:!1}}],["/timeline/",{loader:()=>a.e(5464).then(a.bind(a,4695)),meta:{t:"Timeline",I:!1}}],["/zh/timeline/",{loader:()=>a.e(8229).then(a.bind(a,3284)),meta:{t:"时间轴",I:!1}}]])},8761:(e,t,a)=>{a.d(t,{U:()=>n});const n=JSON.parse('{"base":"/","lang":"en-US","title":"","description":"","head":[],"locales":{"/":{"lang":"en-US","title":"Nlog","description":"A blog of neverbiasu"},"/zh/":{"lang":"zh-CN","title":"Nlog","description":"neverbiasu 的博客"}}}')},6653:(e,t,a)=>{a.d(t,{K:()=>n});const n=JSON.parse('{"encrypt":{"config":{"/demo/encrypt.html":["$2a$10$d8onUL2DjoEn7JmjyfXGa.5MX9Mg.WE5YeuIcEPCvgwGCwczFhgG2"],"/zh/demo/encrypt.html":["$2a$10$mWRAfOyZg.eQ0os9VZKDZOL.p.2QiPAtQE.SLVGll5hGazobf60B6"]}},"author":{"name":"neverbiasu","url":"https://neverbiasu.github.io"},"logo":"logo.svg","repo":"vuepress-theme-hope/vuepress-theme-hope","docsDir":"src","blog":{"medias":{"BiliBili":"https://space.bilibili.com/342773888","Email":"neverbiasu@gmail.com","GitHub":"https://github.com/neverbiasu","Gmail":"neverbiasu@gmail.com","Instagram":"https://instagram.com","CodeWithGPU":{"icon":"https://raw.githubusercontent.com/neverbiasu/blog/refs/heads/main/src/.vuepress/public/assets/icon/codewithgpu.png","link":"https://www.codewithgpu.com/u/fayche"},"ModelScope":{"icon":"https://raw.githubusercontent.com/neverbiasu/neverbiasu.github.io/d958df931a64984dbbd4c1700330e666ce91c1e3/src/.vuepress/public/assets/icon/modelscope.svg","link":"https://modelscope.cn/profile/ModelE"},"VuePressThemeHope":{"icon":"https://theme-hope-assets.vuejs.press/logo.svg","link":"https://theme-hope.vuejs.press"}}},"locales":{"/zh/":{"lang":"zh-CN","navbarLocales":{"langName":"简体中文","selectLangAriaLabel":"选择语言"},"metaLocales":{"author":"作者","date":"写作日期","origin":"原创","views":"访问量","category":"分类","tag":"标签","readingTime":"阅读时间","words":"字数","toc":"此页内容","prev":"上一页","next":"下一页","lastUpdated":"上次编辑于","contributors":"贡献者","editLink":"在 GitHub 上编辑此页","print":"打印"},"blogLocales":{"article":"文章","articleList":"文章列表","category":"分类","tag":"标签","timeline":"时间轴","timelineTitle":"昨日不在","all":"全部","intro":"个人介绍","star":"星标","empty":"$text 为空"},"paginationLocales":{"prev":"上一页","next":"下一页","navigate":"跳转到","action":"前往","errorText":"请输入 1 到 $page 之前的页码！"},"outlookLocales":{"themeColor":"主题色","darkmode":"外观","fullscreen":"全屏"},"encryptLocales":{"iconLabel":"文章已加密","placeholder":"输入密码","remember":"记住密码","errorHint":"请输入正确的密码"},"routeLocales":{"skipToContent":"跳至主要內容","notFoundTitle":"页面不存在","notFoundMsg":["这里什么也没有","我们是怎么来到这儿的？","这 是 四 零 四 !","看起来你访问了一个失效的链接"],"back":"返回上一页","home":"带我回家"},"navbar":["/zh/","/zh/demo/",{"text":"博客","icon":"pen-to-square","prefix":"/zh/posts/","children":[{"text":"ai-impls","icon":"pen-to-square","prefix":"ai-impls/","children":[{"text":"yolov9","icon":"pen-to-square","link":"yolov9"}]},{"text":"ai-weekly","icon":"pen-to-square","prefix":"ai-weekly/","children":[{"text":"001","icon":"pen-to-square","link":"001"},{"text":"002","icon":"pen-to-square","link":"002"},{"text":"003","icon":"pen-to-square","link":"003"},{"text":"004","icon":"pen-to-square","link":"004"},{"text":"005","icon":"pen-to-square","link":"005"},{"text":"006","icon":"pen-to-square","link":"006"},{"text":"007","icon":"pen-to-square","link":"007"},{"text":"008","icon":"pen-to-square","link":"008"},{"text":"009","icon":"pen-to-square","link":"009"},{"text":"010","icon":"pen-to-square","link":"010"},{"text":"011","icon":"pen-to-square","link":"011"},{"text":"012","icon":"pen-to-square","link":"012"},{"text":"013","icon":"pen-to-square","link":"013"},{"text":"014","icon":"pen-to-square","link":"014"},{"text":"015","icon":"pen-to-square","link":"015"},{"text":"016","icon":"pen-to-square","link":"016"},{"text":"017","icon":"pen-to-square","link":"017"},{"text":"018","icon":"pen-to-square","link":"018"},{"text":"019","icon":"pen-to-square","link":"019"},{"text":"020","icon":"pen-to-square","link":"020"},{"text":"021","icon":"pen-to-square","link":"021"},{"text":"022","icon":"pen-to-square","link":"022"},{"text":"023","icon":"pen-to-square","link":"023"},{"text":"024","icon":"pen-to-square","link":"024"},{"text":"025","icon":"pen-to-square","link":"025"},{"text":"026","icon":"pen-to-square","link":"026"},{"text":"027","icon":"pen-to-square","link":"027"},{"text":"028","icon":"pen-to-square","link":"028"},{"text":"029","icon":"pen-to-square","link":"029"},{"text":"030","icon":"pen-to-square","link":"030"},{"text":"031","icon":"pen-to-square","link":"031"},{"text":"032","icon":"pen-to-square","link":"032"},{"text":"033","icon":"pen-to-square","link":"033"},{"text":"034","icon":"pen-to-square","link":"034"},{"text":"035","icon":"pen-to-square","link":"035"},{"text":"036","icon":"pen-to-square","link":"036"},{"text":"037","icon":"pen-to-square","link":"037"},{"text":"X01","icon":"pen-to-square","link":"X01"}]},{"text":"dairys","icon":"pen-to-square","prefix":"dairys/","children":[{"text":"250222","icon":"pen-to-square","link":"250222"},{"text":"250223","icon":"pen-to-square","link":"250223"}]},{"text":"papers","icon":"pen-to-square","prefix":"papers/","children":[{"text":"3steps-paper-reading","icon":"pen-to-square","link":"3steps-paper-reading"},{"text":"alexnet","icon":"pen-to-square","link":"alexnet"},{"text":"colorizediffusion","icon":"pen-to-square","link":"colorizediffusion"},{"text":"framepack","icon":"pen-to-square","link":"framepack"},{"text":"hunyuancustom","icon":"pen-to-square","link":"hunyuancustom"},{"text":"icedit","icon":"pen-to-square","link":"icedit"},{"text":"reptext","icon":"pen-to-square","link":"reptext"},{"text":"resnet","icon":"pen-to-square","link":"resnet"},{"text":"transformer","icon":"pen-to-square","link":"transformer"}]},{"text":"reprints","icon":"pen-to-square","prefix":"reprints/","children":[{"text":"ai-art-newsletter-jan-25","icon":"pen-to-square","link":"ai-art-newsletter-jan-25"},{"text":"crody\'s-model-merge-guide","icon":"pen-to-square","link":"crody\'s-model-merge-guide"},{"text":"experiments-with-mcp-using-github-copilot","icon":"pen-to-square","link":"experiments-with-mcp-using-github-copilot"},{"text":"explaining-tokens-the-language-and-currency-of-ai-nvidia-blog","icon":"pen-to-square","link":"explaining-tokens-the-language-and-currency-of-ai-nvidia-blog"},{"text":"generative-ai-powered-design","icon":"pen-to-square","link":"generative-ai-powered-design"},{"text":"illustrious-lu-v0.03","icon":"pen-to-square","link":"illustrious-lu-v0.03"},{"text":"illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language","icon":"pen-to-square","link":"illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language"},{"text":"illustrious-xl-v2.0-the-best-training-base-model-in-1536-age","icon":"pen-to-square","link":"illustrious-xl-v2.0-the-best-training-base-model-in-1536-age"},{"text":"mcp-flash-in-the-pan-or-future-standard","icon":"pen-to-square","link":"mcp-flash-in-the-pan-or-future-standard"},{"text":"niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything","icon":"pen-to-square","link":"niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything"},{"text":"niji-study-1-measuring-with-your-eyes","icon":"pen-to-square","link":"niji-study-1-measuring-with-your-eyes"},{"text":"qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview","icon":"pen-to-square","link":"qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview"}]},{"text":"templates","icon":"pen-to-square","prefix":"templates/","children":[{"text":"papers","icon":"pen-to-square","link":"papers"}]},{"text":"thoughts","icon":"pen-to-square","prefix":"thoughts/","children":[{"text":"platform-operation-thoughts-after-comfycon","icon":"pen-to-square","link":"platform-operation-thoughts-after-comfycon"}]},{"text":"web","icon":"pen-to-square","prefix":"web/","children":[{"text":"vue-1","icon":"pen-to-square","link":"vue-1"}]}]}],"sidebar":{"/zh/":["",{"text":"如何使用","icon":"laptop-code","prefix":"demo/","link":"demo/","children":"structure"},{"text":"文章","icon":"book","prefix":"posts/","children":"structure"},"intro",{"text":"幻灯片","icon":"person-chalkboard","link":"https://ecosystem.vuejs.press/zh/plugins/markdown/revealjs/demo.html"}]},"footer":"我的页脚","displayFooter":true,"blog":{"description":"一个人工智能学习者，前端开发者","intro":"/zh/intro.html"}},"/":{"lang":"en-US","navbarLocales":{"langName":"English","selectLangAriaLabel":"Select language"},"metaLocales":{"author":"Author","date":"Writing Date","origin":"Original","views":"Page views","category":"Category","tag":"Tag","readingTime":"Reading Time","words":"Words","toc":"On This Page","prev":"Prev","next":"Next","lastUpdated":"Last update","contributors":"Contributors","editLink":"Edit this page on GitHub","print":"Print"},"blogLocales":{"article":"Articles","articleList":"Article List","category":"Category","tag":"Tag","timeline":"Timeline","timelineTitle":"Yesterday Once More!","all":"All","intro":"Personal Intro","star":"Star","empty":"No $text"},"paginationLocales":{"prev":"Prev","next":"Next","navigate":"Jump to","action":"Go","errorText":"Please enter a number between 1 and $page !"},"outlookLocales":{"themeColor":"Theme Color","darkmode":"Theme Mode","fullscreen":"Full Screen"},"encryptLocales":{"iconLabel":"Page Encrypted","placeholder":"Enter password","remember":"Remember password","errorHint":"Please enter the correct password!"},"routeLocales":{"skipToContent":"Skip to main content","notFoundTitle":"Page not found","notFoundMsg":["There’s nothing here.","How did we get here?","That’s a Four-Oh-Four.","Looks like we\'ve got some broken links."],"back":"Go back","home":"Take me home"},"navbar":[{"text":"home","link":"/home"},"/demo/",{"text":"Posts","icon":"pen-to-square","prefix":"/posts/","children":[{"text":"Apple","icon":"pen-to-square","prefix":"apple/","children":[{"text":"Apple1","icon":"pen-to-square","link":"1"},{"text":"Apple2","icon":"pen-to-square","link":"2"},"3","4"]},{"text":"Banana","icon":"pen-to-square","prefix":"banana/","children":[{"text":"Banana 1","icon":"pen-to-square","link":"1"},{"text":"Banana 2","icon":"pen-to-square","link":"2"},"3","4"]},{"text":"Cherry","icon":"pen-to-square","link":"cherry"},{"text":"Dragon Fruit","icon":"pen-to-square","link":"dragonfruit"},"tomato","strawberry"]}],"sidebar":{"/":["",{"text":"Demo","icon":"laptop-code","prefix":"demo/","link":"demo/","children":"structure"},{"text":"Articles","icon":"book","prefix":"posts/","children":"structure"},"intro",{"text":"Slides","icon":"person-chalkboard","link":"https://ecosystem.vuejs.press/plugins/markdown/revealjs/demo.html"}]},"footer":"My own footer","displayFooter":true,"blog":{"description":"An AI student && A FrontEnd programmer","intro":"/intro.html"}}}}')},4923:(e,t,a)=>{},8123:(e,t,a)=>{a.d(t,{v:()=>n});const n={"/zh/demo/":["markdown","layout","page","disable","encrypt"],"/zh/posts/":[{text:"Ai Impls",prefix:"ai-impls/",collapsible:!0,children:["yolov9"]},{text:"Ai Weekly",prefix:"ai-weekly/",collapsible:!0,children:["X01","001","017","028","020","023","036","031","022","016","010","035","034","005","013","025","014","006","024","021","033","027","037","004","018","030","003","009","026","019","012","032","002","029","015","011","007","008"]},{text:"Dairys",prefix:"dairys/",collapsible:!0,children:["250222","250223"]},{text:"Papers",prefix:"papers/",collapsible:!0,children:["alexnet","colorizediffusion","framepack","hunyuancustom","icedit","reptext","resnet","transformer","3steps-paper-reading"]},{text:"Reprints",prefix:"reprints/",collapsible:!0,children:["mcp-flash-in-the-pan-or-future-standard","generative-ai-powered-design","niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything","niji-study-1-measuring-with-your-eyes","ai-art-newsletter-jan-25","crody's-model-merge-guide","illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language","illustrious-xl-v2.0-the-best-training-base-model-in-1536-age","illustrious-lu-v0.03","qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview","experiments-with-mcp-using-github-copilot","explaining-tokens-the-language-and-currency-of-ai-nvidia-blog"]},{text:"Templates",prefix:"templates/",collapsible:!0,children:["papers"]},{text:"Thoughts",prefix:"thoughts/",collapsible:!0,children:["platform-operation-thoughts-after-comfycon"]},{text:"Web",prefix:"web/",collapsible:!0,children:["vue-1"]}],"/demo/":["layout","markdown","page","disable","encrypt"],"/posts/":[{text:"Reprints",prefix:"reprints/",collapsible:!0,children:["generative-ai-powered-design","niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything","mcp-flash-in-the-pan-or-future-standard","niji-study-1-measuring-with-your-eyes","model-block-merge","model-block-merge-1","model-block-merge-2","crody's-model-merge-guide","experimenting-with-mcp-using-github-copilot","explaining-tokens-the-language-and-currency-of-ai-nvidia-blog","illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language","illustrious-xl-v2.0-the-best-training-base-model-in-1536-age","illustrious-lu-v0.03","qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview","ai-art-newsletter-jan-25","what-is-block-merging"]}]}},2878:(e,t,a)=>{a.d(t,{P:()=>n});const n={BiliBili:'<svg xmlns="http://www.w3.org/2000/svg" class="icon bilibili-icon" viewBox="0 0 1024 1024"><circle cx="512" cy="512" r="512" fill="#1296db"/><path fill="#fff" d="M745.363 177.725a47 47 0 0 1 0 66.3L702.5 286.85h44A141 141 0 0 1 887 427.512v281.25a141 141 0 0 1-141 140.626H277.25A141 141 0 0 1 137 708.763v-281.25a141 141 0 0 1 141-141h43.725l-42.788-42.825a47 47 0 1 1 66.263-66.3l99.45 99.45c2.963 2.962 5.438 6.187 7.425 9.637h120.487c1.988-3.45 4.5-6.75 7.463-9.675l99.413-99.45a47 47 0 0 1 66.3 0zm1.012 203.25h-468.75a47 47 0 0 0-46.763 43.388l-.112 3.525v281.25c0 24.712 19.125 44.962 43.387 46.724l3.488.15h468.75a47 47 0 0 0 46.763-43.387l.112-3.487v-281.25c0-26-21-47-47-46.876zm-375 93.75c26 0 47 21 47 47v47a47 47 0 1 1-93.75 0V521.6c0-26 21-47 47-47zm281.25 0c26 0 47 21 47 47v47a47 47 0 1 1-93.75 0V521.6c0-26 21-47 47-47z"/></svg>',Email:'<svg xmlns="http://www.w3.org/2000/svg" class="icon email-icon" viewBox="0 0 1024 1024"><circle cx="512" cy="512" r="512" fill="#1384FF"/><path fill="#fff" d="M270.077 286.233H751.99c32.933 0 59.86 24.855 60.274 55.51l-301.023 157L210.217 341.88c.207-30.723 26.927-55.717 59.86-55.717zm-59.929 115.714-.276 277.756c0 30.931 27.134 56.2 60.205 56.2H751.99c33.14 0 60.274-25.269 60.274-56.2V401.81L518.283 551.492a15.88 15.88 0 0 1-14.43 0L210.148 401.947z"/></svg>',GitHub:'<svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024"><circle cx="512" cy="512" r="512" fill="#171515"/><path fill="#fff" d="M509.423 146.442c-200.317 0-362.756 162.42-362.756 362.8 0 160.266 103.936 296.24 248.109 344.217 18.139 3.327 24.76-7.872 24.76-17.486 0-8.613-.313-31.427-.49-61.702-100.912 21.923-122.205-48.63-122.205-48.63-16.495-41.91-40.28-53.067-40.28-53.067-32.937-22.51 2.492-22.053 2.492-22.053 36.407 2.566 55.568 37.386 55.568 37.386 32.362 55.438 84.907 39.43 105.58 30.143 3.296-23.444 12.667-39.43 23.032-48.498-80.557-9.156-165.246-40.28-165.246-179.297 0-39.604 14.135-71.988 37.342-97.348-3.731-9.178-16.18-46.063 3.556-96.009 0 0 30.46-9.754 99.76 37.19 28.937-8.048 59.97-12.071 90.823-12.211 30.807.14 61.843 4.165 90.822 12.21 69.26-46.944 99.663-37.189 99.663-37.189 19.792 49.946 7.34 86.831 3.61 96.01 23.25 25.359 37.29 57.742 37.29 97.347 0 139.366-84.82 170.033-165.637 179.013 13.026 11.2 24.628 33.342 24.628 67.182 0 48.498-.445 87.627-.445 99.521 0 9.702 6.535 20.988 24.945 17.444 144.03-48.067 247.881-183.95 247.881-344.175 0-200.378-162.442-362.798-362.802-362.798z"/></svg>',Gmail:'<svg xmlns="http://www.w3.org/2000/svg" class="icon gmail-icon" viewBox="0 0 1024 1024"><circle cx="512" cy="512" r="512" fill="#DB4437"/><path fill="#E67C73" d="M277.48 285.567h465.767v441.362H277.48V285.567z"/><path fill="#FFF" d="M282.543 285.567h-10.645c-25.962 0-47.122 21.808-47.122 48.705v343.952c0 26.897 21.08 48.705 47.122 48.705h24.976V407.954l213.49 169.95 213.489-169.95V726.93h24.975c26.04 0 47.123-21.809 47.123-48.705V334.272c0-26.897-21.134-48.705-47.123-48.705h-10.644L510.364 480.44 282.542 285.567z"/></svg>',Instagram:'<svg xmlns="http://www.w3.org/2000/svg" class="icon instagram-icon" viewBox="0 0 1024 1024"><circle cx="512" cy="512" r="512" fill="#181818"/><path fill="#fff" d="M512 348.16c-88.222 0-163.84 71.417-163.84 163.84 0 88.222 71.417 163.84 163.84 163.84 88.222 0 163.84-71.417 163.84-163.84 0-88.222-75.618-163.84-163.84-163.84zm0 268.866c-58.814 0-105.026-46.212-105.026-105.026S453.186 406.974 512 406.974 617 453.186 617 512s-46.186 105-105 105zM680.041 306.15c-21 0-37.81 16.804-37.81 37.809s16.805 37.81 37.81 37.81 37.81-16.805 37.81-37.81-16.805-37.81-37.81-37.81z"/><path fill="#FFF" d="M659.036 196.923h-16.804c-50.413-4.2-210.051-4.2-260.464 0-96.623-4.2-180.644 71.418-184.845 168.041v16.804c-4.2 50.413-4.2 210.051 0 260.464-4.2 96.623 71.418 180.644 168.041 184.845h16.804c50.413 4.2 210.051 4.2 260.464 0 96.623 4.2 180.644-71.418 184.845-168.041V381.768c4.2-96.623-71.418-180.644-168.041-184.845zM759.86 696.845c-12.604 29.407-33.609 50.412-58.815 58.814-121.83 16.805-247.86 16.805-373.891 0-29.407-12.603-50.412-33.608-58.814-58.814-12.604-63.015-16.805-126-12.604-184.845-4.2-63.015 0-126 12.604-184.845 12.603-29.407 33.608-50.412 58.814-58.814 121.83-16.805 247.86-16.805 373.891 0 29.407 12.603 50.412 33.608 58.815 58.814 12.603 63.015 16.804 126 12.603 184.845 4.2 63.015 0 126-12.603 184.845z"/></svg>'}}},e=>{e.O(0,[6332,9156],(()=>e(e.s=8731))),e.O()}]);