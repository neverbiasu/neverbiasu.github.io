"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[7291],{66262:(e,t)=>{t.A=(e,t)=>{const a=e.__vccOpts||e;for(const[e,n]of t)a[e]=n;return a}},42047:(e,t,a)=>{a.r(t),a.d(t,{comp:()=>o,data:()=>r});var n=a(20641);const i={},o=(0,a(66262).A)(i,[["render",function(e,t){return(0,n.uX)(),(0,n.CE)("div",null,t[0]||(t[0]=[(0,n.Fv)('<h1 id="introducing-flux-1-kontext-and-the-bfl-playground" tabindex="-1"><a class="header-anchor" href="#introducing-flux-1-kontext-and-the-bfl-playground"><span>Introducing FLUX.1 Kontext and the BFL Playground</span></a></h1><p>Today, we are excited to release FLUX.1 Kontext, a suite of generative flow matching models that allows you to generate and edit images. Unlike existing text-to-image models, the FLUX.1 Kontext family performs <strong><em>in-context</em></strong> image generation, allowing you to prompt with both text and images, and seamlessly extract and modify visual concepts to produce new, coherent renderings.</p><figure><img src="https://cdn.sanity.io/images/gsvmb6gz/production/52e38891df903fdee79f6b4ed0fb63f00a43e376-2211x1174.png?rect=0,113,2211,949&amp;w=960&amp;h=412&amp;fit=max&amp;auto=format" alt="Kontext Grid" tabindex="0" loading="lazy"><figcaption>Kontext Grid</figcaption></figure><figure><img src="https://cdn.sanity.io/images/gsvmb6gz/production/877061601ac57191c2327c5ab3378587268c945f-1240x1898.png?fit=max&amp;auto=format" alt="Context-aware editing example" tabindex="0" loading="lazy"><figcaption>Context-aware editing example</figcaption></figure><p><em>Consistent, context-aware text-and-image generation and editing.</em></p><h2 id="your-images-your-words-your-world" tabindex="-1"><a class="header-anchor" href="#your-images-your-words-your-world"><span>YOUR IMAGES. YOUR WORDS. YOUR WORLD.</span></a></h2><p>FLUX.1 Kontext marks a significant expansion of classic text-to-image models by unifying instant text-based image editing and text-to-image generation. As a multimodal flow model, it combines state-of-the-art character consistency, context understanding and local editing capabilities with strong text-to-image synthesis.</p><h2 id="improved-text-to-image-capabilities" tabindex="-1"><a class="header-anchor" href="#improved-text-to-image-capabilities"><span>Improved Text-to-Image Capabilities</span></a></h2><p>Whether for ideation, drafting, conceptual design, or just for fun - text-to-image remains a crucial component of today&#39;s image generation. The FLUX.1 Kontext models deliver state-of-the-art image generation results with strong prompt following, photorealistic rendering, and competitive typography—all at inference speeds up to 8x faster than current leading models (e.g. GPT-Image).</p><h2 id="play-create-manipulate" tabindex="-1"><a class="header-anchor" href="#play-create-manipulate"><span>Play. Create. Manipulate…</span></a></h2><p>FLUX.1 Kontext models go beyond text-to-image. Unlike previous flow models that only allow for pure text based generation, FLUX.1 Kontext models also understand and can create from existing images. With FLUX.1 Kontext you can modify an input image via simple text instructions, enabling flexible and instant image editing - no need for finetuning or complex editing workflows. The core capabilities of the the FLUX.1 Kontext suite are:</p><ul><li>Character consistency: Preserve unique elements of an image, such as a reference character or object in a picture, across multiple scenes and environments.</li><li>Local editing: Make targeted modifications of specific elements in an image without affecting the rest.</li><li>Style Reference: Generate novel scenes while preserving unique styles from a reference image, directed by text prompts.</li><li>Interactive Speed: Minimal latency for both image generation and editing.</li></ul><h2 id="and-iterate-modify-step-by-step" tabindex="-1"><a class="header-anchor" href="#and-iterate-modify-step-by-step"><span>…and Iterate: modify step by step</span></a></h2><p>Flux.1 Kontext allows you to iteratively add more instructions and build on previous edits, refining your creation step-by-step with minimal latency, while preserving image quality and character consistency.</p><h2 id="the-flux-1-kontext-pro-models" tabindex="-1"><a class="header-anchor" href="#the-flux-1-kontext-pro-models"><span>The FLUX.1 Kontext [pro] Models</span></a></h2><p>As part of the FLUX.1 Kontext suite we bring two new in-context image models to the BFL API.</p><h3 id="flux-1-kontext-pro-a-pioneer-for-fast-iterative-image-editing" tabindex="-1"><a class="header-anchor" href="#flux-1-kontext-pro-a-pioneer-for-fast-iterative-image-editing"><span>FLUX.1 Kontext [pro] - A pioneer for fast, iterative image editing</span></a></h3><p>A single model that delivers local editing, generative in-context modifications and classic text-to-image generation in signature FLUX.1 quality. FLUX.1 Kontext [pro] handles both text and reference images as inputs, seamlessly enabling targeted, local edits in specific image regions and complex transformations of entire scenes. Operating up to an order of magnitude faster than previous state-of-the art models, FLUX.1 Kontext [pro] is a pioneer for iterative editing, since it&#39;s the first model that allows users to build upon previous edits through multiple turns, while maintaining characters, identities, styles, and distinctive features consistent across different scenes and viewpoints.</p><h3 id="flux-1-kontext-max-maximum-performance-at-high-speed" tabindex="-1"><a class="header-anchor" href="#flux-1-kontext-max-maximum-performance-at-high-speed"><span>FLUX.1 Kontext [max] - Maximum Performance at High Speed</span></a></h3><p>Our new experimental model greatly improves prompt adherence and typography generation, and high consistency for editing. All these without compromise on speed.</p><p>FLUX.1 Kontext [max] and FLUX.1 Kontext [pro] are available at <a href="https://www.krea.ai/edit" target="_blank" rel="noopener noreferrer">KreaAI</a>, <a href="https://www.freepik.com/ai/image-generator" target="_blank" rel="noopener noreferrer">Freepik</a>, <a href="https://ltx.studio/blog/flux-kontext-in-ltx-studio" target="_blank" rel="noopener noreferrer">Lightricks</a>, <a href="https://openart.ai/create" target="_blank" rel="noopener noreferrer">OpenArt</a> and <a href="https://www.canva.com/design/DAGog-jP6m4/ZvVMXL7cop_zqRc0gHnTMg/view?utm_content=DAGog-jP6m4&amp;utm_campaign=designshare&amp;utm_medium=link2&amp;utm_source=uniquelinks&amp;utlId=h68d63046d6" target="_blank" rel="noopener noreferrer">LeonardoAI</a> and via our infrastructure partners <a href="https://blog.fal.ai/flux-kontext-available-on-fal/" target="_blank" rel="noopener noreferrer">FAL</a>, <a href="https://replicate.com/blog/flux-kontext" target="_blank" rel="noopener noreferrer">Replicate</a>, <a href="https://runware.ai/blog/introducing-flux1-kontext-instruction-based-image-editing-with-ai?utm_source=bfl" target="_blank" rel="noopener noreferrer">Runware</a>, <a href="https://datacrunch.io/flux-kontext" target="_blank" rel="noopener noreferrer">DataCrunch</a>, <a href="https://www.together.ai/models/flux-1-kontext-max" target="_blank" rel="noopener noreferrer">TogetherAI</a> and <a href="https://blog.comfy.org/p/flux1-kontext-api-node-in-day-1-workflow" target="_blank" rel="noopener noreferrer">ComfyOrg</a>. We received support for preference data collection by <a href="https://openart.ai/create" target="_blank" rel="noopener noreferrer">OpenArt</a> and <a href="https://www.krea.ai/edit" target="_blank" rel="noopener noreferrer">KreaAI</a>.</p><h2 id="flux-1-kontext-dev-available-in-private-beta" tabindex="-1"><a class="header-anchor" href="#flux-1-kontext-dev-available-in-private-beta"><span>FLUX.1 Kontext [dev] available in Private Beta</span></a></h2><p>We deeply believe that open research and weight sharing are fundamental to safe technological innovation. We developed an open-weight variant, FLUX.1 Kontext [dev] - a lightweight 12B diffusion transformer suitable for customization and compatible with previous FLUX.1 [dev] inference code. We open FLUX.1 Kontext [dev] in a private beta release, for research usage and safety testing. Please contact us at <a href="mailto:kontext-dev@blackforestlabs.ai" target="_blank" rel="noopener noreferrer">kontext-dev@blackforestlabs.ai</a> if you&#39;re interested. Upon public release FLUX.1 Kontext [dev] will be distributed through our partners <a href="https://blog.fal.ai/flux-kontext-available-on-fal/" target="_blank" rel="noopener noreferrer">FAL</a>, <a href="https://replicate.com/blog/flux-kontext" target="_blank" rel="noopener noreferrer">Replicate</a>, <a href="https://runware.ai/blog/introducing-flux1-kontext-instruction-based-image-editing-with-ai?utm_source=bfl" target="_blank" rel="noopener noreferrer">Runware</a>, <a href="https://datacrunch.io/flux-kontext" target="_blank" rel="noopener noreferrer">DataCrunch</a>, <a href="https://www.together.ai/models/flux-1-kontext-dev" target="_blank" rel="noopener noreferrer">TogetherAI</a> and <a href="https://huggingface.co/black-forest-labs" target="_blank" rel="noopener noreferrer">HuggingFace</a>.</p><h2 id="performance-evaluation" tabindex="-1"><a class="header-anchor" href="#performance-evaluation"><span>Performance Evaluation</span></a></h2><p>To validate the performance of our FLUX.1 Kontext models we conducted an extensive performance evaluation that we release in <a href="https://cdn.sanity.io/files/gsvmb6gz/production/880b072208997108f87e5d2729d8a8be481310b5.pdf" target="_blank" rel="noopener noreferrer">a tech report</a>. Here we give a short summary: to evaluate our models, we compile KontextBench, a benchmark for text-to-image generation and image-to-image generation from crowd-sourced real-world use cases. We will release this benchmark in the future.</p><figure><img src="https://cdn.sanity.io/images/gsvmb6gz/production/14b5fef2009f608b69d226d4fd52fb9de723b8fc-3024x2529.png?fit=max&amp;auto=format" alt="Evaluation results" tabindex="0" loading="lazy"><figcaption>Evaluation results</figcaption></figure><p><em><strong>We show evaluation results across six in-context image generation tasks. FLUX.1 Kontext [pro] consistently ranks among the top performers across all tasks, achieving the highest scores in Text Editing and Character Preservation</strong></em></p><p>We evaluate image-to-image models, including our FLUX.1 Kontext models across six KontextBench tasks. FLUX.1 Kontext [pro] consistently ranks among the top performers across all tasks, achieving the highest scores in text editing and character preservation (see Figure above) while consistently outperforming competing state-of-the-art models in inference speed (see Figure below)</p><figure><img src="https://cdn.sanity.io/images/gsvmb6gz/production/bd7858229e1efefd71b2235c1c8edb64ebbfffe0-1600x535.png?fit=max&amp;auto=format" alt="Latency comparison" tabindex="0" loading="lazy"><figcaption>Latency comparison</figcaption></figure><p><em><strong>FLUX.1 Kontext models consistently achieve lower latencies than competing state-of-the-art models for both text-to-image generation (left) and image-editing (right)</strong></em></p><p>We evaluate FLUX.1 Kontext on text-to-image benchmarks across multiple quality dimensions. FLUX.1 Kontext models demonstrate competitive performance across aesthetics, prompt following, typography, and realism benchmarks.</p><figure><img src="https://cdn.sanity.io/images/gsvmb6gz/production/f71e7c530401b4cb7dcc75af2cf0967e28655bd4-3026x2769.png?fit=max&amp;auto=format" alt="T2I Evaluation" tabindex="0" loading="lazy"><figcaption>T2I Evaluation</figcaption></figure><figure><img src="https://cdn.sanity.io/images/gsvmb6gz/production/55131bdeb6ab53ed0d7173f4aac905ab9407577f-1600x800.jpg?fit=max&amp;auto=format" alt="Head tilt example" tabindex="0" loading="lazy"><figcaption>Head tilt example</figcaption></figure><p><em><strong>left:</strong> input image; <strong>middle</strong>: edit from input: &quot;tilt her head towards the camera&quot;, <strong>right:</strong> &quot;make her laugh&quot;</em></p><figure><img src="https://cdn.sanity.io/images/gsvmb6gz/production/edb93beadb3a16904da945a1cc1bb7266f18328b-1600x292.jpg?fit=max&amp;auto=format" alt="Text editing example" tabindex="0" loading="lazy"><figcaption>Text editing example</figcaption></figure><p><em><strong>left:</strong> input image; <strong>middle</strong>: edit from input: &quot;change the \\&#39;YOU HAD ME AT BEER\\&#39; to \\&#39;YOU HAD ME AT CONTEXT\\&#39;&quot;, <strong>right:</strong> &quot;change the setting to a night club&quot;</em></p><h2 id="failure-cases" tabindex="-1"><a class="header-anchor" href="#failure-cases"><span>Failure Cases</span></a></h2><p>FLUX.1 Kontext exhibits some limitations in its current implementation. Excessive multi-turn editing sessions can introduce visual artifacts that degrade image quality. The model occasionally fails to follow instructions accurately, ignoring specific prompt requirements in rare cases. World knowledge remains limited, affecting the model&#39;s ability to generate contextually accurate content. Additionally, the distillation process can introduce visual artifacts that impact output fidelity.</p><figure><img src="https://cdn.sanity.io/images/gsvmb6gz/production/2971768ab02f9b860c74791e018be2595e521d1b-1600x534.jpg?fit=max&amp;auto=format" alt="Failure case illustration" tabindex="0" loading="lazy"><figcaption>Failure case illustration</figcaption></figure><p><em><strong>Illustration of a FLUX.1 Kontext failure case:</strong> After six iterative edits, the generation is visually degraded and contains visible artifacts.</em></p><h2 id="a-flux-api-demo-introducing-the-bfl-playground" tabindex="-1"><a class="header-anchor" href="#a-flux-api-demo-introducing-the-bfl-playground"><span>A FLUX API Demo: Introducing The BFL Playground</span></a></h2><p>Since launch, we have been consistently asked to make our models easier to test and demo. Today, we are introducing the FLUX Playground: A streamlined interface for testing our most advanced FLUX models without technical integration.</p><p>The Playground allows developers and teams to validate use cases, demonstrate capabilities to stakeholders, and experiment with advanced image generation in real-time. Whether evaluating technical feasibility or showcasing results to decision-makers, the Playground provides immediate access to assess FLUX&#39;s capabilities before moving to full API implementation.</p><p>At BFL, our mission is to build the most advanced models and infrastructure for media generation. The Playground serves as an entry point to the BFL API, designed to accelerate the path from evaluation to production deployment. It is available, today, at <a href="https://playground.bfl.ai/" target="_blank" rel="noopener noreferrer">https://playground.bfl.ai/</a>.</p><p><em>We&#39;re just getting started. If you want to join us on our mission, we are actively hiring talented individuals across multiple roles. Apply <a href="https://job-boards.greenhouse.io/blackforestlabs" target="_blank" rel="noopener noreferrer">here.</a></em></p><h2 id="resources" tabindex="-1"><a class="header-anchor" href="#resources"><span>Resources</span></a></h2><ul><li><a href="https://cdn.sanity.io/files/gsvmb6gz/production/880b072208997108f87e5d2729d8a8be481310b5.pdf" target="_blank" rel="noopener noreferrer">Read the full tech report</a></li><li><a href="https://bfl.ai/" target="_blank" rel="noopener noreferrer">Black Forest Labs</a></li><li><a href="https://playground.bfl.ai/" target="_blank" rel="noopener noreferrer">BFL Playground</a></li></ul><hr><p><em>Originally published by Black Forest Labs on May 29, 2025</em></p>',49)]))}]]),r=JSON.parse('{"path":"/posts/reprints/flux-1-kontext.html","title":"Introducing FLUX.1 Kontext and the BFL Playground","lang":"en-US","frontmatter":{"title":"Introducing FLUX.1 Kontext and the BFL Playground","date":"2025-05-29T00:00:00.000Z","category":"News","author":"Black Forest Labs","tags":["AI","Image Generation","FLUX","Machine Learning"],"description":"Introducing FLUX.1 Kontext and the BFL Playground Today, we are excited to release FLUX.1 Kontext, a suite of generative flow matching models that allows you to generate and edi...","gitInclude":[],"head":[["link",{"rel":"alternate","hreflang":"zh-cn","href":"https://neverbiasu.github.io/zh/posts/reprints/flux-1-kontext.html"}],["meta",{"property":"og:url","content":"https://neverbiasu.github.io/posts/reprints/flux-1-kontext.html"}],["meta",{"property":"og:site_name","content":"Nlog"}],["meta",{"property":"og:title","content":"Introducing FLUX.1 Kontext and the BFL Playground"}],["meta",{"property":"og:description","content":"Introducing FLUX.1 Kontext and the BFL Playground Today, we are excited to release FLUX.1 Kontext, a suite of generative flow matching models that allows you to generate and edi..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://cdn.sanity.io/images/gsvmb6gz/production/52e38891df903fdee79f6b4ed0fb63f00a43e376-2211x1174.png?rect=0,113,2211,949&w=960&h=412&fit=max&auto=format"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:locale:alternate","content":"zh-CN"}],["meta",{"property":"article:author","content":"Black Forest Labs"}],["meta",{"property":"article:tag","content":"AI"}],["meta",{"property":"article:tag","content":"Image Generation"}],["meta",{"property":"article:tag","content":"FLUX"}],["meta",{"property":"article:tag","content":"Machine Learning"}],["meta",{"property":"article:published_time","content":"2025-05-29T00:00:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Introducing FLUX.1 Kontext and the BFL Playground\\",\\"image\\":[\\"https://cdn.sanity.io/images/gsvmb6gz/production/52e38891df903fdee79f6b4ed0fb63f00a43e376-2211x1174.png?rect=0,113,2211,949&w=960&h=412&fit=max&auto=format\\",\\"https://cdn.sanity.io/images/gsvmb6gz/production/877061601ac57191c2327c5ab3378587268c945f-1240x1898.png?fit=max&auto=format\\",\\"https://cdn.sanity.io/images/gsvmb6gz/production/14b5fef2009f608b69d226d4fd52fb9de723b8fc-3024x2529.png?fit=max&auto=format\\",\\"https://cdn.sanity.io/images/gsvmb6gz/production/bd7858229e1efefd71b2235c1c8edb64ebbfffe0-1600x535.png?fit=max&auto=format\\",\\"https://cdn.sanity.io/images/gsvmb6gz/production/f71e7c530401b4cb7dcc75af2cf0967e28655bd4-3026x2769.png?fit=max&auto=format\\",\\"https://cdn.sanity.io/images/gsvmb6gz/production/55131bdeb6ab53ed0d7173f4aac905ab9407577f-1600x800.jpg?fit=max&auto=format\\",\\"https://cdn.sanity.io/images/gsvmb6gz/production/edb93beadb3a16904da945a1cc1bb7266f18328b-1600x292.jpg?fit=max&auto=format\\",\\"https://cdn.sanity.io/images/gsvmb6gz/production/2971768ab02f9b860c74791e018be2595e521d1b-1600x534.jpg?fit=max&auto=format\\"],\\"datePublished\\":\\"2025-05-29T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Black Forest Labs\\"}]}"]]},"headers":[{"level":2,"title":"YOUR IMAGES. YOUR WORDS. YOUR WORLD.","slug":"your-images-your-words-your-world","link":"#your-images-your-words-your-world","children":[]},{"level":2,"title":"Improved Text-to-Image Capabilities","slug":"improved-text-to-image-capabilities","link":"#improved-text-to-image-capabilities","children":[]},{"level":2,"title":"Play. Create. Manipulate…","slug":"play-create-manipulate","link":"#play-create-manipulate","children":[]},{"level":2,"title":"…and Iterate: modify step by step","slug":"and-iterate-modify-step-by-step","link":"#and-iterate-modify-step-by-step","children":[]},{"level":2,"title":"The FLUX.1 Kontext [pro] Models","slug":"the-flux-1-kontext-pro-models","link":"#the-flux-1-kontext-pro-models","children":[{"level":3,"title":"FLUX.1 Kontext [pro] - A pioneer for fast, iterative image editing","slug":"flux-1-kontext-pro-a-pioneer-for-fast-iterative-image-editing","link":"#flux-1-kontext-pro-a-pioneer-for-fast-iterative-image-editing","children":[]},{"level":3,"title":"FLUX.1 Kontext [max] - Maximum Performance at High Speed","slug":"flux-1-kontext-max-maximum-performance-at-high-speed","link":"#flux-1-kontext-max-maximum-performance-at-high-speed","children":[]}]},{"level":2,"title":"FLUX.1 Kontext [dev] available in Private Beta","slug":"flux-1-kontext-dev-available-in-private-beta","link":"#flux-1-kontext-dev-available-in-private-beta","children":[]},{"level":2,"title":"Performance Evaluation","slug":"performance-evaluation","link":"#performance-evaluation","children":[]},{"level":2,"title":"Failure Cases","slug":"failure-cases","link":"#failure-cases","children":[]},{"level":2,"title":"A FLUX API Demo: Introducing The BFL Playground","slug":"a-flux-api-demo-introducing-the-bfl-playground","link":"#a-flux-api-demo-introducing-the-bfl-playground","children":[]},{"level":2,"title":"Resources","slug":"resources","link":"#resources","children":[]}],"readingTime":{"minutes":4.75,"words":1424},"filePathRelative":"posts/reprints/flux-1-kontext.md","localizedDate":"May 29, 2025","excerpt":"\\n<p>Today, we are excited to release FLUX.1 Kontext, a suite of generative flow matching models that allows you to generate and edit images. Unlike existing text-to-image models, the FLUX.1 Kontext family performs <strong><em>in-context</em></strong> image generation, allowing you to prompt with both text and images, and seamlessly extract and modify visual concepts to produce new, coherent renderings.</p>","autoDesc":true}')}}]);