"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[705],{6262:(i,s)=>{s.A=(i,s)=>{const a=i.__vccOpts||i;for(const[i,n]of s)a[i]=n;return a}},1500:(i,s,a)=>{a.r(s),a.d(s,{comp:()=>t,data:()=>l});var n=a(641);const e={},t=(0,a(6262).A)(e,[["render",function(i,s){return(0,n.uX)(),(0,n.CE)("div",null,s[0]||(s[0]=[(0,n.Fv)('<h1 id="lora-fine-tuning-flux-1-dev-on-consumer-hardware" tabindex="-1"><a class="header-anchor" href="#lora-fine-tuning-flux-1-dev-on-consumer-hardware"><span>(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware</span></a></h1><div class="hint-container tip"><p class="hint-container-title">Tips</p><figure><a href="https://colab.research.google.com/github/DerekLiu35/notebooks/blob/main/flux_lora_quant_blogpost.ipynb" target="_blank" rel="noopener noreferrer"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" tabindex="0" loading="lazy"></a><figcaption>Open In Colab</figcaption></figure></div><p>In our previous post, <a href="https://huggingface.co/blog/diffusers-quantization" target="_blank" rel="noopener noreferrer">Exploring Quantization Backends in Diffusers</a>, we dived into how various quantization techniques can shrink diffusion models like FLUX.1-dev, making them significantly more accessible for <em>inference</em> without drastically compromising performance. We saw how <code>bitsandbytes</code>, <code>torchao</code>, and others reduce memory footprints for generating images.</p><p>Performing inference is cool, but to make these models truly our own, we also need to be able to fine-tune them. Therefore, in this post, we tackle <strong>efficient</strong> <em>fine-tuning</em> of these models with peak memory use under ~10 GB of VRAM on a single GPU. This post will guide you through fine-tuning FLUX.1-dev using QLoRA with the <code>diffusers</code> library. We&#39;ll showcase results from an NVIDIA RTX 4090. We&#39;ll also highlight how FP8 training with <code>torchao</code> can further optimize speed on compatible hardware.</p><h2 id="table-of-contents" tabindex="-1"><a class="header-anchor" href="#table-of-contents"><span>Table of Contents</span></a></h2><ol><li><a href="#dataset">Dataset</a></li><li><a href="#flux-architecture">FLUX Architecture</a></li><li><a href="#qlora-fine-tuning-flux1-dev-with-diffusers">QLoRA Fine-tuning FLUX.1-dev with <code>diffusers</code></a><ul><li><a href="#key-optimization-techniques">Key Optimization Techniques</a></li><li><a href="#pre-computing-text-embeddings-clipt5">Pre-computing Text Embeddings (CLIP/T5)</a></li><li><a href="#how-to-use-it">How to use it</a></li><li><a href="#setup--results">Setup &amp; Results</a></li></ul></li><li><a href="#fp8-fine-tuning-with-torchao">FP8 Fine-tuning with <code>torchao</code></a></li><li><a href="#inference-with-trained-lora-adapters">Inference with Trained LoRA Adapters</a><ul><li><a href="#option-1-loading-lora-adapters">Option 1: Loading LoRA Adapters</a></li><li><a href="#option-2-merging-lora-into-base-model">Option 2: Merging LoRA into Base Model</a></li></ul></li><li><a href="#running-on-google-colab">Running on Google Colab</a></li><li><a href="#conclusion">Conclusion</a></li></ol><h2 id="dataset" tabindex="-1"><a class="header-anchor" href="#dataset"><span>Dataset</span></a></h2><p>We aim to fine-tune <code>black-forest-labs/FLUX.1-dev</code> to adopt the artistic style of Alphonse Mucha, using a small <a href="https://huggingface.co/datasets/derekl35/alphonse-mucha-style" target="_blank" rel="noopener noreferrer">dataset</a>.</p><h2 id="flux-architecture" tabindex="-1"><a class="header-anchor" href="#flux-architecture"><span>FLUX Architecture</span></a></h2><p>The model consists of three main components:</p><ul><li>Text Encoders (CLIP and T5)</li><li>Transformer (Main Model - Flux Transformer)</li><li>Variational Auto-Encoder (VAE)</li></ul><p>In our QLoRA approach, we focus exclusively on fine-tuning the <strong>transformer component</strong>. The text encoders and VAE remain frozen throughout training.</p><h2 id="qlora-fine-tuning-flux-1-dev-with-diffusers" tabindex="-1"><a class="header-anchor" href="#qlora-fine-tuning-flux-1-dev-with-diffusers"><span>QLoRA Fine-tuning FLUX.1-dev with <code>diffusers</code></span></a></h2><p>We used a <code>diffusers</code> training script (slightly modified from <a href="https://github.com/huggingface/diffusers/blob/main/examples/research_projects/flux_lora_quantization/train_dreambooth_lora_flux_miniature.py" target="_blank" rel="noopener noreferrer">https://github.com/huggingface/diffusers/blob/main/examples/research_projects/flux_lora_quantization/train_dreambooth_lora_flux_miniature.py</a>) designed for DreamBooth-style LoRA fine-tuning of FLUX models. Also, a shortened version to reproduce the results in this blogpost (and used in the <a href="https://colab.research.google.com/github/DerekLiu35/notebooks/blob/main/flux_lora_quant_blogpost.ipynb" target="_blank" rel="noopener noreferrer">Google Colab</a>) is available <a href="https://github.com/huggingface/diffusers/blob/main/examples/research_projects/flux_lora_quantization/train_dreambooth_lora_flux_nano.py" target="_blank" rel="noopener noreferrer">here</a>. Let&#39;s examine the crucial parts for QLoRA and memory efficiency:</p><h3 id="key-optimization-techniques" tabindex="-1"><a class="header-anchor" href="#key-optimization-techniques"><span>Key Optimization Techniques</span></a></h3><p><strong>LoRA (Low-Rank Adaptation) Deep Dive:</strong><a href="https://huggingface.co/docs/peft/main/en/conceptual_guides/lora" target="_blank" rel="noopener noreferrer">LoRA</a> makes model training more efficient by keeping track of the weight updates with low-rank matrices. Instead of updating the full weight matrix W, LoRA learns two smaller matrices A and B. The update to the weights for the model is ΔW = BA, where A ∈ R^(r×k) and B ∈ R^(d×r). The number r (called <em>rank</em>) is much smaller than the original dimensions, which means less parameters to update. Lastly, α is a scaling factor for the LoRA activations. This affects how much LoRA affects the updates, and is often set to the same value as the r or a multiple of it. It helps balance the influence of the pre-trained model and the LoRA adapter. For a general introduction to the concept, check out our previous blog post: <a href="https://huggingface.co/blog/lora" target="_blank" rel="noopener noreferrer">Using LoRA for Efficient Stable Diffusion Fine-Tuning</a>.</p><figure><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/peft/lora_diagram.png" alt="Illustration of LoRA injecting two low-rank matrices around a frozen weight matrix" tabindex="0" loading="lazy"><figcaption>Illustration of LoRA injecting two low-rank matrices around a frozen weight matrix</figcaption></figure><p><strong>QLoRA: The Efficiency Powerhouse:</strong><a href="https://huggingface.co/docs/peft/main/en/developer_guides/quantization" target="_blank" rel="noopener noreferrer">QLoRA</a> enhances LoRA by first loading the pre-trained base model in a quantized format (typically 4-bit via <code>bitsandbytes</code>), drastically cutting the base model&#39;s memory footprint. It then trains LoRA adapters (usually in FP16/BF16) on top of this quantized base. This dramatically lowers the VRAM needed to hold the base model.</p><p>For instance, in the <a href="https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/README_hidream.md#using-quantization" target="_blank" rel="noopener noreferrer">DreamBooth training script for HiDream</a> 4-bit quantization with bitsandbytes reduces the peak memory usage of a LoRA fine-tune from ~60GB down to ~37GB with negligible-to-none quality degradation. The very same principle is what we apply here to fine-tune FLUX.1 on a consumer-grade hardware.</p><p><strong>8-bit Optimizer (AdamW):</strong> Standard AdamW optimizer maintains first and second moment estimates for each parameter in 32-bit (FP32), which consumes a lot of memory. The 8-bit AdamW uses block-wise quantization to store optimizer states in 8-bit precision, while maintaining training stability. This technique can reduce optimizer memory usage by ~75% compared to standard FP32 AdamW. Enabling it in the script is straightforward:</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Check for the --use_8bit_adam flag</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> args.use_8bit_adam:</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        optimizer_class </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> bnb.optim.AdamW8bit</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">else</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        optimizer_class </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.optim.AdamW</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">optimizer </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> optimizer_class</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        params_to_optimize,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        betas</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(args.adam_beta1, args.adam_beta2),</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        weight_decay</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">args.adam_weight_decay,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        eps</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">args.adam_epsilon,</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Gradient Checkpointing:</strong> During forward pass, intermediate activations are typically stored for backward pass gradient computation. Gradient checkpointing trades computation for memory by only storing certain <em>checkpoint activations</em> and recomputing others during backpropagation.</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> args.gradient_checkpointing:</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        transformer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">enable_gradient_checkpointing</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Cache Latents:</strong> This optimization technique pre-processes all training images through the VAE encoder before the beginning of the training. It stores the resulting latent representations in memory. During the training, instead of encoding images on-the-fly, the cached latents are directly used. This approach offers two main benefits:</p><ol><li>eliminates redundant VAE encoding computations during training, speeding up each training step</li><li>allows the VAE to be completely removed from GPU memory after caching. The trade-off is increased RAM usage to store all cached latents, but this is typically manageable for small datasets.</li></ol><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Cache latents before training if the flag is set</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> args.cache_latents:</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        latents_cache </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> []</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> batch </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> tqdm</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(train_dataloader, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">desc</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Caching latents&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">                with</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">no_grad</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">():</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                        batch[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;pixel_values&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> batch[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;pixel_values&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">to</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                accelerator.device, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">non_blocking</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">weight_dtype</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                        )</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                        latents_cache.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(vae.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">encode</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(batch[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;pixel_values&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]).latent_dist)</span></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # VAE is no longer needed, free up its memory</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        del</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> vae</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">        free_memory</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Setting up 4-bit Quantization (<code>BitsAndBytesConfig</code>):</strong></p><p>This section demonstrates the QLoRA configuration for the base model:</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Determine compute dtype based on mixed precision</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bnb_4bit_compute_dtype </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.float32</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> args.mixed_precision </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">==</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;fp16&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        bnb_4bit_compute_dtype </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.float16</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">elif</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> args.mixed_precision </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">==</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;bf16&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        bnb_4bit_compute_dtype </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.bfloat16</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">nf4_config </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> BitsAndBytesConfig</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        load_in_4bit</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        bnb_4bit_quant_type</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;nf4&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        bnb_4bit_compute_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bnb_4bit_compute_dtype,</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxTransformer2DModel.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        args.pretrained_model_name_or_path,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        subfolder</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;transformer&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        quantization_config</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">nf4_config,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        torch_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bnb_4bit_compute_dtype,</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Prepare model for k-bit training</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> prepare_model_for_kbit_training</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(transformer, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">use_gradient_checkpointing</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">False</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Gradient checkpointing is enabled later via transformer.enable_gradient_checkpointing() if arg is set</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Defining LoRA Configuration (<code>LoraConfig</code>):</strong> Adapters are added to the quantized transformer:</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer_lora_config </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> LoraConfig</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        r</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">args.rank,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        lora_alpha</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">args.rank, </span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        init_lora_weights</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;gaussian&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        target_modules</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;to_k&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;to_q&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;to_v&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;to_out.0&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">], </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># FLUX attention blocks</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">add_adapter</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(transformer_lora_config)</span></span>\n<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;trainable params: </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">num_parameters</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">only_trainable</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> || all params: </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">num_parameters</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># trainable params: 4,669,440 || all params: 11,906,077,760</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Only these LoRA parameters become trainable.</p><h3 id="pre-computing-text-embeddings-clip-t5" tabindex="-1"><a class="header-anchor" href="#pre-computing-text-embeddings-clip-t5"><span>Pre-computing Text Embeddings (CLIP/T5)</span></a></h3><p>Before we launch the QLoRA fine-tune we can save a huge chunk of VRAM and wall-clock time by caching outputs of text encoders once.</p><p>At training time the dataloader simply reads the cached embeddings instead of re-encoding the caption, so the CLIP/T5 encoder never has to sit in GPU memory.</p><details class="hint-container details"><summary>Code</summary><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># https://github.com/huggingface/diffusers/blob/main/examples/research_projects/flux_lora_quantization/compute_embeddings.py</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> argparse</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pandas </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pd</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> datasets </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> load_dataset</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> huggingface_hub.utils </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> insecure_hashlib</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tqdm.auto </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tqdm</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> transformers </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> T5EncoderModel</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> diffusers </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxPipeline</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">MAX_SEQ_LENGTH</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> =</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 77</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">OUTPUT_PATH</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> =</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;embeddings.parquet&quot;</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> generate_image_hash</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">image</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> insecure_hashlib.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">sha256</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(image.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">tobytes</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()).</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">hexdigest</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> load_flux_dev_pipeline</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">():</span></span>\n<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">        id</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> =</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;black-forest-labs/FLUX.1-dev&quot;</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        text_encoder </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> T5EncoderModel.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">id</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">subfolder</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;text_encoder_2&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">load_in_8bit</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">device_map</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;auto&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        pipeline </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxPipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>\n<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">                id</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">text_encoder_2</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">text_encoder, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">transformer</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">vae</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">device_map</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;balanced&quot;</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        )</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pipeline</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">@torch</span><span style="--shiki-light:#4078F2;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">no_grad</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> compute_embeddings</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">pipeline</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> prompts</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> max_sequence_length</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        all_prompt_embeds </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> []</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        all_pooled_prompt_embeds </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> []</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        all_text_ids </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> []</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> prompt </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> tqdm</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(prompts, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">desc</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Encoding prompts.&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                (</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                        prompt_embeds,</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                        pooled_prompt_embeds,</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                        text_ids,</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                ) </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">encode_prompt</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">prompt</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">prompt, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">prompt_2</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">max_sequence_length</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">max_sequence_length)</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                all_prompt_embeds.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(prompt_embeds)</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                all_pooled_prompt_embeds.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(pooled_prompt_embeds)</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                all_text_ids.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(text_ids)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        max_memory </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.cuda.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">max_memory_allocated</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">() </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">/</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 1024</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> /</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 1024</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> /</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 1024</span></span>\n<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">        print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Max memory allocated: </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">max_memory</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">:.3f</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> GB&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> all_prompt_embeds, all_pooled_prompt_embeds, all_text_ids</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> run</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">args</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        dataset </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> load_dataset</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Norod78/Yarn-art-style&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">split</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;train&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        image_prompts </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> {</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">generate_image_hash</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(sample[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;image&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]): sample[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;text&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> sample </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> dataset}</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        all_prompts </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> list</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(image_prompts.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">values</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">())</span></span>\n<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">        print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">len</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(all_prompts)</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        pipeline </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> load_flux_dev_pipeline</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        all_prompt_embeds, all_pooled_prompt_embeds, all_text_ids </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> compute_embeddings</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                pipeline, all_prompts, args.max_sequence_length</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        )</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        data </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> []</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> i, (image_hash, _) </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> enumerate</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(image_prompts.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">items</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()):</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                data.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">((image_hash, all_prompt_embeds[i], all_pooled_prompt_embeds[i], all_text_ids[i]))</span></span>\n<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">        print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">len</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(data)</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # Create a DataFrame</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        embedding_cols </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;prompt_embeds&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;pooled_prompt_embeds&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;text_ids&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        df </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pd.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">DataFrame</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(data, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">columns</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;image_hash&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> embedding_cols)</span></span>\n<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">        print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">len</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(df)</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # Convert embedding lists to arrays (for proper storage in parquet)</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> col </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> embedding_cols:</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                df[col] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> df[col].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">apply</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">lambda</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> x</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: x.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">cpu</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">().</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">numpy</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">().</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">flatten</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">().</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">tolist</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">())</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # Save the dataframe to a parquet file</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        df.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">to_parquet</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(args.output_path)</span></span>\n<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">        print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Data successfully serialized to </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">args.output_path</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> __name__</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> ==</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;__main__&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        parser </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> argparse.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">ArgumentParser</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        parser.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">add_argument</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>\n<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">                &quot;--max_sequence_length&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">                type</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">int</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">                default</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">MAX_SEQ_LENGTH</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">                help</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Maximum sequence length to use for computing the embeddings. The more the higher computational costs.&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        )</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        parser.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">add_argument</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;--output_path&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">type</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">str</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">default</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">OUTPUT_PATH</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">help</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Path to serialize the parquet file.&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        args </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> parser.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">parse_args</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">        run</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(args)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><h3 id="how-to-use-it" tabindex="-1"><a class="header-anchor" href="#how-to-use-it"><span>How to use it</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">python</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> compute_embeddings.py</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --max_sequence_length</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 77</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --output_path</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> embeddings_alphonse_mucha.parquet</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>By combining this with cached VAE latents (<code>--cache_latents</code>) you whittle the active model down to just the quantized transformer + LoRA adapters, keeping the whole fine-tune comfortably under 10 GB of GPU memory.</p><h3 id="setup-results" tabindex="-1"><a class="header-anchor" href="#setup-results"><span>Setup &amp; Results</span></a></h3><p>For this demonstration, we leveraged an NVIDIA RTX 4090 (24GB VRAM) to explore its performance. The full training command using <code>accelerate</code> is shown below.</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># You need to pre-compute the text embeddings first. See the diffusers repo.</span></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># https://github.com/huggingface/diffusers/tree/main/examples/research_projects/flux_lora_quantization</span></span>\n<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">accelerate</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> launch</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --config_file=accelerate.yaml</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    train_dreambooth_lora_flux_miniature.py</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --pretrained_model_name_or_path=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;black-forest-labs/FLUX.1-dev&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --data_df_path=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;embeddings_alphonse_mucha.parquet&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --output_dir=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;alphonse_mucha_lora_flux_nf4&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --mixed_precision=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;bf16&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --use_8bit_adam</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --weighting_scheme=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;none&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --width=512</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --height=768</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --train_batch_size=1</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --repeats=1</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --learning_rate=1e-4</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --guidance_scale=1</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --report_to=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;wandb&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --gradient_accumulation_steps=4</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --gradient_checkpointing</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\ </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">#</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> can</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> drop</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> checkpointing</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> when</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> HW</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> has</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> more</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> than</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 16</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> GB.</span></span>\n<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">    --lr_scheduler</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;constant&quot;</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --lr_warmup_steps=0</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --cache_latents</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --rank=4</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --max_train_steps=700</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --seed=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;0&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Configuration for RTX 4090:</strong> On our RTX 4090, we used a <code>train_batch_size</code> of 1, <code>gradient_accumulation_steps</code> of 4, <code>mixed_precision=&quot;bf16&quot;</code>, <code>gradient_checkpointing=True</code>, <code>use_8bit_adam=True</code>, a LoRA <code>rank</code> of 4, and resolution of 512x768. Latents were cached with <code>cache_latents=True</code>.</p><p><strong>Memory Footprint (RTX 4090):</strong></p><ul><li><strong>QLoRA:</strong> Peak VRAM usage for QLoRA fine-tuning was approximately 9GB.</li><li><strong>BF16 LoRA:</strong> Running standard LoRA (with the base FLUX.1-dev in FP16) on the same setup consumed 26 GB VRAM.</li><li><strong>BF16 full finetuning:</strong> An estimate would be ~120 GB VRAM with no memory optimizations.</li></ul><p><strong>Training Time (RTX 4090):</strong> Fine-tuning for 700 steps on the Alphonse Mucha dataset took approximately 41 minutes on the RTX 4090 with <code>train_batch_size</code> of 1 and resolution of 512x768.</p><p><strong>Output Quality:</strong> The ultimate measure is the generated art. Here are samples from our QLoRA fine-tuned model on the <a href="https://huggingface.co/datasets/derekl35/alphonse-mucha-style" target="_blank" rel="noopener noreferrer">derekl35/alphonse-mucha-style</a> dataset:</p><p>This table compares the primary <code>bf16</code> precision results. The goal of the fine-tuning was to teach the model the distinct style of Alphonse Mucha.</p><table><thead><tr><th>Prompt</th><th>Base Model Output</th><th>QLoRA Fine-tuned Output (Mucha Style)</th></tr></thead><tbody><tr><td><em>&quot;Serene raven-haired woman, moonlit lilies, swirling botanicals, alphonse mucha style&quot;</em></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base2_bf16.png" alt="Base model output for the first prompt" loading="lazy"></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged2_qlora_bf16.png" alt="QLoRA model output for the first prompt" loading="lazy"></td></tr><tr><td><em>&quot;a puppy in a pond, alphonse mucha style&quot;</em></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base3_bf16.png" alt="Base model output for the second prompt" loading="lazy"></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged3_qlora_bf16.png" alt="QLoRA model output for the second prompt" loading="lazy"></td></tr><tr><td><em>&quot;Ornate fox with a collar of autumn leaves and berries, amidst a tapestry of forest foliage, alphonse mucha style&quot;</em></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base5_bf16.png" alt="Base model output for the third prompt" loading="lazy"></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged5_qlora_bf16.png" alt="QLoRA model output for the third prompt" loading="lazy"></td></tr></tbody></table><p>The fine-tuned model nicely captured Mucha&#39;s iconic art nouveau style, evident in the decorative motifs and distinct color palette. The QLoRA process maintained excellent fidelity while learning the new style.</p><details class="hint-container details"><summary>fp16 comparison</summary><p>The results are nearly identical, showing that QLoRA performs effectively with both <code>fp16</code> and <code>bf16</code> mixed precision.</p><h3 id="model-comparison-base-vs-qlora-fine-tuned-fp16" tabindex="-1"><a class="header-anchor" href="#model-comparison-base-vs-qlora-fine-tuned-fp16"><span>Model Comparison: Base vs. QLoRA Fine-tuned (fp16)</span></a></h3><table><thead><tr><th>Prompt</th><th>Base Model Output</th><th>QLoRA Fine-tuned Output (Mucha Style)</th></tr></thead><tbody><tr><td><em>&quot;Serene raven-haired woman, moonlit lilies, swirling botanicals, alphonse mucha style&quot;</em></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base2.png" alt="Base model output for the first prompt" loading="lazy"></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged2.png" alt="QLoRA model output for the first prompt" loading="lazy"></td></tr><tr><td><em>&quot;a puppy in a pond, alphonse mucha style&quot;</em></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base3.png" alt="Base model output for the second prompt" loading="lazy"></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged3.png" alt="QLoRA model output for the second prompt" loading="lazy"></td></tr><tr><td><em>&quot;Ornate fox with a collar of autumn leaves and berries, amidst a tapestry of forest foliage, alphonse mucha style&quot;</em></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base5.png" alt="Base model output for the third prompt" loading="lazy"></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged5.png" alt="QLoRA model output for the third prompt" loading="lazy"></td></tr></tbody></table></details><h2 id="fp8-fine-tuning-with-torchao" tabindex="-1"><a class="header-anchor" href="#fp8-fine-tuning-with-torchao"><span>FP8 Fine-tuning with <code>torchao</code></span></a></h2><p>For users with NVIDIA GPUs possessing compute capability 8.9 or greater (such as the H100, RTX 4090), even greater speed efficiencies can be achieved by leveraging FP8 training via the <code>torchao</code> library.</p><p>We fine-tuned FLUX.1-dev LoRA on an H100 SXM GPU slightly modified <a href="https://github.com/sayakpaul/diffusers-torchao/" target="_blank" rel="noopener noreferrer"><code>diffusers-torchao</code></a> <a href="https://gist.github.com/sayakpaul/f0358dd4f4bcedf14211eba5704df25a#file-train_dreambooth_lora_flux-py" target="_blank" rel="noopener noreferrer">training scripts</a>. The following command was used:</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">accelerate</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> launch</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> train_dreambooth_lora_flux.py</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --pretrained_model_name_or_path=black-forest-labs/FLUX.1-dev</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --dataset_name=derekl35/alphonse-mucha-style</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --instance_prompt=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;a woman, alphonse mucha style&quot;</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --caption_column=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;text&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --output_dir=alphonse_mucha_fp8_lora_flux</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --mixed_precision=bf16</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --use_8bit_adam</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --weighting_scheme=none</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --height=768</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --width=512</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --train_batch_size=1</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --repeats=1</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --learning_rate=1e-4</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --guidance_scale=1</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --report_to=wandb</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --gradient_accumulation_steps=1</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --gradient_checkpointing</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --lr_scheduler=constant</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --lr_warmup_steps=0</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --rank=4</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --max_train_steps=700</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --checkpointing_steps=600</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --seed=0</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --do_fp8_training</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --push_to_hub</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>The training run had a <strong>peak memory usage of 36.57 GB</strong> and completed in approximately <strong>20 minutes</strong>.</p><p>Qualitative results from this FP8 fine-tuned model are also available:</p><figure><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_fp8_combined.png" alt="FP8 model outputs" tabindex="0" loading="lazy"><figcaption>FP8 model outputs</figcaption></figure><p>Key steps to enable FP8 training with <code>torchao</code> involve:</p><ol><li><strong>Injecting FP8 layers</strong> into the model using <code>convert_to_float8_training</code> from <code>torchao.float8</code>.</li><li><strong>Defining a <code>module_filter_fn</code></strong> to specify which modules should and should not be converted to FP8.</li></ol><p>For a more detailed guide and code snippets, please refer to <a href="https://gist.github.com/sayakpaul/f0358dd4f4bcedf14211eba5704df25a" target="_blank" rel="noopener noreferrer">this gist</a> and the <a href="https://github.com/sayakpaul/diffusers-torchao/tree/main/training" target="_blank" rel="noopener noreferrer"><code>diffusers-torchao</code> repository</a>.</p><h2 id="inference-with-trained-lora-adapters" tabindex="-1"><a class="header-anchor" href="#inference-with-trained-lora-adapters"><span>Inference with Trained LoRA Adapters</span></a></h2><p>After training your <a href="https://huggingface.co/collections/derekl35/flux-qlora-68527afe2c0ca7bc82a6d8d9" target="_blank" rel="noopener noreferrer">LoRA adapters</a>, you have two main approaches for inference.</p><h3 id="option-1-loading-lora-adapters" tabindex="-1"><a class="header-anchor" href="#option-1-loading-lora-adapters"><span>Option 1: Loading LoRA Adapters</span></a></h3><p>One approach is to <a href="https://huggingface.co/docs/diffusers/v0.33.1/en/using-diffusers/loading_adapters#lora" target="_blank" rel="noopener noreferrer">load your trained LoRA adapters</a> on top of the base model.</p><p><strong>Benefits of Loading LoRA:</strong></p><ul><li><strong>Flexibility:</strong> Easily switch between different LoRA adapters without reloading the base model</li><li><strong>Experimentation:</strong> Test multiple artistic styles or concepts by swapping adapters</li><li><strong>Modularity:</strong> Combine multiple LoRA adapters using <code>set_adapters()</code> for creative blending</li><li><strong>Storage efficiency:</strong> Keep a single base model and multiple small adapter files</li></ul><details class="hint-container details"><summary>Code</summary><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> diffusers </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxPipeline, FluxTransformer2DModel, BitsAndBytesConfig</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch </span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">ckpt_id </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;black-forest-labs/FLUX.1-dev&quot;</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxPipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        ckpt_id, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">torch_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.float16</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">load_lora_weights</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;derekl35/alphonse_mucha_qlora_flux&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">weight_name</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;pytorch_lora_weights.safetensors&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">enable_model_cpu_offload</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> pipeline</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>\n<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;a puppy in a pond, alphonse mucha style&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">num_inference_steps</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">28</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">guidance_scale</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">3.5</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">height</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">768</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">width</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">512</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">generator</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">manual_seed</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">).images[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">save</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;alphonse_mucha.png&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><h3 id="option-2-merging-lora-into-base-model" tabindex="-1"><a class="header-anchor" href="#option-2-merging-lora-into-base-model"><span>Option 2: Merging LoRA into Base Model</span></a></h3><p>For when you want maximum efficiency with a single style, you can <a href="https://huggingface.co/docs/diffusers/using-diffusers/merge_loras" target="_blank" rel="noopener noreferrer">merge the LoRA weights</a> into the base model.</p><p><strong>Benefits of Merging LoRA:</strong></p><ul><li><strong>VRAM efficiency:</strong> No additional memory overhead from adapter weights during inference</li><li><strong>Speed:</strong> Slightly faster inference as there&#39;s no need to apply adapter computations</li><li><strong>Quantization compatibility:</strong> Can re-quantize the merged model for maximum memory efficiency</li></ul><details class="hint-container details"><summary>Code</summary><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> diffusers </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxPipeline, AutoPipelineForText2Image, FluxTransformer2DModel, BitsAndBytesConfig</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch </span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">ckpt_id </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;black-forest-labs/FLUX.1-dev&quot;</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxPipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        ckpt_id, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">text_encoder</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">text_encoder_2</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">torch_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.float16</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">load_lora_weights</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;derekl35/alphonse_mucha_qlora_flux&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">weight_name</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;pytorch_lora_weights.safetensors&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">fuse_lora</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">unload_lora_weights</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline.transformer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">save_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;fused_transformer&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bnb_4bit_compute_dtype </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.bfloat16</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">nf4_config </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> BitsAndBytesConfig</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        load_in_4bit</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        bnb_4bit_quant_type</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;nf4&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        bnb_4bit_compute_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bnb_4bit_compute_dtype,</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxTransformer2DModel.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>\n<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;fused_transformer&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        quantization_config</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">nf4_config,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        torch_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bnb_4bit_compute_dtype,</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> AutoPipelineForText2Image.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        ckpt_id, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">transformer</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">torch_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bnb_4bit_compute_dtype</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">enable_model_cpu_offload</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> pipeline</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>\n<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;a puppy in a pond, alphonse mucha style&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">num_inference_steps</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">28</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">guidance_scale</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">3.5</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">height</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">768</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">width</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">512</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">generator</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">manual_seed</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">).images[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">save</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;alphonse_mucha_merged.png&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><h2 id="running-on-google-colab" tabindex="-1"><a class="header-anchor" href="#running-on-google-colab"><span>Running on Google Colab</span></a></h2><p>While we showcased results on an RTX 4090, the same code can be run on more accessible hardware like the T4 GPU available in <a href="https://colab.research.google.com/github/DerekLiu35/notebooks/blob/main/flux_lora_quant_blogpost.ipynb" target="_blank" rel="noopener noreferrer">Google Colab</a> for free.</p><p>On a T4, you can expect the fine-tuning process to take significantly longer around 4 hours for the same number of steps. This is a trade-off for accessibility, but it makes custom fine-tuning possible without high-end hardware. Be mindful of usage limits if running on Colab, as a 4-hour training run might push them.</p><h2 id="conclusion" tabindex="-1"><a class="header-anchor" href="#conclusion"><span>Conclusion</span></a></h2><p>QLoRA, coupled with the <code>diffusers</code> library, significantly democratizes the ability to customize state-of-the-art models like FLUX.1-dev. As demonstrated on an RTX 4090, efficient fine-tuning is well within reach, yielding high-quality stylistic adaptations. Furthermore, for users with the latest NVIDIA hardware, <code>torchao</code> enables even faster training through FP8 precision.</p><h3 id="share-your-creations-on-the-hub" tabindex="-1"><a class="header-anchor" href="#share-your-creations-on-the-hub"><span>Share your creations on the Hub!</span></a></h3><p>Sharing your fine-tuned LoRA adapters is a fantastic way to contribute to the open-source community. It allows others to easily try out your styles, build on your work, and helps create a vibrant ecosystem of creative AI tools.</p><p>If you&#39;ve trained a LoRA for FLUX.1-dev, we encourage you to <a href="https://huggingface.co/docs/transformers/en/model_sharing" target="_blank" rel="noopener noreferrer">share</a> it. The easiest way is to add the <code>--push_to_hub</code> flag to the training script. Alternatively, if you have already trained a model and want to upload it, you can use the following snippet.</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Prereqs:</span></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># - pip install huggingface_hub diffusers</span></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># - Run `huggingface-cli login` (or set HF_TOKEN env-var) once.</span></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># - save model</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> huggingface_hub </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> create_repo, upload_folder</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">repo_id </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;your-username/alphonse_mucha_qlora_flux&quot;</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">create_repo</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(repo_id, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">exist_ok</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">upload_folder</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        repo_id</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">repo_id,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        folder_path</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;alphonse_mucha_qlora_flux&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>\n<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        commit_message</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Add Alphonse Mucha LoRA adapter&quot;</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Check out our Mucha QLoRA <a href="https://huggingface.co/derekl35/alphonse_mucha_qlora_flux" target="_blank" rel="noopener noreferrer">https://huggingface.co/derekl35/alphonse_mucha_qlora_flux</a> FP8 LoRA <a href="https://huggingface.co/derekl35/alphonse_mucha_fp8_lora_flux" target="_blank" rel="noopener noreferrer">https://huggingface.co/derekl35/alphonse_mucha_fp8_lora_flux</a>. You can find both, plus other adapters, in <a href="https://huggingface.co/collections/derekl35/flux-qlora-68527afe2c0ca7bc82a6d8d9" target="_blank" rel="noopener noreferrer">this collection</a> as an example.</p><p>We can&#39;t wait to see what you create!</p>',84)]))}]]),l=JSON.parse('{"path":"/posts/reprints/flux-qlora.html","title":"(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware","lang":"en-US","frontmatter":{"title":"(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware","date":"2024-06-19T00:00:00.000Z","author":"Derek Liu, Marc Sun, Sayak Paul, merve, Linoy Tsaban","tags":["FLUX","LoRA","QLoRA","Fine-tuning","diffusers","quantization"],"category":"AI/ML","description":"(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware Tips Open In ColabOpen In Colab In our previous post, Exploring Quantization Backends in Diffusers, we dived into how various ...","gitInclude":[],"head":[["link",{"rel":"alternate","hreflang":"zh-cn","href":"https://neverbiasu.github.io/zh/posts/reprints/flux-qlora.html"}],["meta",{"property":"og:url","content":"https://neverbiasu.github.io/posts/reprints/flux-qlora.html"}],["meta",{"property":"og:site_name","content":"Nlog"}],["meta",{"property":"og:title","content":"(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware"}],["meta",{"property":"og:description","content":"(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware Tips Open In ColabOpen In Colab In our previous post, Exploring Quantization Backends in Diffusers, we dived into how various ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://colab.research.google.com/assets/colab-badge.svg"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:locale:alternate","content":"zh-CN"}],["meta",{"property":"article:author","content":"Derek Liu, Marc Sun, Sayak Paul, merve, Linoy Tsaban"}],["meta",{"property":"article:tag","content":"FLUX"}],["meta",{"property":"article:tag","content":"LoRA"}],["meta",{"property":"article:tag","content":"QLoRA"}],["meta",{"property":"article:tag","content":"Fine-tuning"}],["meta",{"property":"article:tag","content":"diffusers"}],["meta",{"property":"article:tag","content":"quantization"}],["meta",{"property":"article:published_time","content":"2024-06-19T00:00:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware\\",\\"image\\":[\\"https://colab.research.google.com/assets/colab-badge.svg\\",\\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/peft/lora_diagram.png\\",\\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base2_bf16.png\\",\\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged2_qlora_bf16.png\\",\\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base3_bf16.png\\",\\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged3_qlora_bf16.png\\",\\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base5_bf16.png\\",\\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged5_qlora_bf16.png\\",\\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base2.png\\",\\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged2.png\\",\\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base3.png\\",\\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged3.png\\",\\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base5.png\\",\\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged5.png\\",\\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_fp8_combined.png\\"],\\"datePublished\\":\\"2024-06-19T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Derek Liu, Marc Sun, Sayak Paul, merve, Linoy Tsaban\\"}]}"]]},"headers":[{"level":2,"title":"Table of Contents","slug":"table-of-contents","link":"#table-of-contents","children":[]},{"level":2,"title":"Dataset","slug":"dataset","link":"#dataset","children":[]},{"level":2,"title":"FLUX Architecture","slug":"flux-architecture","link":"#flux-architecture","children":[]},{"level":2,"title":"QLoRA Fine-tuning FLUX.1-dev with diffusers","slug":"qlora-fine-tuning-flux-1-dev-with-diffusers","link":"#qlora-fine-tuning-flux-1-dev-with-diffusers","children":[{"level":3,"title":"Key Optimization Techniques","slug":"key-optimization-techniques","link":"#key-optimization-techniques","children":[]},{"level":3,"title":"Pre-computing Text Embeddings (CLIP/T5)","slug":"pre-computing-text-embeddings-clip-t5","link":"#pre-computing-text-embeddings-clip-t5","children":[]},{"level":3,"title":"How to use it","slug":"how-to-use-it","link":"#how-to-use-it","children":[]},{"level":3,"title":"Setup & Results","slug":"setup-results","link":"#setup-results","children":[]}]},{"level":2,"title":"FP8 Fine-tuning with torchao","slug":"fp8-fine-tuning-with-torchao","link":"#fp8-fine-tuning-with-torchao","children":[]},{"level":2,"title":"Inference with Trained LoRA Adapters","slug":"inference-with-trained-lora-adapters","link":"#inference-with-trained-lora-adapters","children":[{"level":3,"title":"Option 1: Loading LoRA Adapters","slug":"option-1-loading-lora-adapters","link":"#option-1-loading-lora-adapters","children":[]},{"level":3,"title":"Option 2: Merging LoRA into Base Model","slug":"option-2-merging-lora-into-base-model","link":"#option-2-merging-lora-into-base-model","children":[]}]},{"level":2,"title":"Running on Google Colab","slug":"running-on-google-colab","link":"#running-on-google-colab","children":[]},{"level":2,"title":"Conclusion","slug":"conclusion","link":"#conclusion","children":[{"level":3,"title":"Share your creations on the Hub!","slug":"share-your-creations-on-the-hub","link":"#share-your-creations-on-the-hub","children":[]}]}],"readingTime":{"minutes":9.82,"words":2947},"filePathRelative":"posts/reprints/flux-qlora.md","localizedDate":"June 19, 2024","excerpt":"\\n<div class=\\"hint-container tip\\">\\n<p class=\\"hint-container-title\\">Tips</p>\\n<figure><a href=\\"https://colab.research.google.com/github/DerekLiu35/notebooks/blob/main/flux_lora_quant_blogpost.ipynb\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\"><img src=\\"https://colab.research.google.com/assets/colab-badge.svg\\" alt=\\"Open In Colab\\" tabindex=\\"0\\" loading=\\"lazy\\"></a><figcaption>Open In Colab</figcaption></figure>\\n</div>","autoDesc":true}')}}]);