"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[6712],{6262:(e,a)=>{a.A=(e,a)=>{const t=e.__vccOpts||e;for(const[e,r]of a)t[e]=r;return t}},6441:(e,a,t)=>{t.r(a),t.d(a,{comp:()=>n,data:()=>s});var r=t(641);const i={},n=(0,t(6262).A)(i,[["render",function(e,a){return(0,r.uX)(),(0,r.CE)("div",null,a[0]||(a[0]=[(0,r.Fv)('<h1 id="framepack压缩加速视频生成-step1x-edit开源高质量图像编辑-dreamid高保真换脸【ai周报】" tabindex="-1"><a class="header-anchor" href="#framepack压缩加速视频生成-step1x-edit开源高质量图像编辑-dreamid高保真换脸【ai周报】"><span>FramePack压缩加速视频生成 | Step1X-Edit开源高质量图像编辑 | DreamID高保真换脸【AI周报】</span></a></h1><figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cc9b2c75-69a4-4156-88c6-4a3ba910cff8/width=800,original=false/01145-1691900756-masterpiece,best quality,amazing quality,ultra high res,_kanna kamui,silver dragon horns,_bioluminescent scales,blue sailor unif.jpeg" alt="封面源自C站作者Koal2" tabindex="0" loading="lazy"><figcaption>封面源自C站作者Koal2</figcaption></figure><h2 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span>摘要</span></a></h2><p>本周亮点：FramePack提出上下文压缩方法，大幅提升视频生成效率；Step1X-Edit开源图像编辑框架，性能接近闭源大模型；Describe Anything实现精细的局部图像视频描述模型；DreamID基于扩散模型实现高保真快速换脸。其余详见正文。</p><hr><h2 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span>目录</span></a></h2><ol><li><a href="#framepack%E6%8F%90%E5%8D%87%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90%E6%95%88%E7%8E%87%E7%9A%84%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8E%8B%E7%BC%A9%E6%A1%86%E6%9E%B6">FramePack：提升视频生成效率的上下文压缩框架</a></li><li><a href="#step1x-edit%E5%BC%80%E6%BA%90%E5%9B%BE%E5%83%8F%E7%BC%96%E8%BE%91%E6%A1%86%E6%9E%B6%E5%AA%B2%E7%BE%8E-gpt-4o-%E4%B8%8E-gemini2-flash">Step1X-Edit：开源图像编辑框架，媲美 GPT-4o 与 Gemini2 Flash</a></li><li><a href="#describe-anything%E5%B1%80%E9%83%A8%E5%8C%BA%E5%9F%9F%E7%9A%84%E7%B2%BE%E7%BB%86%E5%9B%BE%E5%83%8F%E4%B8%8E%E8%A7%86%E9%A2%91%E6%8F%8F%E8%BF%B0%E6%A8%A1%E5%9E%8B">Describe Anything：局部区域的精细图像与视频描述模型</a></li><li><a href="#dreamid%E5%9F%BA%E4%BA%8E%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%AB%98%E4%BF%9D%E7%9C%9F%E5%BF%AB%E9%80%9F%E6%8D%A2%E8%84%B8%E6%96%B9%E6%B3%95">DreamID：基于扩散模型的高保真快速换脸方法</a></li><li><a href="#dreamo%E5%A4%9A%E6%9D%A1%E4%BB%B6%E5%9B%BE%E5%83%8F%E5%AE%9A%E5%88%B6%E7%BB%9F%E4%B8%80%E6%A1%86%E6%9E%B6">DreamO：多条件图像定制统一框架</a></li><li><a href="#styleme3d%E5%A4%9A%E7%BC%96%E7%A0%81%E5%99%A8%E9%A9%B1%E5%8A%A8%E7%9A%843d%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB%E6%A1%86%E6%9E%B6%E6%8F%90%E5%8D%87%E8%89%BA%E6%9C%AF%E9%A3%8E%E6%A0%BC%E4%B8%80%E8%87%B4%E6%80%A7">StyleMe3D：多编码器驱动的3D风格迁移框架，提升艺术风格一致性</a></li></ol><hr><h2 id="framepack-提升视频生成效率的上下文压缩框架" tabindex="-1"><a class="header-anchor" href="#framepack-提升视频生成效率的上下文压缩框架"><span>FramePack：提升视频生成效率的上下文压缩框架</span></a></h2><figure><img src="/assets/images/ai-weekly/framepack/ui.png" alt="FramePack UI 图" tabindex="0" loading="lazy"><figcaption>FramePack UI 图</figcaption></figure><p><strong>概要</strong>：<strong>FramePack</strong> 是由 <strong>lllyasviel 团队</strong> 提出的创新视频生成框架，旨在解决长序列视频生成中的计算瓶颈问题。该方法通过对输入帧进行压缩，使得 Transformer 的上下文长度固定，从而在不增加计算负担的情况下处理大量帧。FramePack 能够在仅使用 6GB GPU 内存的情况下，以每秒 30 帧的速度生成视频，即使在笔记本电脑上也能实现高效的视频扩散生成。</p><p><strong>标签</strong>：#视频生成 #上下文压缩 #Transformer #高效计算 #视频扩散</p><hr><h2 id="step1x-edit-开源图像编辑框架-媲美-gpt-4o-与-gemini2-flash" tabindex="-1"><a class="header-anchor" href="#step1x-edit-开源图像编辑框架-媲美-gpt-4o-与-gemini2-flash"><span>Step1X-Edit：开源图像编辑框架，媲美 GPT-4o 与 Gemini2 Flash</span></a></h2><figure><img src="https://github.com/stepfun-ai/Step1X-Edit/raw/main/assets/image_edit_demo.gif" alt="Step1X-Edit Teaser 图" tabindex="0" loading="lazy"><figcaption>Step1X-Edit Teaser 图</figcaption></figure><p><strong>概要</strong>：<strong>Step1X-Edit</strong> 是由 <strong>StepFun-AI</strong> 发布的开源图像编辑模型，旨在缩小与闭源模型（如 GPT-4o、Gemini2 Flash）之间的性能差距。该框架结合多模态大语言模型（Multimodal LLM）处理参考图像与用户编辑指令，提取潜在嵌入（latent embedding），并通过扩散图像解码器生成目标图像。训练过程中，团队构建了高质量的数据生成流程，确保数据多样性与代表性。评估结果显示，Step1X-Edit 在新提出的 GEdit-Bench 基准上显著优于现有开源模型，性能接近领先的闭源模型，推动了图像编辑领域的发展。</p><p><strong>标签</strong>：#图像编辑 #多模态大模型 #扩散模型 #开源框架 #高质量数据生成</p><hr><h2 id="describe-anything-局部区域的精细图像与视频描述模型" tabindex="-1"><a class="header-anchor" href="#describe-anything-局部区域的精细图像与视频描述模型"><span>Describe Anything：局部区域的精细图像与视频描述模型</span></a></h2><figure><img src="https://describe-anything.github.io/images/slideshow/slide6.jpg" alt="Describe Anything Pipeline 图" tabindex="0" loading="lazy"><figcaption>Describe Anything Pipeline 图</figcaption></figure><p><strong>概要</strong>：<strong>Describe Anything Model (DAM)</strong> 是由 <strong>NVIDIA</strong> 与 <strong>UC Berkeley</strong> 等机构联合开发的多模态大模型，专注于图像和视频中指定区域的精细化描述。用户可通过点击、框选、涂鸦或掩码等方式指定区域，DAM 结合“Focal Prompt”机制与局部视觉骨干网络，生成包含纹理、颜色、形状等细节的丰富描述。该模型支持图像与视频的区域描述，视频仅需在一帧上标注目标区域，DAM 即可追踪并描述其在时序中的变化。此外，DAM 提供指令控制的描述风格调整和零样本区域问答能力，适用于数据标注、辅助分析等多种场景。</p><p><strong>标签</strong>：#局部描述 #图像视频理解 #多模态模型 #区域问答 #视觉语言模型</p><hr><h2 id="dreamid-基于扩散模型的高保真快速换脸方法" tabindex="-1"><a class="header-anchor" href="#dreamid-基于扩散模型的高保真快速换脸方法"><span>DreamID：基于扩散模型的高保真快速换脸方法</span></a></h2><figure><img src="https://superhero-7.github.io/DreamID/images/model_00.png" alt="DreamID Overview 图" tabindex="0" loading="lazy"><figcaption>DreamID Overview 图</figcaption></figure><p><strong>概要</strong>：<strong>DreamID</strong> 是由 <strong>ByteDance 智能创作团队</strong> 提出的一种基于扩散模型的高保真换脸方法。该方法引入了显式的三元组身份组（Triplet ID Group）监督机制，显著提升了身份相似性和属性保留能力。通过采用加速扩散模型 SD Turbo，DreamID 将推理步骤减少至单次迭代，实现了高效的像素级端到端训练。其模型架构包括 SwapNet、FaceNet 和 ID Adapter，能够在复杂光照、大角度和遮挡等挑战场景下，生成高质量的 512×512 分辨率换脸图像，推理时间仅需 0.6 秒。</p><p><strong>标签</strong>：#扩散模型 #换脸 #身份保留 #高保真 #快速推理</p><hr><h2 id="dreamo-多条件图像定制统一框架" tabindex="-1"><a class="header-anchor" href="#dreamo-多条件图像定制统一框架"><span>DreamO：多条件图像定制统一框架</span></a></h2><figure><img src="https://mc-e.github.io/project/DreamO/static/assets/model.png" alt="DreamO Overview 图" tabindex="0" loading="lazy"><figcaption>DreamO Overview 图</figcaption></figure><p><strong>概要</strong>：<strong>DreamO</strong> 是由 <strong>字节跳动</strong> 提出的图像定制统一框架，基于 Diffusion Transformer（DiT）架构，支持身份、主体、风格、试穿等多种条件的灵活组合与控制。该方法引入特征路由约束（Feature Routing Constraint）以增强条件一致性，并设计占位符策略（Placeholder Strategy）实现条件位置控制。训练过程中，DreamO 构建了涵盖多种定制任务的大规模数据集，并采用三阶段渐进式训练策略：初始阶段处理简单任务，全面训练阶段增强定制能力，质量对齐阶段纠正低质量数据引入的偏差。</p><p><strong>标签</strong>：#图像定制 #多条件控制 #DiffusionTransformer #特征路由 #渐进式训练</p><hr><h2 id="styleme3d-多编码器驱动的3d风格迁移框架-提升艺术风格一致性" tabindex="-1"><a class="header-anchor" href="#styleme3d-多编码器驱动的3d风格迁移框架-提升艺术风格一致性"><span>StyleMe3D：多编码器驱动的3D风格迁移框架，提升艺术风格一致性</span></a></h2><figure><img src="https://styleme3d.github.io/static/images/styleme3d_visual_result.png" alt="StyleMe3D Result 图" tabindex="0" loading="lazy"><figcaption>StyleMe3D Result 图</figcaption></figure><p><strong>概要</strong>：<strong>StyleMe3D</strong> 是一个由多个编码器驱动的 3D 高斯点云风格迁移框架，旨在解决传统 3D Gaussian Splatting 在艺术风格迁移中的语义错位和细节破碎问题。该方法引入多模态风格条件控制、语义解耦和感知质量优化机制，包括动态风格得分蒸馏（DSSD）、对比风格描述子（CSD）、多尺度优化（SOS）和 3D 高斯质量评估（3DG-QA）。通过仅优化 RGB 属性，StyleMe3D 保持几何结构完整性，实现从单一物体到复杂场景的风格一致性，适用于游戏、虚拟世界和数字艺术等应用场景。</p><p><strong>标签</strong>：#3D风格迁移 #高斯点云 #多模态建模 #语义解耦 #实时渲染</p><hr><h3 id="参考链接" tabindex="-1"><a class="header-anchor" href="#参考链接"><span><strong>参考链接</strong></span></a></h3><ol><li><a href="https://lllyasviel.github.io/frame_pack_gitpage/" target="_blank" rel="noopener noreferrer">FramePack 项目主页</a></li><li><a href="https://github.com/lllyasviel/FramePack" target="_blank" rel="noopener noreferrer">FramePack GitHub 仓库</a></li><li><a href="https://arxiv.org/html/2504.12626" target="_blank" rel="noopener noreferrer">FramePack 论文链接</a></li><li><a href="https://github.com/stepfun-ai/Step1X-Edit" target="_blank" rel="noopener noreferrer">Step1X-Edit 项目主页</a></li><li><a href="https://arxiv.org/html/2504.17761v1" target="_blank" rel="noopener noreferrer">Step1X-Edit 论文链接</a></li><li><a href="https://describe-anything.github.io/" target="_blank" rel="noopener noreferrer">Describe Anything 项目主页</a></li><li><a href="https://github.com/NVlabs/describe-anything" target="_blank" rel="noopener noreferrer">Describe Anything GitHub 仓库</a></li><li><a href="https://arxiv.org/pdf/2504.16072" target="_blank" rel="noopener noreferrer">Describe Anything 论文链接</a></li><li><a href="https://superhero-7.github.io/DreamID/" target="_blank" rel="noopener noreferrer">DreamID 项目主页</a></li><li><a href="https://github.com/superhero-7/DreamID" target="_blank" rel="noopener noreferrer">DreamID GitHub 仓库</a></li><li><a href="https://arxiv.org/html/2504.14509v2" target="_blank" rel="noopener noreferrer">DreamID 论文链接</a></li><li><a href="https://mc-e.github.io/project/DreamO/" target="_blank" rel="noopener noreferrer">DreamO 项目主页</a></li><li><a href="https://github.com/bytedance/DreamO" target="_blank" rel="noopener noreferrer">DreamO GitHub 仓库</a></li><li><a href="https://arxiv.org/html/2504.16915" target="_blank" rel="noopener noreferrer">DreamO 论文链接</a></li><li><a href="https://styleme3d.github.io/" target="_blank" rel="noopener noreferrer">StyleMe3D 项目主页</a></li><li><a href="https://github.com/AIGCResearch/styleme3d" target="_blank" rel="noopener noreferrer">StyleMe3D GitHub 仓库</a></li><li><a href="https://arxiv.org/html/2504.15281" target="_blank" rel="noopener noreferrer">StyleMe3D 论文链接</a></li></ol>',40)]))}]]),s=JSON.parse('{"path":"/zh/posts/ai-weekly/035.html","title":"FramePack压缩加速视频生成 | Step1X-Edit开源高质量图像编辑 | DreamID高保真换脸【AI周报】","lang":"zh-CN","frontmatter":{"description":"FramePack压缩加速视频生成 | Step1X-Edit开源高质量图像编辑 | DreamID高保真换脸【AI周报】 封面源自C站作者Koal2封面源自C站作者Koal2 摘要 本周亮点：FramePack提出上下文压缩方法，大幅提升视频生成效率；Step1X-Edit开源图像编辑框架，性能接近闭源大模型；Describe Anything实现精...","gitInclude":[],"head":[["meta",{"property":"og:url","content":"https://neverbiasu.github.io/zh/posts/ai-weekly/035.html"}],["meta",{"property":"og:site_name","content":"Nlog"}],["meta",{"property":"og:title","content":"FramePack压缩加速视频生成 | Step1X-Edit开源高质量图像编辑 | DreamID高保真换脸【AI周报】"}],["meta",{"property":"og:description","content":"FramePack压缩加速视频生成 | Step1X-Edit开源高质量图像编辑 | DreamID高保真换脸【AI周报】 封面源自C站作者Koal2封面源自C站作者Koal2 摘要 本周亮点：FramePack提出上下文压缩方法，大幅提升视频生成效率；Step1X-Edit开源图像编辑框架，性能接近闭源大模型；Describe Anything实现精..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cc9b2c75-69a4-4156-88c6-4a3ba910cff8/width=800,original=false/01145-1691900756-masterpiece,best%20quality,amazing%20quality,ultra%20high%20res,_kanna%20kamui,silver%20dragon%20horns,_bioluminescent%20scales,blue%20sailor%20unif.jpeg"}],["meta",{"property":"og:locale","content":"zh-CN"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"FramePack压缩加速视频生成 | Step1X-Edit开源高质量图像编辑 | DreamID高保真换脸【AI周报】\\",\\"image\\":[\\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cc9b2c75-69a4-4156-88c6-4a3ba910cff8/width=800,original=false/01145-1691900756-masterpiece,best%20quality,amazing%20quality,ultra%20high%20res,_kanna%20kamui,silver%20dragon%20horns,_bioluminescent%20scales,blue%20sailor%20unif.jpeg\\",\\"https://neverbiasu.github.io/assets/images/ai-weekly/framepack/ui.png\\",\\"https://github.com/stepfun-ai/Step1X-Edit/raw/main/assets/image_edit_demo.gif\\",\\"https://describe-anything.github.io/images/slideshow/slide6.jpg\\",\\"https://superhero-7.github.io/DreamID/images/model_00.png\\",\\"https://mc-e.github.io/project/DreamO/static/assets/model.png\\",\\"https://styleme3d.github.io/static/images/styleme3d_visual_result.png\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"neverbiasu\\",\\"url\\":\\"https://neverbiasu.github.io\\"}]}"]]},"headers":[{"level":2,"title":"摘要","slug":"摘要","link":"#摘要","children":[]},{"level":2,"title":"目录","slug":"目录","link":"#目录","children":[]},{"level":2,"title":"FramePack：提升视频生成效率的上下文压缩框架","slug":"framepack-提升视频生成效率的上下文压缩框架","link":"#framepack-提升视频生成效率的上下文压缩框架","children":[]},{"level":2,"title":"Step1X-Edit：开源图像编辑框架，媲美 GPT-4o 与 Gemini2 Flash","slug":"step1x-edit-开源图像编辑框架-媲美-gpt-4o-与-gemini2-flash","link":"#step1x-edit-开源图像编辑框架-媲美-gpt-4o-与-gemini2-flash","children":[]},{"level":2,"title":"Describe Anything：局部区域的精细图像与视频描述模型","slug":"describe-anything-局部区域的精细图像与视频描述模型","link":"#describe-anything-局部区域的精细图像与视频描述模型","children":[]},{"level":2,"title":"DreamID：基于扩散模型的高保真快速换脸方法","slug":"dreamid-基于扩散模型的高保真快速换脸方法","link":"#dreamid-基于扩散模型的高保真快速换脸方法","children":[]},{"level":2,"title":"DreamO：多条件图像定制统一框架","slug":"dreamo-多条件图像定制统一框架","link":"#dreamo-多条件图像定制统一框架","children":[]},{"level":2,"title":"StyleMe3D：多编码器驱动的3D风格迁移框架，提升艺术风格一致性","slug":"styleme3d-多编码器驱动的3d风格迁移框架-提升艺术风格一致性","link":"#styleme3d-多编码器驱动的3d风格迁移框架-提升艺术风格一致性","children":[{"level":3,"title":"参考链接","slug":"参考链接","link":"#参考链接","children":[]}]}],"readingTime":{"minutes":5.96,"words":1787},"filePathRelative":"zh/posts/ai-weekly/035.md","excerpt":"\\n<figure><img src=\\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cc9b2c75-69a4-4156-88c6-4a3ba910cff8/width=800,original=false/01145-1691900756-masterpiece,best quality,amazing quality,ultra high res,_kanna kamui,silver dragon horns,_bioluminescent scales,blue sailor unif.jpeg\\" alt=\\"封面源自C站作者Koal2\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>封面源自C站作者Koal2</figcaption></figure>","autoDesc":true}')}}]);