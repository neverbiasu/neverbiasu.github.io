"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[2547],{6262:(e,a)=>{a.A=(e,a)=>{const t=e.__vccOpts||e;for(const[e,i]of a)t[e]=i;return t}},2947:(e,a,t)=>{t.r(a),t.d(a,{comp:()=>n,data:()=>o});var i=t(641);const r={},n=(0,t(6262).A)(r,[["render",function(e,a){return(0,i.uX)(),(0,i.CE)("div",null,a[0]||(a[0]=[(0,i.Fv)('<h1 id="blip3-o多模态统一模型-minimax-speech零样本语音合成-intellect-2去中心化rl训练【ai周报】" tabindex="-1"><a class="header-anchor" href="#blip3-o多模态统一模型-minimax-speech零样本语音合成-intellect-2去中心化rl训练【ai周报】"><span>BLIP3-o多模态统一模型 | MiniMax-Speech零样本语音合成 | INTELLECT-2去中心化RL训练【AI周报】</span></a></h1><figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/646c745b-b1dd-441d-a510-4416734f49a7/anim=false,width=450/ca47c2dc-4c18-4015-b397-bd86d53ba442_0.jpeg" alt="封面源自C站作者Koal2" tabindex="0" loading="lazy"><figcaption>封面源自C站作者Koal2</figcaption></figure><h2 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span>摘要</span></a></h2><p>本周亮点：BLIP3-o统一理解与生成任务；MiniMax-Speech实现32语种零样本语音克隆；INTELLECT-2首次实现全球去中心化强化学习大模型训练；Step1X-3D发布高保真3D资产生成框架；CAST支持从单图重建结构化3D场景。</p><hr><h2 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span>目录</span></a></h2><ol><li><a href="#blip3-o%E5%85%A8%E5%BC%80%E6%BA%90%E7%BB%9F%E4%B8%80%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88%E7%90%86%E8%A7%A3%E4%B8%8E%E7%94%9F%E6%88%90%E8%83%BD%E5%8A%9B">BLIP3-o：全开源统一多模态模型，融合理解与生成能力</a></li><li><a href="#minimax-speech%E6%94%AF%E6%8C%8132%E8%AF%AD%E7%A7%8D%E7%9A%84%E9%9B%B6%E6%A0%B7%E6%9C%AC%E8%AF%AD%E9%9F%B3%E5%85%8B%E9%9A%86%E5%A4%A7%E6%A8%A1%E5%9E%8B">MiniMax-Speech：支持32语种的零样本语音克隆大模型</a></li><li><a href="#step1x-3d%E9%AB%98%E4%BF%9D%E7%9C%9F%E5%8F%AF%E6%8E%A7%E7%9A%843d%E8%B5%84%E4%BA%A7%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E6%94%AF%E6%8C%81lora%E5%BE%AE%E8%B0%83">Step1X-3D：高保真可控的3D资产生成模型，支持LoRA微调</a></li><li><a href="#marigold%E8%BD%BB%E9%87%8F%E7%BA%A7%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%9B%BE%E5%83%8F%E5%88%86%E6%9E%90">Marigold：轻量级扩散模型微调，实现多任务图像分析</a></li><li><a href="#intellect-2%E5%85%A8%E7%90%83%E5%8E%BB%E4%B8%AD%E5%BF%83%E5%8C%96%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83%E7%9A%8432b%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B">INTELLECT-2：全球去中心化强化学习训练的32B推理模型</a></li><li><a href="#cast%E5%8D%95%E5%BC%A0rgb%E5%9B%BE%E5%83%8F%E9%A9%B1%E5%8A%A8%E7%9A%84%E7%BB%84%E4%BB%B6%E5%AF%B9%E9%BD%903d%E5%9C%BA%E6%99%AF%E9%87%8D%E5%BB%BA">CAST：单张RGB图像驱动的组件对齐3D场景重建</a></li></ol><hr><h2 id="blip3-o-全开源统一多模态模型-融合理解与生成能力" tabindex="-1"><a class="header-anchor" href="#blip3-o-全开源统一多模态模型-融合理解与生成能力"><span>BLIP3-o：全开源统一多模态模型，融合理解与生成能力</span></a></h2><figure><img src="https://github.com/JiuhaiChen/BLIP3o/raw/main/figure/image.png" alt="BLIP3-o Teaser 图" tabindex="0" loading="lazy"><figcaption>BLIP3-o Teaser 图</figcaption></figure><p><strong>概要</strong>：<strong>BLIP3-o</strong> 是由<strong>Salesforce Research</strong> 和 <strong>马里兰大学</strong> 等机构联合提出的全开源统一多模态模型系列，融合了自回归与扩散架构，采用“先理解后生成”的策略，创新性地结合 CLIP 特征与 Flow Matching 训练方法，显著提升了图像生成质量与多模态理解能力。该模型支持图像理解与生成任务，并提供完整的训练数据集与代码，促进多模态研究的开放性与可复现性。</p><p><strong>标签</strong>：#多模态模型 #图像生成 #开源 #CLIP #FlowMatching</p><hr><h2 id="minimax-speech-支持32语种的零样本语音克隆大模型" tabindex="-1"><a class="header-anchor" href="#minimax-speech-支持32语种的零样本语音克隆大模型"><span>MiniMax-Speech：支持32语种的零样本语音克隆大模型</span></a></h2><figure><img src="https://minimax-ai.github.io/tts_tech_report/assets/images/system-overview.jpg" alt="MiniMax-Speech Overview 图" tabindex="0" loading="lazy"><figcaption>MiniMax-Speech Overview 图</figcaption></figure><p><strong>概要</strong>：<strong>MiniMax-Speech</strong> 是由 <strong>MiniMax</strong> 发布的新一代语音合成大模型，具备强大的零样本语音克隆能力。该模型基于自回归 Transformer 架构，融合可学习的音色编码器（Learnable Speaker Encoder），能够从参考音频中提取音色特征，实现高保真、情感丰富的语音合成。支持32种语言和多种情绪风格，适用于内容创作、虚拟人、教育等多种场景。在多个国际权威评测中，MiniMax-Speech 在字错误率（WER）和说话人相似度等指标上取得领先，展现出卓越的语音合成质量和广泛的应用潜力。</p><p><strong>标签</strong>：#语音合成 #零样本克隆 #多语种支持 #个性化语音 #高保真音频</p><hr><h2 id="step1x-3d-高保真可控的3d资产生成模型-支持lora微调" tabindex="-1"><a class="header-anchor" href="#step1x-3d-高保真可控的3d资产生成模型-支持lora微调"><span>Step1X-3D：高保真可控的3D资产生成模型，支持LoRA微调</span></a></h2><figure><img src="https://github.com/stepfun-ai/Step1X-3D/raw/main/assets/step1x-3d-teaser.png" alt="Step1X-3D Teaser 图" tabindex="0" loading="lazy"><figcaption>Step1X-3D Teaser 图</figcaption></figure><p><strong>概要</strong>：<strong>Step1X-3D</strong> 是由 <strong>阶跃星辰</strong> 发布的开源3D生成模型，拥有4.8B参数（几何模块1.3B，纹理模块3.5B），采用原生两阶段架构，解耦几何与纹理表征。该模型通过混合VAE-DiT几何生成器与基于扩散的纹理合成模块，确保生成的3D模型结构完整、纹理细节丰富。Step1X-3D支持从文本提示或单张图像生成高质量的3D模型，并兼容LoRA等2D控制技术，提升生成的可控性与易用性。模型已开源训练代码和800K高质量3D资产，助力3D内容创作。</p><p><strong>标签</strong>：#3D生成 #高保真建模 #纹理合成 #可控性 #LoRA微调</p><hr><h2 id="marigold-轻量级扩散模型微调-实现多任务图像分析" tabindex="-1"><a class="header-anchor" href="#marigold-轻量级扩散模型微调-实现多任务图像分析"><span>Marigold：轻量级扩散模型微调，实现多任务图像分析</span></a></h2><figure><img src="https://github.com/prs-eth/Marigold/raw/main/doc/teaser_marigold_all.jpg" alt="Marigold Teaser 图" tabindex="0" loading="lazy"><figcaption>Marigold Teaser 图</figcaption></figure><p><strong>概要</strong>：<strong>Marigold</strong> 是 <strong>苏黎世联邦理工学院</strong> 推出的扩散模型适配框架，旨在将预训练的 Stable Diffusion 模型转化为高效的图像分析工具，支持单目深度估计、表面法线预测和图像内在属性分解等任务。该方法通过最小化架构修改，结合小规模合成数据，在单张 GPU 上数日内完成训练，具备出色的零样本泛化能力。Marigold 还支持快速推理（&lt;100ms）和高分辨率处理，适用于资源受限场景。</p><p><strong>标签</strong>：#扩散模型 #图像分析 #深度估计 #表面法线 #内在属性分解 #轻量级微调</p><hr><h2 id="intellect-2-全球去中心化强化学习训练的32b推理模型" tabindex="-1"><a class="header-anchor" href="#intellect-2-全球去中心化强化学习训练的32b推理模型"><span>INTELLECT-2：全球去中心化强化学习训练的32B推理模型</span></a></h2><figure><img src="https://cdn.prod.website-files.com/66239f0441b09824acb92c7e/682107b3b1d00e49e0e1d232_toploc-validator.png" alt="INTELLECT-2 Overview 图" tabindex="0" loading="lazy"><figcaption>INTELLECT-2 Overview 图</figcaption></figure><p><strong>概要</strong>：<strong>INTELLECT-2</strong> 是由 <strong>Prime Intellect 团队</strong> 发布的 320 亿参数语言模型，首次通过全球去中心化的强化学习（RL）方式进行训练。该模型采用异步分布式 RL 框架 PRIME-RL，结合高效权重广播系统 SHARDCAST 和验证机制 TOPLOC，确保训练稳定性与数据可靠性。实验结果表明，INTELLECT-2 在数学和编程任务上超越同类模型 QwQ-32B，验证了去中心化 RL 训练的有效性和潜力。</p><p><strong>标签</strong>：#去中心化训练 #强化学习 #大语言模型 #异步训练 #开源模型</p><hr><h2 id="cast-单张rgb图像驱动的组件对齐3d场景重建" tabindex="-1"><a class="header-anchor" href="#cast-单张rgb图像驱动的组件对齐3d场景重建"><span>CAST：单张RGB图像驱动的组件对齐3D场景重建</span></a></h2><figure><img src="https://arxiv.org/html/2502.12894v2/extracted/6434240/figs/teaser.png" alt="CAST Teaser 图" tabindex="0" loading="lazy"><figcaption>CAST Teaser 图</figcaption></figure><p><strong>概要</strong>：<strong>CAST</strong>（Component-Aligned 3D Scene Reconstruction from a Single RGB Image）是由 <strong>上海科技大学</strong> 提出的一种创新的3D场景重建方法，能够从单张RGB图像中生成结构合理、物理一致的3D场景。该方法首先提取图像中的对象级2D分割和相对深度信息，利用GPT模型分析对象间的空间关系，确保重建结果的连贯性。随后，CAST使用考虑遮挡的3D生成模型独立生成每个对象的完整几何形状，并通过对齐生成模块计算必要的变换，将生成的网格精确地放置到场景的点云中。最后，CAST引入物理一致性校正步骤，利用精细的关系图优化对象姿态，确保生成场景在物理交互上的准确性。该方法在虚拟内容创作、机器人仿真等领域具有广泛的应用前景。</p><p><strong>标签</strong>：#3D重建 #单图像输入 #GPT空间关系建模 #物理一致性 #虚拟仿真</p><hr><h3 id="参考链接" tabindex="-1"><a class="header-anchor" href="#参考链接"><span><strong>参考链接</strong></span></a></h3><ol><li><a href="https://github.com/jiuhaichen/blip3o" target="_blank" rel="noopener noreferrer">BLIP3-o Github 仓库</a></li><li><a href="https://arxiv.org/html/2505.09568v1" target="_blank" rel="noopener noreferrer">BLIP3-o 论文</a></li><li><a href="https://minimax-ai.github.io/tts_tech_report/" target="_blank" rel="noopener noreferrer">MiniMax-Speech 技术报告</a></li><li><a href="https://arxiv.org/html/2505.07916" target="_blank" rel="noopener noreferrer">MiniMax-Speech 论文</a></li><li><a href="https://github.com/stepfun-ai/Step1X-3D" target="_blank" rel="noopener noreferrer">Step1X-3D Github 仓库</a></li><li><a href="https://arxiv.org/html/2505.07747" target="_blank" rel="noopener noreferrer">Step1X-3D 论文</a></li><li><a href="https://marigoldcomputervision.github.io/" target="_blank" rel="noopener noreferrer">Marigold 项目主页</a></li><li><a href="https://github.com/prs-eth/Marigold" target="_blank" rel="noopener noreferrer">Marigold GitHub 仓库</a></li><li><a href="https://arxiv.org/html/2505.09358" target="_blank" rel="noopener noreferrer">Marigold 论文</a></li><li><a href="https://www.primeintellect.ai/blog/intellect-2-release" target="_blank" rel="noopener noreferrer">INTELLECT-2 博客</a></li><li><a href="https://github.com/PrimeIntellect-ai/prime-rl" target="_blank" rel="noopener noreferrer">INTELLECT-2 GitHub 仓库</a></li><li><a href="https://arxiv.org/html/2505.07291" target="_blank" rel="noopener noreferrer">INTELLECT-2 论文</a></li><li><a href="https://sites.google.com/view/cast4" target="_blank" rel="noopener noreferrer">CAST 项目主页</a></li><li><a href="https://arxiv.org/html/2502.12894" target="_blank" rel="noopener noreferrer">CAST 论文</a></li></ol>',40)]))}]]),o=JSON.parse('{"path":"/zh/posts/ai-weekly/038.html","title":"BLIP3-o多模态统一模型 | MiniMax-Speech零样本语音合成 | INTELLECT-2去中心化RL训练【AI周报】","lang":"zh-CN","frontmatter":{"description":"BLIP3-o多模态统一模型 | MiniMax-Speech零样本语音合成 | INTELLECT-2去中心化RL训练【AI周报】 封面源自C站作者Koal2封面源自C站作者Koal2 摘要 本周亮点：BLIP3-o统一理解与生成任务；MiniMax-Speech实现32语种零样本语音克隆；INTELLECT-2首次实现全球去中心化强化学习大模型训练...","gitInclude":[],"head":[["meta",{"property":"og:url","content":"https://neverbiasu.github.io/zh/posts/ai-weekly/038.html"}],["meta",{"property":"og:site_name","content":"Nlog"}],["meta",{"property":"og:title","content":"BLIP3-o多模态统一模型 | MiniMax-Speech零样本语音合成 | INTELLECT-2去中心化RL训练【AI周报】"}],["meta",{"property":"og:description","content":"BLIP3-o多模态统一模型 | MiniMax-Speech零样本语音合成 | INTELLECT-2去中心化RL训练【AI周报】 封面源自C站作者Koal2封面源自C站作者Koal2 摘要 本周亮点：BLIP3-o统一理解与生成任务；MiniMax-Speech实现32语种零样本语音克隆；INTELLECT-2首次实现全球去中心化强化学习大模型训练..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/646c745b-b1dd-441d-a510-4416734f49a7/anim=false,width=450/ca47c2dc-4c18-4015-b397-bd86d53ba442_0.jpeg"}],["meta",{"property":"og:locale","content":"zh-CN"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"BLIP3-o多模态统一模型 | MiniMax-Speech零样本语音合成 | INTELLECT-2去中心化RL训练【AI周报】\\",\\"image\\":[\\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/646c745b-b1dd-441d-a510-4416734f49a7/anim=false,width=450/ca47c2dc-4c18-4015-b397-bd86d53ba442_0.jpeg\\",\\"https://github.com/JiuhaiChen/BLIP3o/raw/main/figure/image.png\\",\\"https://minimax-ai.github.io/tts_tech_report/assets/images/system-overview.jpg\\",\\"https://github.com/stepfun-ai/Step1X-3D/raw/main/assets/step1x-3d-teaser.png\\",\\"https://github.com/prs-eth/Marigold/raw/main/doc/teaser_marigold_all.jpg\\",\\"https://cdn.prod.website-files.com/66239f0441b09824acb92c7e/682107b3b1d00e49e0e1d232_toploc-validator.png\\",\\"https://arxiv.org/html/2502.12894v2/extracted/6434240/figs/teaser.png\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"neverbiasu\\",\\"url\\":\\"https://neverbiasu.github.io\\"}]}"]]},"headers":[{"level":2,"title":"摘要","slug":"摘要","link":"#摘要","children":[]},{"level":2,"title":"目录","slug":"目录","link":"#目录","children":[]},{"level":2,"title":"BLIP3-o：全开源统一多模态模型，融合理解与生成能力","slug":"blip3-o-全开源统一多模态模型-融合理解与生成能力","link":"#blip3-o-全开源统一多模态模型-融合理解与生成能力","children":[]},{"level":2,"title":"MiniMax-Speech：支持32语种的零样本语音克隆大模型","slug":"minimax-speech-支持32语种的零样本语音克隆大模型","link":"#minimax-speech-支持32语种的零样本语音克隆大模型","children":[]},{"level":2,"title":"Step1X-3D：高保真可控的3D资产生成模型，支持LoRA微调","slug":"step1x-3d-高保真可控的3d资产生成模型-支持lora微调","link":"#step1x-3d-高保真可控的3d资产生成模型-支持lora微调","children":[]},{"level":2,"title":"Marigold：轻量级扩散模型微调，实现多任务图像分析","slug":"marigold-轻量级扩散模型微调-实现多任务图像分析","link":"#marigold-轻量级扩散模型微调-实现多任务图像分析","children":[]},{"level":2,"title":"INTELLECT-2：全球去中心化强化学习训练的32B推理模型","slug":"intellect-2-全球去中心化强化学习训练的32b推理模型","link":"#intellect-2-全球去中心化强化学习训练的32b推理模型","children":[]},{"level":2,"title":"CAST：单张RGB图像驱动的组件对齐3D场景重建","slug":"cast-单张rgb图像驱动的组件对齐3d场景重建","link":"#cast-单张rgb图像驱动的组件对齐3d场景重建","children":[{"level":3,"title":"参考链接","slug":"参考链接","link":"#参考链接","children":[]}]}],"readingTime":{"minutes":5.91,"words":1774},"filePathRelative":"zh/posts/ai-weekly/038.md","excerpt":"\\n<figure><img src=\\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/646c745b-b1dd-441d-a510-4416734f49a7/anim=false,width=450/ca47c2dc-4c18-4015-b397-bd86d53ba442_0.jpeg\\" alt=\\"封面源自C站作者Koal2\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>封面源自C站作者Koal2</figcaption></figure>\\n<h2>摘要</h2>\\n<p>本周亮点：BLIP3-o统一理解与生成任务；MiniMax-Speech实现32语种零样本语音克隆；INTELLECT-2首次实现全球去中心化强化学习大模型训练；Step1X-3D发布高保真3D资产生成框架；CAST支持从单图重建结构化3D场景。</p>","autoDesc":true}')}}]);