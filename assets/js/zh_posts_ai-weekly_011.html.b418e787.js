"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[4246],{6262:(e,i)=>{i.A=(e,i)=>{const t=e.__vccOpts||e;for(const[e,n]of i)t[e]=n;return t}},8738:(e,i,t)=>{t.r(i),t.d(i,{comp:()=>a,data:()=>o});var n=t(641);const r={},a=(0,t(6262).A)(r,[["render",function(e,i){return(0,n.uX)(),(0,n.CE)("div",null,i[0]||(i[0]=[(0,n.Fv)('<h1 id="腾讯hunyuan3d重塑3d重建-mvpaint多视角提升3d材质一致性-promptfix实现高质量图像修复【ai周报】" tabindex="-1"><a class="header-anchor" href="#腾讯hunyuan3d重塑3d重建-mvpaint多视角提升3d材质一致性-promptfix实现高质量图像修复【ai周报】"><span>腾讯Hunyuan3D重塑3D重建|MVPaint多视角提升3D材质一致性|PromptFix实现高质量图像修复【AI周报】</span></a></h1><figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bb18d643-4bac-439b-a647-35b9355aee31/width=450/38613991.jpeg" alt="封面" tabindex="0" loading="lazy"><figcaption>封面</figcaption></figure><h2 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span>摘要</span></a></h2><p>本周聚焦视觉与生成领域突破：腾讯混元3D 推出高效3D重建工具，支持实时场景重建；MVPaint提升3D材质一致性，实现高质量多视角纹理生成；PromptFix利用Diffusion模型进行多任务图像修复，覆盖上色、去雾等。其余详见正文。</p><h2 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span><strong>目录</strong></span></a></h2><ol><li><a href="#HiCo-T2I:%E5%88%86%E5%B1%82%E5%8F%AF%E6%8E%A7Diffusion%E6%A8%A1%E5%9E%8B%E5%B8%83%E5%B1%80%E5%88%B0%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90">HiCo-T2I: 分层可控Diffusion模型布局到图像生成</a></li><li><a href="#Hunyuan3D-1:%E8%85%BE%E8%AE%AF%E6%8E%A8%E5%87%BA%E7%9A%84%E9%AB%98%E6%95%883D%E5%86%85%E5%AE%B9%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B">Hunyuan3D-1: 腾讯推出的高效 3D 内容生成模型</a></li><li><a href="#AutoVFX:%E7%89%A9%E7%90%86%E7%9C%9F%E5%AE%9E%E6%84%9F%E8%A7%86%E9%A2%91%E7%BC%96%E8%BE%91%E7%B3%BB%E7%BB%9F">AutoVFX: 物理真实感视频编辑系统</a></li><li><a href="#HelloMeme:%E9%AB%98%E7%BA%A7%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E9%A9%B1%E5%8A%A8%E7%9A%84%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B">HelloMeme: 高级注意力机制驱动的生成模型</a></li><li><a href="#MVPaint:%E5%A4%9A%E8%A7%86%E8%A7%92%E4%B8%80%E8%87%B4%E7%9A%843D%E7%BA%B9%E7%90%86%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B">MVPaint: 多视角一致的 3D 纹理生成模型</a></li><li><a href="#PromptFix:%E5%AE%9E%E7%8E%B0%E6%99%BA%E8%83%BD%E5%9B%BE%E5%83%8F%E4%BF%AE%E5%A4%8D%E7%9A%84Diffusion%E6%A8%A1%E5%9E%8B">PromptFix: 实现智能图像修复的 Diffusion 模型</a></li><li><a href="#DomainGallery:%E7%B2%BE%E7%BB%86%E5%8C%96%E9%A2%86%E5%9F%9F%E9%80%82%E5%BA%94%E7%9A%84Diffusion%E6%A8%A1%E5%9E%8B">DomainGallery: 精细化领域适应的 Diffusion 模型</a></li></ol><hr><h2 id="hico-分层可控diffusion模型布局到图像生成" tabindex="-1"><a class="header-anchor" href="#hico-分层可控diffusion模型布局到图像生成"><span>HiCo: 分层可控Diffusion模型布局到图像生成</span></a></h2><figure><img src="https://360cvgroup.github.io/HiCo_T2I/HiCo/framework.png" alt="HiCo Framework 图" tabindex="0" loading="lazy"><figcaption>HiCo Framework 图</figcaption></figure><p><strong>概要</strong>: <strong>HiCo-T2I</strong> 是由 <strong>360 CV 研究院</strong> 推出的新型 Hierarchical Controllable Diffusion Model，用于布局到图像生成任务。其核心创新在于引入分层控制策略，以更好地处理复杂场景和多对象布局。通过多分支结构和融合模块，该模型在空间解耦上表现优异。研究团队还构建了新的 HiCo-7K 基准数据集，用于评估模型在自然场景中的生成效果。</p><p><strong>标签</strong>: #Diffusion模型 #布局到图片 #可控生成 #360AIResearch</p><hr><h2 id="hunyuan3d-1-腾讯推出的高效3d内容生成模型" tabindex="-1"><a class="header-anchor" href="#hunyuan3d-1-腾讯推出的高效3d内容生成模型"><span>Hunyuan3D-1: :腾讯推出的高效3D内容生成模型</span></a></h2><figure><img src="https://raw.githubusercontent.com/Tencent/Hunyuan3D-1/main/assets/overview_3.png" alt="Hunyuan3D-1 Overview 图" tabindex="0" loading="lazy"><figcaption>Hunyuan3D-1 Overview 图</figcaption></figure><p><em>概要</em>*: <strong>Hunyuan3D-1</strong> 是 <strong>腾讯</strong> 推出的新一代 3D 内容生成模型，旨在实现高效的单图像 3D 重建和生成。该模型以其卓越的性能和高质量的 3D 网格输出而受到关注，尤其在实时性方面表现优异：标准模型在 NVIDIA A100 GPU 上可在 25 秒内完成单次 3D 重建，而精简版模型更快，仅需 10 秒。Hunyuan3D-1 的设计包含了多分辨率Diffusion模型结构，能够处理细节丰富的复杂场景，同时提供了一键安装工具，支持 Windows 环境和云计算服务，如 RunPod。</p><p><strong>标签</strong>: #3D重建 #图生3D #腾讯 #Diffusion模型l #实时性能</p><hr><h2 id="autovfx-物理真实感视频编辑算法" tabindex="-1"><a class="header-anchor" href="#autovfx-物理真实感视频编辑算法"><span>AutoVFX: 物理真实感视频编辑算法</span></a></h2><figure><img src="https://haoyuhsu.github.io/autovfx-website/src/imgs/teasor.png" alt="AutoVFX Teaser 图" tabindex="0" loading="lazy"><figcaption>AutoVFX Teaser 图</figcaption></figure><p><strong>概要</strong>: <strong>AutoVFX</strong> 是由 <strong>伊利诺伊大学</strong> 开发的一款基于自然语言指令的视频编辑算法，专注于提供物理真实感的效果。通过集成先进的分割模型（如 Grounded-SAM 和 DEVA）、修复模型（如 LaMa），以及 3D 重建技术（如 Gaussian Splatting 和 BakedSDF），该系统能够实现从语义跟踪、光照估计到视频内容修复的全流程自动化处理。AutoVFX 支持用户使用简单的文本提示进行编辑，极大地简化了视频制作过程，适用于广告制作、影视后期等场景。</p><p><strong>标签</strong>: #视频编辑 #自然语言处理 #GroundedSAM #3D重建</p><hr><h2 id="hellomeme-高级注意力机制驱动的生成模型" tabindex="-1"><a class="header-anchor" href="#hellomeme-高级注意力机制驱动的生成模型"><span>HelloMeme: 高级注意力机制驱动的生成模型</span></a></h2><figure><img src="https://songkey.github.io/hellomeme/static/images/image.jpg" alt="HelloMeme Comparison 图" tabindex="0" loading="lazy"><figcaption>HelloMeme Comparison 图</figcaption></figure><p><strong>概要</strong>: <strong>HelloMeme</strong> 是由 <strong>HelloVision</strong> 开发的创新型图像和视频生成工具，集成了 Spatial Knitting Attention（SKAttention）技术，显著提升了Diffusion模型的条件控制和生成效果。通过 SKAttention 机制，模型能够有效嵌入高层次的语义条件，实现更高保真度的图像与视频内容生成。 HelloMeme 提供了两个主要功能接口：图像生成和视频生成。用户可通过参考图像与驱动图像（或视频）进行内容生成，支持细粒度的面部追踪和风格化处理。项目还推出了 ComfyUI 界面，便于用户通过简单的操作体验模型功能，特别适用于创意制作和个性化表情包生成等场景。</p><p><strong>标签</strong>: #Diffusion模型 #注意力机制 #图像生成 #视频生成 # 表情控制</p><hr><h2 id="mvpaint-多视角一致的3d纹理生成模型" tabindex="-1"><a class="header-anchor" href="#mvpaint-多视角一致的3d纹理生成模型"><span>MVPaint: 多视角一致的3D纹理生成模型</span></a></h2><figure><img src="https://mvpaint.github.io/assets/pipeline.jpg" alt="MVPaint Pipeline 图" tabindex="0" loading="lazy"><figcaption>MVPaint Pipeline 图</figcaption></figure><p><strong>概要</strong>: <strong>MVPaint</strong> 是由 <strong>腾讯PCG</strong>、<strong>上海AI实验室</strong>、<strong>南洋理工S-Lab</strong> 和 <strong>清华大学</strong> 组成的 <strong>3DTopia</strong> 团队开发的一种多视角一致的 3D 纹理生成框架，专注于提高 3D 物体纹理的生成质量和一致性。该模型通过三个主要模块实现高效纹理合成：</p><ol><li><strong>同步多视角生成（SMG）</strong>：并行处理多视角图像生成，提高整体纹理一致性。</li><li><strong>空间感知 3D 修复（S3I）</strong>：利用修复模块填补未观察到的纹理区域，避免出现纹理空洞。</li><li><strong>UV 精细化（UVR）</strong>：通过 UV 空间的超分辨率和无缝平滑算法，提升纹理细节并减少 UV 展开造成的不连续问题。</li></ol><p>实验结果表明，MVPaint 在多视角一致性和高保真纹理生成上超越了现有的最先进方法，适用于游戏、影视等 3D 内容创作场景。</p><p><strong>标签</strong>: #3D纹理 #多视角一致性 #Diffusion模型 #纹理修复</p><hr><h2 id="promptfix-实现智能图像修复的diffusion模型" tabindex="-1"><a class="header-anchor" href="#promptfix-实现智能图像修复的diffusion模型"><span>PromptFix: 实现智能图像修复的Diffusion模型</span></a></h2><figure><img src="https://arxiv.org/html/2405.16785v2/extracted/5917194/figures/PromptFix.png" alt="PromptFix Teaser 图" tabindex="0" loading="lazy"><figcaption>PromptFix Teaser 图</figcaption></figure><p><strong>概要</strong>: <strong>PromptFix</strong> 是一款专为图像修复任务设计的Diffusion模型工具，由 <strong>微软亚研</strong> 推出。PromptFix 支持从用户提示中解析任务，并进行智能修复，包括上色、去雾、去模糊、去除水印和低光照增强等多种功能。模型核心采用 20 步去噪过程，能够在保留图像结构的基础上有效改善图像质量。PromptFix 提供了丰富的预训练模型和超过一百万样本的训练数据集，涵盖多个图像处理任务，为研究者和开发者提供强大的工具支持。</p><p><strong>标签</strong>: #图像修复 #Diffusion模型 # #图像增强</p><hr><h2 id="domaingallery-精细化领域适应的diffusion模型" tabindex="-1"><a class="header-anchor" href="#domaingallery-精细化领域适应的diffusion模型"><span>DomainGallery: 精细化领域适应的Diffusion模型</span></a></h2><figure><img src="https://arxiv.org/html/2411.04571v1/extracted/5984099/figures/intro.jpg" alt="DomainGallery Teaser 图" tabindex="0" loading="lazy"><figcaption>DomainGallery Teaser 图</figcaption></figure><p><strong>概要</strong>: <strong>DomainGallery</strong>是 <strong>上交</strong> 和 <strong>蚂蚁集团</strong> 提出的一种领域自适应的图像合成算法，专注于使用少量数据进行高质量生成。模型通过微调预训练模型，在目标域数据稀少的情况下依然能够生成高质量且多样化的图像。DomainGallery 引入了新的对比损失和参数冻结策略，减少了过拟合现象，特别适用于人脸生成、艺术风格迁移等需要精细领域迁移的任务。实验结果显示，DomainGallery 在生成质量和领域适应性上优于现有的方法，能够高效处理小样本和未见领域数据。</p><p><strong>标签</strong>: #Diffusion模型 #领域适应 #小样本学习 #图像合成</p><hr><h3 id="参考链接" tabindex="-1"><a class="header-anchor" href="#参考链接"><span>参考链接</span></a></h3><ol><li><a href="https://360cvgroup.github.io/HiCo_T2I/" target="_blank" rel="noopener noreferrer">HiCo-T2I 项目主页</a></li><li><a href="https://github.com/360CVGroup/HiCo_T2I" target="_blank" rel="noopener noreferrer">HiCo-T2I GitHub 仓库</a></li><li><a href="https://arxiv.org/pdf/2410.14324" target="_blank" rel="noopener noreferrer">HiCo-T2I 论文</a></li><li><a href="https://huggingface.co/qihoo360" target="_blank" rel="noopener noreferrer">HiCo-T2I 模型（Hugging Face）</a></li><li><a href="https://github.com/Tencent/Hunyuan3D-1" target="_blank" rel="noopener noreferrer">Hunyuan3D-1 GitHub 仓库</a></li><li><a href="https://huggingface.co/tencent/Hunyuan3D-1" target="_blank" rel="noopener noreferrer">Hunyuan3D-1 模型（Hugging Face）</a></li><li><a href="https://3d.hunyuan.tencent.com/hunyuan3d.pdf" target="_blank" rel="noopener noreferrer">Hunyuan3D-1 项目介绍 PDF</a></li><li><a href="https://haoyuhsu.github.io/autovfx-website/" target="_blank" rel="noopener noreferrer">AutoVFX 项目主页</a></li><li><a href="https://github.com/haoyuhsu/autovfx" target="_blank" rel="noopener noreferrer">AutoVFX GitHub 仓库</a></li><li><a href="https://arxiv.org/pdf/2411.02394" target="_blank" rel="noopener noreferrer">AutoVFX 论文</a></li><li><a href="https://songkey.github.io/hellomeme/" target="_blank" rel="noopener noreferrer">HelloMeme 项目主页</a></li><li><a href="https://github.com/HelloVision/HelloMeme" target="_blank" rel="noopener noreferrer">HelloMeme GitHub 仓库</a></li><li><a href="https://arxiv.org/pdf/2410.22901" target="_blank" rel="noopener noreferrer">HelloMeme 论文</a></li><li><a href="https://mvpaint.github.io/" target="_blank" rel="noopener noreferrer">MVPaint 项目主页</a></li><li><a href="https://github.com/3DTopia/MVPaint" target="_blank" rel="noopener noreferrer">MVPaint GitHub 仓库</a></li><li><a href="https://arxiv.org/pdf/2411.02336" target="_blank" rel="noopener noreferrer">MVPaint 论文</a></li><li><a href="https://www.yongshengyu.com/PromptFix-Page/" target="_blank" rel="noopener noreferrer">PromptFix 项目主页</a></li><li><a href="https://github.com/yeates/promptfix" target="_blank" rel="noopener noreferrer">PromptFix GitHub 仓库</a></li><li><a href="https://arxiv.org/pdf/2405.16785" target="_blank" rel="noopener noreferrer">PromptFix 论文</a></li><li><a href="https://github.com/Ldhlwh/DomainGallery" target="_blank" rel="noopener noreferrer">DomainGallery GitHub 仓库</a></li><li><a href="https://arxiv.org/pdf/2411.04571" target="_blank" rel="noopener noreferrer">DomainGallery 论文</a></li></ol>',46)]))}]]),o=JSON.parse('{"path":"/zh/posts/ai-weekly/011.html","title":"腾讯Hunyuan3D重塑3D重建|MVPaint多视角提升3D材质一致性|PromptFix实现高质量图像修复【AI周报】","lang":"zh-CN","frontmatter":{"description":"腾讯Hunyuan3D重塑3D重建|MVPaint多视角提升3D材质一致性|PromptFix实现高质量图像修复【AI周报】 封面封面 摘要 本周聚焦视觉与生成领域突破：腾讯混元3D 推出高效3D重建工具，支持实时场景重建；MVPaint提升3D材质一致性，实现高质量多视角纹理生成；PromptFix利用Diffusion模型进行多任务图像修复，覆盖上...","gitInclude":[],"head":[["meta",{"property":"og:url","content":"https://neverbiasu.github.io/zh/posts/ai-weekly/011.html"}],["meta",{"property":"og:site_name","content":"Nlog"}],["meta",{"property":"og:title","content":"腾讯Hunyuan3D重塑3D重建|MVPaint多视角提升3D材质一致性|PromptFix实现高质量图像修复【AI周报】"}],["meta",{"property":"og:description","content":"腾讯Hunyuan3D重塑3D重建|MVPaint多视角提升3D材质一致性|PromptFix实现高质量图像修复【AI周报】 封面封面 摘要 本周聚焦视觉与生成领域突破：腾讯混元3D 推出高效3D重建工具，支持实时场景重建；MVPaint提升3D材质一致性，实现高质量多视角纹理生成；PromptFix利用Diffusion模型进行多任务图像修复，覆盖上..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bb18d643-4bac-439b-a647-35b9355aee31/width=450/38613991.jpeg"}],["meta",{"property":"og:locale","content":"zh-CN"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"腾讯Hunyuan3D重塑3D重建|MVPaint多视角提升3D材质一致性|PromptFix实现高质量图像修复【AI周报】\\",\\"image\\":[\\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bb18d643-4bac-439b-a647-35b9355aee31/width=450/38613991.jpeg\\",\\"https://360cvgroup.github.io/HiCo_T2I/HiCo/framework.png\\",\\"https://raw.githubusercontent.com/Tencent/Hunyuan3D-1/main/assets/overview_3.png\\",\\"https://haoyuhsu.github.io/autovfx-website/src/imgs/teasor.png\\",\\"https://songkey.github.io/hellomeme/static/images/image.jpg\\",\\"https://mvpaint.github.io/assets/pipeline.jpg\\",\\"https://arxiv.org/html/2405.16785v2/extracted/5917194/figures/PromptFix.png\\",\\"https://arxiv.org/html/2411.04571v1/extracted/5984099/figures/intro.jpg\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"neverbiasu\\",\\"url\\":\\"https://mister-hope.com\\"}]}"]]},"headers":[{"level":2,"title":"摘要","slug":"摘要","link":"#摘要","children":[]},{"level":2,"title":"目录","slug":"目录","link":"#目录","children":[]},{"level":2,"title":"HiCo: 分层可控Diffusion模型布局到图像生成","slug":"hico-分层可控diffusion模型布局到图像生成","link":"#hico-分层可控diffusion模型布局到图像生成","children":[]},{"level":2,"title":"Hunyuan3D-1: :腾讯推出的高效3D内容生成模型","slug":"hunyuan3d-1-腾讯推出的高效3d内容生成模型","link":"#hunyuan3d-1-腾讯推出的高效3d内容生成模型","children":[]},{"level":2,"title":"AutoVFX: 物理真实感视频编辑算法","slug":"autovfx-物理真实感视频编辑算法","link":"#autovfx-物理真实感视频编辑算法","children":[]},{"level":2,"title":"HelloMeme: 高级注意力机制驱动的生成模型","slug":"hellomeme-高级注意力机制驱动的生成模型","link":"#hellomeme-高级注意力机制驱动的生成模型","children":[]},{"level":2,"title":"MVPaint: 多视角一致的3D纹理生成模型","slug":"mvpaint-多视角一致的3d纹理生成模型","link":"#mvpaint-多视角一致的3d纹理生成模型","children":[]},{"level":2,"title":"PromptFix: 实现智能图像修复的Diffusion模型","slug":"promptfix-实现智能图像修复的diffusion模型","link":"#promptfix-实现智能图像修复的diffusion模型","children":[]},{"level":2,"title":"DomainGallery: 精细化领域适应的Diffusion模型","slug":"domaingallery-精细化领域适应的diffusion模型","link":"#domaingallery-精细化领域适应的diffusion模型","children":[{"level":3,"title":"参考链接","slug":"参考链接","link":"#参考链接","children":[]}]}],"readingTime":{"minutes":6.53,"words":1959},"filePathRelative":"zh/posts/ai-weekly/011.md","excerpt":"\\n<figure><img src=\\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bb18d643-4bac-439b-a647-35b9355aee31/width=450/38613991.jpeg\\" alt=\\"封面\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>封面</figcaption></figure>\\n<h2>摘要</h2>\\n<p>本周聚焦视觉与生成领域突破：腾讯混元3D 推出高效3D重建工具，支持实时场景重建；MVPaint提升3D材质一致性，实现高质量多视角纹理生成；PromptFix利用Diffusion模型进行多任务图像修复，覆盖上色、去雾等。其余详见正文。</p>","autoDesc":true}')}}]);