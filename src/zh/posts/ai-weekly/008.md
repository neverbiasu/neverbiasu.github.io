# **阿里开源Animate-X革新AI角色动画|ZeroComp实现创新3D对象合成|F5-TTS提升TTS语音的自然度【AI周报】**

![](https://fastly.jsdelivr.net/gh/bucketio/img12@main/2024/10/20/1729433178592-bd22ef03-8cac-448b-9ab1-3f2dcddac6c3.jpeg)

## **摘要**

本周AI周报关注几项前沿生成模型：ZeroComp在3D合成领域开辟新路径，CtrLoRA实现可控图像生成的高效框架，F5-TTS通过流匹配技术提升语音生成效果，HyperDreamBooth加快个性化文本到图像的速度。其余成果详见正文。

## **目录**

- [**阿里开源Animate-X革新AI角色动画|ZeroComp实现创新3D对象合成|F5-TTS提升TTS语音的自然度【AI周报】**](#阿里开源animate-x革新ai角色动画zerocomp实现创新3d对象合成f5-tts提升tts语音的自然度ai周报)
  - [**摘要**](#摘要)
  - [**目录**](#目录)
  - [**ZeroComp: 零样本对象合成**](#zerocomp-零样本对象合成)
  - [**CtrLoRA: ControlNet和LoRA高效结合**](#ctrlora-controlnet和lora高效结合)
  - [**Animate-X: 通用角色图像动画**](#animate-x-通用角色图像动画)
  - [**F5-TTS: 基于流匹配的高效文本到语音系统**](#f5-tts-基于流匹配的高效文本到语音系统)
  - [**HyperDreamBooth: 快速个性化文本到图像模型的超网络**](#hyperdreambooth-快速个性化文本到图像模型的超网络)
  - [**Janus: 统一多模态理解与生成框架**](#janus-统一多模态理解与生成框架)
    - [**参考链接**](#参考链接)

---

## **ZeroComp: 零样本对象合成**

![](https://lvsn.github.io/ZeroComp/assets/Pipeline1_or4.png)

ZeroComp Pipeline 图

**概要**：**ZeroComp**[1][2] 是**丰田**开发的一种零样本3D对象合成方法，利用图像内在特性实现无需配对图像的合成。它结合了ControlNet和Stable Diffusion模型，能够无缝地将虚拟3D对象集成到场景中，并在各类场景中表现出色，尤其是在室外合成方面。

**标签**：#3D合成 #ControlNet #Diffusion 模型 #零样本学习

---

## **CtrLoRA: ControlNet和LoRA高效结合**

![](https://github.com/xyfJASON/ctrlora/raw/main/assets/banner.jpg)

CtrlLoRA Banner 图

**概要**: **CtrLoRA**[3][4] 是**中科院**提出的一个可扩展的高效框架，用于可控图像生成。它通过一个基础ControlNet模型学习图像生成的通用知识，结合特定条件的LoRA，使用户可以快速适应新条件，减少90%的可学习参数。这一方法显著降低了训练成本，使得新手用户也能在短时间内实现良好结果。

**标签**: #ControlNet #LoRA #图像生成 #Diffusion 模型

---

## **Animate-X: 通用角色图像动画**

![](https://img.alicdn.com/imgextra/i3/O1CN01QZs1bU1LoW68dhIb2_!!6000000001346-0-tps-1783-856.jpg)

Animate-X Results 图

**概要**: **Animate-X**[5][6] 是由阿里研究院提出的一个通用角色动画框架。该系统基于 LDM 模型，通过引入隐式和显式姿势指示器，增强对运动模式的表示，实现高质量动画生成，支持人类和拟人角色。其新提出的 **A²Bench** 基准测试用于评估动画效果，实验表明其在性能上超越现有方法。

**标签**: #角色动画 #阿里 #运动表示 #LDM

---

## **F5-TTS: 基于流匹配的高效文本到语音系统**

![](https://swivid.github.io/F5-TTS/pics/f5tts_overview.png)

F5-TTS Overview 图

**概要**: **F5-TTS**[7][8][9] 是**上交**、**剑桥**和**吉利公司**一同研发的一个完全非自回归的文本到语音系统，基于流匹配和Diffusion Transformer (DiT) 模型。该系统通过填充标记和去噪生成语音，无需复杂的持续时间模型和文本编码器。F5-TTS展现出高自然度和表达力，支持无缝语言切换，训练在100K小时的多语言数据集上完成，实时生成效率达到0.15，极大提高了性能和效率。

**标签**: #文本到语音 #流匹配 #Diffusion Transformer #多语言

---

## **HyperDreamBooth: 快速个性化文本到图像模型的超网络**

![](https://hyperdreambooth.github.io/files/teaser_v2.png)

HyperDreamBooth Teaser 图

**概要**: **HyperDreamBooth**[10][11] 由 **Google Research** 提出，利用单张图像个人化文本到图像Diffusion模型，速度比DreamBooth快25倍。该方法采用超网络生成个性化权重，结合快速微调，能在约20秒内完成个性化，且生成的模型仅需100KB，展现出高效性和保真度。

**标签**: #超网络 #个性化生成 #Google #Diffusion 模型

---

## **Janus: 统一多模态理解与生成框架**

![](https://github.com/deepseek-ai/Janus/raw/main/images/teaser.png)

Janus Teaser 图

**概要**: **Janus**[12][13] 是**deepseek**提出的一个新型自回归框架，旨在统一多模态理解与生成。通过分离的视觉编码路径，该模型解决了传统方法的局限性，提升了灵活性与性能。实验显示，Janus在多项任务中超越了现有的统一模型和特定任务模型，成为下一代多模态模型的有力候选者。

**标签**: #多模态 #视觉编码 #自回归模型 #deepseek

---

### **参考链接**

1. [ZeroComp 项目主页](https://lvsn.github.io/ZeroComp)  
2. [ZeroComp 论文](https://arxiv.org/pdf/2410.08168)  
3. [CtrLoRA GitHub 仓库](https://github.com/xyfJASON/ctrlora)  
4. [CtrLoRA 论文](https://arxiv.org/pdf/2410.09400)  
5. [Animate-X 项目主页](https://lucaria-academy.github.io/Animate-X)  
6. [Animate-X Github 仓库](https://github.com/Lucaria-Academy/Animate-X)
7. [F5-TTS 项目主页](https://swivid.github.io/F5-TTS)  
8. [F5-TTS Github 仓库](https://github.com/SWivid/F5-TTS)
9. [F5-TTS 论文](https://arxiv.org/pdf/2410.06885)  
10. [HyperDreamBooth 项目主页](https://hyperdreambooth.github.io/)  
11. [HyperDreamBooth GitHub 仓库](https://github.com/JiauZhang/hyperdreambooth)  
12. [Janus GitHub 仓库](https://github.com/deepseek-ai/Janus)  
13. [Janus 论文](https://arxiv.org/pdf/2410.13848)  