# 多模态SOTA InternVL 3.5 | 统一风格生成 USO | 真实感角色动画 OmniHuman-1.5【AI周报】

## 摘要

本周亮点：OpenGVLab 开源了性能媲美商业模型的 InternVL 3.5 多模态模型系列；微软发布了 VibeVoice，一个能生成长达90分钟对话音频的开源TTS模型；字节跳动推出 OmniHuman-1.5，可从单张图片和音轨生成富有表现力的角色动画。详见正文，相关参考链接请见文末。

---

## 目录

1. [InternVL 3.5：性能媲美 GPT-4o 的开源多模态模型](#InternVL-3.5)
2. [VibeVoice：微软开源的长篇对话式音频生成模型](#VibeVoice)
3. [USO：字节跳动发布统一风格和主题的图像生成模型](#USO)
4. [OmniHuman-1.5：字节跳动推出富有表现力的角色动画生成模型](#OmniHuman-1.5)
5. [MV-RAG：检索增强的文本到3D生成，攻克域外概念难题](#MV-RAG)
6. [T2I-ReasonBench：评估文本到图像模型推理能力的新基准](#T2I-ReasonBench)

---

## InternVL 3.5：性能媲美 GPT-4o 的开源多模态模型

![InternVL 3.5 Performance 图](https://huggingface.co/OpenGVLab/InternVL3_5-241B-A28B/resolve/main/images/performance.jpg)

**概要**：**OpenGVLab** 发布了 **InternVL 3.5**，一个全新的开源多模态模型系列。该系列模型在多功能性、推理能力和推理效率方面均有显著提升，其最强大的版本 InternVL3.5-241B-A28B 在通用多模态、推理、文本和智能体任务上达到了开源模型的顶尖水平，性能可与 GPT-4o 等商业模型相媲美。此外，团队还提供了更小、更高效的模型版本，以适应不同应用场景的需求。

**标签**：#多模态 #大语言模型 #开源 #InternVL #OpenGVLab

---

## VibeVoice：微软开源的长篇对话式音频生成模型

![VibeVoice Evaluation 图](https://huggingface.co/microsoft/VibeVoice-1.5B/resolve/main/figures/Fig1.png)

**概要**：**微软**发布了 **VibeVoice**，一个前沿的开源文本转语音（TTS）模型，专为生成富有表现力的长篇多说话人对话音频（如播客）而设计。该模型能够生成长达90分钟、包含多达4个不同说话人的音频，解决了传统TTS系统在可扩展性、说话人一致性和自然轮换方面的挑战。

**标签**：#文本转语音 #TTS #开源 #Microsoft #VibeVoice

---

## USO：字节跳动发布统一风格和主题的图像生成模型

![USO Teaser 图](https://github.com/bytedance/USO/raw/main/assets/teaser.webp)

**概要**：**字节跳动** 的 **UXO** 团队发布了 **USO**（Unified Style-Subject Optimized），一个统一了风格驱动和主题驱动的图像生成模型。USO 能够将任意主题与任意风格自由结合，同时保持主题和风格的高度一致性与保真度。该模型采用解耦学习方案和风格奖励学习范式，实现了强大的生成效果。

**标签**：#图像生成 #风格迁移 #主题保留 #ByteDance #USO

---

## OmniHuman-1.5：字节跳动推出富有表现力的角色动画生成模型

![OmniHuman-1.5 Teaser 图](https://arxiv.org/html/2508.19209v1/figs/teaser.jpg)

**概要**：**字节跳动智能创作**团队发布了 **OmniHuman-1.5**，该模型能仅通过一张图片和一段音轨，生成富有表现力的长篇角色动画。其独特的“双系统”架构，结合了多模态大语言模型（MLLM）的规划能力和扩散变换器的快速反应能力，可生成超过一分钟的包含动态运动和复杂多角色互动的视频。

**标签**：#角色动画 #音频驱动 #多模态 #ByteDance #OmniHuman

---

## MV-RAG：检索增强的文本到3D生成，攻克域外概念难题

![MV-RAG Teaser 图](https://camo.githubusercontent.com/f0991ba8b1eb5b1bab2d8dcfcfcdc6c58edec774d58dd8851e4f6f7c48a8bcaf/68747470733a2f2f796f736566646179616e692e6769746875622e696f2f4d562d5241472f7374617469632f696d616765732f7465617365722e6a7067)

**概要**：**耶路撒冷希伯来大学**（The Hebrew University of Jerusalem）的研究人员提出了 **MV-RAG**，一个新颖的文本到3D生成管线。该方法利用检索增强生成（RAG）技术，从大型2D图像数据库中检索相关图像，并将其作为条件输入到多视图扩散模型中，从而为域外（out-of-domain）或罕见的概念生成一致且准确的3D模型。

**标签**：#文本到3D #检索增强生成 #RAG #3D建模 #OOD

---

## T2I-ReasonBench：评估文本到图像模型推理能力的新基准

![T2I-ReasonBench Teaser 图](https://github.com/KaiyueSun98/T2I-ReasonBench/raw/main/asset/teaser.png)

**概要**：来自**香港大学**和**香港中文大学**的研究人员推出了 **T2I-ReasonBench**，这是一个旨在探索文本到图像（T2I）模型推理能力边界的新型基准。该基准包含800个精心设计的提示，分为成语解读、文本图像设计、实体推理和科学推理四个维度，对模型的潜在含义推断、领域知识整合和上下文歧义解决能力提出了挑战。

**标签**：#基准测试 #文本到图像 #T2I #模型评测 #Reasoning

---

### **参考链接**
1.  [InternVL 3.5 项目主页](https://chat.intern-ai.org.cn/)
2.  [InternVL 3.5 GitHub 仓库](https://github.com/OpenGVLab/InternVL)
3.  [InternVL 3.5 论文](https://arxiv.org/html/2508.18265v2)
4.  [VibeVoice 项目主页](https://microsoft.github.io/VibeVoice/)
5.  [VibeVoice GitHub 仓库](https://github.com/microsoft/VibeVoice)
6.  [VibeVoice 论文](https://arxiv.org/html/2508.19205v1)
7.  [VibeVoice Hugging Face](https://huggingface.co/microsoft/VibeVoice-1.5B)
8.  [USO 项目主页](https://bytedance.github.io/USO/)
9.  [USO GitHub 仓库](https://github.com/bytedance/USO)
10. [USO 论文](https://arxiv.org/html/2508.18966v1)
11. [OmniHuman-1.5 项目主页](https://omnihuman-lab.github.io/v1_5/)
12. [OmniHuman-1.5 论文](https://arxiv.org/html/2508.19209v1)
13. [MV-RAG 项目主页](https://yosefdayani.github.io/MV-RAG/)
14. [MV-RAG GitHub 仓库](https://github.com/yosefdayani/MV-RAG)
15. [MV-RAG 论文](https://arxiv.org/html/2508.16577v1)
16. [T2I-ReasonBench GitHub 仓库](https://github.com/KaiyueSun98/T2I-ReasonBench)
17. [T2I-ReasonBench 论文](https://arxiv.org/html/2508.17472v1)
