# HiDream-I1引领图像生成 | Cobra支持海量上色参考 | InstantCharacter高效定制角色【AI周报】

![封面源自C站作者Koal2](https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/781e2f08-150f-4ce9-8cfe-0b9865785381/original=true,quality=90/00021-2797360292.jpeg)

## 摘要  

本周亮点：HiDream-I1 发布17B参数基础模型，支持多风格图像生成；Cobra 引入稀疏DiT，支持200+图像指导漫画上色；InstantCharacter 结合视觉编码与适配器结构，实现灵活角色定制。其余详见正文。

---

## 目录  

1. [Seaweed-7B：高效训练的视频生成基础模型](#seaweed-7b高效训练的视频生成基础模型)
2. [HiDream-I1：17B参数开源模型，支持多风格图像生成](#hidream-i117b参数开源模型支持多风格图像生成)
3. [Cobra：支持海量参考图的漫画线稿自动上色模型](#cobra支持海量参考图的漫画线稿自动上色模型)
4. [InstantCharacter：腾讯推出可扩展的角色定制扩散框架](#instantcharacter腾讯推出可扩展的角色定制扩散框架)
5. [DMM：多风格图像生成模型融合新范式](#dmm多风格图像生成模型融合新范式)
6. [FlexIP：灵活控制身份保持与个性化的图像生成框架](#flexip灵活控制身份保持与个性化的图像生成框架)
7. [Complex-Edit：支持多步修改的复杂图像编辑评估基准](#complex-edit支持多步修改的复杂图像编辑评估基准)

---

## Seaweed-7B：高效训练的视频生成基础模型

![Seaweed-7B VAE Overview 图](https://arxiv.org/html/2504.08685v1/x2.png)

**概要**：**Seaweed-7B** 是由 **Seaweed 团队** 提出的一款中等规模视频生成基础模型，具备70亿参数，专为高效训练设计。该方法结合优化的三维空间-时间 U-Net 架构与渐进式训练策略，使用多阶段分辨率提升和跨数据源多任务学习方式，在保持训练成本低的同时实现稳定的视频生成能力。模型设计强调灵活扩展和适应不同分辨率，适配多种视频生成任务场景。

**标签**：#视频生成 #基础模型 #三维U-Net #高效训练 #多任务学习

---

## HiDream-I1：17B参数开源模型，支持多风格图像生成

![HiDream-I1 Demo 图](https://github.com/HiDream-ai/HiDream-I1/raw/main/assets/demo.jpg)

**概要**：**HiDream-I1** 是由 **HiDream.ai** 发布的开源图像生成基础模型，拥有 17B 参数，支持多种风格的图像生成，包括写实、卡通和艺术风格。该模型在多个基准测试中表现优异，尤其在 GenEval 和 DPG-Bench 上取得领先成绩。HiDream-I1 提供全量模型及两个蒸馏版本，适配不同性能需求，支持商业用途，已集成至 ComfyUI 和 Hugging Face 平台，便于开发者快速部署和使用。

**标签**：#图像生成 #个性化定制 #多主体生成 #跨模态对齐 #位置编码

---

## Cobra：支持海量参考图的漫画线稿自动上色模型

![Cobra Teaser 图](https://zhuang2002.github.io/Cobra/fig/teaser.png)

**概要**：**Cobra** 是由 **清华大学、香港中文大学** 和 **腾讯 ARC 实验室** 联合提出的高效漫画线稿上色框架，旨在支持海量参考图指导下的自动上色任务。该方法最多支持 200 张参考图，同时结合用户色彩提示，在保持风格一致性的同时实现准确上色。Cobra 基于 Causal Sparse DiT 架构，引入可复用位置编码与稀疏注意力机制，显著提升推理速度和记忆效率，满足真实场景中对响应速度与质量的双重要求，具备良好的工业应用潜力。

**标签**：#线稿上色 #参考图引导 #漫画生成 #稀疏注意力 #CausalSparseDiT

---

## InstantCharacter：腾讯推出可扩展的角色定制扩散框架

![InstantCharacter Teaser 图](https://instantcharacter.github.io/static/images/teaser.png)

**概要**：**InstantCharacter** 是由 **腾讯 Hunyuan 团队** 提出的角色定制扩散框架，基于 Diffusion Transformer 架构，支持多风格、多姿态的角色个性化生成。其核心在于引入可扩展的全 Transformer 适配器，结合 SigLIP 与 DINOv2 等视觉编码器，提升角色特征提取与生成质量。训练采用三阶段策略，利用千万级角色数据集，分别优化身份一致性、文本可控性与图像保真度。该方法在保持高保真度的同时，实现了开放域角色的快速定制与文本驱动的灵活编辑，适用于动漫、游戏等多种创意场景。

**标签**：#角色定制 #扩散模型 #多风格生成 #高保真度 #文本可控性

---

## DMM：多风格图像生成模型融合新范式

![DMM Overview 图](https://github.com/MCG-NJU/DMM/raw/main/assets/method.jpg)

**概要**：**DMM** 是由 **南京大学多媒体计算研究组（MCG-NJU）** 提出的一种基于蒸馏的模型融合方法，旨在将多个专注于不同风格的文本到图像（T2I）生成模型压缩为一个统一的模型。通过引入风格可控的图像生成流程，DMM 能够在保持各个教师模型风格特性的同时，实现任意风格图像的生成。该方法有效解决了传统线性插值方法在风格融合中存在的兼容性和混淆问题，显著减少了参数冗余和存储成本，提升了模型的实用性和部署效率。

**标签**：#图像生成 #模型融合 #风格控制 #蒸馏学习 #多风格生成 

---

## FlexIP：灵活控制身份保持与个性化的图像生成框架

![FlexIP Teaser 图](https://flexip.oss-cn-beijing.aliyuncs.com/imgs/paper/teaser-diverse-prompt.jpg)

**概要**：**FlexIP** 是一个旨在在保持主体身份一致性的同时，实现个性化风格编辑的图像生成框架。该方法引入了两个独立的模块：Preservation Adapter 用于捕捉身份特征，Personalization Adapter 用于风格操控。通过动态调整这两个模块的权重，用户可以在生成过程中灵活控制图像的身份保持与个性化程度，满足多样化的图像生成需求。

**标签**：#图像生成 #身份保持 #个性化编辑 #动态控制 #多风格生成 

---

## Complex-Edit：支持多步修改的复杂图像编辑评估基准

![Complex-Edit Teaser 图](https://ucsc-vlaa.github.io/Complex-Edit/static/images/teaser.png)

**概要**：**Complex-Edit** 是一个专为评估图像编辑模型处理复杂指令能力而设计的基准，支持多步骤、连贯性强的图像编辑流程。该基准通过“Chain-of-Edit”方法生成一系列由 GPT-4o 合成的复杂编辑指令，涵盖颜色调整、对象添加、背景替换等操作类型，并配合自动化的多模态评估机制进行质量测评。Complex-Edit 强调对模型语义理解和连续执行能力的全面评估，有助于推动更强编辑泛化能力的发展。

**标签**：#图像编辑 #多步编辑 #复杂指令 #自动评估 #生成基准

---

### **参考链接**

1. [Seaweed-7B 项目主页](https://seaweed.video/)
2. [Seaweed-7B 论文链接](https://arxiv.org/html/2504.08685)
3. [HiDream-I1 GitHub 仓库](https://github.com/HiDream-ai/HiDream-I1)
4. [Cobra 项目主页](https://zhuang2002.github.io/Cobra/)
5. [Cobra GitHub 仓库](https://github.com/Zhuang2002/Cobra)
6. [Cobra 论文链接](https://arxiv.org/html/2504.12240v1)
7. [InstantCharacter 项目主页](https://instantcharacter.github.io/)
8. [InstantCharacter GitHub 仓库](https://github.com/Tencent/InstantCharacter)
9. [InstantCharacter 论文链接](https://arxiv.org/html/2504.12395v1)
10. [DMM GitHub 仓库](https://github.com/MCG-NJU/DMM)
11. [DMM 论文链接](https://arxiv.org/html/2504.12364v1)
12. [FlexIP 项目主页](https://flexip-tech.github.io/flexip/#/)
13. [FlexIP 论文链接](https://arxiv.org/html/2504.07405)
14. [Complex-Edit 项目主页](https://ucsc-vlaa.github.io/Complex-Edit/)
15. [Complex-Edit GitHub 仓库](https://github.com/UCSC-VLAA/Complex-Edit)
16. [Complex-Edit 论文链接](https://arxiv.org/html/2504.13143v1)
