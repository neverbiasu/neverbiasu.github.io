# EasyRef多模态高效图参考生成框架|SynCamMaster实现视角同步|SwiftEdit支持高速图像编辑【AI周报】

![封面源自C站作者tavoltennis837](https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/49053226-463c-4b1a-ae6d-74e4079be9f0/width=450/44419355.jpeg)

## 摘要  

本周聚焦生成与编辑：EasyRef 推出高效视频参考生成；SynCamMaster 实现多相机视角同步；StyleMaster 提供艺术风格视频转换；SwiftEdit 用单步扩散实现高速图像编辑，助力创意表达。详见正文。

---

## 目录

1. [EasyRef：多模态高效图参考生成框架](#EasyRef：多模态高效图参考生成框架)
2. [SynCamMaster：多相机视角同步视频生成](#SynCamMaster：多相机视角同步视频生成)
3. [StyleMaster：艺术风格视频生成与转换](#StyleMaster：艺术风格视频生成与转换)
4. [StyleStudio：文本驱动的多元素风格迁移](#StyleStudio：文本驱动的多元素风格迁移)
5. [DiffSensei：多模态定制化漫画生成框架](#DiffSensei：多模态定制化漫画生成框架)
6. [SwiftEdit：超高速文本引导图像编辑](#SwiftEdit：超高速文本引导图像编辑)

---

## EasyRef：多模态高效图参考生成框架

![EasyRef Teaser 图](https://easyref-gen.github.io/static/images/easyref_webpage/teaser_page_1.png)

**概要**：**EasyRef** 是一种面向扩散模型的多参考图像生成工具，结合多模态大模型 (MLLM) 和适配器结构实现个性化生成。通过高效的参考融合和渐进式训练，EasyRef 能捕获多张参考图像中的一致视觉元素，并支持零样本泛化任务。此外，其新推出的 MRBench 基准测试证明了在多领域生成中的卓越表现。

**标签**：#多模态AI #参考生成 #扩散模型 #个性化生成

---

## SynCamMaster：多相机视角同步视频生成

![SynCamMaster Pipeline 图](https://jianhongbai.github.io/SynCamMaster/pics/fig_pipe.jpg)

**概要**：**SynCamMaster** 是由浙江大学与快手联合开发的多相机同步视频生成框架，旨在提升开域场景的多视角一致性视频生成能力。框架采用预训练的文本到视频模型，并通过引入相机嵌入和视角同步模块，实现动态内容在不同视角之间的几何一致性。此外，项目设计了渐进式训练方案，利用合成与单目视频数据提高生成效果，可支持 6 自由度相机运动的内容创作。

**标签**：#多视角生成 #相机同步 #文本到视频 #动态一致性  

---

## StyleMaster：艺术风格视频生成与转换

![StyleMaster Pipeline 图](https://zixuan-ye.github.io/stylemaster/image/pipeline.png)

**概要**：**StyleMaster** 是一款聚焦视频艺术风格生成与转换的工具，结合局部纹理选择、全局风格提取和动作适配模块，有效提升生成质量。项目通过 Gray Tile ControlNet 提供精确内容引导，支持多样化的风格迁移。StyleMaster 能生成与参考图像风格高度一致的高质量视频，适用于艺术创作、动态设计等领域。

**标签**：#风格迁移 #视频生成 #内容引导 #ControlNet 

---

## StyleStudio：文本驱动的多元素风格迁移

![StyleStudio Teaser 图](https://stylestudio-official.github.io/assets/teaser.jpg)

**概要**：**StyleStudio** 是一款文本驱动的风格迁移工具，通过跨模态自适应归一化 (AdaIN) 和风格分类无引导方法 (SCFG)，实现对风格元素的选择性控制。框架还引入了教师模型，在早期生成阶段稳定空间布局，减少伪影产生。StyleStudio 不依赖额外微调，可轻松整合到现有风格迁移框架中，为文本到图像任务提供了更高质量和灵活性的风格控制。

**标签**：#风格迁移 #文本驱动 #多模态 #风格控制  #AdaIN

---

## DiffSensei：多模态定制化漫画生成框架

![DiffSensei Demo 图](https://jianzongwu.github.io/projects/diffsensei/static/images/nobel_prize/image.png)

**概要**：**DiffSensei** 是一种结合多模态大模型 (LLMs) 与扩散模型的漫画生成工具，支持从输入角色图像和文本描述生成定制化的黑白漫画。框架利用角色适配模块和细粒度生成控制方法，实现多分辨率漫画面板的灵活生成。此外，项目提供了开放数据集 MangaZero，进一步支持社区研究与实践。

**标签**：#漫画生成 #多模态大模型 #Diffusion模型 #角色适配

---

## SwiftEdit：超高速文本引导图像编辑

![SwiftEdit Overview 图](https://swift-edit.github.io/images/method/main_diagram.png)

**概要**：**SwiftEdit** 是一种基于单步扩散的图像编辑框架，专注于实现超高速文本引导的局部和全局图像修改。框架引入了一步反演 (one-step inversion) 和注意力重缩放机制，显著加快编辑速度（达 0.23 秒），且保持生成质量。相比多步扩散方法，SwiftEdit 计算效率提升超 50 倍，是一款面向实时图像编辑应用的突破性工具。

**标签**：#图像编辑 #单步扩散 #高效生成 #文本引导 #注意力机制

---

### **参考链接**

1. [EasyRef 项目主页](https://easyref-gen.github.io/)  
2. [EasyRef GitHub](https://github.com/TempleX98/EasyRef)  
3. [EasyRef 论文](https://arxiv.org/html/2412.09618)  
4. [SynCamMaster 项目主页](https://jianhongbai.github.io/SynCamMaster/)  
5. [SynCamMaster GitHub](https://github.com/KwaiVGI/SynCamMaster)  
6. [SynCamMaster 论文](https://arxiv.org/html/2412.07760v1)  
7. [StyleMaster 项目主页](https://zixuan-ye.github.io/stylemaster/)  
8. [StyleMaster GitHub](https://github.com/KwaiVGI/StyleMaster)  
9. [StyleMaster 论文](https://arxiv.org/html/2412.07744v1)  
10. [StyleStudio 项目主页](https://stylestudio-official.github.io/)  
11. [StyleStudio GitHub](https://github.com/Westlake-AGI-Lab/StyleStudio)  
12. [StyleStudio 论文](https://arxiv.org/html/2412.08503v1)  
13. [DiffSensei 项目主页](https://jianzongwu.github.io/projects/diffsensei/)  
14. [DiffSensei GitHub](https://github.com/jianzongwu/DiffSensei)  
15. [DiffSensei 论文](https://arxiv.org/html/2412.07589v1)  
16. [SwiftEdit 项目主页](https://swift-edit.github.io/#)  
17. [SwiftEdit 论文](https://arxiv.org/html/2412.04301v2)  
