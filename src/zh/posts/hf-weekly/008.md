# GLM-4.5V推理强化|Qwen-Image-Lightning提速25×|GameCraft开源【HF周报】

![封面图](/assets/images/placeholder.png)

## 摘要

本周亮点：Z.ai 推出 GLM‑4.5V（多模态+思维模式）；Qwen‑Image‑Lightning 4/8步蒸馏提速；腾讯开源 Hunyuan‑GameCraft。含 Gemma3‑270M、Jan‑v1‑4B、Ovis2.5‑2B、LFM2‑VL‑1.6B。详见正文与文末参考链接。

---

## 目录

1. [GLM-4.5V：MoE多模态+思维模式，兼顾基准与实用](#zai-orgglm-45vmoe多模态思维模式兼顾基准与实用)
2. [Qwen-Image-Lightning：4/8步蒸馏LoRA，提速12–25×](#lightx2vqwen-image-lightning48步蒸馏lora提速1225)
3. [Hunyuan-GameCraft-1.0：键鼠可控的交互式游戏视频生成](#tencenthunyuan-gamecraft-10键鼠可控的交互式游戏视频生成)
4. [gemma-3-270m：270M小体量多模态，32K上下文](#googlegemma-3-270m270m小体量多模态32k上下文)
5. [Jan-v1-4B：Agentic推理，SimpleQA达91.1%](#janhqjan-v1-4bagentic推理simpleqa达911)
6. [Ovis2.5-2B：NaViT原生分辨率+思维预算](#aidc-aiovis252bnavit原生分辨率思维预算)
7. [LFM2-VL-1.6B：面向边缘端的高效VLM](#liquidailfm2-vl-16b面向边缘端的高效vlm)

---

## GLM-4.5V：MoE多模态+思维模式，兼顾基准与实用

![GLM-4.5V Benchmark 图](https://raw.githubusercontent.com/zai-org/GLM-V/refs/heads/main/resources/bench_45v.jpeg)

**概要**：**Z.ai** 发布 **GLM-4.5V**，基于下一代旗舰文本基座 GLM-4.5-Air（MoE，106B参数、12B激活），在42项视觉语言基准同规模SOTA，覆盖图像/视频/文档理解、GUI智能体与定位等任务；并延续“Thinking Mode”思维开关，支持在快速响应与深度推理间灵活取舍，强调真实场景可用性与格式鲁棒性。

**标签**：#Z.ai #GLM-4.5V #MoE多模态 #思维模式开关 #GUI智能体

---

## Qwen-Image-Lightning：4/8步蒸馏LoRA，提速12–25×

**概要**：**ModelTC** 发布 **Qwen-Image-Lightning**（基于 Qwen-Image 的蒸馏加速方案），提供4步与8步LoRA权重，在多数场景保持接近基座质量的同时，实现约12–25×加速；兼容 Diffusers 与 ComfyUI 工作流，易于落地高效文生图，适合对吞吐与延迟要求敏感的生成应用。

**标签**：#ModelTC #Qwen-Image-Lightning #蒸馏加速 #Few-steps生成 #ComfyUI工作流

---

## Hunyuan-GameCraft-1.0：键鼠可控的交互式游戏视频生成

![Hunyuan-GameCraft Teaser 图](https://huggingface.co/tencent/Hunyuan-GameCraft-1.0/resolve/main/asset/teaser.png)

**概要**：**腾讯**发布 **Hunyuan-GameCraft-1.0**，面向游戏环境的高动态交互式视频生成框架。其创新在于将键盘与鼠标输入统一到共享相机表示空间，并采用混合历史条件训练以自回归扩展长序列，同时通过蒸馏优化推理效率与可玩性，支持多GPU并行与低显存单卡推理，向实时部署迈进。

**标签**：#Tencent #Hunyuan-GameCraft #交互式视频 #键鼠动作条件 #实时推理

---

## gemma-3-270m：270M小体量多模态，32K上下文

**概要**：**Google DeepMind** 发布 **Gemma 3 270M**，小体量多模态模型，支持文本与图像输入、文本输出，提供32K上下文（大规格至128K），多语言覆盖140+语言，适合资源受限环境部署；同时强调训练与伦理安全实践，并开放预训练与指令版权重（需同意使用条款）。

**标签**：#GoogleDeepMind #Gemma3-270M #小型多模态 #32K上下文 #开放可用条款

---

## Jan-v1-4B：Agentic推理，SimpleQA达91.1%

![Jan-v1-4B Benchmark 图](https://cdn-uploads.huggingface.co/production/uploads/65713d70f56f9538679e5a56/6CaETynCW18MXgDrbp_N9.png)

**概要**：**JanHQ** 发布 **Jan-v1-4B**，基于 Qwen3-4B-Thinking 强化推理与工具使用，面向 Jan App 的智能体任务，SimpleQA 达91.1% 显示在小体量上亦具良好事实问答能力；支持 vLLM 与 llama.cpp 本地部署，便于在桌面与私有环境快速体验与集成。

**标签**：#JanHQ #Jan-v1-4B #Agentic推理 #工具调用 #SimpleQA_91_1

---

## Ovis2.5-2B：NaViT原生分辨率+思维预算

![Ovis2.5-2B Benchmark 图](https://cdn-uploads.huggingface.co/production/uploads/637aebed7ce76c3b834cea37/kh-1dhZRAduP-P4SkIhXr.png)

**概要**：**AIDC-AI** 发布 **Ovis2.5-2B**，采用 NaViT 以原生分辨率处理变长图像，保留细节与全局布局，并在推理侧提供“思维模式/思维预算”以在延迟与准确间动态折中；在图表/文档OCR、视频理解与定位等任务上展示小模型强多模态能力，延续“小体量大性能”理念。

**标签**：#AIDC-AI #Ovis2_5-2B #NaViT原生分辨率 #思维预算 #图表文档OCR

---

## LFM2-VL-1.6B：面向边缘端的高效VLM

![LFM2-VL-1.6B 配图](https://cdn-uploads.huggingface.co/production/uploads/61b8e2ba285851687028d395/7_6D7rWrLxp2hb6OHSV1p.png)

**概要**：**Liquid AI** 发布 **LFM2‑VL‑1.6B**，基于 LFM2 语言塔与 SigLIP2 NaFlex 视觉编码器，提供原生分辨率处理、动态图像token、拼块与全局缩略联合策略，推理时可调速质权衡；相较同类小型VLM具更低时延，适合边缘端部署与垂直场景微调。

**标签**：#LiquidAI #LFM2-VL-1_6B #边缘端部署 #SigLIP2_NaFlex #可变分辨率

---

### **参考链接**

1. [GLM-4.5V](https://huggingface.co/zai-org/GLM-4.5V)
2. [Qwen-Image-Lightning](https://huggingface.co/lightx2v/Qwen-Image-Lightning)
3. [Hunyuan-GameCraft-1.0](https://huggingface.co/tencent/Hunyuan-GameCraft-1.0)
4. [gemma-3-270m](https://huggingface.co/google/gemma-3-270m)
5. [Jan-v1-4B](https://huggingface.co/janhq/Jan-v1-4B)
6. [Ovis2.5-2B](https://huggingface.co/AIDC-AI/Ovis2.5-2B)
7. [LFM2-VL-1.6B](https://huggingface.co/LiquidAI/LFM2-VL-1.6B)
