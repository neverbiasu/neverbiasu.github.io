# Wan2.2突破720P三模态视频生成 | Z.ai开源355B智能体GLM-4.5 | Intern-S1科学推理235B MoE【HF周报】

![封面图](/assets/images/placeholder.png)

## 摘要

本周亮点：Wan2.2发布5B和14B模型支持720P视频生成，Z.ai推出355B MoE架构的GLM-4.5智能体基础模型，Intern-S1发布235B科学推理多模态模型专攻科研领域。详细内容见下文，相关参考链接请见文末。

---

## 目录

1. [Wan2.2：首个支持文本-图像-视频三模态生成的720P模型](#wan22)
2. [GLM-4.5：355B参数MoE架构的开源智能体基础模型](#glm-45)
3. [Intern-S1：235B MoE科学推理多模态模型](#intern-s1)
4. [Step3：321B参数高效多模态推理模型](#step3)
5. [dots.ocr：1.7B参数多语言文档解析统一模型](#dotsocr)
6. [Skywork-UniPic-1.5B：统一视觉理解与生成模型](#skywork-unipic-15b)
7. [GPT-Image-Edit-1.5M：百万级GPT生成图像编辑数据集](#gpt-image-edit-15m)
8. [FLUX.1-Krea-dev：高质量快速图像生成在线体验](#flux1-krea-dev)

---

## Wan2.2：首个支持文本-图像-视频三模态生成的720P模型

![Wan2.2 Performance 图](https://huggingface.co/Wan-AI/Wan2.2-TI2V-5B/resolve/main/assets/performance.png)

**概要**：**Wan-AI**发布Wan2.2视频生成模型，这是业界首个统一支持文本到视频、图像到视频以及文本-图像到视频三种模态的720P高清视频生成系统。该模型引入了创新的MoE架构，通过高噪声专家和低噪声专家的动态切换，在保持计算成本不变的情况下大幅提升模型容量。5B版本采用高压缩Wan2.2-VAE实现4×32×32压缩比，可在单张RTX 4090上9分钟内生成5秒720P@24fps视频，在性能和效率方面均达到行业领先水平。

**标签**：#Wan-AI #MoE架构 #多模态视频生成 #Wan2.2系列 #高清视频合成

---

## GLM-4.5：355B参数MoE架构的开源智能体基础模型

![GLM-4.5 Benchmark 图](https://raw.githubusercontent.com/zai-org/GLM-4.5/refs/heads/main/resources/bench.png)

**概要**：**Z.ai**开源GLM-4.5智能体基础模型，这是一个采用355B总参数、32B激活参数的MoE架构大语言模型，专为智能体应用而设计。该模型统一了推理、编程和智能体能力，支持思考模式和非思考模式两种推理方式，在12项行业标准基准测试中获得63.2分的优异成绩，位列开源和商业模型第三位。GLM-4.5-Air紧凑版本采用106B总参数、12B激活参数，在保持高效率的同时达到59.8分的竞争性表现。

**标签**：#Z.ai #智能体模型 #混合推理 #GLM系列 #开源商用

---

## Intern-S1：235B MoE科学推理多模态模型

![Intern-S1 Logo 图](https://cdn-uploads.huggingface.co/production/uploads/642695e5274e7ad464c8a5ba/E43cgEXBRWjVJlU_-hdh6.png)

**概要**：**InternLM团队**发布Intern-S1多模态推理模型，基于235B MoE语言模型和6B视觉编码器构建，在5万亿多模态数据上进行连续预训练，其中超过2.5万亿为科学领域专用数据。该模型在保持强大通用能力的同时，在化学结构解释、蛋白质序列理解、化合物合成路径规划等科学领域任务中表现卓越，成为真实科学应用场景下的强大研究助手，并支持动态分词器实现对分子式、蛋白质序列的原生理解。

**标签**：#InternLM #科学推理 #多模态模型 #Intern-S1 #科研助手

---

## Step3：321B参数高效多模态推理模型

![Step3 Benchmark 图](https://huggingface.co/stepfun-ai/step3/resolve/main/figures/step3_bmk.jpeg)

**概要**：**StepFun**发布Step3多模态推理模型，采用321B总参数、38B激活参数的MoE架构设计，通过多矩阵分解注意力(MFA)和注意力-FFN分解(AFD)技术实现端到端的解码成本最小化。该模型在视觉-语言推理任务中达到顶级性能，同时在旗舰级和低端加速器上都保持出色的推理效率，为成本效益型多模态智能应用提供了理想的解决方案。

**标签**：#StepFun #成本效益 #推理优化 #Step3 #多模态智能

---

## dots.ocr：1.7B参数多语言文档解析统一模型

![dots.ocr Evaluation 图](https://raw.githubusercontent.com/rednote-hilab/dots.ocr/master/assets/chart.png)

**概要**：**小红书**发布dots.ocr多语言文档解析模型，这是一个基于1.7B参数LLM的统一视觉-语言模型，在单一架构内同时实现布局检测和内容识别，并保持良好的阅读顺序。该模型在OmniDocBench上达到SOTA性能，支持100多种低资源语言的文档解析，通过简单的提示词切换即可在不同任务间转换，证明了VLM在传统检测任务中的竞争优势，为文档智能化处理提供了更简洁高效的解决方案。

**标签**：#小红书 #文档解析 #多语言支持 #dots.ocr #OCR识别

---

## Skywork-UniPic-1.5B：统一视觉理解与生成模型

![Skywork-UniPic-1.5B Teaser 图](https://huggingface.co/Skywork/Skywork-UniPic-1.5B/resolve/main/teaser-1.png)

**概要**：**昆仑万维**发布Skywork-UniPic-1.5B统一多模态模型，这是一个15亿参数的自回归模型，在单一架构内支持图像理解、文本到图像生成和图像编辑三大核心视觉-语言任务。该模型从零开始在大规模多模态语料上训练，在GenEval、DPG-Bench等多项基准测试中取得竞争性结果，为统一图像-文本任务提供了高效的解决方案。

**标签**：#昆仑万维 #统一架构 #自回归模型 #Skywork系列 #图像生成编辑

---

## GPT-Image-Edit-1.5M：百万级GPT生成图像编辑数据集

![GPT-Image-Edit-1.5M Teaser 图](https://ucsc-vlaa.github.io/GPT-Image-Edit/static/images/GPT-Edit_teaser_image-cropped.png)

**概要**：**UCSC-VLAA**团队发布GPT-Image-Edit-1.5M数据集，这是一个包含155万样本的大规模图像编辑数据集，基于HQ-Edit、UltraEdit、OmniEdit和Complex-Edit构建，所有输出图像均由GPT-Image-1重新生成。数据集涵盖原始、重写和复杂三种指令复杂度级别，统一了多种图像编辑任务，为训练高质量图像编辑模型提供了宝贵的数据资源。

**标签**：#UCSC-VLAA #图像编辑数据集 #GPT生成 #数据集构建 #训练资源

---

## FLUX.1-Krea-dev：高质量快速图像生成在线体验

![FLUX.1-Krea-dev Teaser 图](https://huggingface.co/black-forest-labs/FLUX.1-Krea-dev/resolve/main/teaser.png)

**概要**：**Black Forest Labs**推出FLUX.1-Krea-dev在线演示空间，这是基于FLUX.1模型的增强版图像生成服务，专为快速高质量图像创作而优化。该平台结合了FLUX.1的强大生成能力与Krea的用户友好界面，为创作者提供直观便捷的AI图像生成体验，支持多种风格和主题的创意图像制作，展现了商业级图像生成模型的实用价值和应用潜力。

**标签**：#Black Forest Labs #在线服务 #图像生成平台 #FLUX模型 #创意工具

---

### **参考链接**

1. [Wan2.2-TI2V-5B模型](https://huggingface.co/Wan-AI/Wan2.2-TI2V-5B)
2. [Wan2.2-T2V-A14B模型](https://huggingface.co/Wan-AI/Wan2.2-T2V-A14B)
3. [GLM-4.5模型](https://huggingface.co/zai-org/GLM-4.5)
4. [Intern-S1模型](https://huggingface.co/internlm/Intern-S1)
5. [Step3模型](https://huggingface.co/stepfun-ai/step3)
6. [dots.ocr模型](https://huggingface.co/rednote-hilab/dots.ocr)
7. [Skywork-UniPic-1.5B模型](https://huggingface.co/Skywork/Skywork-UniPic-1.5B)
8. [GPT-Image-Edit-1.5M数据集](https://huggingface.co/datasets/UCSC-VLAA/GPT-Image-Edit-1.5M)
9. [FLUX.1-Krea-dev演示空间](https://huggingface.co/spaces/black-forest-labs/FLUX.1-Krea-dev)
