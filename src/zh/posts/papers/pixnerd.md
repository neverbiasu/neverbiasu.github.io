# 【论文精读】PixNerd：像素神经场扩散

![示例样本（256×256 与 512×512），由 PixNerd-XL/16 生成；CFG=3.5，展示整体生成质量与风格多样性](https://arxiv.org/html/2507.23268v2/x3.png)

## 摘要

PixNerd 将神经场融入扩散 Transformer，于像素空间按块解码像素速度，无需 VAE。ImageNet 256×256 FID 2.16、512×512 FID 2.84；GenEval 0.73、DPG 80.9，训练推理与潜在扩散同量级。

---

## 目录

1. [背景与研究目标](#背景与研究目标)  
2. [方法与创新点](#方法与创新点)  
3. [实验与结果分析](#实验与结果分析)  
4. [模型启发与方法延伸](#模型启发与方法延伸)  
5. [结论与未来展望](#结论与未来展望)  

---

## 背景与研究目标

1. 背景与问题：主流扩散模型多在 VAE 压缩的潜在空间中训练（如 DiT、SiT），计算高效但存在两阶段范式带来的累积误差与解码伪影。直接像素空间扩散虽可避免 VAE 伪影，但因高维度与大 patch 学习困难，常需复杂级联流程，训练/采样负担重。
2. 相关工作与数据集：对比 LDM/DiT/SiT 等潜在扩散，以及 ADM、PixelFlow、RDM 等像素扩散；主要实验在 ImageNet 256×256 与 512×512，文本到图像在 GenEval 与 DPG 基准上评测。
3. 研究目标：提出单尺度、单阶段、端到端的像素空间扩散框架，在不依赖 VAE 的前提下兼顾高保真与高效率，并在大 patch 设置下学习细粒度细节。

---

## 方法与创新点、

![左：与其他扩散范式对比；右：PixNerd 架构，遵循 DiT 设计并以神经场替代最终线性投影以建模大块内细节](https://arxiv.org/html/2507.23268v2/x2.png)

### 1. 整体流程：

在扩散 Transformer（Rectified Flow 速度参数化）中，最后的“逐块线性投影”被“逐块神经场解码”替代。具体做法是用 Transformer 的隐藏状态为每个图像块预测一组小型 MLP 的权重，然后将块内像素坐标的编码与噪声像素拼接输入该 MLP，输出像素级速度，完成去噪。
  1. 按块权重预测：由隐藏状态 Xⁿ 经 SiLU+Linear 预测 {W¹ⁿ, W²ⁿ}，构成该块的 MLP；对权重与输出特征施以行/特征归一化以稳定训练与收敛。
  2. 坐标编码：采用 DCT-Basis 相比传统正弦/余弦编码收敛更快、细节更优；将局部像素坐标 (i,j) 编码后与噪声像素值拼接供块内 MLP 解码像素速度。
  3. 单尺度、单阶段：保持与潜在扩散近似的 token 数，不使用级联金字塔与 VAE，简化训练与推理。

### 2. 关键增强：
  1. 架构与训练：SwiGLU、RMSNorm、RoPE、lognorm sampling 调度；引入与 DINOv2-Base 的表示对齐损失（权重 0.5），提升稳定性与感知质量。
  2. 采样器：实践表明 Adams 二阶求解器在有限步数下优于欧拉；间隔式 CFG（区间约 [0.1,1]，默认 3.5）带来更好 FID。

### 3. 与现有方法的不同：
不依赖 VAE，无两阶段误差与解码伪影；相较像素级级联方法（如 PixelFlow/RDM），以单阶段端到端替代复杂管线；相较“线性投影解码”，按块神经场能在大 patch 下保留像素级细节。

---

## 实验与结果分析

![文本到图像 512×512 可视化示例，展示不同长度与风格的文本描述。针对不同长度和风格的文本输入，PixNerd 能以大 patch（16）生成高质量样本。采样采用 Adams 二阶求解器（25 步），CFG 设为 4.0。](https://arxiv.org/html/2507.23268v2/x4.png)

### 1. 计算效率：

  1. 资源对比显示，PixNerd 训练/推理显存与延迟与潜在扩散相当；相较 ADM-G、PixelFlow 等像素扩散，延迟近 8× 更优，使直接像素合成具备实用性。

### 2. 类别到图像（ImageNet）：

  1. 256×256：PixNerd-XL/16 在 50 步 Adams-2 下达 2.16 FID（Euler-100 为 2.15），与 DiT/SiT 等潜在扩散相当，显著优于 JetFormer/FractalMAR/ADM 等像素基线；
  2. 512×512：微调达 2.84 FID，继续保持竞争力。

### 3. 文本到图像：

  1. 使用 ~45M 开源数据训练，PixNerd-XXL/16 在 GenEval 总分 0.73、DPG 平均 80.9，优于 PixelFlow，并与部分主流潜在扩散模型竞争。

### 4. 任意分辨率（免训练）：

![免训练任意分辨率生成；保持预训练分辨率的 token 数，仅对神经场坐标做插值以适配目标分辨率](https://arxiv.org/html/2507.23268v2/x5.png)

  1. 通过在 Transformer 中保持 token 数不变，仅插值神经场坐标来匹配目标分辨率，实现无需重新训练的任意分辨率/纵横比生成。

### 消融与关键结论

1. 坐标编码：DCT-Basis 显著优于 sin/cos 编码；
2. 神经场归一化：对 FC1/FC2 权重与输出特征同时归一化最佳；
3. MLP 结构：2 层、64 通道在性能/效率间最优折中；
4. 推理：Adams-2 在有限步数下优于欧拉，CFG 约 3.4–3.6 最优。

---

## 模型启发与方法延伸

1. 神经场可作为“可微像素解码器”无缝嵌入生成模型，在保持可控 token 规模下，增强大 patch 的细粒度表达能力；
2. 与语义表征对齐（如 DINOv2、CLIP）结合，有望进一步提升构图与结构一致性；
3. 训练与部署简化（无 VAE、无级联）对工业落地友好；任意分辨率机制为长宽比自适应与分辨率放大提供工程思路；
4. 后续可探索原生长宽比训练、像素空间后训练与奖励建模、与视频/3D 神经场的跨域迁移等。

---

## 结论与未来展望

1. 贡献总结：提出单尺度、单阶段、端到端的像素扩散框架 PixNerd，以按块神经场解码替代线性投影，在 ImageNet 与 T2I 基准上达到与潜在扩散相当的质量与效率，并显著优于既有像素扩散方法；
2. 优势与不足：优点在于无 VAE 伪影、管线简洁、任意分辨率灵活与高效采样；不足包括个别场景细节仍不清晰，与部分最强潜在模型仍存在指标差距；
3. 展望：结合更强文本编码与多模态对齐、原生尺寸训练与像素空间 SFT/RL，将进一步缩小差距；神经场解码范式有望拓展到视频、3D 与跨模态生成。

---

### **参考链接**

1. [项目主页](https://huggingface.co/spaces/MCG-NJU/PixNerd)
2. [代码仓库](https://github.com/MCG-NJU/PixNerd)
3. [模型仓库](https://huggingface.co/spaces/MCG-NJU/PixNerd)
4. [论文原文](https://arxiv.org/abs/2507.23268)
