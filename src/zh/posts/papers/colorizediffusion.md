# 【论文精读】ColorizeDiffusion：基于参考图像和文本的可调整草图上色方法

![ColorizeDiffusion Teaser](https://arxiv.org/html/2401.01456v3/x1.png)

## 摘要

ColorizeDiffusion由东京工业大学研究团队提出，旨在解决草图上色中的"分布问题"——参考图像与草图结构的平衡困境。基于扩散模型，该方法通过三种创新训练策略和零样本文本调控，实现精确可控的上色效果，支持动漫/漫画风格创作。

---

## 目录

1. [背景与研究目标](#背景与研究目标)  
2. [方法与创新点](#方法与创新点)  
3. [实验与结果分析](#实验与结果分析)  
4. [模型启发与方法延伸](#模型启发与方法延伸)  
5. [结论与未来展望](#结论与未来展望)  

---

## 背景与研究目标

### 问题：参考图像上色的"分布问题"

现有参考图像上色方法面临一个根本性矛盾。即使是先进的T2I（Text-to-Image）模型，在结合如ControlNet等工具进行草图引导上色时，也可能出现"分布问题"。如下图所示，当文本提示与草图结构存在潜在冲突时（例如，提示中描述的服装覆盖了草图中的手臂区域），模型可能优先遵循文本提示，导致与草图不一致的分割和颜色分配，尤其是在预期为肤色的区域。具体而言，下图展示了网络在手臂区域优先处理提示条件而非草图，导致非预期的上色差异，尤其是在预期为肤色的区域，造成视觉上不协调的分割。此结果由ControlNet_lineart_anime + Anything v3框架生成。

![T2I上色中的分布问题示例](https://arxiv.org/html/2401.01456v3/x2.png)

- **核心挑战**：参考图像提供了丰富的颜色信息，但往往导致结果优先参考图像信息而忽略草图结构。
- **本质分析**：在分布层面，上色结果分布 $$p(z|s,r)$$ 偏离单纯基于草图的分布 $$p(z|s)$$，导致结构失真。下图直观地展示了这一问题：训练后，优化后的条件生成分布 $$p_{\theta}(z|s,r)$$ 的大部分区域会偏离仅基于草图的理想分布 $$p(z|s)$$。

![条件生成分布与理想草图分布的偏离](https://arxiv.org/html/2401.01456v3/x4.png)

### 图像特征表示与CLS标记

在理解ColorizeDiffusion的创新之前，需要了解视觉特征表示的基本概念：

- **CLS标记（Class Token）**：源自视觉Transformer（ViT）和CLIP等模型，是一种特殊标记，用于捕获整个图像的全局特征。它通常位于序列开始位置，经过自注意力机制后包含图像整体语义信息。

- **本地标记（Local Tokens）**：代表图像不同区域的局部特征，保留位置和细节信息，有助于精确控制特定区域。

ColorizeDiffusion基于这两种特征表示方式，设计了全局CLS模型和局部注意力模型两种变体，分别适用于不同精度和效率需求的上色场景。

### 三大创新点

1. **分布问题解决策略**：提出丢弃训练、噪声训练和双条件训练三种策略，系统解决参考图像与草图结构的平衡问题

2. **双重模型架构**：设计CLS模型（全局特征）和注意力模型（局部特征）两种架构，适应不同应用场景和用户需求

3. **零样本文本调控**：无需重训练即可通过文本提示精确调整上色结果，支持全局和局部两种调控机制

---

## 方法与创新点

### 架构概览

ColorizeDiffusion基于Stable Diffusion微调，包含两种主要模型变体：

| 模型类型 | 特征获取 | 优势 | 应用场景 |
|---------|---------|------|----------|
| **CLS模型** | 仅使用CLS标记（全局特征） | 参数少、计算高效、操作简单 | 全局颜色调整、快速原型 |
| **注意力模型** | 使用所有本地标记（局部特征） | 质量高、保留结构好、局部控制精确 | 精细上色、细节调整 |

下图展示了CLS模型的训练流程示意图。
![CLS模型的训练流程](https://arxiv.org/html/2401.01456v3/x6.png)

### 三种解决"分布问题"的创新策略

1. **丢弃训练**：
   - 训练中高概率（0.75-0.8）随机丢弃参考图像
   - 减缓交叉注意力模块优化，保持模型对草图结构敏感

2. **噪声训练** （最有效）：
   - 向参考图像特征添加动态噪声：$$\tau_{\phi,t}(r)=\alpha_t \cdot \tau_{\phi}(r) + \beta_t \cdot \epsilon_r$$
   - 降低参考图像语义权重，同时避免模型退化为编码器解码器

3. **双条件训练**：
   - 添加辅助损失项：$$\lambda \cdot \|\epsilon^{\prime} - \epsilon^{\prime}_{\theta}(z^{\prime}_t,t,s)\|^2_2$$
   - 直接惩罚仅基于草图结果与真实图像差异

### 文本调控技术

无需重训练即可通过文本提示精确调整上色结果。推理流程如下图所示，图像标记（image tokens）在输入到去噪U-Net之前被编辑。图中具体展示了注意力模型使用局部操控（local manipulation）生成的结果。

![ColorizeDiffusion推理流程](https://arxiv.org/html/2401.01456v3/x7.png)

**1. 全局文本调控** (CLS模型)
- 通过调整全局CLS标记实现整体颜色变化
- 支持增强/替换两种操作模式和强度控制

**2. 局部文本调控** (注意力模型)
- 使用位置权重矩阵(PWM)定位并修改特定区域
- 基于目标文本(如"紫色头发")和锚文本(如"棕色头发")计算相关性

---

## 实验与结果分析

本章节介绍ColorizeDiffusion模型的关键实验结果与评估。

### 训练策略比较与消融实验

论文比较了三种解决"分布问题"的训练策略效果。噪声训练策略在保持草图结构和色彩丰富度方面表现最佳，能有效减轻分布问题。消融实验表明，合适的噪声级别和丢弃率对生成质量有显著影响。

![不同训练策略上色效果对比](https://arxiv.org/html/2401.01456v3/x3.png)

对比图显示噪声训练的ColorizeDiffusion(d行)比其他方法更好地平衡了草图结构与参考颜色。特别是Shuffle-noisy模型即使在长时间训练后，仍能保持对草图输入的语义保真度。

![消融研究中的模型上色结果](https://arxiv.org/html/2401.01456v3/x11.png)

### 模型架构与调控技术评估

#### CLS与Attention模型对比

论文提出的两种架构各有优势：Attention模型在细节保留和颜色迁移精确性上表现更优；CLS模型结构更简单、计算效率更高，适用于对细节要求不高的快速上色场景。

![CLS与Attention模型效果对比](https://arxiv.org/html/2401.01456v3/x8.png)

#### 文本调控能力评估

在局部文本调控中，位置权重矩阵(PWM)是关键组件，通过调整阈值可以精确控制编辑区域范围。实验表明，局部调控能更精确地改变目标区域（如头发颜色），同时保持其他区域不变。

![位置权重矩阵效果与全局/局部调控对比](https://arxiv.org/html/2401.01456v3/x9.png)

局部文本操控不仅能修改特定对象的颜色或纹理，还能保持整体图像风格的一致性，使编辑更加自然。

### 与现有方法对比

ColorizeDiffusion与现有方法在颜色准确性、结构保持、细节丰富度等方面进行了对比。结果表明，该方法在保持草图结构的同时，能更好地转移参考图像的颜色信息。

![与现有方法效果对比](https://arxiv.org/html/2401.01456v3/x15.png)

用户研究也验证了模型的实用性和在真实场景中的接受度，参与者普遍认为ColorizeDiffusion生成的结果在视觉质量和一致性上更为出色。

### 综合优势

实验结果突显了ColorizeDiffusion的四大优势：

**结构保真**：有效解决"分布问题"，保持草图线条完整性  
**颜色转移**：准确从参考图像提取颜色信息  
**灵活控制**：支持全局/局部颜色调整，无需重训练  
**多样适配**：两种模型架构适应不同场景需求  

---

## 模型启发与方法延伸

### 技术启示

1. **分布问题的普适性**：可推广至其他多条件生成任务
2. **模块化架构设计**：功能分离为独立模块，用户可按需选择
3. **交互式生成范式**：初始生成+交互式调整，无需重训练实现精细控制

### 应用场景拓展

**动漫/漫画制作**：减轻专业艺术家上色负担，提供快速原型工具  
**艺术教育**：帮助学习者理解颜色应用原理，提供即时反馈  
**游戏/媒体**：支持内容创作中的个性化颜色方案设计  
**跨领域应用**：可拓展到建筑设计、时装设计等领域

---

## 结论与未来展望

### 主要贡献总结

1. 系统分析并解决参考图像上色的"分布问题"，通过三种创新训练策略实现结构保真
2. 设计互补的双模型架构，适应不同应用场景和用户需求
3. 提出零样本文本调控技术，实现精确调整而无需重训练

### 局限性与未来改进

1. **局部调控精度**：当目标区域相近时，PWM可能影响非预期区域
2. **参数调整复杂**：用户需通过实验确定合适的阈值参数
3. **计算资源需求**：模型规模较大，低端设备上应用受限

### 未来研究方向

- 开发自适应可训练模块，减少参数调整需求
- 探索更轻量级的模型设计，降低运行门槛
- 拓展到更多艺术风格，增强通用性

---

### 参考链接

1. [论文原文](https://arxiv.org/abs/2401.01456)
2. [项目代码仓库](https://github.com/tellurion-kanata/colorizeDiffusion)
3. [Hugging Face模型权重](https://huggingface.co/tellurion/colorizer)
