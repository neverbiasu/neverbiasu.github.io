<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.17" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.58" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://neverbiasu.github.io/zh/posts/ai-weekly/018.html"><meta property="og:site_name" content="Nlog"><meta property="og:title" content="Qwen2.5定义多模态模型新高度|DeepSeek-V3突破混合专家能力|Mulberry强化推理反思【AI周报】"><meta property="og:description" content="Qwen2.5定义多模态模型新高度|DeepSeek-V3突破混合专家能力|Mulberry强化推理反思【AI周报】 封面源自C站作者Meower2024封面源自C站作者Meower2024 摘要 本周聚焦大模型与多模态：Qwen2.5 优化预训练与后训练，定义多模态模型新标准；DeepSeek-V3 引入混合专家架构，提升训练效率；Mulberry ..."><meta property="og:type" content="article"><meta property="og:image" content="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b338b22c-394c-4ae0-88d2-2bf15fa83809/original=true,quality=90/47422369.jpeg"><meta property="og:locale" content="zh-CN"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Qwen2.5定义多模态模型新高度|DeepSeek-V3突破混合专家能力|Mulberry强化推理反思【AI周报】","image":["https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b338b22c-394c-4ae0-88d2-2bf15fa83809/original=true,quality=90/47422369.jpeg","https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-72B-Instruct-Score.jpg","https://johanan528.github.io/depthlab_web/static/images/pipeline.jpeg","https://epiphqny.github.io/PAR-project/static/images/image_generation.jpg","https://github.com/deepseek-ai/DeepSeek-V3/raw/main/figures/benchmark.png","https://onevfall.github.io/project_page/ditctrl/static/images/framework.jpg","https://arxiv.org/html/2412.18319v1/x2.png"],"dateModified":null,"author":[{"@type":"Person","name":"neverbiasu","url":"https://mister-hope.com"}]}</script><title>Qwen2.5定义多模态模型新高度|DeepSeek-V3突破混合专家能力|Mulberry强化推理反思【AI周报】 | Nlog</title><meta name="description" content="Qwen2.5定义多模态模型新高度|DeepSeek-V3突破混合专家能力|Mulberry强化推理反思【AI周报】 封面源自C站作者Meower2024封面源自C站作者Meower2024 摘要 本周聚焦大模型与多模态：Qwen2.5 优化预训练与后训练，定义多模态模型新标准；DeepSeek-V3 引入混合专家架构，提升训练效率；Mulberry ...">
    <link rel="stylesheet" href="/assets/css/styles.580a8cdb.css">
    <link rel="preload" href="/assets/js/runtime~app.4b99fa82.js" as="script"><link rel="preload" href="/assets/css/styles.580a8cdb.css" as="style"><link rel="preload" href="/assets/js/9156.1c509bd1.js" as="script"><link rel="preload" href="/assets/js/app.7c0cda6d.js" as="script">
    <link rel="prefetch" href="/assets/js/8300.f7204200.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_X01.html.6836748b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-impls_yolov9.html.7bb15a58.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_006.html.645b2816.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_014.html.cffdc08a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_001.html.33b55688.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_markdown.html.1aaf261f.js" as="script"><link rel="prefetch" href="/assets/js/demo_markdown.html.9911c2a4.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_alexnet.html.dba59701.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_009.html.de0e79d2.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_011.html.b418e787.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_015.html.8c618101.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_020.html.ab45a1aa.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_021.html.1caa9af1.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_010.html.6c22c403.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_005.html.1855ec8b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_003.html.531695b8.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_018.html.541b112b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_012.html.b15fd11c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_013.html.7a159777.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_019.html.f66347bc.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_017.html.c23b0f8c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_016.html.2b7a18e5.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_008.html.ebb403d1.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_002.html.ee246a4d.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_004.html.4f5594ad.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_007.html.83af9508.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_3steps-paper-reading.html.87067fb2.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_page.html.753e4b79.js" as="script"><link rel="prefetch" href="/assets/js/demo_page.html.4afa3f13.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_layout.html.646f85e2.js" as="script"><link rel="prefetch" href="/assets/js/demo_layout.html.840cf7ee.js" as="script"><link rel="prefetch" href="/assets/js/zh_home.html.e9a86969.js" as="script"><link rel="prefetch" href="/assets/js/home.html.4ab09a81.js" as="script"><link rel="prefetch" href="/assets/js/posts_tomato.html.4ec64e05.js" as="script"><link rel="prefetch" href="/assets/js/posts_banana_2.html.b777dd7a.js" as="script"><link rel="prefetch" href="/assets/js/posts_apple_2.html.cb471c51.js" as="script"><link rel="prefetch" href="/assets/js/demo_disable.html.4e2c246d.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_disable.html.0c3baaf7.js" as="script"><link rel="prefetch" href="/assets/js/posts_banana_1.html.49d8bd63.js" as="script"><link rel="prefetch" href="/assets/js/posts_banana_3.html.e166d822.js" as="script"><link rel="prefetch" href="/assets/js/posts_banana_4.html.b1a9e006.js" as="script"><link rel="prefetch" href="/assets/js/posts_apple_4.html.4dd3483d.js" as="script"><link rel="prefetch" href="/assets/js/posts_apple_3.html.4bad7be6.js" as="script"><link rel="prefetch" href="/assets/js/posts_dragonfruit.html.384d6529.js" as="script"><link rel="prefetch" href="/assets/js/posts_apple_1.html.cf4266cf.js" as="script"><link rel="prefetch" href="/assets/js/posts_cherry.html.998d0b32.js" as="script"><link rel="prefetch" href="/assets/js/posts_strawberry.html.8281b0a8.js" as="script"><link rel="prefetch" href="/assets/js/zh_intro.html.7fb5a873.js" as="script"><link rel="prefetch" href="/assets/js/intro.html.eb684c35.js" as="script"><link rel="prefetch" href="/assets/js/zh_index.html.9a2f7b2a.js" as="script"><link rel="prefetch" href="/assets/js/index.html.dcce0346.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_web_vue-1.html.837194ec.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_index.html.bbe7866d.js" as="script"><link rel="prefetch" href="/assets/js/demo_encrypt.html.cdc9232a.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_encrypt.html.78570576.js" as="script"><link rel="prefetch" href="/assets/js/demo_index.html.7c96306f.js" as="script"><link rel="prefetch" href="/assets/js/tag_markdown_index.html.47f7c0f3.js" as="script"><link rel="prefetch" href="/assets/js/category_index.html.54ad007c.js" as="script"><link rel="prefetch" href="/assets/js/timeline_index.html.a7e9a4ac.js" as="script"><link rel="prefetch" href="/assets/js/article_index.html.33c07acb.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_使用指南_index.html.5fc02901.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_使用指南_index.html.c43a019e.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_页面配置_index.html.16ae4ec1.js" as="script"><link rel="prefetch" href="/assets/js/star_index.html.19e783c3.js" as="script"><link rel="prefetch" href="/assets/js/tag_index.html.4cc57efe.js" as="script"><link rel="prefetch" href="/assets/js/category_dragon-fruit_index.html.08cc092a.js" as="script"><link rel="prefetch" href="/assets/js/posts_index.html.3871cd02.js" as="script"><link rel="prefetch" href="/assets/js/category_strawberry_index.html.1bc72525.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_指南_index.html.bfeb79d9.js" as="script"><link rel="prefetch" href="/assets/js/category_vegetable_index.html.7ee52ed8.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_加密_index.html.8841eca0.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_禁用_index.html.ce0a1fc8.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_布局_index.html.5eecea6f.js" as="script"><link rel="prefetch" href="/assets/js/tag_page-config_index.html.8d808e62.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_markdown_index.html.a1350b1c.js" as="script"><link rel="prefetch" href="/assets/js/category_banana_index.html.63335904.js" as="script"><link rel="prefetch" href="/assets/js/category_cherry_index.html.6f1eec48.js" as="script"><link rel="prefetch" href="/assets/js/tag_encryption_index.html.da016b00.js" as="script"><link rel="prefetch" href="/assets/js/category_fruit_index.html.622b963b.js" as="script"><link rel="prefetch" href="/assets/js/category_guide_index.html.b09fdbff.js" as="script"><link rel="prefetch" href="/assets/js/category_apple_index.html.b134390d.js" as="script"><link rel="prefetch" href="/assets/js/tag_disable_index.html.8c6e701e.js" as="script"><link rel="prefetch" href="/assets/js/404.html.7aed0954.js" as="script"><link rel="prefetch" href="/assets/js/tag_layout_index.html.bcdc80c4.js" as="script"><link rel="prefetch" href="/assets/js/tag_yellow_index.html.6f812f38.js" as="script"><link rel="prefetch" href="/assets/js/tag_curly_index.html.bc1b172f.js" as="script"><link rel="prefetch" href="/assets/js/tag_guide_index.html.91bb56f9.js" as="script"><link rel="prefetch" href="/assets/js/tag_round_index.html.6c90183a.js" as="script"><link rel="prefetch" href="/assets/js/tag_small_index.html.9a0cbae4.js" as="script"><link rel="prefetch" href="/assets/js/tag_long_index.html.6ae60735.js" as="script"><link rel="prefetch" href="/assets/js/tag_big_index.html.39281add.js" as="script"><link rel="prefetch" href="/assets/js/tag_red_index.html.8bbff003.js" as="script"><link rel="prefetch" href="/assets/js/zh_timeline_index.html.45587830.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_index.html.f54b4216.js" as="script"><link rel="prefetch" href="/assets/js/zh_article_index.html.c1ccddf0.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_index.html.88fc57b1.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_index.html.72b75c04.js" as="script"><link rel="prefetch" href="/assets/js/zh_star_index.html.4aa5e606.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-impls_index.html.4907b247.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_index.html.f669eed4.js" as="script"><link rel="prefetch" href="/assets/js/posts_banana_index.html.8b0c6fe2.js" as="script"><link rel="prefetch" href="/assets/js/posts_apple_index.html.79e5053d.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_index.html.cf9f0a11.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_web_index.html.6791ec8d.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><!--[--><a class="route-link vp-brand" href="/zh/" aria-label="带我回家"><img class="vp-nav-logo" src="/logo.svg" alt><!----><span class="vp-site-name hide-in-pad">Nlog</span></a><!--]--><!----></div><div class="vp-navbar-center"><!----><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/zh/" aria-label="Blog Home"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="home" width="1em" height="1em"></iconify-icon><!--]-->Blog Home<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/zh/demo/" aria-label="主要功能与配置演示"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="laptop-code" width="1em" height="1em"></iconify-icon><!--]-->主要功能与配置演示<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="博客"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon>博客<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">人工智能实现</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-impls/yolov9.html" aria-label="YOLOv9代码复现"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->YOLOv9代码复现<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">前端开发</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/web/vue-1.html" aria-label="Vue3快速开始"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->Vue3快速开始<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">AI周报</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/weekly/001.html" aria-label="001"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->001<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/weekly/002.html" aria-label="002"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->002<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/weekly/003.html" aria-label="003"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->003<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/weekly/004.html" aria-label="004"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->004<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/weekly/005.html" aria-label="005"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->005<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/weekly/X01.html" aria-label="X01"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->X01<!----></a></li></ul></li></ul></button></div></div></nav><!--]--><!----></div><div class="vp-navbar-end"><!----><!--[--><div class="vp-nav-item"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="选择语言"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon i18n-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="i18n icon" name="i18n" style="width:1rem;height:1rem;vertical-align:middle;"><path d="M379.392 460.8 494.08 575.488l-42.496 102.4L307.2 532.48 138.24 701.44l-71.68-72.704L234.496 460.8l-45.056-45.056c-27.136-27.136-51.2-66.56-66.56-108.544h112.64c7.68 14.336 16.896 27.136 26.112 35.84l45.568 46.08 45.056-45.056C382.976 312.32 409.6 247.808 409.6 204.8H0V102.4h256V0h102.4v102.4h256v102.4H512c0 70.144-37.888 161.28-87.04 210.944L378.88 460.8zM576 870.4 512 1024H409.6l256-614.4H768l256 614.4H921.6l-64-153.6H576zM618.496 768h196.608L716.8 532.48 618.496 768z"></path></svg><!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/" aria-label="English"><!---->English<!----></a></li><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/zh/posts/ai-weekly/018.html" aria-label="简体中文"><!---->简体中文<!----></a></li></ul></button></div></div><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/vuepress-theme-hope/vuepress-theme-hope" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--]--><!----><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/zh/" aria-label="Blog Home"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="home" width="1em" height="1em"></iconify-icon><!--]-->Blog Home<!----></a></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header clickable"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="laptop-code" width="1em" height="1em"></iconify-icon><a class="route-link auto-link vp-sidebar-title no-external-link-icon" href="/zh/demo/" aria-label="如何使用"><!---->如何使用<!----></a><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/zh/demo/markdown.html" aria-label="Markdown 展示"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fab fa-markdown" width="1em" height="1em"></iconify-icon><!--]-->Markdown 展示<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/demo/layout.html" aria-label="布局"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="object-group" width="1em" height="1em"></iconify-icon><!--]-->布局<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/demo/page.html" aria-label="页面配置"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="file" width="1em" height="1em"></iconify-icon><!--]-->页面配置<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/demo/disable.html" aria-label="布局与功能禁用"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="gears" width="1em" height="1em"></iconify-icon><!--]-->布局与功能禁用<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/demo/encrypt.html" aria-label="密码加密的文章"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="lock" width="1em" height="1em"></iconify-icon><!--]-->密码加密的文章<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header active"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="book" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">文章</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Ai Impls</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">Ai Weekly</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/ai-weekly/X01.html" aria-label="AI 会议论文写作完全指南：从零开始构建高质量论文"><!---->AI 会议论文写作完全指南：从零开始构建高质量论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/ai-weekly/001.html" aria-label="AI 证件照生成工具 HivisionIDPhotos 引爆社交媒体 | Show-o 探索多模态未来 | 小红书 InstantX 团队提出风格迁移新方法 CSGO【AI 周报】"><!---->AI 证件照生成工具 HivisionIDPhotos 引爆社交媒体 | Show-o 探索多模态未来 | 小红书 InstantX 团队提出风格迁移新方法 CSGO【AI 周报】<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/ai-weekly/017.html" aria-label="AniDoc简化动画上色||ChatDiT聊天解决图像编辑|GenEx生成3D视频【AI周报】"><!---->AniDoc简化动画上色||ChatDiT聊天解决图像编辑|GenEx生成3D视频【AI周报】<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/ai-weekly/020.html" aria-label="AutoPresent提升幻灯片制作效率 | Hallo3实现动态肖像动画 | R3GAN媲美Diffusion模型【AI周报】"><!---->AutoPresent提升幻灯片制作效率 | Hallo3实现动态肖像动画 | R3GAN媲美Diffusion模型【AI周报】<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/ai-weekly/016.html" aria-label="EasyRef多模态高效图参考生成框架|SynCamMaster实现视角同步|SwiftEdit支持高速图像编辑【AI周报】"><!---->EasyRef多模态高效图参考生成框架|SynCamMaster实现视角同步|SwiftEdit支持高速图像编辑【AI周报】<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/ai-weekly/010.html" aria-label="FaceChain更新人脸转换引领个性生成|GenArtist多模态艺术生成系统|AutoKaggle竞赛助手革新【AI周报】"><!---->FaceChain更新人脸转换引领个性生成|GenArtist多模态艺术生成系统|AutoKaggle竞赛助手革新【AI周报】<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/ai-weekly/005.html" aria-label="Imagine yourself 无调优图像生成亮相 | NovelAI Diffusion V3 提升生成效率 | BAAI 推出多模态模型 Emu3【AI 周报】"><!---->Imagine yourself 无调优图像生成亮相 | NovelAI Diffusion V3 提升生成效率 | BAAI 推出多模态模型 Emu3【AI 周报】<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/ai-weekly/013.html" aria-label="JoyVASA突破多模态动画生成 | DINO-X定义开放世界检测 | StyleCodes实现风格编码迁移【AI周报】"><!---->JoyVASA突破多模态动画生成 | DINO-X定义开放世界检测 | StyleCodes实现风格编码迁移【AI周报】<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/ai-weekly/014.html" aria-label="MaterialAnything生成PBR材质|ConsisID优化ID视频生成|FlipSketch实现草图动画【AI周报】"><!---->MaterialAnything生成PBR材质|ConsisID优化ID视频生成|FlipSketch实现草图动画【AI周报】<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/ai-weekly/006.html" aria-label="Meta 发布 Movie Gen 开启 AI 生成视频新时代 | YOLOv11 引领目标检测革新 | 华盛顿大学 Inverse Painting 重构绘画过程【AI 周报】"><!---->Meta 发布 Movie Gen 开启 AI 生成视频新时代 | YOLOv11 引领目标检测革新 | 华盛顿大学 Inverse Painting 重构绘画过程【AI 周报】<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/ai-weekly/021.html" aria-label="MiniMax-01扩展长文本处理|Seaweed-APT一步视频生成|AnyDressing个性化虚拟试衣【AI周报】"><!---->MiniMax-01扩展长文本处理|Seaweed-APT一步视频生成|AnyDressing个性化虚拟试衣【AI周报】<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/ai-weekly/004.html" aria-label="Qwen 2.5 Coder: 多语言代码生成新高度，InstantDrag 实时交互式图像生成，Omnigen 多模态生成研究进展【AI 周报】"><!---->Qwen 2.5 Coder: 多语言代码生成新高度，InstantDrag 实时交互式图像生成，Omnigen 多模态生成研究进展【AI 周报】<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/zh/posts/ai-weekly/018.html" aria-label="Qwen2.5定义多模态模型新高度|DeepSeek-V3突破混合专家能力|Mulberry强化推理反思【AI周报】"><!---->Qwen2.5定义多模态模型新高度|DeepSeek-V3突破混合专家能力|Mulberry强化推理反思【AI周报】<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/ai-weekly/003.html" aria-label="SaRA 高效微调 Diffusion 模型|Fish-Speech 更新多语种语音生成|IFAdapter 提升图像特征控制【AI 周报】"><!---->SaRA 高效微调 Diffusion 模型|Fish-Speech 更新多语种语音生成|IFAdapter 提升图像特征控制【AI 周报】<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/ai-weekly/009.html" aria-label="Stable Diffusion3.5革新生成精度|AutoTrain高效炼丹|MagicTailor个性化图像编辑【AI周报】"><!---->Stable Diffusion3.5革新生成精度|AutoTrain高效炼丹|MagicTailor个性化图像编辑【AI周报】<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/ai-weekly/019.html" aria-label="StoryWeaver重塑视觉故事生成|Edicho实现一致性图像编辑|VideoAnyDoor增强视频对象插入【AI周报】"><!---->StoryWeaver重塑视觉故事生成|Edicho实现一致性图像编辑|VideoAnyDoor增强视频对象插入【AI周报】<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/ai-weekly/012.html" aria-label="TANGO赋能数字人|ADD-IT重构图像编辑|MikuDance动漫角色舞蹈动画【AI周报】"><!---->TANGO赋能数字人|ADD-IT重构图像编辑|MikuDance动漫角色舞蹈动画【AI周报】<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/ai-weekly/002.html" aria-label="Unity 自研 3D 材质生成大模型 | 支付宝推出 Style Tokenizer|LinFusion 高效生成 16K 图像【AI 周报】"><!---->Unity 自研 3D 材质生成大模型 | 支付宝推出 Style Tokenizer|LinFusion 高效生成 16K 图像【AI 周报】<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/ai-weekly/015.html" aria-label="多模态理解与生成统一Token化框架|NitroFusion单步图像生成|Imagine360探索全景生成视频【AI周报】"><!---->多模态理解与生成统一Token化框架|NitroFusion单步图像生成|Imagine360探索全景生成视频【AI周报】<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/ai-weekly/011.html" aria-label="腾讯Hunyuan3D重塑3D重建|MVPaint多视角提升3D材质一致性|PromptFix实现高质量图像修复【AI周报】"><!---->腾讯Hunyuan3D重塑3D重建|MVPaint多视角提升3D材质一致性|PromptFix实现高质量图像修复【AI周报】<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/ai-weekly/007.html" aria-label="英伟达发布可控图像编辑框架|字节跳动TextToon实时漫画化头像生成|Vivo推出HybridBooth个性化生成【AI周报】"><!---->英伟达发布可控图像编辑框架|字节跳动TextToon实时漫画化头像生成|Vivo推出HybridBooth个性化生成【AI周报】<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/ai-weekly/008.html" aria-label="阿里开源Animate-X革新AI角色动画|ZeroComp实现创新3D对象合成|F5-TTS提升TTS语音的自然度【AI周报】"><!---->阿里开源Animate-X革新AI角色动画|ZeroComp实现创新3D对象合成|F5-TTS提升TTS语音的自然度【AI周报】<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Papers</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Web</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/intro.html" aria-label="Intro Page"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="circle-info" width="1em" height="1em"></iconify-icon><!--]-->Intro Page<!----></a></li><li><a class="auto-link external-link vp-sidebar-link" href="https://ecosystem.vuejs.press/zh/plugins/markdown/revealjs/demo.html" aria-label="幻灯片" rel="noopener noreferrer" target="_blank"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="person-chalkboard" width="1em" height="1em"></iconify-icon><!--]-->幻灯片<!----></a></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->Qwen2.5定义多模态模型新高度|DeepSeek-V3突破混合专家能力|Mulberry强化推理反思【AI周报】</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://mister-hope.com" target="_blank" rel="noopener noreferrer">neverbiasu</a></span><span property="author" content="neverbiasu"></span></span><!----><!----><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 6 分钟</span><meta property="timeRequired" content="PT6M"></span><!----><!----></div><hr></div><div class="vp-toc-placeholder"><aside id="toc"><!----><div class="vp-toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon" name="print"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#摘要">摘要</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#目录">目录</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#qwen2-5-阿里巴巴达摩院推出的多模态大模型">Qwen2.5：阿里巴巴达摩院推出的多模态大模型</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#depthlab-从部分到完整的深度补全模型">DepthLab：从部分到完整的深度补全模型</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#par-并行自回归视觉生成">PAR：并行自回归视觉生成</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#deepseek-v3-6710亿参数的混合专家语言模型">DeepSeek-V3：6710亿参数的混合专家语言模型</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#dit-ctrl-多模态扩散transformer中的注意力控制探索">DiT-CTRL：多模态扩散Transformer中的注意力控制探索</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#mulberry-通过集体蒙特卡罗树搜索增强多模态大模型的推理与反思能力">Mulberry：通过集体蒙特卡罗树搜索增强多模态大模型的推理与反思能力</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#参考文献">参考文献</a></li><!----><!--]--></ul></li><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!----></aside></div><!----><div class="theme-hope-content" vp-content><h1 id="qwen2-5定义多模态模型新高度-deepseek-v3突破混合专家能力-mulberry强化推理反思【ai周报】" tabindex="-1"><a class="header-anchor" href="#qwen2-5定义多模态模型新高度-deepseek-v3突破混合专家能力-mulberry强化推理反思【ai周报】"><span>Qwen2.5定义多模态模型新高度|DeepSeek-V3突破混合专家能力|Mulberry强化推理反思【AI周报】</span></a></h1><figure><img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b338b22c-394c-4ae0-88d2-2bf15fa83809/original=true,quality=90/47422369.jpeg" alt="封面源自C站作者Meower2024" tabindex="0" loading="lazy"><figcaption>封面源自C站作者Meower2024</figcaption></figure><h2 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span>摘要</span></a></h2><p>本周聚焦大模型与多模态：Qwen2.5 优化预训练与后训练，定义多模态模型新标准；DeepSeek-V3 引入混合专家架构，提升训练效率；Mulberry 结合蒙特卡罗树搜索，增强推理与反思能力。详见正文。</p><hr><h2 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span>目录</span></a></h2><ol><li><a href="#Qwen2.5%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E8%BE%BE%E6%91%A9%E9%99%A2%E6%8E%A8%E5%87%BA%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B">Qwen2.5：阿里巴巴达摩院推出的多模态大模型</a></li><li><a href="#DepthLab%EF%BC%9A%E4%BB%8E%E9%83%A8%E5%88%86%E5%88%B0%E5%AE%8C%E6%95%B4%E7%9A%84%E6%B7%B1%E5%BA%A6%E8%A1%A5%E5%85%A8%E6%A8%A1%E5%9E%8B">DepthLab：从部分到完整的深度补全模型 </a></li><li><a href="#PAR%EF%BC%9A%E5%B9%B6%E8%A1%8C%E8%87%AA%E5%9B%9E%E5%BD%92%E8%A7%86%E8%A7%89%E7%94%9F%E6%88%90">PAR：并行自回归视觉生成</a></li><li><a href="#DeepSeek-V3%EF%BC%9A6710%E4%BA%BF%E5%8F%82%E6%95%B0%E7%9A%84%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B">DeepSeek-V3：6710亿参数的混合专家语言模型</a></li><li><a href="#DiT-CTRL%EF%BC%9A%E5%A4%9A%E6%A8%A1%E6%80%81%E6%89%A9%E6%95%A3Transformer%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%8E%A7%E5%88%B6%E6%8E%A2%E7%B4%A2">DiT-CTRL：多模态扩散Transformer中的注意力控制探索</a></li><li><a href="#Mulberry%EF%BC%9A%E9%80%9A%E8%BF%87%E9%9B%86%E4%BD%93%E8%92%99%E7%89%B9%E5%8D%A1%E7%BD%97%E6%A0%91%E6%90%9C%E7%B4%A2%E5%A2%9E%E5%BC%BA%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8E%A8%E7%90%86%E4%B8%8E%E5%8F%8D%E6%80%9D%E8%83%BD%E5%8A%9B">Mulberry：通过集体蒙特卡罗树搜索增强多模态大模型的推理与反思能力</a></li></ol><hr><h2 id="qwen2-5-阿里巴巴达摩院推出的多模态大模型" tabindex="-1"><a class="header-anchor" href="#qwen2-5-阿里巴巴达摩院推出的多模态大模型"><span>Qwen2.5：阿里巴巴达摩院推出的多模态大模型</span></a></h2><figure><img src="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-72B-Instruct-Score.jpg" alt="Qwen2.5 Performance 图" tabindex="0" loading="lazy"><figcaption>Qwen2.5 Performance 图</figcaption></figure><p><strong>概要</strong>：Qwen2.5 是阿里巴巴达摩院发布的多模态大模型系列，旨在满足多样化需求。相比之前的版本，Qwen2.5 在预训练和后训练阶段均有显著提升。预训练方面，模型的高质量预训练数据集从7万亿标记扩展至18万亿标记，增强了常识、专业知识和推理能力。后训练阶段，采用了超过100万样本的精细监督微调和多阶段强化学习，提升了模型的人类偏好对齐能力，特别是在长文本生成、结构化数据分析和指令遵循方面。Qwen2.5 系列提供多种规模的模型，包括基础模型和指令微调模型，并提供量化版本，以适应不同的使用场景。其中，Qwen2.5-72B-Instruct 在语言理解、推理、数学、编码和人类偏好对齐等基准测试中表现出色，超越了许多开源和专有模型。此外，Qwen2.5 还支持训练专用模型，如 Qwen2.5-Math、Qwen2.5-Coder 和多模态模型。</p><p><strong>标签</strong>：#Qwen2.5 #阿里巴巴达摩院 #多模态模型 #大规模预训练 #强化学习</p><hr><h2 id="depthlab-从部分到完整的深度补全模型" tabindex="-1"><a class="header-anchor" href="#depthlab-从部分到完整的深度补全模型"><span>DepthLab：从部分到完整的深度补全模型</span></a></h2><figure><img src="https://johanan528.github.io/depthlab_web/static/images/pipeline.jpeg" alt="DepthLab Pipeline 图" tabindex="0" loading="lazy"><figcaption>DepthLab Pipeline 图</figcaption></figure><p><strong>概要</strong>：DepthLab 是一款由香港大学、香港科技大学和蚂蚁集团的研究人员联合开发的深度补全基础模型，旨在解决深度数据中常见的缺失问题。该模型利用图像扩散先验，能够在已知深度的条件下，可靠地填补缺失区域，保持尺度一致性。DepthLab 在多个下游任务中表现出色，包括 3D 场景修复、文本到 3D 场景生成、稀疏视图重建和 LiDAR 深度补全，超越了现有方法的性能。</p><p><strong>标签</strong>：#DepthLab #深度补全 #图像扩散 #3D场景 #LiDAR</p><hr><h2 id="par-并行自回归视觉生成" tabindex="-1"><a class="header-anchor" href="#par-并行自回归视觉生成"><span>PAR：并行自回归视觉生成</span></a></h2><figure><img src="https://epiphqny.github.io/PAR-project/static/images/image_generation.jpg" alt="PAR Comparison 图" tabindex="0" loading="lazy"><figcaption>PAR Comparison 图</figcaption></figure><p><strong>概要</strong>：PAR（Parallelized Autoregressive Visual Generation）是一种旨在提升视觉生成效率的模型。传统的自回归模型逐个生成视觉数据的每个token，速度较慢。PAR通过并行生成弱依赖性的远距离token，同时对强依赖性的局部token保持顺序生成，从而加快生成过程。该方法无需修改模型架构或tokenizer，即可集成到标准自回归模型中。在ImageNet和UCF-101上的实验表明，PAR在图像和视频生成任务中实现了3.6倍的速度提升，且生成质量与传统方法相当。</p><p><strong>标签</strong>：#PAR #自回归模型 #视觉生成 #并行生成 #深度学习</p><hr><h2 id="deepseek-v3-6710亿参数的混合专家语言模型" tabindex="-1"><a class="header-anchor" href="#deepseek-v3-6710亿参数的混合专家语言模型"><span>DeepSeek-V3：6710亿参数的混合专家语言模型</span></a></h2><figure><img src="https://github.com/deepseek-ai/DeepSeek-V3/raw/main/figures/benchmark.png" alt="DeepSeek-V3 Benchmark 图" tabindex="0" loading="lazy"><figcaption>DeepSeek-V3 Benchmark 图</figcaption></figure><p><strong>概要</strong>：DeepSeek-V3 是由 deepseek-ai 开发的混合专家（MoE）语言模型，总参数量达 6710 亿，每个 token 激活 370 亿参数。该模型采用多头潜在注意力（MLA）和 DeepSeekMoE 架构，结合无辅助损失的负载均衡策略和多 token 预测训练目标，提升了推理效率和训练成本效益。在 14.8 万亿高质量多样化 token 上进行预训练，并经过监督微调和强化学习阶段，展现出卓越的性能，超越了其他开源模型，并与领先的闭源模型相媲美。完整训练耗时约 278.8 万 H800 GPU 小时，过程稳定，无需回滚。</p><p><strong>标签</strong>：#DeepSeek-V3 #混合专家模型 #语言模型 #深度学习 #人工智能</p><hr><h2 id="dit-ctrl-多模态扩散transformer中的注意力控制探索" tabindex="-1"><a class="header-anchor" href="#dit-ctrl-多模态扩散transformer中的注意力控制探索"><span>DiT-CTRL：多模态扩散Transformer中的注意力控制探索</span></a></h2><figure><img src="https://onevfall.github.io/project_page/ditctrl/static/images/framework.jpg" alt="DiT-CTRL Framework图" tabindex="0" loading="lazy"><figcaption>DiT-CTRL Framework图</figcaption></figure><p><strong>概要</strong>：DiT-CTRL是一种无需额外训练的多提示词视频生成方法，旨在解决现有模型在生成包含多个顺序提示词的视频时，缺乏连贯性和自然过渡的问题。通过分析多模态扩散Transformer（MM-DiT）的注意力机制，DiT-CTRL实现了基于掩码的精确语义控制，使生成的视频在不同提示词之间具有平滑过渡和一致的对象运动。实验结果表明，DiT-CTRL在无需额外训练的情况下，实现了多提示词视频生成的最新性能。</p><p><strong>标签</strong>：#DiT-CTRL #多提示词视频生成 #注意力控制 #多模态扩散Transformer #深度学习</p><hr><h2 id="mulberry-通过集体蒙特卡罗树搜索增强多模态大模型的推理与反思能力" tabindex="-1"><a class="header-anchor" href="#mulberry-通过集体蒙特卡罗树搜索增强多模态大模型的推理与反思能力"><span>Mulberry：通过集体蒙特卡罗树搜索增强多模态大模型的推理与反思能力</span></a></h2><p><img src="https://arxiv.org/html/2412.18319v1/x2.png" alt="Mulberry Overview 图" loading="lazy"><strong>概要</strong>：Mulberry 是一种多模态大语言模型（MLLM），旨在通过集体蒙特卡罗树搜索（CoMCTS）提升模型的逐步推理与反思能力。CoMCTS 方法引入集体学习的概念，通过扩展、模拟与错误定位、回传和选择等迭代操作，协作地推测、搜索并确定有效的推理路径，直至得出正确答案。利用 CoMCTS，研究者构建了包含 26 万个多模态数据集的 Mulberry-260k，每个问题都包含丰富、明确的推理节点树。在此基础上训练的 Mulberry 模型在多个基准测试中表现出色，展现了卓越的逐步推理与反思能力。</p><p><strong>标签</strong>：#Mulberry #多模态大语言模型 #推理 #反思 #蒙特卡罗树搜索</p><hr><h3 id="参考文献" tabindex="-1"><a class="header-anchor" href="#参考文献"><span><strong>参考文献</strong></span></a></h3><ol><li><a href="https://github.com/QwenLM/Qwen2.5" target="_blank" rel="noopener noreferrer">Qwen2.5 GitHub</a></li><li><a href="https://arxiv.org/pdf/2412.15115" target="_blank" rel="noopener noreferrer">Qwen2.5 论文</a></li><li><a href="https://johanan528.github.io/depthlab_web/" target="_blank" rel="noopener noreferrer">DepthLab 项目主页</a></li><li><a href="https://github.com/Johanan528/DepthLab" target="_blank" rel="noopener noreferrer">DepthLab GitHub</a></li><li><a href="https://arxiv.org/html/2412.18153v1" target="_blank" rel="noopener noreferrer">DepthLab 论文</a></li><li><a href="https://epiphqny.github.io/PAR-project/" target="_blank" rel="noopener noreferrer">PAR 项目主页</a></li><li><a href="https://github.com/Epiphqny/PAR" target="_blank" rel="noopener noreferrer">PAR GitHub</a></li><li><a href="https://arxiv.org/html/2412.15119v1" target="_blank" rel="noopener noreferrer">PAR 论文</a></li><li><a href="https://www.deepseek.com/" target="_blank" rel="noopener noreferrer">DeepSeek-V3 官网</a></li><li><a href="https://github.com/deepseek-ai/DeepSeek-V3" target="_blank" rel="noopener noreferrer">DeepSeek-V3 GitHub</a></li><li><a href="https://huggingface.co/deepseek-ai/DeepSeek-V3-Base" target="_blank" rel="noopener noreferrer">DeepSeek-V3 Hugging Face</a></li><li><a href="https://onevfall.github.io/project_page/ditctrl/" target="_blank" rel="noopener noreferrer">DiT-CTRL 项目主页</a></li><li><a href="https://github.com/tencentarc/ditctrl" target="_blank" rel="noopener noreferrer">DiT-CTRL GitHub</a></li><li><a href="https://arxiv.org/html/2412.18597v1" target="_blank" rel="noopener noreferrer">DiT-CTRL 论文</a></li><li><a href="https://github.com/hjyao00/mulberry" target="_blank" rel="noopener noreferrer">Mulberry GitHub</a></li><li><a href="https://arxiv.org/html/2412.18319v1" target="_blank" rel="noopener noreferrer">Mulberry 论文</a></li></ol></div><!--[--><div class="theme-hope-content"><Share colorful services="email,facebook,line,linkedin,messenger,qrcode,reddit,telegram,twitter"></Share></div><!--]--><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/vuepress-theme-hope/vuepress-theme-hope/edit/main/src/zh/posts/ai-weekly/018.md" aria-label="在 GitHub 上编辑此页" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->在 GitHub 上编辑此页<!----></a></div><div class="vp-meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/zh/posts/ai-weekly/004.html" aria-label="Qwen 2.5 Coder: 多语言代码生成新高度，InstantDrag 实时交互式图像生成，Omnigen 多模态生成研究进展【AI 周报】"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><!---->Qwen 2.5 Coder: 多语言代码生成新高度，InstantDrag 实时交互式图像生成，Omnigen 多模态生成研究进展【AI 周报】</div></a><a class="route-link auto-link next" href="/zh/posts/ai-weekly/003.html" aria-label="SaRA 高效微调 Diffusion 模型|Fish-Speech 更新多语种语音生成|IFAdapter 提升图像特征控制【AI 周报】"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">SaRA 高效微调 Diffusion 模型|Fish-Speech 更新多语种语音生成|IFAdapter 提升图像特征控制【AI 周报】<!----></div></a></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">我的页脚</div><div class="vp-copyright">Copyright © 2025 neverbiasu </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script src="/assets/js/runtime~app.4b99fa82.js" defer></script><script src="/assets/js/9156.1c509bd1.js" defer></script><script src="/assets/js/app.7c0cda6d.js" defer></script>
  </body>
</html>
