<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.17" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.58" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="alternate" hreflang="en-us" href="https://neverbiasu.github.io/posts/reprints/flux-qlora.html"><meta property="og:url" content="https://neverbiasu.github.io/zh/posts/reprints/flux-qlora.html"><meta property="og:site_name" content="Nlog"><meta property="og:title" content="在消费级硬件上对 FLUX.1-dev 进行（LoRA）微调"><meta property="og:description" content="在消费级硬件上对 FLUX.1-dev 进行（LoRA）微调 提示 Open In ColabOpen In Colab 在我们之前的文章《在 Diffusers 中探索量化后端》中，我们深入研究了各种量化技术如何缩小像 FLUX.1-dev 这样的扩散模型，使它们在_推理_方面显著更易于访问，而不会大幅降低性能。我们看到了 bitsandbytes、..."><meta property="og:type" content="article"><meta property="og:image" content="https://colab.research.google.com/assets/colab-badge.svg"><meta property="og:locale" content="zh-CN"><meta property="og:locale:alternate" content="en-US"><meta property="article:author" content="Derek Liu, Marc Sun, Sayak Paul, merve, Linoy Tsaban"><meta property="article:tag" content="FLUX"><meta property="article:tag" content="LoRA"><meta property="article:tag" content="QLoRA"><meta property="article:tag" content="微调"><meta property="article:tag" content="diffusers"><meta property="article:tag" content="量化"><meta property="article:published_time" content="2024-06-19T00:00:00.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"在消费级硬件上对 FLUX.1-dev 进行（LoRA）微调","image":["https://colab.research.google.com/assets/colab-badge.svg","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/peft/lora_diagram.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base2_bf16.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged2_qlora_bf16.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base3_bf16.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged3_qlora_bf16.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base5_bf16.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged5_qlora_bf16.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base2.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged2.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base3.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged3.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base5.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged5.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_fp8_combined.png"],"datePublished":"2024-06-19T00:00:00.000Z","dateModified":null,"author":[{"@type":"Person","name":"Derek Liu, Marc Sun, Sayak Paul, merve, Linoy Tsaban"}]}</script><title>在消费级硬件上对 FLUX.1-dev 进行（LoRA）微调 | Nlog</title><meta name="description" content="在消费级硬件上对 FLUX.1-dev 进行（LoRA）微调 提示 Open In ColabOpen In Colab 在我们之前的文章《在 Diffusers 中探索量化后端》中，我们深入研究了各种量化技术如何缩小像 FLUX.1-dev 这样的扩散模型，使它们在_推理_方面显著更易于访问，而不会大幅降低性能。我们看到了 bitsandbytes、...">
    <link rel="stylesheet" href="/assets/css/styles.50126b1a.css">
    <link rel="preload" href="/assets/js/runtime~app.95d5da72.js" as="script"><link rel="preload" href="/assets/css/styles.50126b1a.css" as="style"><link rel="preload" href="/assets/js/9156.64e2dfa0.js" as="script"><link rel="preload" href="/assets/js/app.ea25b194.js" as="script">
    <link rel="prefetch" href="/assets/js/posts_reprints_flux-qlora.html.e25c0732.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_flux-qlora.html.bdca01c9.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_news-agents-daily-recap.html.ca04913a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ielts_simon-task2.html.2fe38674.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_crody's-model-merge-guide.html.07f44e7f.js" as="script"><link rel="prefetch" href="/assets/js/8300.853d6b0b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ielts_usage-of-collocations-in-speaking_ielts-collocations.html.86f5c7c6.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_crody's-model-merge-guide.html.046f0899.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_image-recognition.html.07c5196c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_image-recognition.html.61c0e69e.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_blog-images.html.d2c6545e.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html.9d72dc96.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html.9fa0e201.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_what-is-block-merging.html.b7b3e018.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_original-character-lora-sdxl-character-training.html.ce54ff9d.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_step-by-step-visual-introduction-to-diffusion-models.html.cd2854e8.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_flux-kontext.html.ed243625.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_original-character-lora-sdxl-character-training.html.52dcf985.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_repos_material.html.fbe2fd29.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_introduction-of-prompts-ai-illustration-generation-camera-angle-composition-facial-expression.html.fa0b7a73.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_X01.html.eb6ee3d6.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_introduction-of-prompts-ai-illustration-generation-camera-angle-composition-facial-expression.html.f7670351.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_sci_conda.html.1ba5b9e5.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_papers_workflow.html.e18adbce.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language.html.a34aec93.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language.html.d9238744.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_flux-kontext-optimization.html.1a4897dc.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_flux-kontext-optimization.html.5532e6f6.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_step-by-step-visual-introduction-to-diffusion-models.html.e8bf942f.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_repos_comfy-mind.html.6f1a4f44.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-impls_yolov9.html.cbf247d0.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_model-block-merge-1.html.3abbf8d4.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_ai-art-newsletter-jan-25.html.5faf4d51.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_006.html.76c84f58.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_announcing-illustrious-text‑enhancer-tag-booster-and-mood-enhancer.html.517a1ee1.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_model-block-merge-2.html.0f9c14de.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_sdo.html.b7ecccd0.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_announcing-illustrious-text‑enhancer-tag-booster-and-mood-enhancer.html.f6a8fbb8.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_resnet.html.6393e916.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_ai-art-newsletter-jan-25.html.971ce630.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_bagel.html.049a219c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_ming-omni.html.20e14b21.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_omniconsistency.html.4c6e9330.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything.html.314cbfd7.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_014.html.c41082ad.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_flux-1-kontext.html.6297069c.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_niji-lesson-2-the-terminator-line.html.ebdb33a7.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_comfyui-r1.html.bea016dd.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_niji-study-1-measuring-with-your-eyes.html.721630f8.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything.html.22fa5919.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_001.html.2986e89d.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_flux-1-kontext.html.6d0bc73c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_ecomimic-v3.html.a8a6b4b4.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_markdown.html.2b3004d0.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_colorizediffusion.html.c18d15cc.js" as="script"><link rel="prefetch" href="/assets/js/demo_markdown.html.a2081e01.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_niji-study-1-measuring-with-your-eyes.html.403ee9cf.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_repos_checklist.html.2c86bf22.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_hunyuancustom.html.c2b4ff7e.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ielts_simon-task1.html.34242439.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_dairys_250222.html.41739137.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_show-o2.html.6145cdd9.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_hf-weekly_001.html.89ae8f15.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_repos_workflow.html.5967ccd1.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_037.html.b0a4ddd3.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_templates_repos.html.b0b47564.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_033.html.3fc966cc.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_031.html.86f17a2c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_043.html.70bd2bb5.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_icedit.html.ba272966.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_032.html.30191816.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_026.html.6bc17810.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_042.html.51c7aa9e.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_omnigen2.html.7251ca67.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_transformer.html.a9f96585.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_alexnet.html.ffa5e652.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_009.html.b41f980f.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_022.html.33930402.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_030.html.2f8b0739.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_039.html.e4384ea6.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_011.html.4c72c992.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_ai-art-gtc-paris-2025.html.35f9c6c5.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_046.html.7fe6c3c1.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_029.html.6bd2bbb4.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_how-and-when-to-build-multi-agent-systems.html.683f686f.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_reptext.html.3e68da15.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_040.html.77ad6dd0.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_generative-ai-powered-design.html.29b4cfc0.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_045.html.bcee5b9e.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_how-and-when-to-build-multi-agent-systems.html.83239b53.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_034.html.bb3494e0.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_041.html.cc30477b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_ai-art-gtc-paris-2025.html.dd4e6753.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_036.html.103493df.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_044.html.4316f4fc.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_015.html.f3bc358d.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_thoughts_platform-operation-thoughts-after-comfycon.html.0a6fc557.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_020.html.e178431c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_035.html.76b543ac.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_generative-ai-powered-design.html.8ea641cf.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_023.html.2c7192b4.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_021.html.1924500a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_010.html.995fa31e.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_005.html.77979cff.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_qr-lora.html.12a884c9.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_hf-weekly_003.html.add9120d.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_003.html.fe38d2ee.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_038.html.54d019c6.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_018.html.3aabc796.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_012.html.2ce3356f.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_explaining-tokens-the-language-and-currency-of-ai-nvidia-blog.html.98d7044c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_025.html.828c6af4.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_027.html.a69f4cf8.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_framepack.html.79cc8785.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_028.html.23f08d5c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_024.html.c9d95ff5.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_013.html.659095e1.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_vlv.html.66e5a328.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_hf-weekly_002.html.475e8a71.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_019.html.dbd20518.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_illustrious-xl-v2.0-the-best-training-base-model-in-1536-age.html.b5e190f7.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_illustrious-xl-v2.0-the-best-training-base-model-in-1536-age.html.824cc0cb.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_explaining-tokens-the-language-and-currency-of-ai-nvidia-blog.html.0dce2f26.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_017.html.cf727d63.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_niji-lesson-2-the-terminator-line.html.bcba9d63.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_niji-study-2-notan.html.bc893745.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_ovis-u1.html.f00080b2.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_016.html.c3ada0a7.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_mcp-flash-in-the-pan-or-future-standard.html.b142e62d.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_papers_checklist.html.153167b0.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_008.html.8b9058fe.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_002.html.5a4dd3d5.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_niji-video.html.211bd024.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_mcp-flash-in-the-pan-or-future-standard.html.19ff25fe.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_004.html.9173a01b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_niji-video.html.26560c68.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_007.html.eab02414.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_niji-study-2-notan.html.70b1ed6f.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_3steps-paper-reading.html.eda5237e.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_dairys_250223.html.b6746695.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_experiments-with-mcp-using-github-copilot.html.b89c4005.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_experimenting-with-mcp-using-github-copilot.html.f9a39fff.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_illustrious-lu-v0.03.html.dbc0dce0.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_illustrious-lu-v0.03.html.8b95f0b0.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_templates_papers.html.31aef926.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_templates_hf-weekly.html.5c334dac.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_hf-weekly_checklist.html.c3fa5a04.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_templates_ai-weekly.html.61881c27.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_page.html.0b7cffcc.js" as="script"><link rel="prefetch" href="/assets/js/demo_page.html.50e1e3b3.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_prompts_hf-weekly.prompt.html.a49236f9.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_layout.html.9b3fdc7f.js" as="script"><link rel="prefetch" href="/assets/js/demo_layout.html.25c357de.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_hf-weekly_workflow.html.da6dc285.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_prompts_translate.prompt.html.0e65a605.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_prompts_cover.prompt.html.b24a437c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_prompts_ai-weekly.prompt.html.2fe1eb8f.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_prompts_papers.prompt.html.ba28b7ce.js" as="script"><link rel="prefetch" href="/assets/js/home.html.a72e8bb4.js" as="script"><link rel="prefetch" href="/assets/js/zh_home.html.7623eb73.js" as="script"><link rel="prefetch" href="/assets/js/demo_disable.html.aeb75044.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_disable.html.917844f9.js" as="script"><link rel="prefetch" href="/assets/js/zh_intro.html.efed7168.js" as="script"><link rel="prefetch" href="/assets/js/intro.html.50f0afc5.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_prompts_image-extract.prompt.html.9c9b8aa7.js" as="script"><link rel="prefetch" href="/assets/js/zh_index.html.40d3a237.js" as="script"><link rel="prefetch" href="/assets/js/index.html.f45e7c7b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_web_vue-1.html.0755e363.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_index.html.34792277.js" as="script"><link rel="prefetch" href="/assets/js/demo_encrypt.html.25bd9519.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_encrypt.html.06a96e54.js" as="script"><link rel="prefetch" href="/assets/js/tag_artificial-intelligence_index.html.7e3793fa.js" as="script"><link rel="prefetch" href="/assets/js/demo_index.html.febe17c4.js" as="script"><link rel="prefetch" href="/assets/js/category_model-development_index.html.794f5d59.js" as="script"><link rel="prefetch" href="/assets/js/category_image-generation_index.html.2189f40e.js" as="script"><link rel="prefetch" href="/assets/js/category_model-training_index.html.be238a49.js" as="script"><link rel="prefetch" href="/assets/js/category_generative-ai_index.html.b909fb8b.js" as="script"><link rel="prefetch" href="/assets/js/tag_stable-diffusion_index.html.ae5f1c64.js" as="script"><link rel="prefetch" href="/assets/js/category_anime-style_index.html.3108accc.js" as="script"><link rel="prefetch" href="/assets/js/tag_amazon-bedrock_index.html.a67f2776.js" as="script"><link rel="prefetch" href="/assets/js/tag_resource-guide_index.html.5acb26ee.js" as="script"><link rel="prefetch" href="/assets/js/category_explainer_index.html.a8e8f462.js" as="script"><link rel="prefetch" href="/assets/js/category_reprints_index.html.4a06de7a.js" as="script"><link rel="prefetch" href="/assets/js/tag_kohya-ss-gui_index.html.27638eba.js" as="script"><link rel="prefetch" href="/assets/js/tag_fundamentals_index.html.374e901f.js" as="script"><link rel="prefetch" href="/assets/js/category_reprint_index.html.6eafee8b.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_模型上下文协议_index.html.e75af900.js" as="script"><link rel="prefetch" href="/assets/js/tag_illustrious_index.html.ff354070.js" as="script"><link rel="prefetch" href="/assets/js/tag_text2image_index.html.bb9c3a46.js" as="script"><link rel="prefetch" href="/assets/js/tag_taylorseer_index.html.d4b32963.js" as="script"><link rel="prefetch" href="/assets/js/category_aiml_index.html.35fc99fb.js" as="script"><link rel="prefetch" href="/assets/js/tag_diffusers_index.html.8f93bf3f.js" as="script"><link rel="prefetch" href="/assets/js/tag_inference_index.html.b69c0933.js" as="script"><link rel="prefetch" href="/assets/js/tag_replicate_index.html.61deee89.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_阿里巴巴ai研究_index.html.dd5f50e2.js" as="script"><link rel="prefetch" href="/assets/js/tag_markdown_index.html.ec598c41.js" as="script"><link rel="prefetch" href="/assets/js/tag_drawing_index.html.91b0ebb5.js" as="script"><link rel="prefetch" href="/assets/js/tag_flux.1_index.html.83ab9654.js" as="script"><link rel="prefetch" href="/assets/js/tag_lumina_index.html.27a09c4b.js" as="script"><link rel="prefetch" href="/assets/js/tag_prompt_index.html.d3dbd2e7.js" as="script"><link rel="prefetch" href="/assets/js/tag_script_index.html.eae6815c.js" as="script"><link rel="prefetch" href="/assets/js/tag_merge_index.html.ae63ce39.js" as="script"><link rel="prefetch" href="/assets/js/tag_model_index.html.acdbe3e4.js" as="script"><link rel="prefetch" href="/assets/js/tag_qlora_index.html.11905a67.js" as="script"><link rel="prefetch" href="/assets/js/tag_qwen3_index.html.e8eb5022.js" as="script"><link rel="prefetch" href="/assets/js/tag_vpred_index.html.426ee337.js" as="script"><link rel="prefetch" href="/assets/js/tag_notan_index.html.d9a4a654.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_创造者工坊_index.html.094f4c96.js" as="script"><link rel="prefetch" href="/assets/js/tag_flux_index.html.ad3867cf.js" as="script"><link rel="prefetch" href="/assets/js/tag_llms_index.html.67431ae9.js" as="script"><link rel="prefetch" href="/assets/js/tag_lora_index.html.c7ee546c.js" as="script"><link rel="prefetch" href="/assets/js/tag_qwen_index.html.e0838b98.js" as="script"><link rel="prefetch" href="/assets/js/tag_sdxl_index.html.37a19ff3.js" as="script"><link rel="prefetch" href="/assets/js/tag_niji_index.html.a70a9af6.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_大语言模型_index.html.72664ff8.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_计算机视觉_index.html.58b39887.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_输入预处理_index.html.ed9bbf63.js" as="script"><link rel="prefetch" href="/assets/js/tag_art_index.html.fd5de43a.js" as="script"><link rel="prefetch" href="/assets/js/tag_aws_index.html.49d0379d.js" as="script"><link rel="prefetch" href="/assets/js/tag_llm_index.html.3a8069a7.js" as="script"><link rel="prefetch" href="/assets/js/tag_mcp_index.html.5e93604a.js" as="script"><link rel="prefetch" href="/assets/js/tag_gtc_index.html.1e06b509.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_artificial-intelligence_index.html.8cfd6b09.js" as="script"><link rel="prefetch" href="/assets/js/category_index.html.30915709.js" as="script"><link rel="prefetch" href="/assets/js/tag_ai_index.html.691e8ede.js" as="script"><link rel="prefetch" href="/assets/js/tag_lu_index.html.f7da3bcc.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_llm基准测试_index.html.fc9da582.js" as="script"><link rel="prefetch" href="/assets/js/timeline_index.html.3f867224.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_阿里巴巴ai_index.html.c970b0e2.js" as="script"><link rel="prefetch" href="/assets/js/article_index.html.3131e8c3.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_使用指南_index.html.63c177db.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_图像生成_index.html.c3ae9a7c.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_教程指南_index.html.42c5df88.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_模型开发_index.html.185a36fd.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_模型研发_index.html.f6ab3ec2.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_模型训练_index.html.1785036a.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_视频生成_index.html.60de099e.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_论文精读_index.html.7276ab7f.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_动漫风格_index.html.8538e3dd.js" as="script"><link rel="prefetch" href="/assets/js/tag_model-context-protocol_index.html.25f141b3.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_index.html.8158d3a4.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ielts_usage-of-collocations-in-speaking_index.html.b2df067f.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_workflow-generation_index.html.4c431f19.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_人工智能_index.html.f0a2e682.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_使用指南_index.html.fe8c29d0.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_功能发布_index.html.d6a89296.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_反向传播_index.html.ac57d1ff.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_可控生成_index.html.142da7e4.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_图像生成_index.html.dfb3e561.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_图像识别_index.html.9bff49b9.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_基础模型_index.html.7953d298.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_开源项目_index.html.e3cfbec0.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_扩散模型_index.html.829f3a99.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_技术教程_index.html.9ee8291c.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_游戏开发_index.html.6e767c46.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_艺术课程_index.html.46238e22.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_视频生成_index.html.8068090f.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_计算优化_index.html.4e81f12a.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_阿里巴巴_index.html.df377e00.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_页面配置_index.html.c7985dc6.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_model-development_index.html.464b624b.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_机器学习_index.html.fb0ee906.js" as="script"><link rel="prefetch" href="/assets/js/tag_large-language-models_index.html.3bcf45b0.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_2048分辨率_index.html.6fb915df.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_生成式ai_index.html.946ab634.js" as="script"><link rel="prefetch" href="/assets/js/tag_feature-announcement_index.html.5aa6fb5c.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_image-generation_index.html.b26f5abb.js" as="script"><link rel="prefetch" href="/assets/js/star_index.html.0ffd513d.js" as="script"><link rel="prefetch" href="/assets/js/tag_index.html.fc1f1e0b.js" as="script"><link rel="prefetch" href="/assets/js/tag_alibaba-ai-research_index.html.adbbd683.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_epsilon预测_index.html.93831d46.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_多模态ai_index.html.f345a0db.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_多语言ai_index.html.fe70d6af.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_stable-diffusion_index.html.a72cbefd.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_生成式ai_index.html.5736baf2.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_初学者_index.html.f5485ca2.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_张吕敏_index.html.baa96ea6.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_model-training_index.html.7e4d037d.js" as="script"><link rel="prefetch" href="/assets/js/tag_epsilon-prediction_index.html.28d2e698.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_reasoning-model_index.html.1a71ba78.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_generative-ai_index.html.82923755.js" as="script"><link rel="prefetch" href="/assets/js/tag_image-recognition_index.html.a2fa1118.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_公众号_index.html.08bf5712.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_创作者_index.html.e962922e.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_多模态_index.html.0da8de43.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_编辑器_index.html.9af3b2cb.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_amazon-bedrock_index.html.8cef35a6.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_resource-guide_index.html.ea147e91.js" as="script"><link rel="prefetch" href="/assets/js/posts_index.html.efc2f348.js" as="script"><link rel="prefetch" href="/assets/js/tag_game-development_index.html.57d177bb.js" as="script"><link rel="prefetch" href="/assets/js/tag_image-generation_index.html.8b92bc54.js" as="script"><link rel="prefetch" href="/assets/js/tag_machine-learning_index.html.faec0f3f.js" as="script"><link rel="prefetch" href="/assets/js/tag_visual-hierarchy_index.html.a2caed5c.js" as="script"><link rel="prefetch" href="/assets/js/tag_diffusion-models_index.html.93147de9.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_anime-style_index.html.6dcca799.js" as="script"><link rel="prefetch" href="/assets/js/tag_2048-resolution_index.html.f3714f53.js" as="script"><link rel="prefetch" href="/assets/js/tag_computer-vision_index.html.16784659.js" as="script"><link rel="prefetch" href="/assets/js/tag_multilingual-ai_index.html.366e07d4.js" as="script"><link rel="prefetch" href="/assets/js/tag_stablediffusion_index.html.4cefc3f4.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_kohya-ss-gui_index.html.41ea145e.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_fundamentals_index.html.a2abb31f.js" as="script"><link rel="prefetch" href="/assets/js/tag_llm-benchmarks_index.html.a4c66890.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_ai推理_index.html.e5d2b110.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_ai模型_index.html.3bce6dfb.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_ai生成_index.html.7ea51825.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_新闻_index.html.0c095e7c.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_日记_index.html.aa249f5e.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_论文_index.html.bf9a7705.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_高级_index.html.b102e135.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_illustrious_index.html.1cf7c511.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_思考_index.html.cf92ff59.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_指南_index.html.e374501e.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_转载_index.html.5c33d05d.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_explainer_index.html.e16f7b83.js" as="script"><link rel="prefetch" href="/assets/js/tag_automatic1111_index.html.96f5b2d6.js" as="script"><link rel="prefetch" href="/assets/js/tag_generative-ai_index.html.ac7fe732.js" as="script"><link rel="prefetch" href="/assets/js/tag_multimodal-ai_index.html.8e502dbb.js" as="script"><link rel="prefetch" href="/assets/js/tag_agent-systems_index.html.cea033f6.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_text2image_index.html.bc1c311b.js" as="script"><link rel="prefetch" href="/assets/js/category_advanced_index.html.b0b65b54.js" as="script"><link rel="prefetch" href="/assets/js/category_ai-tools_index.html.2197e21d.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_taylorseer_index.html.46aded77.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_reprints_index.html.0826fe61.js" as="script"><link rel="prefetch" href="/assets/js/tag_quantization_index.html.d1270720.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_优化_index.html.33627e19.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_做饭_index.html.14d1e2ca.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_内容_index.html.bf4dd66c.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_创新_index.html.3233a6ef.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_加密_index.html.bfaa97bf.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_协议_index.html.d79c2e92.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_大会_index.html.671b60e0.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_平台_index.html.1473d3b1.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_开源_index.html.68009a9f.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_微调_index.html.00e98616.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_技术_index.html.7b9b8310.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_禁用_index.html.09d49f84.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_艺术_index.html.f039e09a.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_运营_index.html.01477a7c.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_随想_index.html.2130074f.js" as="script"><link rel="prefetch" href="/assets/js/tag_ai-reasoning_index.html.92107949.js" as="script"><link rel="prefetch" href="/assets/js/tag_optimization_index.html.91e14203.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_动漫_index.html.18233701.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_实习_index.html.99c01886.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_布局_index.html.c4128b34.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_训练_index.html.4a46a86c.js" as="script"><link rel="prefetch" href="/assets/js/tag_modelmerging_index.html.3aac36a9.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_辩论_index.html.08c79452.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_量化_index.html.9cd36f77.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_comfymind_index.html.780a1f96.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_framepack_index.html.316e41ca.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_inference_index.html.f694cf8d.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_replicate_index.html.01cc7a53.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_diffusers_index.html.16bfc806.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_reprint_index.html.03c0293c.js" as="script"><link rel="prefetch" href="/assets/js/tag_fine-tuning_index.html.ca8a4059.js" as="script"><link rel="prefetch" href="/assets/js/tag_news-agents_index.html.39bd1dd8.js" as="script"><link rel="prefetch" href="/assets/js/tag_page-config_index.html.fd4f47e9.js" as="script"><link rel="prefetch" href="/assets/js/tag_usage-guide_index.html.069580af.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_markdown_index.html.4742eec1.js" as="script"><link rel="prefetch" href="/assets/js/category_novice_index.html.7561c64e.js" as="script"><link rel="prefetch" href="/assets/js/category_papers_index.html.180b7727.js" as="script"><link rel="prefetch" href="/assets/js/tag_alibaba-ai_index.html.f5c3b72c.js" as="script"><link rel="prefetch" href="/assets/js/tag_art-lesson_index.html.6dc9ccf1.js" as="script"><link rel="prefetch" href="/assets/js/tag_base-model_index.html.3c68635b.js" as="script"><link rel="prefetch" href="/assets/js/tag_encryption_index.html.ba9c6633.js" as="script"><link rel="prefetch" href="/assets/js/tag_modelmerge_index.html.f79dfcbf.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_drawing_index.html.d6ef8b08.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_ovis-u1_index.html.aab779ab.js" as="script"><link rel="prefetch" href="/assets/js/category_guide_index.html.b6dbfe00.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_comfyui_index.html.52422e18.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_aiml_index.html.5317281e.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_flux.1_index.html.703ceaab.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_github_index.html.eacf79c2.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_lumina_index.html.451683ad.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_prompt_index.html.dbf5dc4c.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_script_index.html.0c284078.js" as="script"><link rel="prefetch" href="/assets/js/category_news_index.html.0acac10a.js" as="script"><link rel="prefetch" href="/assets/js/tag_ai-model_index.html.485c27f3.js" as="script"><link rel="prefetch" href="/assets/js/tag_amazon-q_index.html.9b480256.js" as="script"><link rel="prefetch" href="/assets/js/tag_creators_index.html.1bc91546.js" as="script"><link rel="prefetch" href="/assets/js/tag_protocol_index.html.715bc788.js" as="script"><link rel="prefetch" href="/assets/js/tag_training_index.html.3c2840b0.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_merge_index.html.9e5cebd3.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_model_index.html.c5e77c69.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_notan_index.html.d1fbfa1b.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_qlora_index.html.7832f634.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_qwen3_index.html.e94caed5.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_vpred_index.html.557ab6de.js" as="script"><link rel="prefetch" href="/assets/js/tag_disable_index.html.6ed89a53.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_aigc_index.html.51eda4be.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_flux_index.html.5425d666.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_llms_index.html.22e104c5.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_niji_index.html.697abc36.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_lora_index.html.eb2cf7fa.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_sdxl_index.html.aa7ab8d6.js" as="script"><link rel="prefetch" href="/assets/js/404.html.683d9275.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_qwen_index.html.ac1dad5c.js" as="script"><link rel="prefetch" href="/assets/js/tag_debate_index.html.347d53e0.js" as="script"><link rel="prefetch" href="/assets/js/tag_layout_index.html.5a5e41d2.js" as="script"><link rel="prefetch" href="/assets/js/tag_editor_index.html.2106f4d9.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_art_index.html.8deb8f79.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_aws_index.html.defb07a5.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_gtc_index.html.1f7cf941.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_llm_index.html.cdc71de0.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_mcp_index.html.2baec1bd.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_sdo_index.html.c2389a8d.js" as="script"><link rel="prefetch" href="/assets/js/tag_anime_index.html.a8a78e3b.js" as="script"><link rel="prefetch" href="/assets/js/tag_guide_index.html.5173996f.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_lu_index.html.42e4b29c.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_ai_index.html.5a7d4e11.js" as="script"><link rel="prefetch" href="/assets/js/tag_tech_index.html.68c57a8c.js" as="script"><link rel="prefetch" href="/assets/js/tag_tmux_index.html.569017df.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_hf-weekly_index.html.06e8093d.js" as="script"><link rel="prefetch" href="/assets/js/zh_timeline_index.html.e1f1ad46.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_index.html.682e7f3d.js" as="script"><link rel="prefetch" href="/assets/js/zh_article_index.html.cd7570ad.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_papers_index.html.bb25e136.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_index.html.6f900118.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_hf-weekly_index.html.4d97c51d.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_templates_index.html.5a13aa05.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_index.html.2bfde6cd.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_index.html.3201a8c7.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_repos_index.html.d93bee28.js" as="script"><link rel="prefetch" href="/assets/js/zh_star_index.html.f6186c0f.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-impls_index.html.dc9f8315.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_index.html.9a49e407.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_thoughts_index.html.e1e18711.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_prompts_index.html.e3e3d99c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_index.html.5e8ec60f.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_dairys_index.html.6cd7d11b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ielts_index.html.727f9a48.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_repos_index.html.ce9635f7.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_index.html.c78cbce3.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_web_index.html.6fe04daf.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_sci_index.html.e71977aa.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><!--[--><a class="route-link vp-brand" href="/zh/" aria-label="带我回家"><img class="vp-nav-logo" src="/logo.svg" alt><!----><span class="vp-site-name hide-in-pad">Nlog</span></a><!--]--><!----></div><div class="vp-navbar-center"><!----><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/zh/" aria-label="Blog Home"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="home" width="1em" height="1em"></iconify-icon><!--]-->Blog Home<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/zh/demo/" aria-label="主要功能与配置演示"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="laptop-code" width="1em" height="1em"></iconify-icon><!--]-->主要功能与配置演示<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="博客"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon>博客<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ai-impls</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-impls/yolov9.html" aria-label="yolov9"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->yolov9<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ai-weekly</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/001.html" aria-label="001"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->001<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/002.html" aria-label="002"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->002<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/003.html" aria-label="003"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->003<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/004.html" aria-label="004"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->004<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/005.html" aria-label="005"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->005<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/006.html" aria-label="006"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->006<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/007.html" aria-label="007"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->007<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/008.html" aria-label="008"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->008<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/009.html" aria-label="009"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->009<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/010.html" aria-label="010"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->010<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/011.html" aria-label="011"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->011<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/012.html" aria-label="012"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->012<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/013.html" aria-label="013"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->013<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/014.html" aria-label="014"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->014<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/015.html" aria-label="015"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->015<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/016.html" aria-label="016"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->016<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/017.html" aria-label="017"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->017<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/018.html" aria-label="018"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->018<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/019.html" aria-label="019"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->019<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/020.html" aria-label="020"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->020<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/021.html" aria-label="021"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->021<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/022.html" aria-label="022"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->022<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/023.html" aria-label="023"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->023<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/024.html" aria-label="024"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->024<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/025.html" aria-label="025"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->025<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/026.html" aria-label="026"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->026<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/027.html" aria-label="027"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->027<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/028.html" aria-label="028"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->028<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/029.html" aria-label="029"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->029<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/030.html" aria-label="030"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->030<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/031.html" aria-label="031"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->031<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/032.html" aria-label="032"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->032<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/033.html" aria-label="033"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->033<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/034.html" aria-label="034"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->034<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/035.html" aria-label="035"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->035<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/036.html" aria-label="036"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->036<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/037.html" aria-label="037"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->037<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/038.html" aria-label="038"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->038<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/039.html" aria-label="039"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->039<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/040.html" aria-label="040"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->040<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/041.html" aria-label="041"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->041<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/042.html" aria-label="042"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->042<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/043.html" aria-label="043"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->043<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/044.html" aria-label="044"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->044<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/045.html" aria-label="045"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->045<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/046.html" aria-label="046"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->046<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/X01.html" aria-label="X01"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->X01<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">dairys</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/dairys/250222.html" aria-label="250222"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->250222<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/dairys/250223.html" aria-label="250223"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->250223<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">hf-weekly</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/hf-weekly/001.html" aria-label="001"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->001<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/hf-weekly/002.html" aria-label="002"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->002<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/hf-weekly/003.html" aria-label="003"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->003<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ielts</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ielts/simon-task1.html" aria-label="simon-task1"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->simon-task1<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ielts/simon-task2.html" aria-label="simon-task2"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->simon-task2<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">papers</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/3steps-paper-reading.html" aria-label="3steps-paper-reading"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->3steps-paper-reading<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/alexnet.html" aria-label="alexnet"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->alexnet<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/bagel.html" aria-label="bagel"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->bagel<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/colorizediffusion.html" aria-label="colorizediffusion"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->colorizediffusion<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/comfyui-r1.html" aria-label="comfyui-r1"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->comfyui-r1<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/ecomimic-v3.html" aria-label="ecomimic-v3"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->ecomimic-v3<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/flux-kontext.html" aria-label="flux-kontext"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->flux-kontext<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/framepack.html" aria-label="framepack"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->framepack<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/hunyuancustom.html" aria-label="hunyuancustom"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->hunyuancustom<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/icedit.html" aria-label="icedit"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->icedit<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/ming-omni.html" aria-label="ming-omni"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->ming-omni<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/omniconsistency.html" aria-label="omniconsistency"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->omniconsistency<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/omnigen2.html" aria-label="omnigen2"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->omnigen2<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/ovis-u1.html" aria-label="ovis-u1"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->ovis-u1<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/qr-lora.html" aria-label="qr-lora"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->qr-lora<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/reptext.html" aria-label="reptext"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->reptext<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/resnet.html" aria-label="resnet"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->resnet<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/sdo.html" aria-label="sdo"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->sdo<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/show-o2.html" aria-label="show-o2"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->show-o2<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/transformer.html" aria-label="transformer"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->transformer<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/vlv.html" aria-label="vlv"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->vlv<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">prompts</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/prompts/ai-weekly.prompt.html" aria-label="ai-weekly.prompt"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->ai-weekly.prompt<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/prompts/cover.prompt.html" aria-label="cover.prompt"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->cover.prompt<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/prompts/hf-weekly.prompt.html" aria-label="hf-weekly.prompt"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->hf-weekly.prompt<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/prompts/image-extract.prompt.html" aria-label="image-extract.prompt"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->image-extract.prompt<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/prompts/papers.prompt.html" aria-label="papers.prompt"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->papers.prompt<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/prompts/translate.prompt.html" aria-label="translate.prompt"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->translate.prompt<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">repos</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/repos/comfy-mind.html" aria-label="comfy-mind"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->comfy-mind<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">reprints</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/ai-art-gtc-paris-2025.html" aria-label="ai-art-gtc-paris-2025"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->ai-art-gtc-paris-2025<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/ai-art-newsletter-jan-25.html" aria-label="ai-art-newsletter-jan-25"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->ai-art-newsletter-jan-25<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/announcing-illustrious-text%E2%80%91enhancer-tag-booster-and-mood-enhancer.html" aria-label="announcing-illustrious-text‑enhancer-tag-booster-and-mood-enhancer"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->announcing-illustrious-text‑enhancer-tag-booster-and-mood-enhancer<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/crody&#39;s-model-merge-guide.html" aria-label="crody&#39;s-model-merge-guide"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->crody&#39;s-model-merge-guide<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/experiments-with-mcp-using-github-copilot.html" aria-label="experiments-with-mcp-using-github-copilot"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->experiments-with-mcp-using-github-copilot<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/explaining-tokens-the-language-and-currency-of-ai-nvidia-blog.html" aria-label="explaining-tokens-the-language-and-currency-of-ai-nvidia-blog"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->explaining-tokens-the-language-and-currency-of-ai-nvidia-blog<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/flux-1-kontext.html" aria-label="flux-1-kontext"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->flux-1-kontext<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/flux-kontext-optimization.html" aria-label="flux-kontext-optimization"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->flux-kontext-optimization<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link route-link-active auto-link" href="/zh/posts/reprints/flux-qlora.html" aria-label="flux-qlora"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->flux-qlora<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/generative-ai-powered-design.html" aria-label="generative-ai-powered-design"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->generative-ai-powered-design<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/how-and-when-to-build-multi-agent-systems.html" aria-label="how-and-when-to-build-multi-agent-systems"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->how-and-when-to-build-multi-agent-systems<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/illustrious-lu-v0.03.html" aria-label="illustrious-lu-v0.03"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->illustrious-lu-v0.03<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language.html" aria-label="illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/illustrious-xl-v2.0-the-best-training-base-model-in-1536-age.html" aria-label="illustrious-xl-v2.0-the-best-training-base-model-in-1536-age"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->illustrious-xl-v2.0-the-best-training-base-model-in-1536-age<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/image-recognition.html" aria-label="image-recognition"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->image-recognition<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/introduction-of-prompts-ai-illustration-generation-camera-angle-composition-facial-expression.html" aria-label="introduction-of-prompts-ai-illustration-generation-camera-angle-composition-facial-expression"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->introduction-of-prompts-ai-illustration-generation-camera-angle-composition-facial-expression<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/mcp-flash-in-the-pan-or-future-standard.html" aria-label="mcp-flash-in-the-pan-or-future-standard"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->mcp-flash-in-the-pan-or-future-standard<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything.html" aria-label="niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/niji-lesson-2-the-terminator-line.html" aria-label="niji-lesson-2-the-terminator-line"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->niji-lesson-2-the-terminator-line<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/niji-study-1-measuring-with-your-eyes.html" aria-label="niji-study-1-measuring-with-your-eyes"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->niji-study-1-measuring-with-your-eyes<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/niji-study-2-notan.html" aria-label="niji-study-2-notan"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->niji-study-2-notan<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/niji-video.html" aria-label="niji-video"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->niji-video<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/original-character-lora-sdxl-character-training.html" aria-label="original-character-lora-sdxl-character-training"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->original-character-lora-sdxl-character-training<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html" aria-label="qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/step-by-step-visual-introduction-to-diffusion-models.html" aria-label="step-by-step-visual-introduction-to-diffusion-models"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->step-by-step-visual-introduction-to-diffusion-models<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">sci</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/sci/conda.html" aria-label="conda"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->conda<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">templates</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/templates/ai-weekly.html" aria-label="ai-weekly"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->ai-weekly<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/templates/hf-weekly.html" aria-label="hf-weekly"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->hf-weekly<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/templates/papers.html" aria-label="papers"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->papers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/templates/repos.html" aria-label="repos"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->repos<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">thoughts</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/thoughts/platform-operation-thoughts-after-comfycon.html" aria-label="platform-operation-thoughts-after-comfycon"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->platform-operation-thoughts-after-comfycon<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">web</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/web/vue-1.html" aria-label="vue-1"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->vue-1<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">workflows</h4><ul class="vp-dropdown-subitems"></ul></li></ul></button></div></div></nav><!--]--><!----></div><div class="vp-navbar-end"><!----><!--[--><div class="vp-nav-item"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="选择语言"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon i18n-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="i18n icon" name="i18n" style="width:1rem;height:1rem;vertical-align:middle;"><path d="M379.392 460.8 494.08 575.488l-42.496 102.4L307.2 532.48 138.24 701.44l-71.68-72.704L234.496 460.8l-45.056-45.056c-27.136-27.136-51.2-66.56-66.56-108.544h112.64c7.68 14.336 16.896 27.136 26.112 35.84l45.568 46.08 45.056-45.056C382.976 312.32 409.6 247.808 409.6 204.8H0V102.4h256V0h102.4v102.4h256v102.4H512c0 70.144-37.888 161.28-87.04 210.944L378.88 460.8zM576 870.4 512 1024H409.6l256-614.4H768l256 614.4H921.6l-64-153.6H576zM618.496 768h196.608L716.8 532.48 618.496 768z"></path></svg><!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/posts/reprints/flux-qlora.html" aria-label="English"><!---->English<!----></a></li><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/zh/posts/reprints/flux-qlora.html" aria-label="简体中文"><!---->简体中文<!----></a></li></ul></button></div></div><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/vuepress-theme-hope/vuepress-theme-hope" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--]--><!----><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/zh/" aria-label="Blog Home"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="home" width="1em" height="1em"></iconify-icon><!--]-->Blog Home<!----></a></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header clickable"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="laptop-code" width="1em" height="1em"></iconify-icon><a class="route-link auto-link vp-sidebar-title no-external-link-icon" href="/zh/demo/" aria-label="如何使用"><!---->如何使用<!----></a><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/zh/demo/markdown.html" aria-label="Markdown 展示"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fab fa-markdown" width="1em" height="1em"></iconify-icon><!--]-->Markdown 展示<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/demo/layout.html" aria-label="布局"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="object-group" width="1em" height="1em"></iconify-icon><!--]-->布局<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/demo/page.html" aria-label="页面配置"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="file" width="1em" height="1em"></iconify-icon><!--]-->页面配置<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/demo/disable.html" aria-label="布局与功能禁用"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="gears" width="1em" height="1em"></iconify-icon><!--]-->布局与功能禁用<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/demo/encrypt.html" aria-label="密码加密的文章"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="lock" width="1em" height="1em"></iconify-icon><!--]-->密码加密的文章<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header active"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="book" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">文章</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Ai Impls</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Ai Weekly</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Dairys</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Hf Weekly</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Ielts</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Papers</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Prompts</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Repos</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">Reprints</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/mcp-flash-in-the-pan-or-future-standard.html" aria-label="MCP：昙花一现还是未来标准？"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="openmoji:code-editor" width="1em" height="1em"></iconify-icon><!--]-->MCP：昙花一现还是未来标准？<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/generative-ai-powered-design.html" aria-label="生成式AI驱动的设计：使用SD3.5 Large创建游戏环境"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="openmoji:video-game" width="1em" height="1em"></iconify-icon><!--]-->生成式AI驱动的设计：使用SD3.5 Large创建游戏环境<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything.html" aria-label="第一课：测量与抽象的基础：绘画的普遍理论"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="palette" width="1em" height="1em"></iconify-icon><!--]-->第一课：测量与抽象的基础：绘画的普遍理论<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/niji-study-1-measuring-with-your-eyes.html" aria-label="练习1：用眼睛测量"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="ruler" width="1em" height="1em"></iconify-icon><!--]-->练习1：用眼睛测量<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/niji-study-2-notan.html" aria-label="研究 2：Notan"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="contrast" width="1em" height="1em"></iconify-icon><!--]-->研究 2：Notan<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/introduction-of-prompts-ai-illustration-generation-camera-angle-composition-facial-expression.html" aria-label="AI插画生成中的prompt介绍【composition/camera angle/facial expression】"><!---->AI插画生成中的prompt介绍【composition/camera angle/facial expression】<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/ai-art-newsletter-jan-25.html" aria-label="AI艺术工具通讯 - 第1期"><!---->AI艺术工具通讯 - 第1期<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/crody&#39;s-model-merge-guide.html" aria-label="Crody&#39;s Model Merge Guide // Team-C"><!---->Crody&#39;s Model Merge Guide // Team-C<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/step-by-step-visual-introduction-to-diffusion-models.html" aria-label="Diffusion Models 可视化逐步入门"><!---->Diffusion Models 可视化逐步入门<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language.html" aria-label="Illustrious XL 3.0-3.5-vpred: 2048分辨率与自然语言"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="mdi:paint-outline" width="1em" height="1em"></iconify-icon><!--]-->Illustrious XL 3.0-3.5-vpred: 2048分辨率与自然语言<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/illustrious-xl-v2.0-the-best-training-base-model-in-1536-age.html" aria-label="Illustrious XL v2.0：1536分辨率时代最佳的训练基础模型"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="mdi:paint-outline" width="1em" height="1em"></iconify-icon><!--]-->Illustrious XL v2.0：1536分辨率时代最佳的训练基础模型<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/illustrious-lu-v0.03.html" aria-label="Illustrious-LU v0.03"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:microscope" width="1em" height="1em"></iconify-icon><!--]-->Illustrious-LU v0.03<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html" aria-label="Qwen3: 下一代具备混合思维和多语言精通能力的AI模型 | 2025年概览"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:robot" width="1em" height="1em"></iconify-icon><!--]-->Qwen3: 下一代具备混合思维和多语言精通能力的AI模型 | 2025年概览<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/image-recognition.html" aria-label="什么是图像识别？算法和应用"><!---->什么是图像识别？算法和应用<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/experiments-with-mcp-using-github-copilot.html" aria-label="使用 GitHub Copilot 进行 MCP 实验"><!---->使用 GitHub Copilot 进行 MCP 实验<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/announcing-illustrious-text%E2%80%91enhancer-tag-booster-and-mood-enhancer.html" aria-label="发布 Illustrious Text‑Enhancer：Tag Booster 和 Mood Enhancer"><!---->发布 Illustrious Text‑Enhancer：Tag Booster 和 Mood Enhancer<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/zh/posts/reprints/flux-qlora.html" aria-label="在消费级硬件上对 FLUX.1-dev 进行（LoRA）微调"><!---->在消费级硬件上对 FLUX.1-dev 进行（LoRA）微调<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/how-and-when-to-build-multi-agent-systems.html" aria-label="如何以及何时构建多智能体系统"><!---->如何以及何时构建多智能体系统<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/niji-video.html" aria-label="如何使用 niji・journey 制作视频"><!---->如何使用 niji・journey 制作视频<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/original-character-lora-sdxl-character-training.html" aria-label="如何创建原创角色 LoRA [SDXL 训练] SDXL 角色训练"><!---->如何创建原创角色 LoRA [SDXL 训练] SDXL 角色训练<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/flux-kontext-optimization.html" aria-label="我们如何优化 FLUX.1 Kontext [dev]"><!---->我们如何优化 FLUX.1 Kontext [dev]<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/ai-art-gtc-paris-2025.html" aria-label="艺术家和时装设计师利用最先进的AI技术为NVIDIA GTC巴黎画廊创作"><!---->艺术家和时装设计师利用最先进的AI技术为NVIDIA GTC巴黎画廊创作<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/explaining-tokens-the-language-and-currency-of-ai-nvidia-blog.html" aria-label="解释token— AI的语言和货币 | NVIDIA博客"><!---->解释token— AI的语言和货币 | NVIDIA博客<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/niji-lesson-2-the-terminator-line.html" aria-label="课程 2：终结者（线）"><!---->课程 2：终结者（线）<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/flux-1-kontext.html" aria-label="隆重推出 FLUX.1 Kontext 与 BFL Playground"><!---->隆重推出 FLUX.1 Kontext 与 BFL Playground<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Sci</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Templates</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Thoughts</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Web</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Workflows</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/intro.html" aria-label="Intro Page"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="circle-info" width="1em" height="1em"></iconify-icon><!--]-->Intro Page<!----></a></li><li><a class="auto-link external-link vp-sidebar-link" href="https://ecosystem.vuejs.press/zh/plugins/markdown/revealjs/demo.html" aria-label="幻灯片" rel="noopener noreferrer" target="_blank"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="person-chalkboard" width="1em" height="1em"></iconify-icon><!--]-->幻灯片<!----></a></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->在消费级硬件上对 FLUX.1-dev 进行（LoRA）微调</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">Derek Liu, Marc Sun, Sayak Paul, merve, Linoy Tsaban</span></span><span property="author" content="Derek Liu, Marc Sun, Sayak Paul, merve, Linoy Tsaban"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2024年6月19日</span><meta property="datePublished" content="2024-06-19T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 14 分钟</span><meta property="timeRequired" content="PT14M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color4 clickable" role="navigation">AI/ML</span><!--]--><meta property="articleSection" content="AI/ML"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color6 clickable" role="navigation">FLUX</span><span class="page-tag-item color1 clickable" role="navigation">LoRA</span><span class="page-tag-item color3 clickable" role="navigation">QLoRA</span><span class="page-tag-item color6 clickable" role="navigation">微调</span><span class="page-tag-item color5 clickable" role="navigation">diffusers</span><span class="page-tag-item color2 clickable" role="navigation">量化</span><!--]--><meta property="keywords" content="FLUX,LoRA,QLoRA,微调,diffusers,量化"></span></div><hr></div><div class="vp-toc-placeholder"><aside id="toc"><!----><div class="vp-toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon" name="print"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#目录">目录</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#数据集">数据集</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#flux-架构">FLUX 架构</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#使用-diffusers-对-flux-1-dev-进行-qlora-微调">使用 diffusers 对 FLUX.1-dev 进行 QLoRA 微调</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#关键优化技术">关键优化技术</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#预计算文本嵌入-clip-t5">预计算文本嵌入（CLIP/T5）</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#如何使用">如何使用</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#设置和结果">设置和结果</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#使用-torchao-进行-fp8-微调">使用 torchao 进行 FP8 微调</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#使用训练好的-lora-适配器进行推理">使用训练好的 LoRA 适配器进行推理</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#选项-1-加载-lora-适配器">选项 1：加载 LoRA 适配器</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#选项-2-将-lora-合并到基础模型">选项 2：将 LoRA 合并到基础模型</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#在-google-colab-上运行">在 Google Colab 上运行</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#结论">结论</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#在-hub-上分享您的创作">在 Hub 上分享您的创作！</a></li><!----><!--]--></ul></li><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!----></aside></div><!----><div class="theme-hope-content" vp-content><h1 id="在消费级硬件上对-flux-1-dev-进行-lora-微调" tabindex="-1"><a class="header-anchor" href="#在消费级硬件上对-flux-1-dev-进行-lora-微调"><span>在消费级硬件上对 FLUX.1-dev 进行（LoRA）微调</span></a></h1><div class="hint-container tip"><p class="hint-container-title">提示</p><figure><a href="https://colab.research.google.com/github/DerekLiu35/notebooks/blob/main/flux_lora_quant_blogpost.ipynb" target="_blank" rel="noopener noreferrer"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" tabindex="0" loading="lazy"></a><figcaption>Open In Colab</figcaption></figure></div><p>在我们之前的文章《<a href="https://huggingface.co/blog/diffusers-quantization" target="_blank" rel="noopener noreferrer">在 Diffusers 中探索量化后端</a>》中，我们深入研究了各种量化技术如何缩小像 FLUX.1-dev 这样的扩散模型，使它们在_推理_方面显著更易于访问，而不会大幅降低性能。我们看到了 <code>bitsandbytes</code>、<code>torchao</code> 和其他技术如何减少生成图像时的内存占用。</p><p>执行推理很酷，但要让这些模型真正成为我们自己的，我们还需要能够对它们进行微调。因此，在这篇文章中，我们将探讨在单个 GPU 上以不到 10GB 显存的峰值内存使用量进行这些模型的<strong>高效</strong><em>微调</em>。本文将指导您使用 <code>diffusers</code> 库通过 QLoRA 对 FLUX.1-dev 进行微调。我们将展示在 NVIDIA RTX 4090 上的结果。我们还将重点介绍如何在兼容硬件上使用 <code>torchao</code> 的 FP8 训练进一步优化速度。</p><h2 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span>目录</span></a></h2><ol><li><a href="#%E6%95%B0%E6%8D%AE%E9%9B%86">数据集</a></li><li><a href="#flux-%E6%9E%B6%E6%9E%84">FLUX 架构</a></li><li><a href="#%E4%BD%BF%E7%94%A8-diffusers-%E5%AF%B9-flux1-dev-%E8%BF%9B%E8%A1%8C-qlora-%E5%BE%AE%E8%B0%83">使用 <code>diffusers</code> 对 FLUX.1-dev 进行 QLoRA 微调</a><ul><li><a href="#%E5%85%B3%E9%94%AE%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF">关键优化技术</a></li><li><a href="#%E9%A2%84%E8%AE%A1%E7%AE%97%E6%96%87%E6%9C%AC%E5%B5%8C%E5%85%A5clipt5">预计算文本嵌入（CLIP/T5）</a></li><li><a href="#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8">如何使用</a></li><li><a href="#%E8%AE%BE%E7%BD%AE%E5%92%8C%E7%BB%93%E6%9E%9C">设置和结果</a></li></ul></li><li><a href="#%E4%BD%BF%E7%94%A8-torchao-%E8%BF%9B%E8%A1%8C-fp8-%E5%BE%AE%E8%B0%83">使用 <code>torchao</code> 进行 FP8 微调</a></li><li><a href="#%E4%BD%BF%E7%94%A8%E8%AE%AD%E7%BB%83%E5%A5%BD%E7%9A%84-lora-%E9%80%82%E9%85%8D%E5%99%A8%E8%BF%9B%E8%A1%8C%E6%8E%A8%E7%90%86">使用训练好的 LoRA 适配器进行推理</a><ul><li><a href="#%E9%80%89%E9%A1%B9-1%E5%8A%A0%E8%BD%BD-lora-%E9%80%82%E9%85%8D%E5%99%A8">选项 1：加载 LoRA 适配器</a></li><li><a href="#%E9%80%89%E9%A1%B9-2%E5%B0%86-lora-%E5%90%88%E5%B9%B6%E5%88%B0%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B">选项 2：将 LoRA 合并到基础模型</a></li></ul></li><li><a href="#%E5%9C%A8-google-colab-%E4%B8%8A%E8%BF%90%E8%A1%8C">在 Google Colab 上运行</a></li><li><a href="#%E7%BB%93%E8%AE%BA">结论</a></li></ol><h2 id="数据集" tabindex="-1"><a class="header-anchor" href="#数据集"><span>数据集</span></a></h2><p>我们的目标是对 <code>black-forest-labs/FLUX.1-dev</code> 进行微调，使其采用 Alphonse Mucha 的艺术风格，使用一个小型<a href="https://huggingface.co/datasets/derekl35/alphonse-mucha-style" target="_blank" rel="noopener noreferrer">数据集</a>。</p><h2 id="flux-架构" tabindex="-1"><a class="header-anchor" href="#flux-架构"><span>FLUX 架构</span></a></h2><p>该模型由三个主要组件组成：</p><ul><li>文本编码器（CLIP 和 T5）</li><li>Transformer（主模型 - Flux Transformer）</li><li>变分自编码器（VAE）</li></ul><p>在我们的 QLoRA 方法中，我们专门专注于微调 <strong>transformer 组件</strong>。文本编码器和 VAE 在整个训练过程中保持冻结状态。</p><h2 id="使用-diffusers-对-flux-1-dev-进行-qlora-微调" tabindex="-1"><a class="header-anchor" href="#使用-diffusers-对-flux-1-dev-进行-qlora-微调"><span>使用 <code>diffusers</code> 对 FLUX.1-dev 进行 QLoRA 微调</span></a></h2><p>我们使用了一个 <code>diffusers</code> 训练脚本（稍作修改，来自 <a href="https://github.com/huggingface/diffusers/blob/main/examples/research_projects/flux_lora_quantization/train_dreambooth_lora_flux_miniature.py" target="_blank" rel="noopener noreferrer">https://github.com/huggingface/diffusers/blob/main/examples/research_projects/flux_lora_quantization/train_dreambooth_lora_flux_miniature.py</a>），专为 FLUX 模型的 DreamBooth 风格 LoRA 微调而设计。此外，还有一个简化版本来重现本博文中的结果（并在 <a href="https://colab.research.google.com/github/DerekLiu35/notebooks/blob/main/flux_lora_quant_blogpost.ipynb" target="_blank" rel="noopener noreferrer">Google Colab</a> 中使用），可在<a href="https://github.com/huggingface/diffusers/blob/main/examples/research_projects/flux_lora_quantization/train_dreambooth_lora_flux_nano.py" target="_blank" rel="noopener noreferrer">这里</a>获得。让我们检查 QLoRA 和内存效率的关键部分：</p><h3 id="关键优化技术" tabindex="-1"><a class="header-anchor" href="#关键优化技术"><span>关键优化技术</span></a></h3><p><strong>LoRA（低秩适应）深入解析：</strong><a href="https://huggingface.co/docs/peft/main/en/conceptual_guides/lora" target="_blank" rel="noopener noreferrer">LoRA</a> 通过使用低秩矩阵跟踪权重更新，使模型训练更加高效。LoRA 不是更新完整的权重矩阵 W，而是学习两个较小的矩阵 A 和 B。模型权重的更新是 ΔW = BA，其中 A ∈ R^(r×k) 且 B ∈ R^(d×r)。数字 r（称为_秩_）比原始维度小得多，这意味着要更新的参数更少。最后，α 是 LoRA 激活的缩放因子。这影响 LoRA 对更新的影响程度，通常设置为与 r 相同的值或其倍数。它有助于平衡预训练模型和 LoRA 适配器的影响。有关概念的一般介绍，请查看我们之前的博客文章：<a href="https://huggingface.co/blog/lora" target="_blank" rel="noopener noreferrer">使用 LoRA 进行高效的稳定扩散微调</a>。</p><figure><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/peft/lora_diagram.png" alt="LoRA 在冻结权重矩阵周围注入两个低秩矩阵的示意图" tabindex="0" loading="lazy"><figcaption>LoRA 在冻结权重矩阵周围注入两个低秩矩阵的示意图</figcaption></figure><p><strong>QLoRA：效率的动力源：</strong><a href="https://huggingface.co/docs/peft/main/en/developer_guides/quantization" target="_blank" rel="noopener noreferrer">QLoRA</a> 通过首先以量化格式（通常通过 <code>bitsandbytes</code> 进行 4 位）加载预训练基础模型来增强 LoRA，大幅减少基础模型的内存占用。然后在这个量化基础上训练 LoRA 适配器（通常在 FP16/BF16 中）。这大大降低了保存基础模型所需的显存。</p><p>例如，在 <a href="https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/README_hidream.md#using-quantization" target="_blank" rel="noopener noreferrer">HiDream 的 DreamBooth 训练脚本</a>中，使用 bitsandbytes 的 4 位量化将 LoRA 微调的峰值内存使用量从约 60GB 降至约 37GB，质量降低可忽略不计。我们在这里应用的正是同样的原理，在消费级硬件上微调 FLUX.1。</p><p><strong>8 位优化器（AdamW）：</strong> 标准 AdamW 优化器为每个参数维护 32 位（FP32）的一阶和二阶矩估计，这消耗大量内存。8 位 AdamW 使用块级量化将优化器状态存储在 8 位精度中，同时保持训练稳定性。与标准 FP32 AdamW 相比，此技术可将优化器内存使用量减少约 75%。在脚本中启用它很简单：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 检查 --use_8bit_adam 标志</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> args.use_8bit_adam:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        optimizer_class </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> bnb.optim.AdamW8bit</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">else</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        optimizer_class </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.optim.AdamW</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">optimizer </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> optimizer_class</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        params_to_optimize,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        betas</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(args.adam_beta1, args.adam_beta2),</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        weight_decay</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">args.adam_weight_decay,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        eps</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">args.adam_epsilon,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>梯度检查点：</strong> 在前向传播期间，中间激活通常为反向传播梯度计算而存储。梯度检查点通过仅存储某些_检查点激活_并在反向传播期间重新计算其他激活，来用计算换取内存。</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> args.gradient_checkpointing:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        transformer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">enable_gradient_checkpointing</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>缓存潜在变量：</strong> 这种优化技术在训练开始前通过 VAE 编码器预处理所有训练图像。它将生成的潜在表示存储在内存中。在训练期间，不是即时编码图像，而是直接使用缓存的潜在变量。这种方法提供两个主要好处：</p><ol><li>消除训练期间冗余的 VAE 编码计算，加速每个训练步骤</li><li>允许在缓存后完全从 GPU 内存中移除 VAE。权衡是增加 RAM 使用量来存储所有缓存的潜在变量，但对于小数据集来说，这通常是可管理的。</li></ol><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 如果设置了标志，则在训练前缓存潜在变量</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> args.cache_latents:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        latents_cache </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> []</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> batch </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> tqdm</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(train_dataloader, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">desc</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Caching latents&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">                with</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">no_grad</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">():</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                        batch[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;pixel_values&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> batch[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;pixel_values&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">to</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                accelerator.device, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">non_blocking</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">weight_dtype</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                        )</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                        latents_cache.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(vae.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">encode</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(batch[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;pixel_values&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]).latent_dist)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 不再需要 VAE，释放其内存</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        del</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> vae</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">        free_memory</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>设置 4 位量化（<code>BitsAndBytesConfig</code>）：</strong></p><p>本节演示基础模型的 QLoRA 配置：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 根据混合精度确定计算数据类型</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bnb_4bit_compute_dtype </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.float32</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> args.mixed_precision </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">==</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;fp16&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        bnb_4bit_compute_dtype </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.float16</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">elif</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> args.mixed_precision </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">==</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;bf16&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        bnb_4bit_compute_dtype </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.bfloat16</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">nf4_config </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> BitsAndBytesConfig</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        load_in_4bit</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        bnb_4bit_quant_type</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;nf4&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        bnb_4bit_compute_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bnb_4bit_compute_dtype,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxTransformer2DModel.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        args.pretrained_model_name_or_path,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        subfolder</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;transformer&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        quantization_config</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">nf4_config,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        torch_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bnb_4bit_compute_dtype,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 为 k 位训练准备模型</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> prepare_model_for_kbit_training</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(transformer, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">use_gradient_checkpointing</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">False</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 如果设置了参数，梯度检查点稍后通过 transformer.enable_gradient_checkpointing() 启用</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>定义 LoRA 配置（<code>LoraConfig</code>）：</strong> 适配器被添加到量化的 transformer：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer_lora_config </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> LoraConfig</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        r</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">args.rank,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        lora_alpha</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">args.rank, </span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        init_lora_weights</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;gaussian&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        target_modules</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;to_k&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;to_q&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;to_v&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;to_out.0&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">], </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># FLUX 注意力块</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">add_adapter</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(transformer_lora_config)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;trainable params: </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">num_parameters</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">only_trainable</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> || all params: </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">num_parameters</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># trainable params: 4,669,440 || all params: 11,906,077,760</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>只有这些 LoRA 参数变为可训练的。</p><h3 id="预计算文本嵌入-clip-t5" tabindex="-1"><a class="header-anchor" href="#预计算文本嵌入-clip-t5"><span>预计算文本嵌入（CLIP/T5）</span></a></h3><p>在启动 QLoRA 微调之前，我们可以通过一次性缓存文本编码器的输出来节省大量显存和计算时间。</p><p>在训练时，数据加载器只需读取缓存的嵌入，而不是重新编码标题，因此 CLIP/T5 编码器永远不必驻留在 GPU 内存中。</p><details class="hint-container details"><summary>代码</summary><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># https://github.com/huggingface/diffusers/blob/main/examples/research_projects/flux_lora_quantization/compute_embeddings.py</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> argparse</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pandas </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pd</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> datasets </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> load_dataset</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> huggingface_hub.utils </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> insecure_hashlib</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tqdm.auto </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tqdm</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> transformers </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> T5EncoderModel</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> diffusers </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxPipeline</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">MAX_SEQ_LENGTH</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> =</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 77</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">OUTPUT_PATH</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> =</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;embeddings.parquet&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> generate_image_hash</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">image</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> insecure_hashlib.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">sha256</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(image.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">tobytes</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()).</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">hexdigest</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> load_flux_dev_pipeline</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">():</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">        id</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> =</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;black-forest-labs/FLUX.1-dev&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        text_encoder </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> T5EncoderModel.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">id</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">subfolder</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;text_encoder_2&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">load_in_8bit</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">device_map</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;auto&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        pipeline </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxPipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">                id</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">text_encoder_2</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">text_encoder, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">transformer</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">vae</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">device_map</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;balanced&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        )</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pipeline</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">@torch</span><span style="--shiki-light:#4078F2;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">no_grad</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> compute_embeddings</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">pipeline</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> prompts</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> max_sequence_length</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        all_prompt_embeds </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> []</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        all_pooled_prompt_embeds </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> []</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        all_text_ids </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> []</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> prompt </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> tqdm</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(prompts, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">desc</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Encoding prompts.&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                (</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                        prompt_embeds,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                        pooled_prompt_embeds,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                        text_ids,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                ) </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">encode_prompt</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">prompt</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">prompt, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">prompt_2</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">max_sequence_length</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">max_sequence_length)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                all_prompt_embeds.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(prompt_embeds)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                all_pooled_prompt_embeds.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(pooled_prompt_embeds)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                all_text_ids.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(text_ids)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        max_memory </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.cuda.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">max_memory_allocated</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">() </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">/</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 1024</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> /</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 1024</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> /</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 1024</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">        print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Max memory allocated: </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">max_memory</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">:.3f</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> GB&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> all_prompt_embeds, all_pooled_prompt_embeds, all_text_ids</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> run</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">args</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        dataset </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> load_dataset</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Norod78/Yarn-art-style&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">split</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;train&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        image_prompts </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> {</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">generate_image_hash</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(sample[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;image&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]): sample[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;text&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> sample </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> dataset}</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        all_prompts </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> list</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(image_prompts.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">values</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">())</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">        print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">len</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(all_prompts)</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        pipeline </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> load_flux_dev_pipeline</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        all_prompt_embeds, all_pooled_prompt_embeds, all_text_ids </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> compute_embeddings</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                pipeline, all_prompts, args.max_sequence_length</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        )</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        data </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> []</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> i, (image_hash, _) </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> enumerate</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(image_prompts.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">items</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()):</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                data.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">((image_hash, all_prompt_embeds[i], all_pooled_prompt_embeds[i], all_text_ids[i]))</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">        print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">len</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(data)</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 创建 DataFrame</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        embedding_cols </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;prompt_embeds&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;pooled_prompt_embeds&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;text_ids&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        df </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pd.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">DataFrame</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(data, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">columns</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;image_hash&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> embedding_cols)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">        print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">len</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(df)</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 将嵌入列表转换为数组（用于正确存储在 parquet 中）</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> col </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> embedding_cols:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                df[col] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> df[col].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">apply</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">lambda</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> x</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: x.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">cpu</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">().</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">numpy</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">().</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">flatten</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">().</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">tolist</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">())</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 将 dataframe 保存到 parquet 文件</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        df.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">to_parquet</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(args.output_path)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">        print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Data successfully serialized to </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">args.output_path</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> __name__</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> ==</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;__main__&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        parser </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> argparse.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">ArgumentParser</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        parser.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">add_argument</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">                &quot;--max_sequence_length&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">                type</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">int</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">                default</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">MAX_SEQ_LENGTH</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">                help</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;用于计算嵌入的最大序列长度。越多计算成本越高。&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        )</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        parser.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">add_argument</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;--output_path&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">type</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">str</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">default</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">OUTPUT_PATH</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">help</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;序列化 parquet 文件的路径。&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        args </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> parser.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">parse_args</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">        run</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(args)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><h3 id="如何使用" tabindex="-1"><a class="header-anchor" href="#如何使用"><span>如何使用</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">python</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> compute_embeddings.py</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --max_sequence_length</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 77</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --output_path</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> embeddings_alphonse_mucha.parquet</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>通过将此与缓存的 VAE 潜在变量（<code>--cache_latents</code>）结合，您可以将活动模型精简为仅量化的 transformer + LoRA 适配器，使整个微调舒适地保持在 10GB GPU 内存以下。</p><h3 id="设置和结果" tabindex="-1"><a class="header-anchor" href="#设置和结果"><span>设置和结果</span></a></h3><p>在此演示中，我们利用 NVIDIA RTX 4090（24GB 显存）来探索其性能。使用 <code>accelerate</code> 的完整训练命令如下所示。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 您需要首先预计算文本嵌入。请参阅 diffusers 仓库。</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># https://github.com/huggingface/diffusers/tree/main/examples/research_projects/flux_lora_quantization</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">accelerate</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> launch</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --config_file=accelerate.yaml</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    train_dreambooth_lora_flux_miniature.py</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --pretrained_model_name_or_path=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;black-forest-labs/FLUX.1-dev&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --data_df_path=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;embeddings_alphonse_mucha.parquet&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --output_dir=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;alphonse_mucha_lora_flux_nf4&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --mixed_precision=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;bf16&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --use_8bit_adam</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --weighting_scheme=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;none&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --width=512</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --height=768</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --train_batch_size=1</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --repeats=1</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --learning_rate=1e-4</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --guidance_scale=1</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --report_to=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;wandb&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --gradient_accumulation_steps=4</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --gradient_checkpointing</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \ </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">#</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> 当硬件有超过</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> 16GB</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> 时可以去掉检查点</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">    --lr_scheduler</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;constant&quot;</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --lr_warmup_steps=0</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --cache_latents</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --rank=4</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --max_train_steps=700</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --seed=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;0&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>RTX 4090 配置：</strong> 在我们的 RTX 4090 上，我们使用 <code>train_batch_size</code> 为 1，<code>gradient_accumulation_steps</code> 为 4，<code>mixed_precision=&quot;bf16&quot;</code>，<code>gradient_checkpointing=True</code>，<code>use_8bit_adam=True</code>，LoRA <code>rank</code> 为 4，分辨率为 512x768。使用 <code>cache_latents=True</code> 缓存潜在变量。</p><p><strong>内存占用（RTX 4090）：</strong></p><ul><li><strong>QLoRA：</strong> QLoRA 微调的峰值显存使用量约为 9GB。</li><li><strong>BF16 LoRA：</strong> 在相同设置上运行标准 LoRA（基础 FLUX.1-dev 在 FP16 中）消耗 26GB 显存。</li><li><strong>BF16 完全微调：</strong> 在没有内存优化的情况下，估计约为 120GB 显存。</li></ul><p><strong>训练时间（RTX 4090）：</strong> 在 Alphonse Mucha 数据集上进行 700 步微调，在 RTX 4090 上使用 <code>train_batch_size</code> 为 1 和分辨率为 512x768 大约需要 41 分钟。</p><p><strong>输出质量：</strong> 最终衡量标准是生成的艺术品。以下是我们在 <a href="https://huggingface.co/datasets/derekl35/alphonse-mucha-style" target="_blank" rel="noopener noreferrer">derekl35/alphonse-mucha-style</a> 数据集上训练的 QLoRA 微调模型的样本：</p><p>此表比较了主要的 <code>bf16</code> 精度结果。微调的目标是教会模型 Alphonse Mucha 的独特风格。</p><table><thead><tr><th>提示</th><th>基础模型输出</th><th>QLoRA 微调输出（Mucha 风格）</th></tr></thead><tbody><tr><td><em>&quot;宁静的黑发女子，月光百合，漩涡植物，alphonse mucha style&quot;</em></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base2_bf16.png" alt="第一个提示的基础模型输出" loading="lazy"></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged2_qlora_bf16.png" alt="第一个提示的 QLoRA 模型输出" loading="lazy"></td></tr><tr><td><em>&quot;池塘中的小狗，alphonse mucha style&quot;</em></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base3_bf16.png" alt="第二个提示的基础模型输出" loading="lazy"></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged3_qlora_bf16.png" alt="第二个提示的 QLoRA 模型输出" loading="lazy"></td></tr><tr><td><em>&quot;华丽的狐狸，佩戴秋叶和浆果的项圈，置身于森林植物的挂毯中，alphonse mucha style&quot;</em></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base5_bf16.png" alt="第三个提示的基础模型输出" loading="lazy"></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged5_qlora_bf16.png" alt="第三个提示的 QLoRA 模型输出" loading="lazy"></td></tr></tbody></table><p>微调后的模型很好地捕捉到了 Mucha 标志性的新艺术风格，这在装饰图案和独特的调色板中表现得很明显。QLoRA 过程在学习新风格的同时保持了出色的保真度。</p><details class="hint-container details"><summary>fp16 比较</summary><p>结果几乎相同，表明 QLoRA 在 <code>fp16</code> 和 <code>bf16</code> 混合精度下都表现有效。</p><h3 id="模型比较-基础模型-vs-qlora-微调-fp16" tabindex="-1"><a class="header-anchor" href="#模型比较-基础模型-vs-qlora-微调-fp16"><span>模型比较：基础模型 vs. QLoRA 微调（fp16）</span></a></h3><table><thead><tr><th>提示</th><th>基础模型输出</th><th>QLoRA 微调输出（Mucha 风格）</th></tr></thead><tbody><tr><td><em>&quot;宁静的黑发女子，月光百合，漩涡植物，alphonse mucha style&quot;</em></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base2.png" alt="第一个提示的基础模型输出" loading="lazy"></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged2.png" alt="第一个提示的 QLoRA 模型输出" loading="lazy"></td></tr><tr><td><em>&quot;池塘中的小狗，alphonse mucha style&quot;</em></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base3.png" alt="第二个提示的基础模型输出" loading="lazy"></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged3.png" alt="第二个提示的 QLoRA 模型输出" loading="lazy"></td></tr><tr><td><em>&quot;华丽的狐狸，佩戴秋叶和浆果的项圈，置身于森林植物的挂毯中，alphonse mucha style&quot;</em></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base5.png" alt="第三个提示的基础模型输出" loading="lazy"></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged5.png" alt="第三个提示的 QLoRA 模型输出" loading="lazy"></td></tr></tbody></table></details><h2 id="使用-torchao-进行-fp8-微调" tabindex="-1"><a class="header-anchor" href="#使用-torchao-进行-fp8-微调"><span>使用 <code>torchao</code> 进行 FP8 微调</span></a></h2><p>对于拥有计算能力 8.9 或更高的 NVIDIA GPU（如 H100、RTX 4090）的用户，可以通过 <code>torchao</code> 库利用 FP8 训练实现更高的速度效率。</p><p>我们在 H100 SXM GPU 上使用稍作修改的 <a href="https://github.com/sayakpaul/diffusers-torchao/" target="_blank" rel="noopener noreferrer"><code>diffusers-torchao</code></a> <a href="https://gist.github.com/sayakpaul/f0358dd4f4bcedf14211eba5704df25a#file-train_dreambooth_lora_flux-py" target="_blank" rel="noopener noreferrer">训练脚本</a>对 FLUX.1-dev LoRA 进行了微调。使用了以下命令：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">accelerate</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> launch</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> train_dreambooth_lora_flux.py</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --pretrained_model_name_or_path=black-forest-labs/FLUX.1-dev</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --dataset_name=derekl35/alphonse-mucha-style</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --instance_prompt=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;a woman, alphonse mucha style&quot;</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --caption_column=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;text&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --output_dir=alphonse_mucha_fp8_lora_flux</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --mixed_precision=bf16</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --use_8bit_adam</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --weighting_scheme=none</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --height=768</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --width=512</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --train_batch_size=1</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --repeats=1</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --learning_rate=1e-4</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --guidance_scale=1</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --report_to=wandb</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --gradient_accumulation_steps=1</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --gradient_checkpointing</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --lr_scheduler=constant</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --lr_warmup_steps=0</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --rank=4</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --max_train_steps=700</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --checkpointing_steps=600</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --seed=0</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --do_fp8_training</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --push_to_hub</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>训练运行的<strong>峰值内存使用量为 36.57GB</strong>，大约在 <strong>20 分钟</strong>内完成。</p><p>此 FP8 微调模型的定性结果也可获得：</p><figure><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_fp8_combined.png" alt="FP8 模型输出" tabindex="0" loading="lazy"><figcaption>FP8 模型输出</figcaption></figure><p>使用 <code>torchao</code> 启用 FP8 训练的关键步骤包括：</p><ol><li><strong>注入 FP8 层</strong>到模型中，使用 <code>torchao.float8</code> 的 <code>convert_to_float8_training</code>。</li><li>**定义 <code>module_filter_fn</code>**来指定哪些模块应该和不应该转换为 FP8。</li></ol><p>有关更详细的指南和代码片段，请参考<a href="https://gist.github.com/sayakpaul/f0358dd4f4bcedf14211eba5704df25a" target="_blank" rel="noopener noreferrer">此 gist</a> 和 <a href="https://github.com/sayakpaul/diffusers-torchao/tree/main/training" target="_blank" rel="noopener noreferrer"><code>diffusers-torchao</code> 仓库</a>。</p><h2 id="使用训练好的-lora-适配器进行推理" tabindex="-1"><a class="header-anchor" href="#使用训练好的-lora-适配器进行推理"><span>使用训练好的 LoRA 适配器进行推理</span></a></h2><p>训练好<a href="https://huggingface.co/collections/derekl35/flux-qlora-68527afe2c0ca7bc82a6d8d9" target="_blank" rel="noopener noreferrer">LoRA 适配器</a>后，您有两种主要的推理方法。</p><h3 id="选项-1-加载-lora-适配器" tabindex="-1"><a class="header-anchor" href="#选项-1-加载-lora-适配器"><span>选项 1：加载 LoRA 适配器</span></a></h3><p>一种方法是在基础模型之上<a href="https://huggingface.co/docs/diffusers/v0.33.1/en/using-diffusers/loading_adapters#lora" target="_blank" rel="noopener noreferrer">加载您训练好的 LoRA 适配器</a>。</p><p><strong>加载 LoRA 的好处：</strong></p><ul><li><strong>灵活性：</strong> 轻松在不同的 LoRA 适配器之间切换，无需重新加载基础模型</li><li><strong>实验性：</strong> 通过交换适配器测试多种艺术风格或概念</li><li><strong>模块化：</strong> 使用 <code>set_adapters()</code> 组合多个 LoRA 适配器进行创意混合</li><li><strong>存储效率：</strong> 保持一个基础模型和多个小适配器文件</li></ul><details class="hint-container details"><summary>代码</summary><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> diffusers </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxPipeline, FluxTransformer2DModel, BitsAndBytesConfig</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch </span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">ckpt_id </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;black-forest-labs/FLUX.1-dev&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxPipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        ckpt_id, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">torch_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.float16</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">load_lora_weights</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;derekl35/alphonse_mucha_qlora_flux&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">weight_name</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;pytorch_lora_weights.safetensors&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">enable_model_cpu_offload</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> pipeline</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;a puppy in a pond, alphonse mucha style&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">num_inference_steps</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">28</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">guidance_scale</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">3.5</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">height</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">768</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">width</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">512</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">generator</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">manual_seed</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">).images[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">save</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;alphonse_mucha.png&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><h3 id="选项-2-将-lora-合并到基础模型" tabindex="-1"><a class="header-anchor" href="#选项-2-将-lora-合并到基础模型"><span>选项 2：将 LoRA 合并到基础模型</span></a></h3><p>当您希望以单一风格获得最大效率时，可以<a href="https://huggingface.co/docs/diffusers/using-diffusers/merge_loras" target="_blank" rel="noopener noreferrer">将 LoRA 权重合并</a>到基础模型中。</p><p><strong>合并 LoRA 的好处：</strong></p><ul><li><strong>显存效率：</strong> 推理期间没有适配器权重的额外内存开销</li><li><strong>速度：</strong> 推理稍快，因为无需应用适配器计算</li><li><strong>量化兼容性：</strong> 可以重新量化合并后的模型以获得最大内存效率</li></ul><details class="hint-container details"><summary>代码</summary><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> diffusers </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxPipeline, AutoPipelineForText2Image, FluxTransformer2DModel, BitsAndBytesConfig</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch </span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">ckpt_id </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;black-forest-labs/FLUX.1-dev&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxPipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        ckpt_id, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">text_encoder</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">text_encoder_2</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">torch_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.float16</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">load_lora_weights</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;derekl35/alphonse_mucha_qlora_flux&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">weight_name</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;pytorch_lora_weights.safetensors&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">fuse_lora</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">unload_lora_weights</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline.transformer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">save_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;fused_transformer&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bnb_4bit_compute_dtype </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.bfloat16</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">nf4_config </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> BitsAndBytesConfig</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        load_in_4bit</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        bnb_4bit_quant_type</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;nf4&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        bnb_4bit_compute_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bnb_4bit_compute_dtype,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxTransformer2DModel.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;fused_transformer&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        quantization_config</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">nf4_config,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        torch_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bnb_4bit_compute_dtype,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> AutoPipelineForText2Image.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        ckpt_id, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">transformer</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">torch_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bnb_4bit_compute_dtype</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">enable_model_cpu_offload</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> pipeline</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;a puppy in a pond, alphonse mucha style&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">num_inference_steps</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">28</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">guidance_scale</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">3.5</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">height</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">768</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">width</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">512</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">generator</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">manual_seed</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">).images[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">save</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;alphonse_mucha_merged.png&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><h2 id="在-google-colab-上运行" tabindex="-1"><a class="header-anchor" href="#在-google-colab-上运行"><span>在 Google Colab 上运行</span></a></h2><p>虽然我们在 RTX 4090 上展示了结果，但相同的代码可以在更易于访问的硬件上运行，如<a href="https://colab.research.google.com/github/DerekLiu35/notebooks/blob/main/flux_lora_quant_blogpost.ipynb" target="_blank" rel="noopener noreferrer">Google Colab</a>免费提供的 T4 GPU。</p><p>在 T4 上，您可以预期微调过程需要更长时间，相同步数大约需要 4 小时。这是为了可访问性的权衡，但它使得定制微调在没有高端硬件的情况下成为可能。如果在 Colab 上运行，请注意使用限制，因为 4 小时的训练运行可能会推到极限。</p><h2 id="结论" tabindex="-1"><a class="header-anchor" href="#结论"><span>结论</span></a></h2><p>QLoRA 结合 <code>diffusers</code> 库，显著民主化了定制 FLUX.1-dev 等最先进模型的能力。正如在 RTX 4090 上演示的那样，高效微调完全在可及范围内，产生高质量的风格适应。此外，对于拥有最新 NVIDIA 硬件的用户，<code>torchao</code> 通过 FP8 精度实现了更快的训练。</p><h3 id="在-hub-上分享您的创作" tabindex="-1"><a class="header-anchor" href="#在-hub-上分享您的创作"><span>在 Hub 上分享您的创作！</span></a></h3><p>分享您微调的 LoRA 适配器是为开源社区做贡献的绝佳方式。它允许其他人轻松尝试您的风格，基于您的工作构建，并有助于创建一个充满活力的创意 AI 工具生态系统。</p><p>如果您已经为 FLUX.1-dev 训练了 LoRA，我们鼓励您<a href="https://huggingface.co/docs/transformers/en/model_sharing" target="_blank" rel="noopener noreferrer">分享</a>它。最简单的方法是在训练脚本中添加 <code>--push_to_hub</code> 标志。或者，如果您已经训练了模型并想要上传，可以使用以下代码片段。</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 前提条件：</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># - pip install huggingface_hub diffusers</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># - 运行一次 `huggingface-cli login`（或设置 HF_TOKEN 环境变量）</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># - 保存模型</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> huggingface_hub </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> create_repo, upload_folder</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">repo_id </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;your-username/alphonse_mucha_qlora_flux&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">create_repo</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(repo_id, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">exist_ok</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">upload_folder</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        repo_id</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">repo_id,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        folder_path</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;alphonse_mucha_qlora_flux&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        commit_message</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Add Alphonse Mucha LoRA adapter&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>查看我们的 Mucha QLoRA <a href="https://huggingface.co/derekl35/alphonse_mucha_qlora_flux" target="_blank" rel="noopener noreferrer">https://huggingface.co/derekl35/alphonse_mucha_qlora_flux</a> FP8 LoRA <a href="https://huggingface.co/derekl35/alphonse_mucha_fp8_lora_flux" target="_blank" rel="noopener noreferrer">https://huggingface.co/derekl35/alphonse_mucha_fp8_lora_flux</a>。您可以在<a href="https://huggingface.co/collections/derekl35/flux-qlora-68527afe2c0ca7bc82a6d8d9" target="_blank" rel="noopener noreferrer">此集合</a>中找到这两个以及其他适配器作为示例。</p><p>我们迫不及待地想看到您创造的作品！</p></div><!--[--><div class="theme-hope-content"><Share colorful services="email,facebook,line,linkedin,messenger,qrcode,reddit,telegram,twitter"></Share></div><!--]--><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/vuepress-theme-hope/vuepress-theme-hope/edit/main/src/zh/posts/reprints/flux-qlora.md" aria-label="在 GitHub 上编辑此页" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->在 GitHub 上编辑此页<!----></a></div><div class="vp-meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/zh/posts/reprints/announcing-illustrious-text%E2%80%91enhancer-tag-booster-and-mood-enhancer.html" aria-label="发布 Illustrious Text‑Enhancer：Tag Booster 和 Mood Enhancer"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><!---->发布 Illustrious Text‑Enhancer：Tag Booster 和 Mood Enhancer</div></a><a class="route-link auto-link next" href="/zh/posts/reprints/how-and-when-to-build-multi-agent-systems.html" aria-label="如何以及何时构建多智能体系统"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">如何以及何时构建多智能体系统<!----></div></a></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">我的页脚</div><div class="vp-copyright">Copyright © 2025 Derek Liu, Marc Sun, Sayak Paul, merve, Linoy Tsaban </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script src="/assets/js/runtime~app.95d5da72.js" defer></script><script src="/assets/js/9156.64e2dfa0.js" defer></script><script src="/assets/js/app.ea25b194.js" defer></script>
  </body>
</html>
