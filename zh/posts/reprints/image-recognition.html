<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.17" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.58" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="alternate" hreflang="en-us" href="https://neverbiasu.github.io/posts/reprints/image-recognition.html"><meta property="og:url" content="https://neverbiasu.github.io/zh/posts/reprints/image-recognition.html"><meta property="og:site_name" content="Nlog"><meta property="og:title" content="什么是图像识别？算法和应用"><meta property="og:description" content="什么是图像识别？算法和应用 什么是图像识别什么是图像识别 想象一下，一个名叫 Emma 的小女孩对鸟类着迷。每个周末，她都会和爷爷一起去附近的公园观鸟。久而久之，Emma 学会了通过颜色、大小、形状甚至叫声来识别不同的鸟类。一天下午，在翻书时，她毫不费力地指着一张图片说：“看，爷爷！是知更鸟！”她没有测量翼展或分析羽毛类型；她的大脑立即将图像与她在公园..."><meta property="og:type" content="article"><meta property="og:image" content="https://blog.roboflow.com/content/images/size/w1200/2025/06/Screenshot-2025-06-10-at-10.46.38---AM.png"><meta property="og:locale" content="zh-CN"><meta property="og:locale:alternate" content="en-US"><meta property="article:author" content="Timothy M."><meta property="article:tag" content="计算机视觉"><meta property="article:tag" content="图像识别"><meta property="article:published_time" content="2025-06-10T17:51:41.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"什么是图像识别？算法和应用","image":["https://blog.roboflow.com/content/images/size/w1200/2025/06/Screenshot-2025-06-10-at-10.46.38---AM.png","https://blog.roboflow.com/content/images/2025/06/image_recognition.png","https://blog.roboflow.com/content/images/2025/06/grayscale_image_representation.png","https://blog.roboflow.com/content/images/2025/06/rgb_image_representation.png","https://blog.roboflow.com/content/images/2025/06/r_cnn.png","https://blog.roboflow.com/content/images/2025/06/workflow-example.png","https://blog.roboflow.com/content/images/2025/06/custom_models.png","https://blog.roboflow.com/content/images/2025/06/wood_model.png","https://blog.roboflow.com/content/images/2025/06/wk_1-1.png","https://blog.roboflow.com/content/images/2025/06/property_wk_1.png","https://blog.roboflow.com/content/images/2025/06/output_wk_1.png","https://blog.roboflow.com/content/images/2025/06/hand_dataset.png","https://blog.roboflow.com/content/images/2025/06/hand_model.png","https://blog.roboflow.com/content/images/2025/06/wk_hand_recog.png","https://blog.roboflow.com/content/images/2025/06/wk_hand_g_out.png","https://blog.roboflow.com/content/images/2025/06/wk_3.jpeg","https://blog.roboflow.com/content/images/2025/06/input_wk_3.jpeg","https://blog.roboflow.com/content/images/2025/06/florence_wk_3-1.jpeg","https://blog.roboflow.com/content/images/2025/06/vlm_conf.jpeg","https://blog.roboflow.com/content/images/2025/06/output_wk_3.jpeg"],"datePublished":"2025-06-10T17:51:41.000Z","dateModified":null,"author":[{"@type":"Person","name":"Timothy M."}]}</script><title>什么是图像识别？算法和应用 | Nlog</title><meta name="description" content="什么是图像识别？算法和应用 什么是图像识别什么是图像识别 想象一下，一个名叫 Emma 的小女孩对鸟类着迷。每个周末，她都会和爷爷一起去附近的公园观鸟。久而久之，Emma 学会了通过颜色、大小、形状甚至叫声来识别不同的鸟类。一天下午，在翻书时，她毫不费力地指着一张图片说：“看，爷爷！是知更鸟！”她没有测量翼展或分析羽毛类型；她的大脑立即将图像与她在公园...">
    <link rel="stylesheet" href="/assets/css/styles.50126b1a.css">
    <link rel="preload" href="/assets/js/runtime~app.95d5da72.js" as="script"><link rel="preload" href="/assets/css/styles.50126b1a.css" as="style"><link rel="preload" href="/assets/js/9156.64e2dfa0.js" as="script"><link rel="preload" href="/assets/js/app.ea25b194.js" as="script">
    <link rel="prefetch" href="/assets/js/posts_reprints_flux-qlora.html.e25c0732.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_flux-qlora.html.bdca01c9.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_news-agents-daily-recap.html.ca04913a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ielts_simon-task2.html.2fe38674.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_crody's-model-merge-guide.html.07f44e7f.js" as="script"><link rel="prefetch" href="/assets/js/8300.853d6b0b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ielts_usage-of-collocations-in-speaking_ielts-collocations.html.86f5c7c6.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_crody's-model-merge-guide.html.046f0899.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_image-recognition.html.07c5196c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_image-recognition.html.61c0e69e.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_blog-images.html.d2c6545e.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html.9d72dc96.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html.9fa0e201.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_what-is-block-merging.html.b7b3e018.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_original-character-lora-sdxl-character-training.html.ce54ff9d.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_step-by-step-visual-introduction-to-diffusion-models.html.cd2854e8.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_flux-kontext.html.ed243625.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_original-character-lora-sdxl-character-training.html.52dcf985.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_repos_material.html.fbe2fd29.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_introduction-of-prompts-ai-illustration-generation-camera-angle-composition-facial-expression.html.fa0b7a73.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_X01.html.eb6ee3d6.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_introduction-of-prompts-ai-illustration-generation-camera-angle-composition-facial-expression.html.f7670351.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_sci_conda.html.1ba5b9e5.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_papers_workflow.html.e18adbce.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language.html.a34aec93.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language.html.d9238744.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_flux-kontext-optimization.html.1a4897dc.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_flux-kontext-optimization.html.5532e6f6.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_step-by-step-visual-introduction-to-diffusion-models.html.e8bf942f.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_repos_comfy-mind.html.6f1a4f44.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-impls_yolov9.html.cbf247d0.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_model-block-merge-1.html.3abbf8d4.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_ai-art-newsletter-jan-25.html.5faf4d51.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_006.html.76c84f58.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_announcing-illustrious-text‑enhancer-tag-booster-and-mood-enhancer.html.517a1ee1.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_model-block-merge-2.html.0f9c14de.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_sdo.html.b7ecccd0.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_announcing-illustrious-text‑enhancer-tag-booster-and-mood-enhancer.html.f6a8fbb8.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_resnet.html.6393e916.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_ai-art-newsletter-jan-25.html.971ce630.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_bagel.html.049a219c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_ming-omni.html.20e14b21.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_omniconsistency.html.4c6e9330.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything.html.314cbfd7.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_014.html.c41082ad.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_flux-1-kontext.html.6297069c.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_niji-lesson-2-the-terminator-line.html.ebdb33a7.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_comfyui-r1.html.bea016dd.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_niji-study-1-measuring-with-your-eyes.html.721630f8.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything.html.22fa5919.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_001.html.2986e89d.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_flux-1-kontext.html.6d0bc73c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_ecomimic-v3.html.a8a6b4b4.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_markdown.html.2b3004d0.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_colorizediffusion.html.c18d15cc.js" as="script"><link rel="prefetch" href="/assets/js/demo_markdown.html.a2081e01.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_niji-study-1-measuring-with-your-eyes.html.403ee9cf.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_repos_checklist.html.2c86bf22.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_hunyuancustom.html.c2b4ff7e.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ielts_simon-task1.html.34242439.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_dairys_250222.html.41739137.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_show-o2.html.6145cdd9.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_hf-weekly_001.html.89ae8f15.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_repos_workflow.html.5967ccd1.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_037.html.b0a4ddd3.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_templates_repos.html.b0b47564.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_033.html.3fc966cc.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_031.html.86f17a2c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_043.html.70bd2bb5.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_icedit.html.ba272966.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_032.html.30191816.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_026.html.6bc17810.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_042.html.51c7aa9e.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_omnigen2.html.7251ca67.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_transformer.html.a9f96585.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_alexnet.html.ffa5e652.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_009.html.b41f980f.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_022.html.33930402.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_030.html.2f8b0739.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_039.html.e4384ea6.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_011.html.4c72c992.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_ai-art-gtc-paris-2025.html.35f9c6c5.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_046.html.7fe6c3c1.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_029.html.6bd2bbb4.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_how-and-when-to-build-multi-agent-systems.html.683f686f.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_reptext.html.3e68da15.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_040.html.77ad6dd0.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_generative-ai-powered-design.html.29b4cfc0.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_045.html.bcee5b9e.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_how-and-when-to-build-multi-agent-systems.html.83239b53.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_034.html.bb3494e0.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_041.html.cc30477b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_ai-art-gtc-paris-2025.html.dd4e6753.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_036.html.103493df.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_044.html.4316f4fc.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_015.html.f3bc358d.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_thoughts_platform-operation-thoughts-after-comfycon.html.0a6fc557.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_020.html.e178431c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_035.html.76b543ac.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_generative-ai-powered-design.html.8ea641cf.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_023.html.2c7192b4.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_021.html.1924500a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_010.html.995fa31e.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_005.html.77979cff.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_qr-lora.html.12a884c9.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_hf-weekly_003.html.add9120d.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_003.html.fe38d2ee.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_038.html.54d019c6.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_018.html.3aabc796.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_012.html.2ce3356f.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_explaining-tokens-the-language-and-currency-of-ai-nvidia-blog.html.98d7044c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_025.html.828c6af4.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_027.html.a69f4cf8.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_framepack.html.79cc8785.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_028.html.23f08d5c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_024.html.c9d95ff5.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_013.html.659095e1.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_vlv.html.66e5a328.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_hf-weekly_002.html.475e8a71.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_019.html.dbd20518.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_illustrious-xl-v2.0-the-best-training-base-model-in-1536-age.html.b5e190f7.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_illustrious-xl-v2.0-the-best-training-base-model-in-1536-age.html.824cc0cb.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_explaining-tokens-the-language-and-currency-of-ai-nvidia-blog.html.0dce2f26.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_017.html.cf727d63.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_niji-lesson-2-the-terminator-line.html.bcba9d63.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_niji-study-2-notan.html.bc893745.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_ovis-u1.html.f00080b2.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_016.html.c3ada0a7.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_mcp-flash-in-the-pan-or-future-standard.html.b142e62d.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_papers_checklist.html.153167b0.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_008.html.8b9058fe.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_002.html.5a4dd3d5.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_niji-video.html.211bd024.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_mcp-flash-in-the-pan-or-future-standard.html.19ff25fe.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_004.html.9173a01b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_niji-video.html.26560c68.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_007.html.eab02414.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_niji-study-2-notan.html.70b1ed6f.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_3steps-paper-reading.html.eda5237e.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_dairys_250223.html.b6746695.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_experiments-with-mcp-using-github-copilot.html.b89c4005.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_experimenting-with-mcp-using-github-copilot.html.f9a39fff.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_illustrious-lu-v0.03.html.dbc0dce0.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_illustrious-lu-v0.03.html.8b95f0b0.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_templates_papers.html.31aef926.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_templates_hf-weekly.html.5c334dac.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_hf-weekly_checklist.html.c3fa5a04.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_templates_ai-weekly.html.61881c27.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_page.html.0b7cffcc.js" as="script"><link rel="prefetch" href="/assets/js/demo_page.html.50e1e3b3.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_prompts_hf-weekly.prompt.html.a49236f9.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_layout.html.9b3fdc7f.js" as="script"><link rel="prefetch" href="/assets/js/demo_layout.html.25c357de.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_hf-weekly_workflow.html.da6dc285.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_prompts_translate.prompt.html.0e65a605.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_prompts_cover.prompt.html.b24a437c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_prompts_ai-weekly.prompt.html.2fe1eb8f.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_prompts_papers.prompt.html.ba28b7ce.js" as="script"><link rel="prefetch" href="/assets/js/home.html.a72e8bb4.js" as="script"><link rel="prefetch" href="/assets/js/zh_home.html.7623eb73.js" as="script"><link rel="prefetch" href="/assets/js/demo_disable.html.aeb75044.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_disable.html.917844f9.js" as="script"><link rel="prefetch" href="/assets/js/zh_intro.html.efed7168.js" as="script"><link rel="prefetch" href="/assets/js/intro.html.50f0afc5.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_prompts_image-extract.prompt.html.9c9b8aa7.js" as="script"><link rel="prefetch" href="/assets/js/zh_index.html.40d3a237.js" as="script"><link rel="prefetch" href="/assets/js/index.html.f45e7c7b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_web_vue-1.html.0755e363.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_index.html.34792277.js" as="script"><link rel="prefetch" href="/assets/js/demo_encrypt.html.25bd9519.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_encrypt.html.06a96e54.js" as="script"><link rel="prefetch" href="/assets/js/tag_artificial-intelligence_index.html.7e3793fa.js" as="script"><link rel="prefetch" href="/assets/js/demo_index.html.febe17c4.js" as="script"><link rel="prefetch" href="/assets/js/category_model-development_index.html.794f5d59.js" as="script"><link rel="prefetch" href="/assets/js/category_image-generation_index.html.2189f40e.js" as="script"><link rel="prefetch" href="/assets/js/category_model-training_index.html.be238a49.js" as="script"><link rel="prefetch" href="/assets/js/category_generative-ai_index.html.b909fb8b.js" as="script"><link rel="prefetch" href="/assets/js/tag_stable-diffusion_index.html.ae5f1c64.js" as="script"><link rel="prefetch" href="/assets/js/category_anime-style_index.html.3108accc.js" as="script"><link rel="prefetch" href="/assets/js/tag_amazon-bedrock_index.html.a67f2776.js" as="script"><link rel="prefetch" href="/assets/js/tag_resource-guide_index.html.5acb26ee.js" as="script"><link rel="prefetch" href="/assets/js/category_explainer_index.html.a8e8f462.js" as="script"><link rel="prefetch" href="/assets/js/category_reprints_index.html.4a06de7a.js" as="script"><link rel="prefetch" href="/assets/js/tag_kohya-ss-gui_index.html.27638eba.js" as="script"><link rel="prefetch" href="/assets/js/tag_fundamentals_index.html.374e901f.js" as="script"><link rel="prefetch" href="/assets/js/category_reprint_index.html.6eafee8b.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_模型上下文协议_index.html.e75af900.js" as="script"><link rel="prefetch" href="/assets/js/tag_illustrious_index.html.ff354070.js" as="script"><link rel="prefetch" href="/assets/js/tag_text2image_index.html.bb9c3a46.js" as="script"><link rel="prefetch" href="/assets/js/tag_taylorseer_index.html.d4b32963.js" as="script"><link rel="prefetch" href="/assets/js/category_aiml_index.html.35fc99fb.js" as="script"><link rel="prefetch" href="/assets/js/tag_diffusers_index.html.8f93bf3f.js" as="script"><link rel="prefetch" href="/assets/js/tag_inference_index.html.b69c0933.js" as="script"><link rel="prefetch" href="/assets/js/tag_replicate_index.html.61deee89.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_阿里巴巴ai研究_index.html.dd5f50e2.js" as="script"><link rel="prefetch" href="/assets/js/tag_markdown_index.html.ec598c41.js" as="script"><link rel="prefetch" href="/assets/js/tag_drawing_index.html.91b0ebb5.js" as="script"><link rel="prefetch" href="/assets/js/tag_flux.1_index.html.83ab9654.js" as="script"><link rel="prefetch" href="/assets/js/tag_lumina_index.html.27a09c4b.js" as="script"><link rel="prefetch" href="/assets/js/tag_prompt_index.html.d3dbd2e7.js" as="script"><link rel="prefetch" href="/assets/js/tag_script_index.html.eae6815c.js" as="script"><link rel="prefetch" href="/assets/js/tag_merge_index.html.ae63ce39.js" as="script"><link rel="prefetch" href="/assets/js/tag_model_index.html.acdbe3e4.js" as="script"><link rel="prefetch" href="/assets/js/tag_qlora_index.html.11905a67.js" as="script"><link rel="prefetch" href="/assets/js/tag_qwen3_index.html.e8eb5022.js" as="script"><link rel="prefetch" href="/assets/js/tag_vpred_index.html.426ee337.js" as="script"><link rel="prefetch" href="/assets/js/tag_notan_index.html.d9a4a654.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_创造者工坊_index.html.094f4c96.js" as="script"><link rel="prefetch" href="/assets/js/tag_flux_index.html.ad3867cf.js" as="script"><link rel="prefetch" href="/assets/js/tag_llms_index.html.67431ae9.js" as="script"><link rel="prefetch" href="/assets/js/tag_lora_index.html.c7ee546c.js" as="script"><link rel="prefetch" href="/assets/js/tag_qwen_index.html.e0838b98.js" as="script"><link rel="prefetch" href="/assets/js/tag_sdxl_index.html.37a19ff3.js" as="script"><link rel="prefetch" href="/assets/js/tag_niji_index.html.a70a9af6.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_大语言模型_index.html.72664ff8.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_计算机视觉_index.html.58b39887.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_输入预处理_index.html.ed9bbf63.js" as="script"><link rel="prefetch" href="/assets/js/tag_art_index.html.fd5de43a.js" as="script"><link rel="prefetch" href="/assets/js/tag_aws_index.html.49d0379d.js" as="script"><link rel="prefetch" href="/assets/js/tag_llm_index.html.3a8069a7.js" as="script"><link rel="prefetch" href="/assets/js/tag_mcp_index.html.5e93604a.js" as="script"><link rel="prefetch" href="/assets/js/tag_gtc_index.html.1e06b509.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_artificial-intelligence_index.html.8cfd6b09.js" as="script"><link rel="prefetch" href="/assets/js/category_index.html.30915709.js" as="script"><link rel="prefetch" href="/assets/js/tag_ai_index.html.691e8ede.js" as="script"><link rel="prefetch" href="/assets/js/tag_lu_index.html.f7da3bcc.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_llm基准测试_index.html.fc9da582.js" as="script"><link rel="prefetch" href="/assets/js/timeline_index.html.3f867224.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_阿里巴巴ai_index.html.c970b0e2.js" as="script"><link rel="prefetch" href="/assets/js/article_index.html.3131e8c3.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_使用指南_index.html.63c177db.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_图像生成_index.html.c3ae9a7c.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_教程指南_index.html.42c5df88.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_模型开发_index.html.185a36fd.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_模型研发_index.html.f6ab3ec2.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_模型训练_index.html.1785036a.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_视频生成_index.html.60de099e.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_论文精读_index.html.7276ab7f.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_动漫风格_index.html.8538e3dd.js" as="script"><link rel="prefetch" href="/assets/js/tag_model-context-protocol_index.html.25f141b3.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_index.html.8158d3a4.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ielts_usage-of-collocations-in-speaking_index.html.b2df067f.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_workflow-generation_index.html.4c431f19.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_人工智能_index.html.f0a2e682.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_使用指南_index.html.fe8c29d0.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_功能发布_index.html.d6a89296.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_反向传播_index.html.ac57d1ff.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_可控生成_index.html.142da7e4.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_图像生成_index.html.dfb3e561.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_图像识别_index.html.9bff49b9.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_基础模型_index.html.7953d298.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_开源项目_index.html.e3cfbec0.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_扩散模型_index.html.829f3a99.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_技术教程_index.html.9ee8291c.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_游戏开发_index.html.6e767c46.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_艺术课程_index.html.46238e22.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_视频生成_index.html.8068090f.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_计算优化_index.html.4e81f12a.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_阿里巴巴_index.html.df377e00.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_页面配置_index.html.c7985dc6.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_model-development_index.html.464b624b.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_机器学习_index.html.fb0ee906.js" as="script"><link rel="prefetch" href="/assets/js/tag_large-language-models_index.html.3bcf45b0.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_2048分辨率_index.html.6fb915df.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_生成式ai_index.html.946ab634.js" as="script"><link rel="prefetch" href="/assets/js/tag_feature-announcement_index.html.5aa6fb5c.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_image-generation_index.html.b26f5abb.js" as="script"><link rel="prefetch" href="/assets/js/star_index.html.0ffd513d.js" as="script"><link rel="prefetch" href="/assets/js/tag_index.html.fc1f1e0b.js" as="script"><link rel="prefetch" href="/assets/js/tag_alibaba-ai-research_index.html.adbbd683.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_epsilon预测_index.html.93831d46.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_多模态ai_index.html.f345a0db.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_多语言ai_index.html.fe70d6af.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_stable-diffusion_index.html.a72cbefd.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_生成式ai_index.html.5736baf2.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_初学者_index.html.f5485ca2.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_张吕敏_index.html.baa96ea6.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_model-training_index.html.7e4d037d.js" as="script"><link rel="prefetch" href="/assets/js/tag_epsilon-prediction_index.html.28d2e698.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_reasoning-model_index.html.1a71ba78.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_generative-ai_index.html.82923755.js" as="script"><link rel="prefetch" href="/assets/js/tag_image-recognition_index.html.a2fa1118.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_公众号_index.html.08bf5712.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_创作者_index.html.e962922e.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_多模态_index.html.0da8de43.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_编辑器_index.html.9af3b2cb.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_amazon-bedrock_index.html.8cef35a6.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_resource-guide_index.html.ea147e91.js" as="script"><link rel="prefetch" href="/assets/js/posts_index.html.efc2f348.js" as="script"><link rel="prefetch" href="/assets/js/tag_game-development_index.html.57d177bb.js" as="script"><link rel="prefetch" href="/assets/js/tag_image-generation_index.html.8b92bc54.js" as="script"><link rel="prefetch" href="/assets/js/tag_machine-learning_index.html.faec0f3f.js" as="script"><link rel="prefetch" href="/assets/js/tag_visual-hierarchy_index.html.a2caed5c.js" as="script"><link rel="prefetch" href="/assets/js/tag_diffusion-models_index.html.93147de9.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_anime-style_index.html.6dcca799.js" as="script"><link rel="prefetch" href="/assets/js/tag_2048-resolution_index.html.f3714f53.js" as="script"><link rel="prefetch" href="/assets/js/tag_computer-vision_index.html.16784659.js" as="script"><link rel="prefetch" href="/assets/js/tag_multilingual-ai_index.html.366e07d4.js" as="script"><link rel="prefetch" href="/assets/js/tag_stablediffusion_index.html.4cefc3f4.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_kohya-ss-gui_index.html.41ea145e.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_fundamentals_index.html.a2abb31f.js" as="script"><link rel="prefetch" href="/assets/js/tag_llm-benchmarks_index.html.a4c66890.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_ai推理_index.html.e5d2b110.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_ai模型_index.html.3bce6dfb.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_ai生成_index.html.7ea51825.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_新闻_index.html.0c095e7c.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_日记_index.html.aa249f5e.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_论文_index.html.bf9a7705.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_高级_index.html.b102e135.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_illustrious_index.html.1cf7c511.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_思考_index.html.cf92ff59.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_指南_index.html.e374501e.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_转载_index.html.5c33d05d.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_explainer_index.html.e16f7b83.js" as="script"><link rel="prefetch" href="/assets/js/tag_automatic1111_index.html.96f5b2d6.js" as="script"><link rel="prefetch" href="/assets/js/tag_generative-ai_index.html.ac7fe732.js" as="script"><link rel="prefetch" href="/assets/js/tag_multimodal-ai_index.html.8e502dbb.js" as="script"><link rel="prefetch" href="/assets/js/tag_agent-systems_index.html.cea033f6.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_text2image_index.html.bc1c311b.js" as="script"><link rel="prefetch" href="/assets/js/category_advanced_index.html.b0b65b54.js" as="script"><link rel="prefetch" href="/assets/js/category_ai-tools_index.html.2197e21d.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_taylorseer_index.html.46aded77.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_reprints_index.html.0826fe61.js" as="script"><link rel="prefetch" href="/assets/js/tag_quantization_index.html.d1270720.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_优化_index.html.33627e19.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_做饭_index.html.14d1e2ca.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_内容_index.html.bf4dd66c.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_创新_index.html.3233a6ef.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_加密_index.html.bfaa97bf.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_协议_index.html.d79c2e92.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_大会_index.html.671b60e0.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_平台_index.html.1473d3b1.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_开源_index.html.68009a9f.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_微调_index.html.00e98616.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_技术_index.html.7b9b8310.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_禁用_index.html.09d49f84.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_艺术_index.html.f039e09a.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_运营_index.html.01477a7c.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_随想_index.html.2130074f.js" as="script"><link rel="prefetch" href="/assets/js/tag_ai-reasoning_index.html.92107949.js" as="script"><link rel="prefetch" href="/assets/js/tag_optimization_index.html.91e14203.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_动漫_index.html.18233701.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_实习_index.html.99c01886.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_布局_index.html.c4128b34.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_训练_index.html.4a46a86c.js" as="script"><link rel="prefetch" href="/assets/js/tag_modelmerging_index.html.3aac36a9.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_辩论_index.html.08c79452.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_量化_index.html.9cd36f77.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_comfymind_index.html.780a1f96.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_framepack_index.html.316e41ca.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_inference_index.html.f694cf8d.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_replicate_index.html.01cc7a53.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_diffusers_index.html.16bfc806.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_reprint_index.html.03c0293c.js" as="script"><link rel="prefetch" href="/assets/js/tag_fine-tuning_index.html.ca8a4059.js" as="script"><link rel="prefetch" href="/assets/js/tag_news-agents_index.html.39bd1dd8.js" as="script"><link rel="prefetch" href="/assets/js/tag_page-config_index.html.fd4f47e9.js" as="script"><link rel="prefetch" href="/assets/js/tag_usage-guide_index.html.069580af.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_markdown_index.html.4742eec1.js" as="script"><link rel="prefetch" href="/assets/js/category_novice_index.html.7561c64e.js" as="script"><link rel="prefetch" href="/assets/js/category_papers_index.html.180b7727.js" as="script"><link rel="prefetch" href="/assets/js/tag_alibaba-ai_index.html.f5c3b72c.js" as="script"><link rel="prefetch" href="/assets/js/tag_art-lesson_index.html.6dc9ccf1.js" as="script"><link rel="prefetch" href="/assets/js/tag_base-model_index.html.3c68635b.js" as="script"><link rel="prefetch" href="/assets/js/tag_encryption_index.html.ba9c6633.js" as="script"><link rel="prefetch" href="/assets/js/tag_modelmerge_index.html.f79dfcbf.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_drawing_index.html.d6ef8b08.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_ovis-u1_index.html.aab779ab.js" as="script"><link rel="prefetch" href="/assets/js/category_guide_index.html.b6dbfe00.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_comfyui_index.html.52422e18.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_aiml_index.html.5317281e.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_flux.1_index.html.703ceaab.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_github_index.html.eacf79c2.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_lumina_index.html.451683ad.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_prompt_index.html.dbf5dc4c.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_script_index.html.0c284078.js" as="script"><link rel="prefetch" href="/assets/js/category_news_index.html.0acac10a.js" as="script"><link rel="prefetch" href="/assets/js/tag_ai-model_index.html.485c27f3.js" as="script"><link rel="prefetch" href="/assets/js/tag_amazon-q_index.html.9b480256.js" as="script"><link rel="prefetch" href="/assets/js/tag_creators_index.html.1bc91546.js" as="script"><link rel="prefetch" href="/assets/js/tag_protocol_index.html.715bc788.js" as="script"><link rel="prefetch" href="/assets/js/tag_training_index.html.3c2840b0.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_merge_index.html.9e5cebd3.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_model_index.html.c5e77c69.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_notan_index.html.d1fbfa1b.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_qlora_index.html.7832f634.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_qwen3_index.html.e94caed5.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_vpred_index.html.557ab6de.js" as="script"><link rel="prefetch" href="/assets/js/tag_disable_index.html.6ed89a53.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_aigc_index.html.51eda4be.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_flux_index.html.5425d666.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_llms_index.html.22e104c5.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_niji_index.html.697abc36.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_lora_index.html.eb2cf7fa.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_sdxl_index.html.aa7ab8d6.js" as="script"><link rel="prefetch" href="/assets/js/404.html.683d9275.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_qwen_index.html.ac1dad5c.js" as="script"><link rel="prefetch" href="/assets/js/tag_debate_index.html.347d53e0.js" as="script"><link rel="prefetch" href="/assets/js/tag_layout_index.html.5a5e41d2.js" as="script"><link rel="prefetch" href="/assets/js/tag_editor_index.html.2106f4d9.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_art_index.html.8deb8f79.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_aws_index.html.defb07a5.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_gtc_index.html.1f7cf941.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_llm_index.html.cdc71de0.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_mcp_index.html.2baec1bd.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_sdo_index.html.c2389a8d.js" as="script"><link rel="prefetch" href="/assets/js/tag_anime_index.html.a8a78e3b.js" as="script"><link rel="prefetch" href="/assets/js/tag_guide_index.html.5173996f.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_lu_index.html.42e4b29c.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_ai_index.html.5a7d4e11.js" as="script"><link rel="prefetch" href="/assets/js/tag_tech_index.html.68c57a8c.js" as="script"><link rel="prefetch" href="/assets/js/tag_tmux_index.html.569017df.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_hf-weekly_index.html.06e8093d.js" as="script"><link rel="prefetch" href="/assets/js/zh_timeline_index.html.e1f1ad46.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_index.html.682e7f3d.js" as="script"><link rel="prefetch" href="/assets/js/zh_article_index.html.cd7570ad.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_papers_index.html.bb25e136.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_index.html.6f900118.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_hf-weekly_index.html.4d97c51d.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_templates_index.html.5a13aa05.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_index.html.2bfde6cd.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_index.html.3201a8c7.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_repos_index.html.d93bee28.js" as="script"><link rel="prefetch" href="/assets/js/zh_star_index.html.f6186c0f.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-impls_index.html.dc9f8315.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_index.html.9a49e407.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_thoughts_index.html.e1e18711.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_prompts_index.html.e3e3d99c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_index.html.5e8ec60f.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_dairys_index.html.6cd7d11b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ielts_index.html.727f9a48.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_repos_index.html.ce9635f7.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_index.html.c78cbce3.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_web_index.html.6fe04daf.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_sci_index.html.e71977aa.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><!--[--><a class="route-link vp-brand" href="/zh/" aria-label="带我回家"><img class="vp-nav-logo" src="/logo.svg" alt><!----><span class="vp-site-name hide-in-pad">Nlog</span></a><!--]--><!----></div><div class="vp-navbar-center"><!----><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/zh/" aria-label="Blog Home"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="home" width="1em" height="1em"></iconify-icon><!--]-->Blog Home<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/zh/demo/" aria-label="主要功能与配置演示"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="laptop-code" width="1em" height="1em"></iconify-icon><!--]-->主要功能与配置演示<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="博客"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon>博客<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ai-impls</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-impls/yolov9.html" aria-label="yolov9"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->yolov9<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ai-weekly</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/001.html" aria-label="001"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->001<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/002.html" aria-label="002"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->002<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/003.html" aria-label="003"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->003<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/004.html" aria-label="004"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->004<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/005.html" aria-label="005"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->005<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/006.html" aria-label="006"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->006<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/007.html" aria-label="007"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->007<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/008.html" aria-label="008"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->008<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/009.html" aria-label="009"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->009<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/010.html" aria-label="010"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->010<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/011.html" aria-label="011"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->011<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/012.html" aria-label="012"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->012<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/013.html" aria-label="013"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->013<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/014.html" aria-label="014"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->014<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/015.html" aria-label="015"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->015<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/016.html" aria-label="016"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->016<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/017.html" aria-label="017"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->017<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/018.html" aria-label="018"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->018<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/019.html" aria-label="019"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->019<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/020.html" aria-label="020"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->020<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/021.html" aria-label="021"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->021<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/022.html" aria-label="022"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->022<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/023.html" aria-label="023"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->023<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/024.html" aria-label="024"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->024<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/025.html" aria-label="025"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->025<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/026.html" aria-label="026"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->026<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/027.html" aria-label="027"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->027<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/028.html" aria-label="028"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->028<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/029.html" aria-label="029"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->029<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/030.html" aria-label="030"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->030<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/031.html" aria-label="031"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->031<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/032.html" aria-label="032"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->032<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/033.html" aria-label="033"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->033<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/034.html" aria-label="034"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->034<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/035.html" aria-label="035"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->035<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/036.html" aria-label="036"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->036<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/037.html" aria-label="037"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->037<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/038.html" aria-label="038"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->038<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/039.html" aria-label="039"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->039<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/040.html" aria-label="040"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->040<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/041.html" aria-label="041"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->041<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/042.html" aria-label="042"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->042<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/043.html" aria-label="043"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->043<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/044.html" aria-label="044"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->044<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/045.html" aria-label="045"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->045<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/046.html" aria-label="046"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->046<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ai-weekly/X01.html" aria-label="X01"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->X01<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">dairys</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/dairys/250222.html" aria-label="250222"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->250222<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/dairys/250223.html" aria-label="250223"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->250223<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">hf-weekly</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/hf-weekly/001.html" aria-label="001"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->001<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/hf-weekly/002.html" aria-label="002"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->002<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/hf-weekly/003.html" aria-label="003"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->003<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ielts</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ielts/simon-task1.html" aria-label="simon-task1"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->simon-task1<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/ielts/simon-task2.html" aria-label="simon-task2"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->simon-task2<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">papers</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/3steps-paper-reading.html" aria-label="3steps-paper-reading"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->3steps-paper-reading<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/alexnet.html" aria-label="alexnet"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->alexnet<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/bagel.html" aria-label="bagel"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->bagel<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/colorizediffusion.html" aria-label="colorizediffusion"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->colorizediffusion<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/comfyui-r1.html" aria-label="comfyui-r1"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->comfyui-r1<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/ecomimic-v3.html" aria-label="ecomimic-v3"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->ecomimic-v3<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/flux-kontext.html" aria-label="flux-kontext"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->flux-kontext<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/framepack.html" aria-label="framepack"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->framepack<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/hunyuancustom.html" aria-label="hunyuancustom"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->hunyuancustom<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/icedit.html" aria-label="icedit"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->icedit<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/ming-omni.html" aria-label="ming-omni"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->ming-omni<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/omniconsistency.html" aria-label="omniconsistency"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->omniconsistency<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/omnigen2.html" aria-label="omnigen2"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->omnigen2<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/ovis-u1.html" aria-label="ovis-u1"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->ovis-u1<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/qr-lora.html" aria-label="qr-lora"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->qr-lora<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/reptext.html" aria-label="reptext"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->reptext<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/resnet.html" aria-label="resnet"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->resnet<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/sdo.html" aria-label="sdo"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->sdo<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/show-o2.html" aria-label="show-o2"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->show-o2<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/transformer.html" aria-label="transformer"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->transformer<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/papers/vlv.html" aria-label="vlv"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->vlv<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">prompts</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/prompts/ai-weekly.prompt.html" aria-label="ai-weekly.prompt"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->ai-weekly.prompt<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/prompts/cover.prompt.html" aria-label="cover.prompt"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->cover.prompt<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/prompts/hf-weekly.prompt.html" aria-label="hf-weekly.prompt"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->hf-weekly.prompt<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/prompts/image-extract.prompt.html" aria-label="image-extract.prompt"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->image-extract.prompt<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/prompts/papers.prompt.html" aria-label="papers.prompt"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->papers.prompt<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/prompts/translate.prompt.html" aria-label="translate.prompt"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->translate.prompt<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">repos</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/repos/comfy-mind.html" aria-label="comfy-mind"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->comfy-mind<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">reprints</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/ai-art-gtc-paris-2025.html" aria-label="ai-art-gtc-paris-2025"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->ai-art-gtc-paris-2025<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/ai-art-newsletter-jan-25.html" aria-label="ai-art-newsletter-jan-25"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->ai-art-newsletter-jan-25<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/announcing-illustrious-text%E2%80%91enhancer-tag-booster-and-mood-enhancer.html" aria-label="announcing-illustrious-text‑enhancer-tag-booster-and-mood-enhancer"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->announcing-illustrious-text‑enhancer-tag-booster-and-mood-enhancer<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/crody&#39;s-model-merge-guide.html" aria-label="crody&#39;s-model-merge-guide"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->crody&#39;s-model-merge-guide<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/experiments-with-mcp-using-github-copilot.html" aria-label="experiments-with-mcp-using-github-copilot"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->experiments-with-mcp-using-github-copilot<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/explaining-tokens-the-language-and-currency-of-ai-nvidia-blog.html" aria-label="explaining-tokens-the-language-and-currency-of-ai-nvidia-blog"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->explaining-tokens-the-language-and-currency-of-ai-nvidia-blog<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/flux-1-kontext.html" aria-label="flux-1-kontext"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->flux-1-kontext<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/flux-kontext-optimization.html" aria-label="flux-kontext-optimization"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->flux-kontext-optimization<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/flux-qlora.html" aria-label="flux-qlora"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->flux-qlora<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/generative-ai-powered-design.html" aria-label="generative-ai-powered-design"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->generative-ai-powered-design<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/how-and-when-to-build-multi-agent-systems.html" aria-label="how-and-when-to-build-multi-agent-systems"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->how-and-when-to-build-multi-agent-systems<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/illustrious-lu-v0.03.html" aria-label="illustrious-lu-v0.03"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->illustrious-lu-v0.03<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language.html" aria-label="illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/illustrious-xl-v2.0-the-best-training-base-model-in-1536-age.html" aria-label="illustrious-xl-v2.0-the-best-training-base-model-in-1536-age"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->illustrious-xl-v2.0-the-best-training-base-model-in-1536-age<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link route-link-active auto-link" href="/zh/posts/reprints/image-recognition.html" aria-label="image-recognition"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->image-recognition<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/introduction-of-prompts-ai-illustration-generation-camera-angle-composition-facial-expression.html" aria-label="introduction-of-prompts-ai-illustration-generation-camera-angle-composition-facial-expression"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->introduction-of-prompts-ai-illustration-generation-camera-angle-composition-facial-expression<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/mcp-flash-in-the-pan-or-future-standard.html" aria-label="mcp-flash-in-the-pan-or-future-standard"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->mcp-flash-in-the-pan-or-future-standard<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything.html" aria-label="niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/niji-lesson-2-the-terminator-line.html" aria-label="niji-lesson-2-the-terminator-line"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->niji-lesson-2-the-terminator-line<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/niji-study-1-measuring-with-your-eyes.html" aria-label="niji-study-1-measuring-with-your-eyes"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->niji-study-1-measuring-with-your-eyes<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/niji-study-2-notan.html" aria-label="niji-study-2-notan"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->niji-study-2-notan<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/niji-video.html" aria-label="niji-video"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->niji-video<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/original-character-lora-sdxl-character-training.html" aria-label="original-character-lora-sdxl-character-training"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->original-character-lora-sdxl-character-training<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html" aria-label="qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/reprints/step-by-step-visual-introduction-to-diffusion-models.html" aria-label="step-by-step-visual-introduction-to-diffusion-models"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->step-by-step-visual-introduction-to-diffusion-models<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">sci</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/sci/conda.html" aria-label="conda"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->conda<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">templates</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/templates/ai-weekly.html" aria-label="ai-weekly"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->ai-weekly<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/templates/hf-weekly.html" aria-label="hf-weekly"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->hf-weekly<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/templates/papers.html" aria-label="papers"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->papers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/templates/repos.html" aria-label="repos"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->repos<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">thoughts</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/thoughts/platform-operation-thoughts-after-comfycon.html" aria-label="platform-operation-thoughts-after-comfycon"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->platform-operation-thoughts-after-comfycon<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">web</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/web/vue-1.html" aria-label="vue-1"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->vue-1<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">workflows</h4><ul class="vp-dropdown-subitems"></ul></li></ul></button></div></div></nav><!--]--><!----></div><div class="vp-navbar-end"><!----><!--[--><div class="vp-nav-item"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="选择语言"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon i18n-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="i18n icon" name="i18n" style="width:1rem;height:1rem;vertical-align:middle;"><path d="M379.392 460.8 494.08 575.488l-42.496 102.4L307.2 532.48 138.24 701.44l-71.68-72.704L234.496 460.8l-45.056-45.056c-27.136-27.136-51.2-66.56-66.56-108.544h112.64c7.68 14.336 16.896 27.136 26.112 35.84l45.568 46.08 45.056-45.056C382.976 312.32 409.6 247.808 409.6 204.8H0V102.4h256V0h102.4v102.4h256v102.4H512c0 70.144-37.888 161.28-87.04 210.944L378.88 460.8zM576 870.4 512 1024H409.6l256-614.4H768l256 614.4H921.6l-64-153.6H576zM618.496 768h196.608L716.8 532.48 618.496 768z"></path></svg><!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/posts/reprints/image-recognition.html" aria-label="English"><!---->English<!----></a></li><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/zh/posts/reprints/image-recognition.html" aria-label="简体中文"><!---->简体中文<!----></a></li></ul></button></div></div><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/vuepress-theme-hope/vuepress-theme-hope" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--]--><!----><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/zh/" aria-label="Blog Home"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="home" width="1em" height="1em"></iconify-icon><!--]-->Blog Home<!----></a></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header clickable"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="laptop-code" width="1em" height="1em"></iconify-icon><a class="route-link auto-link vp-sidebar-title no-external-link-icon" href="/zh/demo/" aria-label="如何使用"><!---->如何使用<!----></a><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/zh/demo/markdown.html" aria-label="Markdown 展示"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fab fa-markdown" width="1em" height="1em"></iconify-icon><!--]-->Markdown 展示<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/demo/layout.html" aria-label="布局"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="object-group" width="1em" height="1em"></iconify-icon><!--]-->布局<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/demo/page.html" aria-label="页面配置"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="file" width="1em" height="1em"></iconify-icon><!--]-->页面配置<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/demo/disable.html" aria-label="布局与功能禁用"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="gears" width="1em" height="1em"></iconify-icon><!--]-->布局与功能禁用<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/demo/encrypt.html" aria-label="密码加密的文章"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="lock" width="1em" height="1em"></iconify-icon><!--]-->密码加密的文章<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header active"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="book" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">文章</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Ai Impls</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Ai Weekly</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Dairys</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Hf Weekly</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Ielts</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Papers</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Prompts</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Repos</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">Reprints</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/mcp-flash-in-the-pan-or-future-standard.html" aria-label="MCP：昙花一现还是未来标准？"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="openmoji:code-editor" width="1em" height="1em"></iconify-icon><!--]-->MCP：昙花一现还是未来标准？<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/generative-ai-powered-design.html" aria-label="生成式AI驱动的设计：使用SD3.5 Large创建游戏环境"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="openmoji:video-game" width="1em" height="1em"></iconify-icon><!--]-->生成式AI驱动的设计：使用SD3.5 Large创建游戏环境<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything.html" aria-label="第一课：测量与抽象的基础：绘画的普遍理论"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="palette" width="1em" height="1em"></iconify-icon><!--]-->第一课：测量与抽象的基础：绘画的普遍理论<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/niji-study-1-measuring-with-your-eyes.html" aria-label="练习1：用眼睛测量"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="ruler" width="1em" height="1em"></iconify-icon><!--]-->练习1：用眼睛测量<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/niji-study-2-notan.html" aria-label="研究 2：Notan"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="contrast" width="1em" height="1em"></iconify-icon><!--]-->研究 2：Notan<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/introduction-of-prompts-ai-illustration-generation-camera-angle-composition-facial-expression.html" aria-label="AI插画生成中的prompt介绍【composition/camera angle/facial expression】"><!---->AI插画生成中的prompt介绍【composition/camera angle/facial expression】<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/ai-art-newsletter-jan-25.html" aria-label="AI艺术工具通讯 - 第1期"><!---->AI艺术工具通讯 - 第1期<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/crody&#39;s-model-merge-guide.html" aria-label="Crody&#39;s Model Merge Guide // Team-C"><!---->Crody&#39;s Model Merge Guide // Team-C<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/step-by-step-visual-introduction-to-diffusion-models.html" aria-label="Diffusion Models 可视化逐步入门"><!---->Diffusion Models 可视化逐步入门<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language.html" aria-label="Illustrious XL 3.0-3.5-vpred: 2048分辨率与自然语言"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="mdi:paint-outline" width="1em" height="1em"></iconify-icon><!--]-->Illustrious XL 3.0-3.5-vpred: 2048分辨率与自然语言<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/illustrious-xl-v2.0-the-best-training-base-model-in-1536-age.html" aria-label="Illustrious XL v2.0：1536分辨率时代最佳的训练基础模型"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="mdi:paint-outline" width="1em" height="1em"></iconify-icon><!--]-->Illustrious XL v2.0：1536分辨率时代最佳的训练基础模型<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/illustrious-lu-v0.03.html" aria-label="Illustrious-LU v0.03"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:microscope" width="1em" height="1em"></iconify-icon><!--]-->Illustrious-LU v0.03<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html" aria-label="Qwen3: 下一代具备混合思维和多语言精通能力的AI模型 | 2025年概览"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:robot" width="1em" height="1em"></iconify-icon><!--]-->Qwen3: 下一代具备混合思维和多语言精通能力的AI模型 | 2025年概览<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/zh/posts/reprints/image-recognition.html" aria-label="什么是图像识别？算法和应用"><!---->什么是图像识别？算法和应用<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/experiments-with-mcp-using-github-copilot.html" aria-label="使用 GitHub Copilot 进行 MCP 实验"><!---->使用 GitHub Copilot 进行 MCP 实验<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/announcing-illustrious-text%E2%80%91enhancer-tag-booster-and-mood-enhancer.html" aria-label="发布 Illustrious Text‑Enhancer：Tag Booster 和 Mood Enhancer"><!---->发布 Illustrious Text‑Enhancer：Tag Booster 和 Mood Enhancer<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/flux-qlora.html" aria-label="在消费级硬件上对 FLUX.1-dev 进行（LoRA）微调"><!---->在消费级硬件上对 FLUX.1-dev 进行（LoRA）微调<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/how-and-when-to-build-multi-agent-systems.html" aria-label="如何以及何时构建多智能体系统"><!---->如何以及何时构建多智能体系统<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/niji-video.html" aria-label="如何使用 niji・journey 制作视频"><!---->如何使用 niji・journey 制作视频<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/original-character-lora-sdxl-character-training.html" aria-label="如何创建原创角色 LoRA [SDXL 训练] SDXL 角色训练"><!---->如何创建原创角色 LoRA [SDXL 训练] SDXL 角色训练<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/flux-kontext-optimization.html" aria-label="我们如何优化 FLUX.1 Kontext [dev]"><!---->我们如何优化 FLUX.1 Kontext [dev]<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/ai-art-gtc-paris-2025.html" aria-label="艺术家和时装设计师利用最先进的AI技术为NVIDIA GTC巴黎画廊创作"><!---->艺术家和时装设计师利用最先进的AI技术为NVIDIA GTC巴黎画廊创作<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/explaining-tokens-the-language-and-currency-of-ai-nvidia-blog.html" aria-label="解释token— AI的语言和货币 | NVIDIA博客"><!---->解释token— AI的语言和货币 | NVIDIA博客<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/niji-lesson-2-the-terminator-line.html" aria-label="课程 2：终结者（线）"><!---->课程 2：终结者（线）<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/reprints/flux-1-kontext.html" aria-label="隆重推出 FLUX.1 Kontext 与 BFL Playground"><!---->隆重推出 FLUX.1 Kontext 与 BFL Playground<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Sci</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Templates</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Thoughts</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Web</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Workflows</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/intro.html" aria-label="Intro Page"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="circle-info" width="1em" height="1em"></iconify-icon><!--]-->Intro Page<!----></a></li><li><a class="auto-link external-link vp-sidebar-link" href="https://ecosystem.vuejs.press/zh/plugins/markdown/revealjs/demo.html" aria-label="幻灯片" rel="noopener noreferrer" target="_blank"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="person-chalkboard" width="1em" height="1em"></iconify-icon><!--]-->幻灯片<!----></a></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->什么是图像识别？算法和应用</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">Timothy M.</span></span><span property="author" content="Timothy M."></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2025年6月10日</span><meta property="datePublished" content="2025-06-10T17:51:41.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 22 分钟</span><meta property="timeRequired" content="PT22M"></span><!----><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color2 clickable" role="navigation">计算机视觉</span><span class="page-tag-item color4 clickable" role="navigation">图像识别</span><!--]--><meta property="keywords" content="计算机视觉,图像识别"></span></div><hr></div><div class="vp-toc-placeholder"><aside id="toc"><!----><div class="vp-toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon" name="print"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#图像识别如何工作">图像识别如何工作？</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#步骤-1-像素-计算机的视觉语言">步骤 #1：像素（计算机的视觉语言）</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#步骤-2-特征检测-寻找模式">步骤 #2：特征检测（寻找模式）</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#步骤-3-从示例中学习-训练">步骤 #3：从示例中学习（训练）</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#步骤-4-分类-预测时间">步骤 #4：分类（预测时间！）</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#ai-中的图像识别模型类型">AI 中的图像识别模型类型</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#图像分类模型">图像分类模型</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#物体检测模型">物体检测模型</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#实例和语义分割模型">实例和语义分割模型</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#关键点检测和姿态估计模型">关键点检测和姿态估计模型</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#人脸检测和识别">人脸检测和识别</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#视觉语言模型-vlm">视觉语言模型 (VLM)</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#如何使用-roboflow-进行图像识别-ai">如何使用 Roboflow 进行图像识别 AI</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#步骤-1-创建项目">步骤 #1：创建项目</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#步骤-2-上传您的数据集">步骤 #2：上传您的数据集</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#步骤-3-标注图像">步骤 #3：标注图像</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#步骤-4-预处理和增强您的数据">步骤 #4：预处理和增强您的数据</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#步骤-5-生成数据集">步骤 #5：生成数据集</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#步骤-6-训练模型">步骤 #6：训练模型</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#步骤-7-部署您的模型">步骤 #7：部署您的模型</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#roboflow-工作流如何用于图像识别">Roboflow 工作流如何用于图像识别</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#在-roboflow-中使用预训练模型">在 Roboflow 中使用预训练模型</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#使用经过训练或微调的自定义模型处理您的数据">使用经过训练或微调的自定义模型处理您的数据</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#使用-roboflow-构建图像识别-ai">使用 Roboflow 构建图像识别 AI</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#示例-1-检测和计数木材-原木">示例 #1：检测和计数木材/原木</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#示例-2-识别手势">示例 #2：识别手势</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#示例-3-用于图像识别的-vlm">示例 #3：用于图像识别的 VLM</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#图像识别软件">图像识别软件</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#引用此帖子">引用此帖子</a></li><!----><!--]--></ul></li><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!----></aside></div><!----><div class="theme-hope-content" vp-content><h1 id="什么是图像识别-算法和应用" tabindex="-1"><a class="header-anchor" href="#什么是图像识别-算法和应用"><span>什么是图像识别？算法和应用</span></a></h1><figure><img src="https://blog.roboflow.com/content/images/size/w1200/2025/06/Screenshot-2025-06-10-at-10.46.38---AM.png" alt="什么是图像识别" tabindex="0" loading="lazy"><figcaption>什么是图像识别</figcaption></figure><p>想象一下，一个名叫 Emma 的小女孩对鸟类着迷。每个周末，她都会和爷爷一起去附近的公园观鸟。久而久之，Emma 学会了通过颜色、大小、形状甚至叫声来识别不同的鸟类。一天下午，在翻书时，她毫不费力地指着一张图片说：“看，爷爷！是知更鸟！”她没有测量翼展或分析羽毛类型；她的大脑立即将图像与她在公园里对知更鸟的经历和记忆联系起来。</p><p>这种人类天生的观察、理解和识别能力，让我们能够看到并认识事物。但如果我们想让计算机也做同样的事情呢？这正是图像识别旨在实现的目标。</p><p>图像识别是一项计算机视觉任务，它使机器能够解释和识别图像中的物体、人物、地点和动作。它通过分析数字图像中的模式、形状和特征来模仿人类理解视觉数据的能力。</p><p>在其核心，图像识别通过分析图像的像素并识别模式来工作。这是通过复杂的算法实现的，最著名的是一种称为神经网络的计算模型。这些神经网络受到人脑视觉皮层的启发，并在大量标记图像数据集上进行训练。通过处理这些图像，神经网络学会识别不同物体的特征和特性。</p><figure><img src="https://blog.roboflow.com/content/images/2025/06/image_recognition.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><em>计算机如何识别图像</em></p><h2 id="图像识别如何工作" tabindex="-1"><a class="header-anchor" href="#图像识别如何工作"><span>图像识别如何工作？</span></a></h2><p>对人类来说，看到一张图像意味着立即识别出熟悉的形状、颜色或人物。但对于计算机来说，看东西是完全不同的，图像只是数字。以下是计算机如何“看”图像的分步说明。</p><h3 id="步骤-1-像素-计算机的视觉语言" tabindex="-1"><a class="header-anchor" href="#步骤-1-像素-计算机的视觉语言"><span>步骤 #1：像素（计算机的视觉语言）</span></a></h3><p>每张图像都由称为像素的微小点组成。每个像素都拥有一个代表颜色或阴影的数值。例如，灰度图像是一个二维数字网格（如下所示），其中每个数字的范围从 0（黑色）到 255（白色）。彩色图像有红、绿、蓝 (RGB) 三个通道，使其成为一个三维数组。</p><figure><img src="https://blog.roboflow.com/content/images/2025/06/grayscale_image_representation.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><em>灰度图像表示</em></p><figure><img src="https://blog.roboflow.com/content/images/2025/06/rgb_image_representation.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><em>彩色图像表示</em></p><h3 id="步骤-2-特征检测-寻找模式" tabindex="-1"><a class="header-anchor" href="#步骤-2-特征检测-寻找模式"><span>步骤 #2：特征检测（寻找模式）</span></a></h3><p>一旦图像被转换成数字，计算机就会寻找边缘、角落和交汇点、线条和曲线、形状、纹理等模式。它使用滤波器或数学运算（如卷积等）来自动检测这些特征。</p><h3 id="步骤-3-从示例中学习-训练" tabindex="-1"><a class="header-anchor" href="#步骤-3-从示例中学习-训练"><span>步骤 #3：从示例中学习（训练）</span></a></h3><p>计算机会看到数千张标记好的图像（如猫、汽车或鸟类）。在训练期间，它会学习每种物体类型的共同特征。它将这些信息存储在神经网络中，这是一个类似于简化大脑的模型。</p><h3 id="步骤-4-分类-预测时间" tabindex="-1"><a class="header-anchor" href="#步骤-4-分类-预测时间"><span>步骤 #4：分类（预测时间！）</span></a></h3><p>当显示一张新图像时，计算机分析像素，检测特征，将其与所学知识进行比较，并输出一个标签（例如，“浣熊”）和一个置信度分数（例如，94.7%）。</p><p>让我们通过 <a href="https://blog.roboflow.com/what-is-r-cnn/" target="_blank" rel="noopener noreferrer">R-CNN</a> 架构来理解整个过程。下面的 R-CNN 架构图说明了计算机如何使用 R-CNN（基于区域的卷积神经网络）方法来观察和识别图像中的对象。在步骤 1 中，计算机接收输入图像，该图像在内部表示为像素值的网格。在步骤 2 中，R-CNN 不会一次性分析整个图像，而是生成大约 2,000 个区域提议，即图像中可能包含对象的较小部分。然后将这些区域变形为固定大小，并在步骤 3 中通过 CNN，该 CNN 应用一系列数学运算，如卷积、池化和非线性激活，以提取独特的特征（如边缘、纹理或图案）。最后，在步骤 4 中，使用分类器（如 SVM）对每个区域提取的特征进行分类，回答诸如“这是一个人吗？”或“这是一个电视显示器吗？”之类的问题。该过程显示了计算机如何不一次性理解整个图像，而是将其分解为多个部分，寻找有意义的模式，并使用学习到的数据来识别其中的内容，模仿人类视觉扫描场景以识别熟悉对象的方式。</p><figure><img src="https://blog.roboflow.com/content/images/2025/06/r_cnn.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><a href="https://arxiv.org/pdf/1311.2524?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer"><em>R-CNN</em></a><em>架构</em></p><p>计算机不会将图像视为图片，而是将其视为数字网格。通过机器学习，尤其是深度学习，它学会识别这些数字中的模式，并将它们与已知对象进行匹配。就像孩子在看到许多狗之后学会识别狗一样，计算机从数据中学习“看”世界。</p><h2 id="ai-中的图像识别模型类型" tabindex="-1"><a class="header-anchor" href="#ai-中的图像识别模型类型"><span>AI 中的图像识别模型类型</span></a></h2><p>图像识别应用广泛，有不同类型的模型，每种模型都为特定任务而设计，例如分类、检测、分割、人脸识别或关键点估计。</p><h3 id="图像分类模型" tabindex="-1"><a class="header-anchor" href="#图像分类模型"><span>图像分类模型</span></a></h3><p>图像分类为整个图像分配一个标签。模型查看图像并预测它包含什么对象（或类别），如“猫”、“汽车”或“香蕉”。这些模型为整个图像分配一个标签，用于识别图像中的主要对象或场景（例如，“猫”、“飞机”、“骨折”）。</p><p><strong>示例</strong>：</p><ul><li><a href="https://roboflow.com/model/resnet-32?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">ResNet 32</a>/ <a href="https://roboflow.com/model/resnet-50?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">ResNet-50</a>：使用残差连接来解决深度网络退化问题。</li><li><a href="https://roboflow.com/model/vision-transformer?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">Vision Transformers (ViT)</a>：Vision Transformer 使用强大的自然语言处理嵌入 (BERT) 并将其应用于图像。</li></ul><div class="hint-container tip"><p class="hint-container-title">提示</p><p>在此处探索更多分类模型 <a href="https://roboflow.com/models?type=Classification&amp;ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">here</a>。</p></div><h3 id="物体检测模型" tabindex="-1"><a class="header-anchor" href="#物体检测模型"><span>物体检测模型</span></a></h3><p><a href="https://roboflow.com/model-task-type/object-detection?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">物体检测模型</a> 通过绘制边界框并分配标签（例如，“人”、“狗”）来定位和分类图像中的多个对象。这些模型通过在图像中的多个对象周围绘制边界框来定位和分类它们，用于识别和跟踪图像或视频中的多个人、车辆、动物或产品等对象。</p><p><strong>示例</strong>：</p><ul><li><a href="https://roboflow.com/model/yolov12?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">YOLOv12</a>：快速的实时物体检测模型。</li><li><a href="https://roboflow.com/model/detr?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">DETR</a>：基于 Transformer 的端到端物体检测模型。</li><li><a href="https://roboflow.com/model/rf-detr?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">RF-DETR</a>：基于 Transformer 的实时物体检测模型。</li><li><a href="https://roboflow.com/models?type=Object+Detection&amp;ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">Grounding DINO</a>：最先进的零样本物体检测模型。</li></ul><div class="hint-container tip"><p class="hint-container-title">提示</p><p>在此处探索更多物体检测模型 <a href="https://roboflow.com/models?type=Object+Detection&amp;ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">here</a>。</p></div><h3 id="实例和语义分割模型" tabindex="-1"><a class="header-anchor" href="#实例和语义分割模型"><span>实例和语义分割模型</span></a></h3><p>这些模型使用以下方法执行像素级分类：</p><ul><li>语义分割标记每个像素（例如，天空、道路、人）</li><li>实例分割还区分单个对象（例如，人 1 与人 2）</li></ul><p>这些模型用于理解对象的形状和确切边界，例如，将道路车道、肿瘤或叶子与背景隔离。</p><p><strong>示例</strong>：</p><ul><li><a href="https://roboflow.com/model/mask-rcnn?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">Mask R-CNN</a>：将 Faster R-CNN 与像素掩码相结合。</li><li><a href="https://roboflow.com/model/yolov8-instance-segmentation?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">YOLOv8 实例分割</a>：最先进的 YOLOv8 模型支持实例分割任务。</li><li><a href="https://roboflow.com/model/segment-anything-2?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">Segment Anything 2</a>：来自 Meta 的开放世界、基于提示的分割。</li><li><a href="https://roboflow.com/model/segformer?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">SegFormer</a>：用于语义分割任务的基于 Transformer 的模型。</li></ul><div class="hint-container tip"><p class="hint-container-title">提示</p><p>在此处探索实例分割模型 <a href="https://roboflow.com/models?type=Instance+Segmentation&amp;ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">here</a> 和语义分割 <a href="https://roboflow.com/models?type=Semantic+Segmentation&amp;ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">here</a>。</p></div><h3 id="关键点检测和姿态估计模型" tabindex="-1"><a class="header-anchor" href="#关键点检测和姿态估计模型"><span>关键点检测和姿态估计模型</span></a></h3><p><a href="https://roboflow.com/model-task-type/keypoint-detection?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">关键点检测模型</a> 识别对象上的特定地标，通常是人体关节（肘部、手腕、膝盖等）。姿态估计使用这些点来确定身体或对象的姿势或方向。这些模型用于估计人体姿势、手势识别、健身分析和运动捕捉。这些模型通常返回每个人 17-33 个身体关节的坐标：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>[</span></span>
<span class="line"><span>    { &quot;x&quot;: 100, &quot;y&quot;: 200, &quot;label&quot;: &quot;left_elbow&quot; },</span></span>
<span class="line"><span>    ...</span></span>
<span class="line"><span>]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>示例</strong>：</p><ul><li><a href="https://roboflow.com/model/yolo-nas-pose?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">YOLO-NAS Pose</a>：由 Deci AI 开发的关键点检测模型。</li></ul><div class="hint-container tip"><p class="hint-container-title">提示</p><p>在此处探索 Roboflow 支持的关键点检测模型 <a href="https://roboflow.com/models?type=Keypoint+Detection&amp;ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">here</a>。</p></div><h3 id="人脸检测和识别" tabindex="-1"><a class="header-anchor" href="#人脸检测和识别"><span>人脸检测和识别</span></a></h3><p>人脸检测模型在图像中查找和定位人脸，人脸识别模型根据面部特征识别或验证个人。这些模型用于生物特征认证、安全监控、照片中的人脸标记和访问控制系统。</p><p><strong>示例</strong>：</p><ul><li><a href="https://arxiv.org/abs/1905.00641?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">RetinaFace</a>：具有地标提取功能的高精度人脸检测器。</li><li><a href="https://arxiv.org/abs/1503.03832?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">FaceNet</a> / <a href="https://arxiv.org/abs/1801.07698?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">ArcFace</a> / <a href="https://github.com/deepinsight/insightface?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">InsightFace</a>：将人脸转换为用于匹配的嵌入。</li><li><a href="https://github.com/serengil/deepface?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">DeepFace</a>：支持多种后端（如 VGGFace、Dlib 等）的高级包装器。</li></ul><h3 id="视觉语言模型-vlm" tabindex="-1"><a class="header-anchor" href="#视觉语言模型-vlm"><span>视觉语言模型 (VLM)</span></a></h3><p><a href="https://roboflow.com/model-task-type/vision-language?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">VLM</a> 将图像理解与自然语言相结合。你可以问它们：</p><p><em>“这张图片里发生了什么？”</em> 或 <em>“狗在哪里？”</em></p><p>它们既能理解视觉模式，又能理解语言，从而给出智能的、基于文本的答案。这些模型使用自然语言解释图像，并可以回答有关图像的问题、生成标题或按名称查找对象。这些模型用于图像字幕、视觉问答、对象定位（“狗在哪里？”）和多模态 AI 应用。</p><p><strong>示例</strong>：</p><ul><li><a href="https://roboflow.com/model/metaclip?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">MetaCLIP</a>：将图像与文本匹配（零样本）。</li><li><a href="https://roboflow.com/model/florence-2?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">Florence-2</a> / <a href="https://roboflow.com/model/kosmos-2?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">Kosmos-2</a>：用于使用语言进行定位、字幕和分割。</li><li><a href="https://roboflow.com/model/gpt-4o?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">GPT-4o</a>：讨论图像、生成标题、解释文档。</li></ul><h2 id="如何使用-roboflow-进行图像识别-ai" tabindex="-1"><a class="header-anchor" href="#如何使用-roboflow-进行图像识别-ai"><span>如何使用 Roboflow 进行图像识别 AI</span></a></h2><p><a href="https://roboflow.com/?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">Roboflow</a> 允许您 <a href="https://roboflow.com/train?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">训练</a>、测试和 <a href="https://roboflow.com/deploy?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">部署</a> 能够识别图像的计算机视觉模型。只需几个步骤，您就可以构建强大的图像识别系统。以下是使用 Roboflow 构建图像识别 AI 的步骤。</p><h3 id="步骤-1-创建项目" tabindex="-1"><a class="header-anchor" href="#步骤-1-创建项目"><span>步骤 #1：创建项目</span></a></h3><p>选择您要构建图像识别模型的任务类型。Roboflow 支持以下项目类型。</p><ul><li>图像分类（为整个图像分配标签。）</li><li>物体检测（用边界框识别物体及其位置。）</li><li>实例分割（检测多个物体及其形状。）</li><li>语义分割（将每个像素分配给一个标签。）</li><li>关键点检测（识别主体上的关键点/骨架）</li><li>多模态（使用文本对描述图像）</li></ul><h3 id="步骤-2-上传您的数据集" tabindex="-1"><a class="header-anchor" href="#步骤-2-上传您的数据集"><span>步骤 #2：上传您的数据集</span></a></h3><p>项目创建后，将您的图像上传/拖放到 Roboflow 中。您还可以从 <a href="https://universe.roboflow.com/?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">Roboflow universe</a>、YouTube URL、<a href="https://docs.roboflow.com/datasets/adding-data/upload-data-from-aws-gcp-and-azure?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">云提供商</a> 和 <a href="https://docs.roboflow.com/developer/manage-images/upload-an-image?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">上传 API</a> 导入数据。</p><h3 id="步骤-3-标注图像" tabindex="-1"><a class="header-anchor" href="#步骤-3-标注图像"><span>步骤 #3：标注图像</span></a></h3><p>使用 Roboflow 的内置 <a href="https://roboflow.com/annotate?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">标注工具</a> 标记您的图像。您可以使用以下标注技术：</p><ul><li>手动标注：使用 Roboflow 的基于 Web 的 <a href="https://docs.roboflow.com/annotate/annotation-tools?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">标注工具</a> 标记对象（例如，边界框、多边形等）。</li><li>自动标注：使用 Roboflow 的 AI 辅助标注（即 <a href="https://docs.roboflow.com/annotate/ai-labeling/model-assisted-labeling?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">Label Assist</a>、<a href="https://docs.roboflow.com/annotate/ai-labeling/enhanced-smart-polygon-with-sam?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">Smart Polygon</a>、<a href="https://docs.roboflow.com/annotate/ai-labeling/box-prompting-ai-labeling?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">Box Prompting</a>、<a href="https://docs.roboflow.com/annotate/ai-labeling/automated-annotation-with-autodistill?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">Auto Label</a>）来加快流程。</li></ul><h3 id="步骤-4-预处理和增强您的数据" tabindex="-1"><a class="header-anchor" href="#步骤-4-预处理和增强您的数据"><span>步骤 #4：预处理和增强您的数据</span></a></h3><p>Roboflow 提供预处理和增强选项以提高模型鲁棒性：</p><p><strong>预处理</strong>：预处理涉及修改原始图像以使其标准化以进行模型训练。常用技术包括自动定向、隔离对象、静态裁剪、动态裁剪、调整大小、灰度、自动调整对比度、平铺等。</p><p><strong>增强</strong>：增强通过对图像应用随机变换来人为地扩展数据集。这有助于防止过拟合（当模型记住训练数据而不是学习一般模式时）。常用技术包括</p><ul><li>图像级增强，例如翻转、90° 旋转、裁剪、旋转、剪切、灰度、色调、饱和度、亮度、曝光、模糊、噪声、剪切、马赛克。</li><li>边界框级增强，例如翻转、90° 旋转、裁剪、旋转、剪切、亮度、曝光、模糊、噪声。</li></ul><h3 id="步骤-5-生成数据集" tabindex="-1"><a class="header-anchor" href="#步骤-5-生成数据集"><span>步骤 #5：生成数据集</span></a></h3><p>单击“创建”以使用您选择的设置创建数据集版本。</p><h3 id="步骤-6-训练模型" tabindex="-1"><a class="header-anchor" href="#步骤-6-训练模型"><span>步骤 #6：训练模型</span></a></h3><p>您现在可以使用 Roboflow 训练模型。您可以通过“自定义训练”按钮为托管模型选择 Roboflow 的内置自动训练选项。或者，您可以导出数据集以在本地使用 YOLO、TensorFlow 或 PyTorch 进行训练。以下是将数据集导出为 YOLOv8 格式进行训练的示例。</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> roboflow </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> Roboflow</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">rf </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> Roboflow</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">api_key</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;YOUR_API_KEY&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">project </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> rf.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">workspace</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">().</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">project</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;your-project&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">dataset </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> project.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">version</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">).</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">download</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;yolov8&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">提示</p><p>查看示例 <a href="https://github.com/roboflow/notebooks?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">notebooks</a> 来训练您的模型。</p></div><h3 id="步骤-7-部署您的模型" tabindex="-1"><a class="header-anchor" href="#步骤-7-部署您的模型"><span>步骤 #7：部署您的模型</span></a></h3><p>Roboflow 提供灵活的部署选项，允许您在云、本地或各种边缘设备上运行您的视觉模型。训练完成后，Roboflow 提供：</p><ul><li>工作流部署，可快速配置、集成和部署模型到应用程序中。</li><li>托管的图像和视频推理端点部署，这些部署依赖于互联网，易于为非实时和批量处理需求设置。</li><li>边缘部署，适用于嵌入式设备（如 TPU 或 Android 手机），使用自定义代码，或通过 Docker 容器部署到边缘设备（如 NVIDIA Jetson），以实现可扩展的实时推理。</li><li>其他部署选项包括由 Roboflow 管理的专用远程服务器、iOS 上的移动部署、Snap AR Lens Studio 集成等，从而实现跨平台和用例的广泛兼容性。</li></ul><h2 id="roboflow-工作流如何用于图像识别" tabindex="-1"><a class="header-anchor" href="#roboflow-工作流如何用于图像识别"><span>Roboflow 工作流如何用于图像识别</span></a></h2><p>Roboflow Workflows 是一项功能，可让您将多个计算机视觉模型组合成一个管道。工作流不是一次运行一个模型，而是让您自动将对象检测、分类和 <a href="https://roboflow.com/ocr?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">OCR</a>（文本识别）等任务链接在一起，只需一次 API 调用即可获得最终结果。在 Roboflow Workflows 中，您可以使用不同的模型类型和功能块构建图像识别管道，每个块负责一个特定的任务。这些块可以按顺序组合以形成一个完整的视觉处理管道。</p><p>Roboflow Workflows 是一个强大的工具，因为它支持：</p><ul><li>预训练模型</li><li>自定义训练/微调模型</li></ul><h3 id="在-roboflow-中使用预训练模型" tabindex="-1"><a class="header-anchor" href="#在-roboflow-中使用预训练模型"><span>在 Roboflow 中使用预训练模型</span></a></h3><p>Roboflow 提供了几种即用型模型（例如 YOLOv8、YOLOv11、YOLO-NAS、RF-DETR-Base、VLM/多模态模型），您可以在自己的图像上尝试，而无需进行任何训练。您可以借助不同的块在 Roboflow Workflows 中直接使用这些模型。例如，您可以使用 <a href="https://inference.roboflow.com/workflows/blocks/object_detection_model/?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">对象检测模型块</a> 使用 RF-DETR-Base 或 YOLOv8 模型，使用 <a href="https://inference.roboflow.com/workflows/blocks/instance_segmentation_model/?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">实例分割模型块</a> 使用 YOLOv8n-Seg 分割模型，使用 <a href="https://inference.roboflow.com/workflows/blocks/keypoint_detection_model/?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">关键点检测模型块</a> 使用 YOLOv8n-Pose 姿态估计模型，使用 <a href="https://inference.roboflow.com/workflows/blocks/open_ai/?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">OpenAI 块</a> 使用 GPT-4o 模型，使用 <a href="https://inference.roboflow.com/workflows/blocks/google_gemini/?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">Google Gemini 块</a> 使用 gemini-2.0-flash 模型等等。</p><figure><img src="https://blog.roboflow.com/content/images/2025/06/workflow-example.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><em>Roboflow 工作流示例</em></p><div class="hint-container tip"><p class="hint-container-title">提示</p><p><a href="https://roboflow.com/workflows/build?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">Roboflow Workflows</a> 是一个无代码计算机视觉应用程序构建器，允许用户在 Web 浏览器中创建多步骤、复杂的计算机视觉应用程序。它使用户能够连接各种块（预构建的功能）来设计和构建视觉管道，而无需广泛的编码专业知识。这些工作流可以部署在 Roboflow Cloud 上，也可以自托管在各种硬件上，包括边缘设备。</p></div><h3 id="使用经过训练或微调的自定义模型处理您的数据" tabindex="-1"><a class="header-anchor" href="#使用经过训练或微调的自定义模型处理您的数据"><span>使用经过训练或微调的自定义模型处理您的数据</span></a></h3><p>Roboflow 是一个端到端的计算机视觉开发平台。它支持构建计算机视觉模型的整个生命周期，从数据收集和标记到数据集生成、训练、微调、推理、部署和与 API 的集成。一旦您使用 Roboflow 训练了自定义计算机视觉模型，它就会被托管并随时可以通过 API 集成到您的应用程序中。您还可以通过您的工作区或 Roboflow 平台中其他用户工作区中的公开可用模型将这些模型集成到您的 Roboflow Workflow 中。</p><figure><img src="https://blog.roboflow.com/content/images/2025/06/custom_models.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><em>Roboflow 工作区中的自定义训练模型</em></p><h2 id="使用-roboflow-构建图像识别-ai" tabindex="-1"><a class="header-anchor" href="#使用-roboflow-构建图像识别-ai"><span>使用 Roboflow 构建图像识别 AI</span></a></h2><p>现在让我们看一些如何使用 Roboflow 构建图像识别 AI 应用程序的示例。在本节中，我们将使用自定义训练模型（<a href="https://universe.roboflow.com/koba-nanyo/wood-zay26?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">木材/原木检测</a>、<a href="https://universe.roboflow.com/tim-4ijf0/hand-gestures-cjowr/model/2?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">手势识别</a>）以及预训练模型 (Florence-2) 和 Roboflow Workflows 来构建我们的应用程序。</p><h3 id="示例-1-检测和计数木材-原木" tabindex="-1"><a class="header-anchor" href="#示例-1-检测和计数木材-原木"><span>示例 #1：检测和计数木材/原木</span></a></h3><p>在此示例中，我们将构建一个 Roboflow Workflow 应用程序，该应用程序将识别和检测木材/原木并对其进行计数。创建对象检测项目、上传和标记数据集并使用 Roboflow 自动训练选项训练模型。训练好的模型可在 Roboflow 托管的推理服务器上使用，我们可以使用它。</p><p>在此示例中，我们构建了一个 Roboflow Workflow 应用程序，旨在检测和计数图像中的原木（木块）。该项目采用对象检测方法，使用 Roboflow 2.0 对象检测（快速）模型。为了创建此应用程序，将包含 183 张标记有木材原木的图像的自定义数据集上传到 Roboflow。图像中的每个原木都用类别标签“log”进行注释。该模型使用 Roboflow 的 AutoML 训练管道进行训练。该模型经过训练，mAP@50 达到 94.6%，精确率为 95.0%，召回率为 91.4%。训练好的模型，标识为 <a href="https://universe.roboflow.com/koba-nanyo/wood-zay26/model/1?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">wood-zay26/1</a>，托管在 Roboflow 的推理服务器上，可以集成到工作流中或通过 API 调用。</p><figure><img src="https://blog.roboflow.com/content/images/2025/06/wood_model.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><em>Roboflow 上的 <a href="https://universe.roboflow.com/koba-nanyo/wood-zay26/model/1?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">木材/原木检测</a> 模型</em></p><p>我们将通过创建一个新的工作流并添加一个对象检测模型块来将此模型集成到我们的 Roboflow Workflow 中。此块负责使用训练好的模型运行推理。在该块的配置中，将 Model 属性设置为 <a href="https://universe.roboflow.com/koba-nanyo/wood-zay26/model/1?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">wood-zay26/1</a>，它指向部署在 Roboflow 上的自定义对象检测模型。这使工作流能够使用训练好的模型自动检测和标记输入图像中的原木。</p><figure><img src="https://blog.roboflow.com/content/images/2025/06/wk_1-1.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><em>木材/原木检测和计数工作流</em></p><p>现在添加属性定义块。此块用于计算检测次数，有助于计算图像中木材/原木的数量。将此块的 Operations 属性设置为“Count Items”，如下所示。</p><figure><img src="https://blog.roboflow.com/content/images/2025/06/property_wk_1.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><em>属性块配置</em></p><p>最后，添加一个边界框可视化块，以在已识别对象上显示带有边界框的检测结果。工作流执行后，它将生成一个输出图像，突出显示每个检测到的木材原木，让您能够直观地确认模型对图像中原木的识别。</p><figure><img src="https://blog.roboflow.com/content/images/2025/06/output_wk_1.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><em>木材/原木计数工作流的输出</em></p><p>JSON 输出显示了属性块的结果，该结果提供了图像中检测到的木材原木的总数。</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>&quot;property_definition&quot;: 29</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>这种类型的工作流在林业管理、库存跟踪和自动化材料处理中特别有用，在这些领域中需要对堆叠图像中的原木进行计数和识别。</p><p>您还可以使用网络摄像头输入或边缘设备在本地或实时运行此工作流，甚至可以通过调整置信度阈值和重叠设置来进一步自定义它。</p><h3 id="示例-2-识别手势" tabindex="-1"><a class="header-anchor" href="#示例-2-识别手势"><span>示例 #2：识别手势</span></a></h3><p>在此示例中，我们使用来自 Roboflow 的自定义训练的对象检测模型构建了一个 <a href="https://universe.roboflow.com/tim-4ijf0/hand-gestures-cjowr/model/2?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">手势识别</a> 应用程序。该模型旨在根据图像中手的形状检测和识别不同的手势，如下图所示。这些手势用于控制交流灯泡。</p><div class="hint-container tip"><p class="hint-container-title">提示</p><p>阅读完整博客 <a href="https://blog.roboflow.com/gesture-light-system/" target="_blank" rel="noopener noreferrer">使用计算机视觉构建基于手势的灯光控制器</a>。</p></div><p>该模型使用 Roboflow 的 AutoML 管道进行训练，基于 Roboflow 3.0 对象检测（精确）架构，并以 COCOs 检查点为基础。训练数据集由代表各种手势的带注释图像组成，每个手势都用相应的手势名称作为类别进行标记。</p><figure><img src="https://blog.roboflow.com/content/images/2025/06/hand_dataset.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><em>手势数据集</em></p><p>在下面显示的推断中，该模型已成功检测到手势并以 96% 的置信度将其标记为“on”。该模型经过训练，mAP@50 达到 99.5%，精确率为 99.7%，召回率为 100.0%。</p><figure><img src="https://blog.roboflow.com/content/images/2025/06/hand_model.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><em>手势识别模型</em></p><p>我们将使用此模型在 Roboflow Workflow 中构建一个手势识别应用程序。要进行设置，请创建一个新的工作流并添加一个对象检测模型块，将模型属性配置为 <a href="https://universe.roboflow.com/tim-4ijf0/hand-gestures-cjowr/model/2?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">hand-gestures-cjowr/2</a>。然后，同时包含一个边界框可视化块和一个标签可视化块，以显示检测到的手势及其对应的类名。</p><figure><img src="https://blog.roboflow.com/content/images/2025/06/wk_hand_recog.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><em>手势识别工作流</em></p><p>一旦在输入图像上执行工作流，它将用带标签的边界框突出显示每个识别出的手势。</p><figure><img src="https://blog.roboflow.com/content/images/2025/06/wk_hand_g_out.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><em>手势识别工作流的输出</em></p><p>除了处理静态图像外，该工作流还可以处理视频文件和实时视频流。使用 Inference Pipeline SDK，您可以在边缘设备上本地部署和运行工作流，以实时处理视频输入。这使其适用于交互式应用，例如基于手势的控制系统、智能家居界面、辅助技术和手语检测系统。</p><h3 id="示例-3-用于图像识别的-vlm" tabindex="-1"><a class="header-anchor" href="#示例-3-用于图像识别的-vlm"><span>示例 #3：用于图像识别的 VLM</span></a></h3><p>在此示例中，我们使用 Microsoft Florence-2 视觉语言模型 (VLM) 来构建一个智能图像识别应用程序。该应用程序由一个 Roboflow 工作流提供支持，该工作流集成了一个预训练的 Florence-2 模型，能够识别和定位图像中的特定对象。通过提供文本提示，例如对象的名称或描述，模型被引导以检测和突出显示图像中的目标对象。这种方法利用了多模态 AI 的强大功能，将视觉和语言理解相结合，以执行灵活的、基于提示的对象识别。</p><p>创建如下的 Roboflow Workflows。添加 Florence-2 块、VLM as Detector 块、边界框可视化块和标签可视化块。</p><figure><img src="https://blog.roboflow.com/content/images/2025/06/wk_3.jpeg" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><em>使用 VLM 工作流进行对象检测</em></p><p>在输入块中添加一个文本参数，以指定基于文本的提示以及输入图像。</p><figure><img src="https://blog.roboflow.com/content/images/2025/06/input_wk_3.jpeg" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><em>输入块配置</em></p><p>如下配置 Florence-2 块。选择任务类型为“提示对象检测”。将 Prompt 属性与输入块中添加的“prompt”参数绑定。</p><figure><img src="https://blog.roboflow.com/content/images/2025/06/florence_wk_3-1.jpeg" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><em>Florence-2 块配置</em></p><p>现在，如下配置 VLM as Detector 块。VLM 输出和类属性设置为来自 Florence-2 块的输出，模型类型属性设置为 Florence-2，任务类型设置为提示对象检测。</p><figure><img src="https://blog.roboflow.com/content/images/2025/06/vlm_conf.jpeg" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><em>VLM as Detector 锁定配置</em></p><p>通过指定提示并上传输入图像来运行工作流。在这种情况下，提示是“球在哪里？”，输入图像是棒球运动员（击球手）击球的图像。我们想要识别球及其在图像中的位置。</p><figure><img src="https://blog.roboflow.com/content/images/2025/06/output_wk_3.jpeg" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><em>工作流输出</em></p><p>视觉语言模型 (VLM) 通过将视觉理解与自然语言提示相结合，为图像识别提供了一种强大而灵活的方法。VLM 不仅仅依赖于预定义的类，而是允许用户使用简单的文本输入来描述他们想要检测的内容。这使得基于提示的对象检测成为可能，其中模型可以根据给定的描述识别和定位图像中的对象。无论是用于定位特定项目、生成图像标题还是回答视觉问题，VLM 都使图像识别更加直观，更能适应各种现实世界的场景。</p><h2 id="图像识别软件" tabindex="-1"><a class="header-anchor" href="#图像识别软件"><span>图像识别软件</span></a></h2><p>图像识别是计算机视觉的一项强大应用，它使机器能够像人类一样理解和解释视觉数据。借助 Roboflow 等平台，即使没有深厚的编码专业知识，构建和部署智能图像识别系统也变得触手可及。无论是检测原木、识别手势，还是使用视觉语言模型进行基于提示的检测，Roboflow Workflows 都使开发人员能够轻松创建自定义或多模态 AI 管道。这些功能为林业、安防、<a href="https://roboflow.com/industries/retail-and-ecommerce?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">零售</a>、<a href="https://roboflow.com/industries/healthcare-and-medicine?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">医疗保健</a> 等行业的实际应用打开了大门。</p><p>以下是本博客的主要内容，可帮助您了解和应用使用 Roboflow 的图像识别：</p><ul><li><strong>图像识别</strong>：计算机将图像解释为数值数据，并通过训练，它们学会使用神经网络识别模式和对象。</li><li><strong>模型类型</strong>：有适用于各种任务的不同模型，包括分类、对象检测、分割、关键点检测、手势识别和视觉语言理解。</li><li><strong>Roboflow Workflows</strong>：一个无代码/低代码的可视化管道构建器，可让用户链接多种模型类型和功能来创建完整的图像识别系统。</li><li><strong>预训练模型与自定义模型</strong>：Roboflow 两者都支持，可以使用现成的模型，也可以使用 AutoML 在自定义数据集上训练自己的模型。</li><li><strong>实际应用</strong>：从原木计数到实时手势识别和使用 VLM 进行基于提示的对象检测，图像识别具有广泛的用例。</li><li><strong>灵活部署</strong>：Roboflow 支持基于云的、<a href="https://roboflow.com/ai/edge?ref=blog.roboflow.com" target="_blank" rel="noopener noreferrer">边缘设备</a> 和移动部署，以及用于实时或批量推理的托管 API 和 SDK。</li></ul><h3 id="引用此帖子" tabindex="-1"><a class="header-anchor" href="#引用此帖子"><span><strong>引用此帖子</strong></span></a></h3><p>在您的研究中引用此帖子时，请使用以下条目：</p><p><em><a href="https://blog.roboflow.com/author/timothy/" target="_blank" rel="noopener noreferrer">Timothy M.</a>。(2025 年 6 月 10 日)。什么是图像识别？算法和应用。Roboflow 博客：<a href="https://blog.roboflow.com/image-recognition/" target="_blank" rel="noopener noreferrer">https://blog.roboflow.com/image-recognition/</a></em></p></div><!--[--><div class="theme-hope-content"><Share colorful services="email,facebook,line,linkedin,messenger,qrcode,reddit,telegram,twitter"></Share></div><!--]--><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/vuepress-theme-hope/vuepress-theme-hope/edit/main/src/zh/posts/reprints/image-recognition.md" aria-label="在 GitHub 上编辑此页" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->在 GitHub 上编辑此页<!----></a></div><div class="vp-meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/zh/posts/reprints/qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html" aria-label="Qwen3: 下一代具备混合思维和多语言精通能力的AI模型 | 2025年概览"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:robot" width="1em" height="1em"></iconify-icon>Qwen3: 下一代具备混合思维和多语言精通能力的AI模型 | 2025年概览</div></a><a class="route-link auto-link next" href="/zh/posts/reprints/experiments-with-mcp-using-github-copilot.html" aria-label="使用 GitHub Copilot 进行 MCP 实验"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">使用 GitHub Copilot 进行 MCP 实验<!----></div></a></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">我的页脚</div><div class="vp-copyright">Copyright © 2025 Timothy M. </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script src="/assets/js/runtime~app.95d5da72.js" defer></script><script src="/assets/js/9156.64e2dfa0.js" defer></script><script src="/assets/js/app.ea25b194.js" defer></script>
  </body>
</html>
