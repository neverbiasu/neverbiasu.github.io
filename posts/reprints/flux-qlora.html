<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.17" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.58" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="alternate" hreflang="zh-cn" href="https://neverbiasu.github.io/zh/posts/reprints/flux-qlora.html"><meta property="og:url" content="https://neverbiasu.github.io/posts/reprints/flux-qlora.html"><meta property="og:site_name" content="Nlog"><meta property="og:title" content="(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware"><meta property="og:description" content="(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware Tips Open In ColabOpen In Colab In our previous post, Exploring Quantization Backends in Diffusers, we dived into how various ..."><meta property="og:type" content="article"><meta property="og:image" content="https://colab.research.google.com/assets/colab-badge.svg"><meta property="og:locale" content="en-US"><meta property="og:locale:alternate" content="zh-CN"><meta property="article:author" content="Derek Liu, Marc Sun, Sayak Paul, merve, Linoy Tsaban"><meta property="article:tag" content="FLUX"><meta property="article:tag" content="LoRA"><meta property="article:tag" content="QLoRA"><meta property="article:tag" content="Fine-tuning"><meta property="article:tag" content="diffusers"><meta property="article:tag" content="quantization"><meta property="article:published_time" content="2024-06-19T00:00:00.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware","image":["https://colab.research.google.com/assets/colab-badge.svg","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/peft/lora_diagram.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base2_bf16.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged2_qlora_bf16.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base3_bf16.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged3_qlora_bf16.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base5_bf16.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged5_qlora_bf16.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base2.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged2.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base3.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged3.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base5.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged5.png","https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_fp8_combined.png"],"datePublished":"2024-06-19T00:00:00.000Z","dateModified":null,"author":[{"@type":"Person","name":"Derek Liu, Marc Sun, Sayak Paul, merve, Linoy Tsaban"}]}</script><title>(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware | Nlog</title><meta name="description" content="(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware Tips Open In ColabOpen In Colab In our previous post, Exploring Quantization Backends in Diffusers, we dived into how various ...">
    <link rel="stylesheet" href="/assets/css/styles.50126b1a.css">
    <link rel="preload" href="/assets/js/runtime~app.6e2a4ebc.js" as="script"><link rel="preload" href="/assets/css/styles.50126b1a.css" as="style"><link rel="preload" href="/assets/js/9156.1c509bd1.js" as="script"><link rel="preload" href="/assets/js/app.d13efba1.js" as="script">
    <link rel="prefetch" href="/assets/js/posts_reprints_flux-qlora.html.f41f9bde.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_flux-qlora.html.bb116303.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_news-agents-daily-recap.html.b6b19c63.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ielts_simon-task2.html.42244d43.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_crody's-model-merge-guide.html.aefbc33c.js" as="script"><link rel="prefetch" href="/assets/js/8300.f7204200.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_crody's-model-merge-guide.html.4636131a.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_blog-images.html.285021c6.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html.cd48e1e0.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html.1a6c4355.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_what-is-block-merging.html.b7213272.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_original-character-lora-sdxl-character-training.html.852ee2f7.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_step-by-step-visual-introduction-to-diffusion-models.html.07590a5a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_original-character-lora-sdxl-character-training.html.5d707567.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_repos_material.html.518b088f.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_introduction-of-prompts-ai-illustration-generation-camera-angle-composition-facial-expression.html.3bc9b40d.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_X01.html.286d0b31.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_introduction-of-prompts-ai-illustration-generation-camera-angle-composition-facial-expression.html.e8760b35.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_sci_conda.html.c6088184.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_papers_workflow.html.49e6983b.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language.html.3bcbd621.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language.html.a432458f.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_step-by-step-visual-introduction-to-diffusion-models.html.437132d5.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_repos_comfy-mind.html.f60c5090.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-impls_yolov9.html.d931746c.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_model-block-merge-1.html.bc9e83d9.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_ai-art-newsletter-jan-25.html.c7b97d73.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_006.html.f7f5f2c6.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_announcing-illustrious-text‑enhancer-tag-booster-and-mood-enhancer.html.280332e9.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_model-block-merge-2.html.016b931c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_sdo.html.62c55f45.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_announcing-illustrious-text‑enhancer-tag-booster-and-mood-enhancer.html.391dee85.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_resnet.html.7b4e6365.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_ai-art-newsletter-jan-25.html.85db2310.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_bagel.html.eab981b5.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_ming-omni.html.0b4a9776.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_omniconsistency.html.459d124f.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything.html.ca66e748.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_014.html.2d20c099.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_flux-1-kontext.html.97a636c4.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_niji-lesson-2-the-terminator-line.html.bd75f443.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_comfyui-r1.html.fc695785.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_niji-study-1-measuring-with-your-eyes.html.a3d0b79a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything.html.4429ddf0.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_001.html.0cc7a3f6.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_flux-1-kontext.html.a4ed777f.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_markdown.html.cd727a63.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_colorizediffusion.html.f284135a.js" as="script"><link rel="prefetch" href="/assets/js/demo_markdown.html.a2be59df.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_niji-study-1-measuring-with-your-eyes.html.5a4b359a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_repos_checklist.html.a5d8555c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_hunyuancustom.html.82f3d6e0.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ielts_simon-task1.html.b74921cb.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_dairys_250222.html.06c69a55.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_show-o2.html.8edb862c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_hf-weekly_001.html.de44ec24.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_repos_workflow.html.d27c938b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_037.html.a0b49644.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_templates_repos.html.7a8a1c56.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_033.html.9773d8f4.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_031.html.20a0624c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_043.html.fec8617b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_icedit.html.03d6a980.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_032.html.4735e8c8.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_026.html.5614a949.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_042.html.f10046a5.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_omnigen2.html.4699a631.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_transformer.html.12cd3945.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_alexnet.html.14b2d7ef.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_009.html.2102d264.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_022.html.b9e7e9e2.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_030.html.c43bd7aa.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_039.html.a86fffac.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_011.html.339c9ade.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_029.html.08338fe9.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_how-and-when-to-build-multi-agent-systems.html.b16b8928.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_ai-art-gtc-paris-2025.html.fee989e1.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_reptext.html.50a57560.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_040.html.e1f3fe55.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_generative-ai-powered-design.html.1a5d9075.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_how-and-when-to-build-multi-agent-systems.html.a24fe565.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_034.html.cf0e405c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_041.html.6eaf2398.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_036.html.17b68198.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_044.html.70da4be7.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_015.html.473e83a6.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_thoughts_platform-operation-thoughts-after-comfycon.html.e8fcd13a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_035.html.0ea943b3.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_020.html.69998eb7.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_generative-ai-powered-design.html.3852891b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_023.html.35bdf105.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_021.html.6adf8414.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_010.html.cd8e35fa.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_005.html.d52ec160.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_003.html.f31430a4.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_038.html.4fe410af.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_018.html.83564d7d.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_012.html.74ae0f28.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_explaining-tokens-the-language-and-currency-of-ai-nvidia-blog.html.5bbb2226.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_025.html.d33050f6.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_027.html.c1b44168.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_framepack.html.a3a1d6d2.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_028.html.28a9c9d8.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_024.html.afa69a35.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_013.html.209b696d.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_019.html.29dad8a2.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_illustrious-xl-v2.0-the-best-training-base-model-in-1536-age.html.4993a0c3.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_illustrious-xl-v2.0-the-best-training-base-model-in-1536-age.html.c0e6bed7.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_explaining-tokens-the-language-and-currency-of-ai-nvidia-blog.html.0aa02dbe.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_017.html.2a5b34d1.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_niji-lesson-2-the-terminator-line.html.45b8d34a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_niji-study-2-notan.html.eb128aae.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_016.html.ac9b960d.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_mcp-flash-in-the-pan-or-future-standard.html.7c4badd8.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_papers_checklist.html.8f0482a5.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_008.html.a7a36e1a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_002.html.e37efe48.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_niji-video.html.3d77b696.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_mcp-flash-in-the-pan-or-future-standard.html.129894be.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_004.html.f951a958.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_niji-video.html.67627009.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_007.html.4a8c44de.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_niji-study-2-notan.html.6fbe1bc6.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_3steps-paper-reading.html.8bf7271e.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_dairys_250223.html.9b6f0008.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_experiments-with-mcp-using-github-copilot.html.325b729e.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_experimenting-with-mcp-using-github-copilot.html.d38eb7ba.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_illustrious-lu-v0.03.html.ba118f41.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_illustrious-lu-v0.03.html.ca077711.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_templates_papers.html.d6101a35.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_templates_hf-weekly.html.1bd4bd88.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_templates_ai-weekly.html.84f9ae09.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_page.html.753e4b79.js" as="script"><link rel="prefetch" href="/assets/js/demo_page.html.4afa3f13.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_layout.html.9b825e86.js" as="script"><link rel="prefetch" href="/assets/js/demo_layout.html.187c1daf.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_prompts_translate.prompt.html.abc42eb5.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_prompts_ai-weekly.prompt.html.e6131f0e.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_prompts_cover.prompt.html.d54ec0f9.js" as="script"><link rel="prefetch" href="/assets/js/home.html.24f670a9.js" as="script"><link rel="prefetch" href="/assets/js/zh_home.html.bc6f0927.js" as="script"><link rel="prefetch" href="/assets/js/demo_disable.html.307ed297.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_disable.html.145db3b1.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_prompts_papers.prompt.html.0061cba6.js" as="script"><link rel="prefetch" href="/assets/js/zh_intro.html.7fb5a873.js" as="script"><link rel="prefetch" href="/assets/js/intro.html.eb684c35.js" as="script"><link rel="prefetch" href="/assets/js/zh_index.html.9a2f7b2a.js" as="script"><link rel="prefetch" href="/assets/js/index.html.dcce0346.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_web_vue-1.html.8aac8c61.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_index.html.bc7f02c8.js" as="script"><link rel="prefetch" href="/assets/js/demo_encrypt.html.cdc9232a.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_encrypt.html.78570576.js" as="script"><link rel="prefetch" href="/assets/js/tag_artificial-intelligence_index.html.927c4c09.js" as="script"><link rel="prefetch" href="/assets/js/demo_index.html.575191b4.js" as="script"><link rel="prefetch" href="/assets/js/category_model-development_index.html.3da09488.js" as="script"><link rel="prefetch" href="/assets/js/category_image-generation_index.html.a0244739.js" as="script"><link rel="prefetch" href="/assets/js/category_model-training_index.html.773cd11f.js" as="script"><link rel="prefetch" href="/assets/js/category_generative-ai_index.html.f810f2bc.js" as="script"><link rel="prefetch" href="/assets/js/tag_stable-diffusion_index.html.269405a2.js" as="script"><link rel="prefetch" href="/assets/js/category_anime-style_index.html.779b209a.js" as="script"><link rel="prefetch" href="/assets/js/tag_amazon-bedrock_index.html.125e13f3.js" as="script"><link rel="prefetch" href="/assets/js/tag_resource-guide_index.html.cb34dfda.js" as="script"><link rel="prefetch" href="/assets/js/category_explainer_index.html.f69576cd.js" as="script"><link rel="prefetch" href="/assets/js/category_reprints_index.html.6f6748ac.js" as="script"><link rel="prefetch" href="/assets/js/tag_fundamentals_index.html.353f6f8d.js" as="script"><link rel="prefetch" href="/assets/js/tag_kohya-ss-gui_index.html.d6dbc3cb.js" as="script"><link rel="prefetch" href="/assets/js/category_reprint_index.html.4ba60ec9.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_模型上下文协议_index.html.c186d81e.js" as="script"><link rel="prefetch" href="/assets/js/tag_illustrious_index.html.24eaa8ac.js" as="script"><link rel="prefetch" href="/assets/js/tag_text2image_index.html.4744cc37.js" as="script"><link rel="prefetch" href="/assets/js/category_aiml_index.html.b1dca217.js" as="script"><link rel="prefetch" href="/assets/js/tag_diffusers_index.html.aaa1a673.js" as="script"><link rel="prefetch" href="/assets/js/tag_inference_index.html.1f67f1a3.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_阿里巴巴ai研究_index.html.d7071405.js" as="script"><link rel="prefetch" href="/assets/js/tag_markdown_index.html.47f7c0f3.js" as="script"><link rel="prefetch" href="/assets/js/tag_drawing_index.html.40625043.js" as="script"><link rel="prefetch" href="/assets/js/tag_prompt_index.html.421fa58a.js" as="script"><link rel="prefetch" href="/assets/js/tag_lumina_index.html.5ec1f6bc.js" as="script"><link rel="prefetch" href="/assets/js/tag_script_index.html.eee43662.js" as="script"><link rel="prefetch" href="/assets/js/tag_merge_index.html.12b59286.js" as="script"><link rel="prefetch" href="/assets/js/tag_model_index.html.d570405d.js" as="script"><link rel="prefetch" href="/assets/js/tag_qlora_index.html.f99f6977.js" as="script"><link rel="prefetch" href="/assets/js/tag_vpred_index.html.a2942809.js" as="script"><link rel="prefetch" href="/assets/js/tag_notan_index.html.59254a97.js" as="script"><link rel="prefetch" href="/assets/js/tag_qwen3_index.html.5251c172.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_创造者工坊_index.html.3b50fcac.js" as="script"><link rel="prefetch" href="/assets/js/tag_flux_index.html.0c6dc51e.js" as="script"><link rel="prefetch" href="/assets/js/tag_llms_index.html.58fbb4d3.js" as="script"><link rel="prefetch" href="/assets/js/tag_lora_index.html.275e06c5.js" as="script"><link rel="prefetch" href="/assets/js/tag_niji_index.html.b6eb0af8.js" as="script"><link rel="prefetch" href="/assets/js/tag_qwen_index.html.8945a482.js" as="script"><link rel="prefetch" href="/assets/js/tag_sdxl_index.html.5ec0a972.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_大语言模型_index.html.0985c237.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_输入预处理_index.html.1bd558db.js" as="script"><link rel="prefetch" href="/assets/js/tag_aws_index.html.b4d7afb9.js" as="script"><link rel="prefetch" href="/assets/js/tag_llm_index.html.ba8b8540.js" as="script"><link rel="prefetch" href="/assets/js/tag_mcp_index.html.0b743712.js" as="script"><link rel="prefetch" href="/assets/js/tag_art_index.html.75469b85.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_artificial-intelligence_index.html.dfe2c298.js" as="script"><link rel="prefetch" href="/assets/js/category_index.html.54ad007c.js" as="script"><link rel="prefetch" href="/assets/js/tag_ai_index.html.af826e6e.js" as="script"><link rel="prefetch" href="/assets/js/tag_lu_index.html.51f46455.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_llm基准测试_index.html.26bed0dc.js" as="script"><link rel="prefetch" href="/assets/js/timeline_index.html.a7e9a4ac.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_阿里巴巴ai_index.html.f22a6121.js" as="script"><link rel="prefetch" href="/assets/js/article_index.html.630a4265.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_使用指南_index.html.5fc02901.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_图像生成_index.html.e38fbeeb.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_教程指南_index.html.e4b56b47.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_模型开发_index.html.1f86a4b0.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_模型研发_index.html.712a913a.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_模型训练_index.html.3443e619.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_论文精读_index.html.4800887c.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_动漫风格_index.html.df7360be.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_视频生成_index.html.3529cab5.js" as="script"><link rel="prefetch" href="/assets/js/tag_model-context-protocol_index.html.22b04bcf.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_index.html.613896db.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_workflow-generation_index.html.66481f4c.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_人工智能_index.html.794d6daf.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_使用指南_index.html.0bc7a168.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_功能发布_index.html.e109d2ff.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_反向传播_index.html.e994d29c.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_可控生成_index.html.aecf1f90.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_图像生成_index.html.959d833d.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_基础模型_index.html.9e240645.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_开源项目_index.html.82cddcb0.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_扩散模型_index.html.4df40bd3.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_技术教程_index.html.88ba3cd7.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_游戏开发_index.html.b09a0c8e.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_艺术课程_index.html.4b0cb0f8.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_视频生成_index.html.70b080c0.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_计算优化_index.html.2b9642da.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_机器学习_index.html.9e5e7182.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_页面配置_index.html.16ae4ec1.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_model-development_index.html.551b8d6f.js" as="script"><link rel="prefetch" href="/assets/js/tag_large-language-models_index.html.4c95ebe9.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_2048分辨率_index.html.4e58d376.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_image-generation_index.html.103cfe8f.js" as="script"><link rel="prefetch" href="/assets/js/tag_feature-announcement_index.html.09b363cf.js" as="script"><link rel="prefetch" href="/assets/js/tag_index.html.e2e1d2b3.js" as="script"><link rel="prefetch" href="/assets/js/star_index.html.19e783c3.js" as="script"><link rel="prefetch" href="/assets/js/tag_alibaba-ai-research_index.html.00f00478.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_epsilon预测_index.html.e3eff795.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_多模态ai_index.html.df0cad52.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_生成式ai_index.html.6cc3f904.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_stable-diffusion_index.html.eaaa74c2.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_多语言ai_index.html.39f84815.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_初学者_index.html.3bfad167.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_张吕敏_index.html.73238c82.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_model-training_index.html.0f7c5965.js" as="script"><link rel="prefetch" href="/assets/js/tag_epsilon-prediction_index.html.fef56f9a.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_reasoning-model_index.html.dd5d64ac.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_generative-ai_index.html.fb0a6a42.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_公众号_index.html.8c195c50.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_编辑器_index.html.d360ec0e.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_amazon-bedrock_index.html.a61f7bc1.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_resource-guide_index.html.d04068e6.js" as="script"><link rel="prefetch" href="/assets/js/posts_index.html.3871cd02.js" as="script"><link rel="prefetch" href="/assets/js/tag_game-development_index.html.25c4b1d7.js" as="script"><link rel="prefetch" href="/assets/js/tag_image-generation_index.html.4dbf55db.js" as="script"><link rel="prefetch" href="/assets/js/tag_machine-learning_index.html.3af397fd.js" as="script"><link rel="prefetch" href="/assets/js/tag_visual-hierarchy_index.html.2ac2527d.js" as="script"><link rel="prefetch" href="/assets/js/tag_diffusion-models_index.html.2a172a1c.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_anime-style_index.html.e17873b0.js" as="script"><link rel="prefetch" href="/assets/js/tag_multilingual-ai_index.html.4c0272be.js" as="script"><link rel="prefetch" href="/assets/js/tag_stablediffusion_index.html.124c4414.js" as="script"><link rel="prefetch" href="/assets/js/tag_2048-resolution_index.html.ddffe0fa.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_kohya-ss-gui_index.html.c974f590.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_fundamentals_index.html.9ee110b4.js" as="script"><link rel="prefetch" href="/assets/js/tag_llm-benchmarks_index.html.edfcf784.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_ai推理_index.html.4e222fc2.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_ai模型_index.html.0a8848fa.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_ai生成_index.html.e8b741ff.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_思考_index.html.4ebe0236.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_指南_index.html.bfeb79d9.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_新闻_index.html.2da03579.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_日记_index.html.efc2811d.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_论文_index.html.5d587199.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_高级_index.html.087560b8.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_illustrious_index.html.20f3cc22.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_转载_index.html.9060c529.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_explainer_index.html.c33e9c28.js" as="script"><link rel="prefetch" href="/assets/js/tag_agent-systems_index.html.a32071e1.js" as="script"><link rel="prefetch" href="/assets/js/tag_automatic1111_index.html.c12c3b66.js" as="script"><link rel="prefetch" href="/assets/js/tag_generative-ai_index.html.b752db09.js" as="script"><link rel="prefetch" href="/assets/js/tag_multimodal-ai_index.html.7ee6dcf5.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_text2image_index.html.a85ae241.js" as="script"><link rel="prefetch" href="/assets/js/category_ai-tools_index.html.5e9ea626.js" as="script"><link rel="prefetch" href="/assets/js/category_advanced_index.html.2af1cab9.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_reprints_index.html.660fbfd8.js" as="script"><link rel="prefetch" href="/assets/js/tag_ai-reasoning_index.html.77c62597.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_做饭_index.html.7c41eda4.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_创新_index.html.9cae2002.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_加密_index.html.8841eca0.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_协议_index.html.1970640f.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_大会_index.html.983cb142.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_平台_index.html.83a347da.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_开源_index.html.a2a77231.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_微调_index.html.31b5c0be.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_禁用_index.html.ce0a1fc8.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_训练_index.html.24e9bebe.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_运营_index.html.0a50b8f3.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_随想_index.html.8ddee438.js" as="script"><link rel="prefetch" href="/assets/js/tag_modelmerging_index.html.df0addc2.js" as="script"><link rel="prefetch" href="/assets/js/tag_quantization_index.html.5a79085b.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_内容_index.html.89c6d892.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_动漫_index.html.4f609ad2.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_实习_index.html.dddaf71b.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_布局_index.html.5eecea6f.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_技术_index.html.f82d9c56.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_辩论_index.html.f65b3f2b.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_量化_index.html.b48d900d.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_comfymind_index.html.c3e84476.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_framepack_index.html.07dd623f.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_inference_index.html.778fb37a.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_diffusers_index.html.b2b42aad.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_reprint_index.html.b5f70076.js" as="script"><link rel="prefetch" href="/assets/js/tag_fine-tuning_index.html.24efb24e.js" as="script"><link rel="prefetch" href="/assets/js/tag_news-agents_index.html.0f583990.js" as="script"><link rel="prefetch" href="/assets/js/tag_page-config_index.html.8d808e62.js" as="script"><link rel="prefetch" href="/assets/js/tag_usage-guide_index.html.c2077f41.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_markdown_index.html.a1350b1c.js" as="script"><link rel="prefetch" href="/assets/js/category_papers_index.html.59f03152.js" as="script"><link rel="prefetch" href="/assets/js/category_novice_index.html.cec35e9e.js" as="script"><link rel="prefetch" href="/assets/js/tag_alibaba-ai_index.html.894b0a99.js" as="script"><link rel="prefetch" href="/assets/js/tag_art-lesson_index.html.b618c196.js" as="script"><link rel="prefetch" href="/assets/js/tag_base-model_index.html.c5b58cfb.js" as="script"><link rel="prefetch" href="/assets/js/tag_encryption_index.html.da016b00.js" as="script"><link rel="prefetch" href="/assets/js/tag_modelmerge_index.html.3d0402bf.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_comfyui_index.html.7179ed78.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_drawing_index.html.dd6e272d.js" as="script"><link rel="prefetch" href="/assets/js/category_guide_index.html.b09fdbff.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_aiml_index.html.96aaf8ba.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_github_index.html.de7609a0.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_lumina_index.html.68c8b23b.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_prompt_index.html.1021afea.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_script_index.html.e8d6f354.js" as="script"><link rel="prefetch" href="/assets/js/category_news_index.html.48e4f908.js" as="script"><link rel="prefetch" href="/assets/js/tag_ai-model_index.html.3172a9f6.js" as="script"><link rel="prefetch" href="/assets/js/tag_amazon-q_index.html.518860d5.js" as="script"><link rel="prefetch" href="/assets/js/tag_protocol_index.html.b00c0ab4.js" as="script"><link rel="prefetch" href="/assets/js/tag_creators_index.html.eec1dfb4.js" as="script"><link rel="prefetch" href="/assets/js/tag_training_index.html.d26c09d7.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_merge_index.html.bca3eb67.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_model_index.html.47c13d2c.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_notan_index.html.1c3f1573.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_qlora_index.html.b901cc6b.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_qwen3_index.html.eb7ea33b.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_vpred_index.html.c67540a3.js" as="script"><link rel="prefetch" href="/assets/js/tag_disable_index.html.8c6e701e.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_aigc_index.html.3ec82a3e.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_flux_index.html.82b0b718.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_llms_index.html.ac9f4e69.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_niji_index.html.c55ad797.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_lora_index.html.b731c2fb.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_qwen_index.html.3518548c.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_sdxl_index.html.9d98c972.js" as="script"><link rel="prefetch" href="/assets/js/404.html.7aed0954.js" as="script"><link rel="prefetch" href="/assets/js/tag_debate_index.html.c7d3c227.js" as="script"><link rel="prefetch" href="/assets/js/tag_layout_index.html.bcdc80c4.js" as="script"><link rel="prefetch" href="/assets/js/tag_editor_index.html.b22bc8a3.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_art_index.html.9768d361.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_aws_index.html.06e8caf8.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_llm_index.html.b638107a.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_sdo_index.html.a88c4c12.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_mcp_index.html.7ae31099.js" as="script"><link rel="prefetch" href="/assets/js/tag_anime_index.html.15a54200.js" as="script"><link rel="prefetch" href="/assets/js/tag_guide_index.html.91bb56f9.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_lu_index.html.a4b35906.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_ai_index.html.5ab5815f.js" as="script"><link rel="prefetch" href="/assets/js/tag_tech_index.html.d2ce09af.js" as="script"><link rel="prefetch" href="/assets/js/tag_tmux_index.html.208703b1.js" as="script"><link rel="prefetch" href="/assets/js/tag_gtc_index.html.4aba4d30.js" as="script"><link rel="prefetch" href="/assets/js/zh_timeline_index.html.817ad8b0.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_index.html.f54b4216.js" as="script"><link rel="prefetch" href="/assets/js/zh_article_index.html.c1ccddf0.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_papers_index.html.ed8f1f15.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_hf-weekly_index.html.e7adee5c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_templates_index.html.57f3fb88.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_index.html.265e7d02.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_index.html.88fc57b1.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_index.html.72b75c04.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_repos_index.html.6b5bfa17.js" as="script"><link rel="prefetch" href="/assets/js/zh_star_index.html.4aa5e606.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-impls_index.html.4907b247.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_index.html.3fbed4eb.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_thoughts_index.html.85e68346.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_prompts_index.html.4dd92e02.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_dairys_index.html.0360a596.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_index.html.f669eed4.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ielts_index.html.81d1d811.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_repos_index.html.af7a0e5c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_index.html.cf9f0a11.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_sci_index.html.4dfd874c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_web_index.html.6791ec8d.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><!--[--><a class="route-link vp-brand" href="/" aria-label="Take me home"><img class="vp-nav-logo" src="/logo.svg" alt><!----><span class="vp-site-name hide-in-pad">Nlog</span></a><!--]--><!----></div><div class="vp-navbar-center"><!----><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/home.html" aria-label="home"><!---->home<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/demo/" aria-label="Features demo"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="laptop-code" width="1em" height="1em"></iconify-icon><!--]-->Features demo<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Posts"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon>Posts<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Apple</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/apple/1.html" aria-label="Apple1"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->Apple1<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/apple/2.html" aria-label="Apple2"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->Apple2<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/apple/3.html" aria-label="/posts/apple/3.html"><!---->/posts/apple/3.html<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/apple/4.html" aria-label="/posts/apple/4.html"><!---->/posts/apple/4.html<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Banana</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/banana/1.html" aria-label="Banana 1"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->Banana 1<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/banana/2.html" aria-label="Banana 2"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->Banana 2<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/banana/3.html" aria-label="/posts/banana/3.html"><!---->/posts/banana/3.html<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/banana/4.html" aria-label="/posts/banana/4.html"><!---->/posts/banana/4.html<!----></a></li></ul></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/posts/cherry.html" aria-label="Cherry"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->Cherry<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/posts/dragonfruit.html" aria-label="Dragon Fruit"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->Dragon Fruit<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/posts/tomato.html" aria-label="/posts/tomato.html"><!---->/posts/tomato.html<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/posts/strawberry.html" aria-label="/posts/strawberry.html"><!---->/posts/strawberry.html<!----></a></li></ul></button></div></div></nav><!--]--><!----></div><div class="vp-navbar-end"><!----><!--[--><div class="vp-nav-item"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Select language"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon i18n-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="i18n icon" name="i18n" style="width:1rem;height:1rem;vertical-align:middle;"><path d="M379.392 460.8 494.08 575.488l-42.496 102.4L307.2 532.48 138.24 701.44l-71.68-72.704L234.496 460.8l-45.056-45.056c-27.136-27.136-51.2-66.56-66.56-108.544h112.64c7.68 14.336 16.896 27.136 26.112 35.84l45.568 46.08 45.056-45.056C382.976 312.32 409.6 247.808 409.6 204.8H0V102.4h256V0h102.4v102.4h256v102.4H512c0 70.144-37.888 161.28-87.04 210.944L378.88 460.8zM576 870.4 512 1024H409.6l256-614.4H768l256 614.4H921.6l-64-153.6H576zM618.496 768h196.608L716.8 532.48 618.496 768z"></path></svg><!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/posts/reprints/flux-qlora.html" aria-label="English"><!---->English<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/zh/posts/reprints/flux-qlora.html" aria-label="简体中文"><!---->简体中文<!----></a></li></ul></button></div></div><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/vuepress-theme-hope/vuepress-theme-hope" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--]--><!----><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/" aria-label="Blog Home"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="home" width="1em" height="1em"></iconify-icon><!--]-->Blog Home<!----></a></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header clickable"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="laptop-code" width="1em" height="1em"></iconify-icon><a class="route-link auto-link vp-sidebar-title no-external-link-icon" href="/demo/" aria-label="Demo"><!---->Demo<!----></a><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/demo/layout.html" aria-label="Layout"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="object-group" width="1em" height="1em"></iconify-icon><!--]-->Layout<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/demo/markdown.html" aria-label="Markdown Enhance"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fab fa-markdown" width="1em" height="1em"></iconify-icon><!--]-->Markdown Enhance<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/demo/page.html" aria-label="Page Config"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="file" width="1em" height="1em"></iconify-icon><!--]-->Page Config<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/demo/disable.html" aria-label="Disabling layout and features"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="gears" width="1em" height="1em"></iconify-icon><!--]-->Disabling layout and features<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/demo/encrypt.html" aria-label="Encryption Article"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="lock" width="1em" height="1em"></iconify-icon><!--]-->Encryption Article<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header active"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="book" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Articles</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">Reprints</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/generative-ai-powered-design.html" aria-label="Generative AI-Powered Design: Creating Game Environments with SD3.5 Large"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="openmoji:video-game" width="1em" height="1em"></iconify-icon><!--]-->Generative AI-Powered Design: Creating Game Environments with SD3.5 Large<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything.html" aria-label="Lesson 1: Fundamentals of Measurement and Abstraction: The Theory of (How to Draw) Everything"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="palette" width="1em" height="1em"></iconify-icon><!--]-->Lesson 1: Fundamentals of Measurement and Abstraction: The Theory of (How to Draw) Everything<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/mcp-flash-in-the-pan-or-future-standard.html" aria-label="MCP: Flash in the Pan or Future Standard?"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="openmoji:code-editor" width="1em" height="1em"></iconify-icon><!--]-->MCP: Flash in the Pan or Future Standard?<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/niji-lesson-2-the-terminator-line.html" aria-label="Lesson 2: The Terminator (Line)"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="palette" width="1em" height="1em"></iconify-icon><!--]-->Lesson 2: The Terminator (Line)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/niji-study-1-measuring-with-your-eyes.html" aria-label="Study 1: Measuring With Your Eyes"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="ruler" width="1em" height="1em"></iconify-icon><!--]-->Study 1: Measuring With Your Eyes<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/niji-study-2-notan.html" aria-label="Study 2: Notan"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="contrast" width="1em" height="1em"></iconify-icon><!--]-->Study 2: Notan<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/posts/reprints/flux-qlora.html" aria-label="(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware"><!---->(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/model-block-merge-1.html" aria-label="[Experiment Report] Investigating the Influence of Each U-Net Layer with Model Block Merge #1"><!---->[Experiment Report] Investigating the Influence of Each U-Net Layer with Model Block Merge #1<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/model-block-merge-2.html" aria-label="[Experiment Report] Investigating the Influence of Each U-Net Layer with Model Block Merge #1"><!---->[Experiment Report] Investigating the Influence of Each U-Net Layer with Model Block Merge #1<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/announcing-illustrious-text%E2%80%91enhancer-tag-booster-and-mood-enhancer.html" aria-label="Announcing Illustrious Text‑Enhancer: Tag Booster &amp; Mood Enhancer"><!---->Announcing Illustrious Text‑Enhancer: Tag Booster &amp; Mood Enhancer<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/ai-art-gtc-paris-2025.html" aria-label="Artists, Fashion Designers Tap State-of-the-Art AI for NVIDIA GTC Paris Gallery"><!---->Artists, Fashion Designers Tap State-of-the-Art AI for NVIDIA GTC Paris Gallery<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/blog-images.html" aria-label="Blog Images Generator"><!---->Blog Images Generator<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/news-agents-daily-recap.html" aria-label="Building News Agents for Daily News Recaps with MCP, Q, and tmux"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:newspaper" width="1em" height="1em"></iconify-icon><!--]-->Building News Agents for Daily News Recaps with MCP, Q, and tmux<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/crody&#39;s-model-merge-guide.html" aria-label="Crody&#39;s Model Merge Guide // Team-C"><!---->Crody&#39;s Model Merge Guide // Team-C<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/experimenting-with-mcp-using-github-copilot.html" aria-label="Experimenting with MCP using GitHub Copilot"><!---->Experimenting with MCP using GitHub Copilot<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/explaining-tokens-the-language-and-currency-of-ai-nvidia-blog.html" aria-label="Explaining Tokens — the Language and Currency of AI"><!---->Explaining Tokens — the Language and Currency of AI<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/how-and-when-to-build-multi-agent-systems.html" aria-label="How and when to build multi-agent systems"><!---->How and when to build multi-agent systems<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/original-character-lora-sdxl-character-training.html" aria-label="How to create an original character LoRA [SDXL Training] SDXL Character Training"><!---->How to create an original character LoRA [SDXL Training] SDXL Character Training<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/niji-video.html" aria-label="How to make videos with niji・journey"><!---->How to make videos with niji・journey<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language.html" aria-label="Illustrious XL 3.0-3.5-vpred: 2048 Resolution and Natural Language"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="mdi:paint-outline" width="1em" height="1em"></iconify-icon><!--]-->Illustrious XL 3.0-3.5-vpred: 2048 Resolution and Natural Language<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/illustrious-xl-v2.0-the-best-training-base-model-in-1536-age.html" aria-label="Illustrious XL v2.0—The best training base model in 1536 age"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="mdi:paint-outline" width="1em" height="1em"></iconify-icon><!--]-->Illustrious XL v2.0—The best training base model in 1536 age<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/illustrious-lu-v0.03.html" aria-label="Illustrious-LU v0.03"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:microscope" width="1em" height="1em"></iconify-icon><!--]-->Illustrious-LU v0.03<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/flux-1-kontext.html" aria-label="Introducing FLUX.1 Kontext and the BFL Playground"><!---->Introducing FLUX.1 Kontext and the BFL Playground<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/introduction-of-prompts-ai-illustration-generation-camera-angle-composition-facial-expression.html" aria-label="Introduction of prompts in AI illustration generation [composition / camera angle / facial expression]"><!---->Introduction of prompts in AI illustration generation [composition / camera angle / facial expression]<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html" aria-label="Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 Overview"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:robot" width="1em" height="1em"></iconify-icon><!--]-->Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 Overview<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/step-by-step-visual-introduction-to-diffusion-models.html" aria-label="Step by Step visual introduction to Diffusion Models"><!---->Step by Step visual introduction to Diffusion Models<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/ai-art-newsletter-jan-25.html" aria-label="The AI tools for Art Newsletter - Issue 1"><!---->The AI tools for Art Newsletter - Issue 1<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/what-is-block-merging.html" aria-label="What is Block Merging?"><!---->What is Block Merging?<!----></a></li></ul></section></li></ul></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/intro.html" aria-label="Intro Page"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="circle-info" width="1em" height="1em"></iconify-icon><!--]-->Intro Page<!----></a></li><li><a class="auto-link external-link vp-sidebar-link" href="https://ecosystem.vuejs.press/plugins/markdown/revealjs/demo.html" aria-label="Slides" rel="noopener noreferrer" target="_blank"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="person-chalkboard" width="1em" height="1em"></iconify-icon><!--]-->Slides<!----></a></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware</h1><div class="page-info"><span class="page-author-info" aria-label="Author🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">Derek Liu, Marc Sun, Sayak Paul, merve, Linoy Tsaban</span></span><span property="author" content="Derek Liu, Marc Sun, Sayak Paul, merve, Linoy Tsaban"></span></span><!----><span class="page-date-info" aria-label="Writing Date📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">June 19, 2024</span><meta property="datePublished" content="2024-06-19T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 10 min</span><meta property="timeRequired" content="PT10M"></span><span class="page-category-info" aria-label="Category🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color4 clickable" role="navigation">AI/ML</span><!--]--><meta property="articleSection" content="AI/ML"></span><span class="page-tag-info" aria-label="Tag🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color6 clickable" role="navigation">FLUX</span><span class="page-tag-item color1 clickable" role="navigation">LoRA</span><span class="page-tag-item color3 clickable" role="navigation">QLoRA</span><span class="page-tag-item color6 clickable" role="navigation">Fine-tuning</span><span class="page-tag-item color5 clickable" role="navigation">diffusers</span><span class="page-tag-item color7 clickable" role="navigation">quantization</span><!--]--><meta property="keywords" content="FLUX,LoRA,QLoRA,Fine-tuning,diffusers,quantization"></span></div><hr></div><div class="vp-toc-placeholder"><aside id="toc"><!----><div class="vp-toc-header">On This Page<button type="button" class="print-button" title="Print"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon" name="print"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#table-of-contents">Table of Contents</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#dataset">Dataset</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#flux-architecture">FLUX Architecture</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#qlora-fine-tuning-flux-1-dev-with-diffusers">QLoRA Fine-tuning FLUX.1-dev with diffusers</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#key-optimization-techniques">Key Optimization Techniques</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#pre-computing-text-embeddings-clip-t5">Pre-computing Text Embeddings (CLIP/T5)</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#how-to-use-it">How to use it</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#setup-results">Setup &amp; Results</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#fp8-fine-tuning-with-torchao">FP8 Fine-tuning with torchao</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#inference-with-trained-lora-adapters">Inference with Trained LoRA Adapters</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#option-1-loading-lora-adapters">Option 1: Loading LoRA Adapters</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#option-2-merging-lora-into-base-model">Option 2: Merging LoRA into Base Model</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#running-on-google-colab">Running on Google Colab</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#conclusion">Conclusion</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#share-your-creations-on-the-hub">Share your creations on the Hub!</a></li><!----><!--]--></ul></li><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!----></aside></div><!----><div class="theme-hope-content" vp-content><h1 id="lora-fine-tuning-flux-1-dev-on-consumer-hardware" tabindex="-1"><a class="header-anchor" href="#lora-fine-tuning-flux-1-dev-on-consumer-hardware"><span>(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware</span></a></h1><div class="hint-container tip"><p class="hint-container-title">Tips</p><figure><a href="https://colab.research.google.com/github/DerekLiu35/notebooks/blob/main/flux_lora_quant_blogpost.ipynb" target="_blank" rel="noopener noreferrer"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" tabindex="0" loading="lazy"></a><figcaption>Open In Colab</figcaption></figure></div><p>In our previous post, <a href="https://huggingface.co/blog/diffusers-quantization" target="_blank" rel="noopener noreferrer">Exploring Quantization Backends in Diffusers</a>, we dived into how various quantization techniques can shrink diffusion models like FLUX.1-dev, making them significantly more accessible for <em>inference</em> without drastically compromising performance. We saw how <code>bitsandbytes</code>, <code>torchao</code>, and others reduce memory footprints for generating images.</p><p>Performing inference is cool, but to make these models truly our own, we also need to be able to fine-tune them. Therefore, in this post, we tackle <strong>efficient</strong> <em>fine-tuning</em> of these models with peak memory use under ~10 GB of VRAM on a single GPU. This post will guide you through fine-tuning FLUX.1-dev using QLoRA with the <code>diffusers</code> library. We&#39;ll showcase results from an NVIDIA RTX 4090. We&#39;ll also highlight how FP8 training with <code>torchao</code> can further optimize speed on compatible hardware.</p><h2 id="table-of-contents" tabindex="-1"><a class="header-anchor" href="#table-of-contents"><span>Table of Contents</span></a></h2><ol><li><a href="#dataset">Dataset</a></li><li><a href="#flux-architecture">FLUX Architecture</a></li><li><a href="#qlora-fine-tuning-flux1-dev-with-diffusers">QLoRA Fine-tuning FLUX.1-dev with <code>diffusers</code></a><ul><li><a href="#key-optimization-techniques">Key Optimization Techniques</a></li><li><a href="#pre-computing-text-embeddings-clipt5">Pre-computing Text Embeddings (CLIP/T5)</a></li><li><a href="#how-to-use-it">How to use it</a></li><li><a href="#setup--results">Setup &amp; Results</a></li></ul></li><li><a href="#fp8-fine-tuning-with-torchao">FP8 Fine-tuning with <code>torchao</code></a></li><li><a href="#inference-with-trained-lora-adapters">Inference with Trained LoRA Adapters</a><ul><li><a href="#option-1-loading-lora-adapters">Option 1: Loading LoRA Adapters</a></li><li><a href="#option-2-merging-lora-into-base-model">Option 2: Merging LoRA into Base Model</a></li></ul></li><li><a href="#running-on-google-colab">Running on Google Colab</a></li><li><a href="#conclusion">Conclusion</a></li></ol><h2 id="dataset" tabindex="-1"><a class="header-anchor" href="#dataset"><span>Dataset</span></a></h2><p>We aim to fine-tune <code>black-forest-labs/FLUX.1-dev</code> to adopt the artistic style of Alphonse Mucha, using a small <a href="https://huggingface.co/datasets/derekl35/alphonse-mucha-style" target="_blank" rel="noopener noreferrer">dataset</a>.</p><h2 id="flux-architecture" tabindex="-1"><a class="header-anchor" href="#flux-architecture"><span>FLUX Architecture</span></a></h2><p>The model consists of three main components:</p><ul><li>Text Encoders (CLIP and T5)</li><li>Transformer (Main Model - Flux Transformer)</li><li>Variational Auto-Encoder (VAE)</li></ul><p>In our QLoRA approach, we focus exclusively on fine-tuning the <strong>transformer component</strong>. The text encoders and VAE remain frozen throughout training.</p><h2 id="qlora-fine-tuning-flux-1-dev-with-diffusers" tabindex="-1"><a class="header-anchor" href="#qlora-fine-tuning-flux-1-dev-with-diffusers"><span>QLoRA Fine-tuning FLUX.1-dev with <code>diffusers</code></span></a></h2><p>We used a <code>diffusers</code> training script (slightly modified from <a href="https://github.com/huggingface/diffusers/blob/main/examples/research_projects/flux_lora_quantization/train_dreambooth_lora_flux_miniature.py" target="_blank" rel="noopener noreferrer">https://github.com/huggingface/diffusers/blob/main/examples/research_projects/flux_lora_quantization/train_dreambooth_lora_flux_miniature.py</a>) designed for DreamBooth-style LoRA fine-tuning of FLUX models. Also, a shortened version to reproduce the results in this blogpost (and used in the <a href="https://colab.research.google.com/github/DerekLiu35/notebooks/blob/main/flux_lora_quant_blogpost.ipynb" target="_blank" rel="noopener noreferrer">Google Colab</a>) is available <a href="https://github.com/huggingface/diffusers/blob/main/examples/research_projects/flux_lora_quantization/train_dreambooth_lora_flux_nano.py" target="_blank" rel="noopener noreferrer">here</a>. Let&#39;s examine the crucial parts for QLoRA and memory efficiency:</p><h3 id="key-optimization-techniques" tabindex="-1"><a class="header-anchor" href="#key-optimization-techniques"><span>Key Optimization Techniques</span></a></h3><p><strong>LoRA (Low-Rank Adaptation) Deep Dive:</strong><a href="https://huggingface.co/docs/peft/main/en/conceptual_guides/lora" target="_blank" rel="noopener noreferrer">LoRA</a> makes model training more efficient by keeping track of the weight updates with low-rank matrices. Instead of updating the full weight matrix W, LoRA learns two smaller matrices A and B. The update to the weights for the model is ΔW = BA, where A ∈ R^(r×k) and B ∈ R^(d×r). The number r (called <em>rank</em>) is much smaller than the original dimensions, which means less parameters to update. Lastly, α is a scaling factor for the LoRA activations. This affects how much LoRA affects the updates, and is often set to the same value as the r or a multiple of it. It helps balance the influence of the pre-trained model and the LoRA adapter. For a general introduction to the concept, check out our previous blog post: <a href="https://huggingface.co/blog/lora" target="_blank" rel="noopener noreferrer">Using LoRA for Efficient Stable Diffusion Fine-Tuning</a>.</p><figure><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/peft/lora_diagram.png" alt="Illustration of LoRA injecting two low-rank matrices around a frozen weight matrix" tabindex="0" loading="lazy"><figcaption>Illustration of LoRA injecting two low-rank matrices around a frozen weight matrix</figcaption></figure><p><strong>QLoRA: The Efficiency Powerhouse:</strong><a href="https://huggingface.co/docs/peft/main/en/developer_guides/quantization" target="_blank" rel="noopener noreferrer">QLoRA</a> enhances LoRA by first loading the pre-trained base model in a quantized format (typically 4-bit via <code>bitsandbytes</code>), drastically cutting the base model&#39;s memory footprint. It then trains LoRA adapters (usually in FP16/BF16) on top of this quantized base. This dramatically lowers the VRAM needed to hold the base model.</p><p>For instance, in the <a href="https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/README_hidream.md#using-quantization" target="_blank" rel="noopener noreferrer">DreamBooth training script for HiDream</a> 4-bit quantization with bitsandbytes reduces the peak memory usage of a LoRA fine-tune from ~60GB down to ~37GB with negligible-to-none quality degradation. The very same principle is what we apply here to fine-tune FLUX.1 on a consumer-grade hardware.</p><p><strong>8-bit Optimizer (AdamW):</strong> Standard AdamW optimizer maintains first and second moment estimates for each parameter in 32-bit (FP32), which consumes a lot of memory. The 8-bit AdamW uses block-wise quantization to store optimizer states in 8-bit precision, while maintaining training stability. This technique can reduce optimizer memory usage by ~75% compared to standard FP32 AdamW. Enabling it in the script is straightforward:</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Check for the --use_8bit_adam flag</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> args.use_8bit_adam:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        optimizer_class </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> bnb.optim.AdamW8bit</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">else</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        optimizer_class </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.optim.AdamW</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">optimizer </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> optimizer_class</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        params_to_optimize,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        betas</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(args.adam_beta1, args.adam_beta2),</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        weight_decay</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">args.adam_weight_decay,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        eps</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">args.adam_epsilon,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Gradient Checkpointing:</strong> During forward pass, intermediate activations are typically stored for backward pass gradient computation. Gradient checkpointing trades computation for memory by only storing certain <em>checkpoint activations</em> and recomputing others during backpropagation.</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> args.gradient_checkpointing:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        transformer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">enable_gradient_checkpointing</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Cache Latents:</strong> This optimization technique pre-processes all training images through the VAE encoder before the beginning of the training. It stores the resulting latent representations in memory. During the training, instead of encoding images on-the-fly, the cached latents are directly used. This approach offers two main benefits:</p><ol><li>eliminates redundant VAE encoding computations during training, speeding up each training step</li><li>allows the VAE to be completely removed from GPU memory after caching. The trade-off is increased RAM usage to store all cached latents, but this is typically manageable for small datasets.</li></ol><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Cache latents before training if the flag is set</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> args.cache_latents:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        latents_cache </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> []</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> batch </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> tqdm</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(train_dataloader, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">desc</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Caching latents&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">                with</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">no_grad</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">():</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                        batch[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;pixel_values&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> batch[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;pixel_values&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">to</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                accelerator.device, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">non_blocking</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">weight_dtype</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                        )</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                        latents_cache.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(vae.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">encode</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(batch[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;pixel_values&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]).latent_dist)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # VAE is no longer needed, free up its memory</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        del</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> vae</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">        free_memory</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Setting up 4-bit Quantization (<code>BitsAndBytesConfig</code>):</strong></p><p>This section demonstrates the QLoRA configuration for the base model:</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Determine compute dtype based on mixed precision</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bnb_4bit_compute_dtype </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.float32</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> args.mixed_precision </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">==</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;fp16&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        bnb_4bit_compute_dtype </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.float16</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">elif</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> args.mixed_precision </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">==</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;bf16&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        bnb_4bit_compute_dtype </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.bfloat16</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">nf4_config </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> BitsAndBytesConfig</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        load_in_4bit</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        bnb_4bit_quant_type</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;nf4&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        bnb_4bit_compute_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bnb_4bit_compute_dtype,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxTransformer2DModel.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        args.pretrained_model_name_or_path,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        subfolder</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;transformer&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        quantization_config</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">nf4_config,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        torch_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bnb_4bit_compute_dtype,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Prepare model for k-bit training</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> prepare_model_for_kbit_training</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(transformer, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">use_gradient_checkpointing</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">False</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Gradient checkpointing is enabled later via transformer.enable_gradient_checkpointing() if arg is set</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Defining LoRA Configuration (<code>LoraConfig</code>):</strong> Adapters are added to the quantized transformer:</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer_lora_config </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> LoraConfig</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        r</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">args.rank,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        lora_alpha</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">args.rank, </span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        init_lora_weights</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;gaussian&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        target_modules</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;to_k&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;to_q&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;to_v&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;to_out.0&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">], </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># FLUX attention blocks</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">add_adapter</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(transformer_lora_config)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;trainable params: </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">num_parameters</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">only_trainable</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> || all params: </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">num_parameters</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># trainable params: 4,669,440 || all params: 11,906,077,760</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Only these LoRA parameters become trainable.</p><h3 id="pre-computing-text-embeddings-clip-t5" tabindex="-1"><a class="header-anchor" href="#pre-computing-text-embeddings-clip-t5"><span>Pre-computing Text Embeddings (CLIP/T5)</span></a></h3><p>Before we launch the QLoRA fine-tune we can save a huge chunk of VRAM and wall-clock time by caching outputs of text encoders once.</p><p>At training time the dataloader simply reads the cached embeddings instead of re-encoding the caption, so the CLIP/T5 encoder never has to sit in GPU memory.</p><details class="hint-container details"><summary>Code</summary><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># https://github.com/huggingface/diffusers/blob/main/examples/research_projects/flux_lora_quantization/compute_embeddings.py</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> argparse</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pandas </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pd</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> datasets </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> load_dataset</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> huggingface_hub.utils </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> insecure_hashlib</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tqdm.auto </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tqdm</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> transformers </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> T5EncoderModel</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> diffusers </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxPipeline</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">MAX_SEQ_LENGTH</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> =</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 77</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">OUTPUT_PATH</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> =</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;embeddings.parquet&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> generate_image_hash</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">image</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> insecure_hashlib.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">sha256</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(image.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">tobytes</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()).</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">hexdigest</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> load_flux_dev_pipeline</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">():</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">        id</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> =</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;black-forest-labs/FLUX.1-dev&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        text_encoder </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> T5EncoderModel.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">id</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">subfolder</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;text_encoder_2&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">load_in_8bit</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">device_map</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;auto&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        pipeline </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxPipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">                id</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">text_encoder_2</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">text_encoder, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">transformer</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">vae</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">device_map</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;balanced&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        )</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pipeline</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">@torch</span><span style="--shiki-light:#4078F2;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">no_grad</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> compute_embeddings</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">pipeline</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> prompts</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> max_sequence_length</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        all_prompt_embeds </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> []</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        all_pooled_prompt_embeds </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> []</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        all_text_ids </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> []</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> prompt </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> tqdm</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(prompts, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">desc</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Encoding prompts.&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                (</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                        prompt_embeds,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                        pooled_prompt_embeds,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                        text_ids,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                ) </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">encode_prompt</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">prompt</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">prompt, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">prompt_2</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">max_sequence_length</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">max_sequence_length)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                all_prompt_embeds.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(prompt_embeds)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                all_pooled_prompt_embeds.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(pooled_prompt_embeds)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                all_text_ids.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(text_ids)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        max_memory </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.cuda.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">max_memory_allocated</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">() </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">/</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 1024</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> /</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 1024</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> /</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 1024</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">        print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Max memory allocated: </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">max_memory</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">:.3f</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> GB&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> all_prompt_embeds, all_pooled_prompt_embeds, all_text_ids</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> run</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">args</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        dataset </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> load_dataset</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Norod78/Yarn-art-style&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">split</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;train&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        image_prompts </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> {</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">generate_image_hash</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(sample[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;image&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]): sample[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;text&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> sample </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> dataset}</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        all_prompts </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> list</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(image_prompts.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">values</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">())</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">        print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">len</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(all_prompts)</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        pipeline </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> load_flux_dev_pipeline</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        all_prompt_embeds, all_pooled_prompt_embeds, all_text_ids </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> compute_embeddings</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                pipeline, all_prompts, args.max_sequence_length</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        )</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        data </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> []</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> i, (image_hash, _) </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> enumerate</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(image_prompts.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">items</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()):</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                data.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">((image_hash, all_prompt_embeds[i], all_pooled_prompt_embeds[i], all_text_ids[i]))</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">        print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">len</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(data)</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # Create a DataFrame</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        embedding_cols </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;prompt_embeds&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;pooled_prompt_embeds&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;text_ids&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        df </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pd.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">DataFrame</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(data, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">columns</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;image_hash&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> embedding_cols)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">        print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">len</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(df)</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # Convert embedding lists to arrays (for proper storage in parquet)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> col </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> embedding_cols:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                df[col] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> df[col].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">apply</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">lambda</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> x</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: x.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">cpu</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">().</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">numpy</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">().</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">flatten</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">().</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">tolist</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">())</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # Save the dataframe to a parquet file</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        df.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">to_parquet</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(args.output_path)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">        print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Data successfully serialized to </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">args.output_path</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> __name__</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> ==</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;__main__&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        parser </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> argparse.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">ArgumentParser</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        parser.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">add_argument</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">                &quot;--max_sequence_length&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">                type</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">int</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">                default</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">MAX_SEQ_LENGTH</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">                help</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Maximum sequence length to use for computing the embeddings. The more the higher computational costs.&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        )</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        parser.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">add_argument</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;--output_path&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">type</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">str</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">default</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">OUTPUT_PATH</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">help</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Path to serialize the parquet file.&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        args </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> parser.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">parse_args</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">        run</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(args)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><h3 id="how-to-use-it" tabindex="-1"><a class="header-anchor" href="#how-to-use-it"><span>How to use it</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">python</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> compute_embeddings.py</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --max_sequence_length</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 77</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --output_path</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> embeddings_alphonse_mucha.parquet</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>By combining this with cached VAE latents (<code>--cache_latents</code>) you whittle the active model down to just the quantized transformer + LoRA adapters, keeping the whole fine-tune comfortably under 10 GB of GPU memory.</p><h3 id="setup-results" tabindex="-1"><a class="header-anchor" href="#setup-results"><span>Setup &amp; Results</span></a></h3><p>For this demonstration, we leveraged an NVIDIA RTX 4090 (24GB VRAM) to explore its performance. The full training command using <code>accelerate</code> is shown below.</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># You need to pre-compute the text embeddings first. See the diffusers repo.</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># https://github.com/huggingface/diffusers/tree/main/examples/research_projects/flux_lora_quantization</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">accelerate</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> launch</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --config_file=accelerate.yaml</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    train_dreambooth_lora_flux_miniature.py</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --pretrained_model_name_or_path=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;black-forest-labs/FLUX.1-dev&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --data_df_path=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;embeddings_alphonse_mucha.parquet&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --output_dir=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;alphonse_mucha_lora_flux_nf4&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --mixed_precision=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;bf16&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --use_8bit_adam</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --weighting_scheme=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;none&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --width=512</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --height=768</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --train_batch_size=1</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --repeats=1</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --learning_rate=1e-4</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --guidance_scale=1</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --report_to=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;wandb&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --gradient_accumulation_steps=4</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --gradient_checkpointing</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \ </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">#</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> can</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> drop</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> checkpointing</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> when</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> HW</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> has</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> more</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> than</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 16</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> GB.</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">    --lr_scheduler</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;constant&quot;</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --lr_warmup_steps=0</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --cache_latents</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --rank=4</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --max_train_steps=700</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --seed=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;0&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Configuration for RTX 4090:</strong> On our RTX 4090, we used a <code>train_batch_size</code> of 1, <code>gradient_accumulation_steps</code> of 4, <code>mixed_precision=&quot;bf16&quot;</code>, <code>gradient_checkpointing=True</code>, <code>use_8bit_adam=True</code>, a LoRA <code>rank</code> of 4, and resolution of 512x768. Latents were cached with <code>cache_latents=True</code>.</p><p><strong>Memory Footprint (RTX 4090):</strong></p><ul><li><strong>QLoRA:</strong> Peak VRAM usage for QLoRA fine-tuning was approximately 9GB.</li><li><strong>BF16 LoRA:</strong> Running standard LoRA (with the base FLUX.1-dev in FP16) on the same setup consumed 26 GB VRAM.</li><li><strong>BF16 full finetuning:</strong> An estimate would be ~120 GB VRAM with no memory optimizations.</li></ul><p><strong>Training Time (RTX 4090):</strong> Fine-tuning for 700 steps on the Alphonse Mucha dataset took approximately 41 minutes on the RTX 4090 with <code>train_batch_size</code> of 1 and resolution of 512x768.</p><p><strong>Output Quality:</strong> The ultimate measure is the generated art. Here are samples from our QLoRA fine-tuned model on the <a href="https://huggingface.co/datasets/derekl35/alphonse-mucha-style" target="_blank" rel="noopener noreferrer">derekl35/alphonse-mucha-style</a> dataset:</p><p>This table compares the primary <code>bf16</code> precision results. The goal of the fine-tuning was to teach the model the distinct style of Alphonse Mucha.</p><table><thead><tr><th>Prompt</th><th>Base Model Output</th><th>QLoRA Fine-tuned Output (Mucha Style)</th></tr></thead><tbody><tr><td><em>&quot;Serene raven-haired woman, moonlit lilies, swirling botanicals, alphonse mucha style&quot;</em></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base2_bf16.png" alt="Base model output for the first prompt" loading="lazy"></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged2_qlora_bf16.png" alt="QLoRA model output for the first prompt" loading="lazy"></td></tr><tr><td><em>&quot;a puppy in a pond, alphonse mucha style&quot;</em></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base3_bf16.png" alt="Base model output for the second prompt" loading="lazy"></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged3_qlora_bf16.png" alt="QLoRA model output for the second prompt" loading="lazy"></td></tr><tr><td><em>&quot;Ornate fox with a collar of autumn leaves and berries, amidst a tapestry of forest foliage, alphonse mucha style&quot;</em></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base5_bf16.png" alt="Base model output for the third prompt" loading="lazy"></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged5_qlora_bf16.png" alt="QLoRA model output for the third prompt" loading="lazy"></td></tr></tbody></table><p>The fine-tuned model nicely captured Mucha&#39;s iconic art nouveau style, evident in the decorative motifs and distinct color palette. The QLoRA process maintained excellent fidelity while learning the new style.</p><details class="hint-container details"><summary>fp16 comparison</summary><p>The results are nearly identical, showing that QLoRA performs effectively with both <code>fp16</code> and <code>bf16</code> mixed precision.</p><h3 id="model-comparison-base-vs-qlora-fine-tuned-fp16" tabindex="-1"><a class="header-anchor" href="#model-comparison-base-vs-qlora-fine-tuned-fp16"><span>Model Comparison: Base vs. QLoRA Fine-tuned (fp16)</span></a></h3><table><thead><tr><th>Prompt</th><th>Base Model Output</th><th>QLoRA Fine-tuned Output (Mucha Style)</th></tr></thead><tbody><tr><td><em>&quot;Serene raven-haired woman, moonlit lilies, swirling botanicals, alphonse mucha style&quot;</em></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base2.png" alt="Base model output for the first prompt" loading="lazy"></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged2.png" alt="QLoRA model output for the first prompt" loading="lazy"></td></tr><tr><td><em>&quot;a puppy in a pond, alphonse mucha style&quot;</em></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base3.png" alt="Base model output for the second prompt" loading="lazy"></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged3.png" alt="QLoRA model output for the second prompt" loading="lazy"></td></tr><tr><td><em>&quot;Ornate fox with a collar of autumn leaves and berries, amidst a tapestry of forest foliage, alphonse mucha style&quot;</em></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_base5.png" alt="Base model output for the third prompt" loading="lazy"></td><td><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_merged5.png" alt="QLoRA model output for the third prompt" loading="lazy"></td></tr></tbody></table></details><h2 id="fp8-fine-tuning-with-torchao" tabindex="-1"><a class="header-anchor" href="#fp8-fine-tuning-with-torchao"><span>FP8 Fine-tuning with <code>torchao</code></span></a></h2><p>For users with NVIDIA GPUs possessing compute capability 8.9 or greater (such as the H100, RTX 4090), even greater speed efficiencies can be achieved by leveraging FP8 training via the <code>torchao</code> library.</p><p>We fine-tuned FLUX.1-dev LoRA on an H100 SXM GPU slightly modified <a href="https://github.com/sayakpaul/diffusers-torchao/" target="_blank" rel="noopener noreferrer"><code>diffusers-torchao</code></a> <a href="https://gist.github.com/sayakpaul/f0358dd4f4bcedf14211eba5704df25a#file-train_dreambooth_lora_flux-py" target="_blank" rel="noopener noreferrer">training scripts</a>. The following command was used:</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">accelerate</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> launch</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> train_dreambooth_lora_flux.py</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --pretrained_model_name_or_path=black-forest-labs/FLUX.1-dev</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --dataset_name=derekl35/alphonse-mucha-style</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --instance_prompt=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;a woman, alphonse mucha style&quot;</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --caption_column=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;text&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --output_dir=alphonse_mucha_fp8_lora_flux</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --mixed_precision=bf16</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --use_8bit_adam</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --weighting_scheme=none</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --height=768</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --width=512</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --train_batch_size=1</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --repeats=1</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --learning_rate=1e-4</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --guidance_scale=1</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --report_to=wandb</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --gradient_accumulation_steps=1</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --gradient_checkpointing</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --lr_scheduler=constant</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --lr_warmup_steps=0</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --rank=4</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --max_train_steps=700</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --checkpointing_steps=600</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --seed=0</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --do_fp8_training</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --push_to_hub</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>The training run had a <strong>peak memory usage of 36.57 GB</strong> and completed in approximately <strong>20 minutes</strong>.</p><p>Qualitative results from this FP8 fine-tuned model are also available:</p><figure><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/quantization-backends-diffusers2/alphonse_mucha_fp8_combined.png" alt="FP8 model outputs" tabindex="0" loading="lazy"><figcaption>FP8 model outputs</figcaption></figure><p>Key steps to enable FP8 training with <code>torchao</code> involve:</p><ol><li><strong>Injecting FP8 layers</strong> into the model using <code>convert_to_float8_training</code> from <code>torchao.float8</code>.</li><li><strong>Defining a <code>module_filter_fn</code></strong> to specify which modules should and should not be converted to FP8.</li></ol><p>For a more detailed guide and code snippets, please refer to <a href="https://gist.github.com/sayakpaul/f0358dd4f4bcedf14211eba5704df25a" target="_blank" rel="noopener noreferrer">this gist</a> and the <a href="https://github.com/sayakpaul/diffusers-torchao/tree/main/training" target="_blank" rel="noopener noreferrer"><code>diffusers-torchao</code> repository</a>.</p><h2 id="inference-with-trained-lora-adapters" tabindex="-1"><a class="header-anchor" href="#inference-with-trained-lora-adapters"><span>Inference with Trained LoRA Adapters</span></a></h2><p>After training your <a href="https://huggingface.co/collections/derekl35/flux-qlora-68527afe2c0ca7bc82a6d8d9" target="_blank" rel="noopener noreferrer">LoRA adapters</a>, you have two main approaches for inference.</p><h3 id="option-1-loading-lora-adapters" tabindex="-1"><a class="header-anchor" href="#option-1-loading-lora-adapters"><span>Option 1: Loading LoRA Adapters</span></a></h3><p>One approach is to <a href="https://huggingface.co/docs/diffusers/v0.33.1/en/using-diffusers/loading_adapters#lora" target="_blank" rel="noopener noreferrer">load your trained LoRA adapters</a> on top of the base model.</p><p><strong>Benefits of Loading LoRA:</strong></p><ul><li><strong>Flexibility:</strong> Easily switch between different LoRA adapters without reloading the base model</li><li><strong>Experimentation:</strong> Test multiple artistic styles or concepts by swapping adapters</li><li><strong>Modularity:</strong> Combine multiple LoRA adapters using <code>set_adapters()</code> for creative blending</li><li><strong>Storage efficiency:</strong> Keep a single base model and multiple small adapter files</li></ul><details class="hint-container details"><summary>Code</summary><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> diffusers </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxPipeline, FluxTransformer2DModel, BitsAndBytesConfig</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch </span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">ckpt_id </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;black-forest-labs/FLUX.1-dev&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxPipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        ckpt_id, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">torch_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.float16</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">load_lora_weights</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;derekl35/alphonse_mucha_qlora_flux&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">weight_name</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;pytorch_lora_weights.safetensors&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">enable_model_cpu_offload</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> pipeline</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;a puppy in a pond, alphonse mucha style&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">num_inference_steps</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">28</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">guidance_scale</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">3.5</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">height</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">768</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">width</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">512</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">generator</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">manual_seed</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">).images[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">save</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;alphonse_mucha.png&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><h3 id="option-2-merging-lora-into-base-model" tabindex="-1"><a class="header-anchor" href="#option-2-merging-lora-into-base-model"><span>Option 2: Merging LoRA into Base Model</span></a></h3><p>For when you want maximum efficiency with a single style, you can <a href="https://huggingface.co/docs/diffusers/using-diffusers/merge_loras" target="_blank" rel="noopener noreferrer">merge the LoRA weights</a> into the base model.</p><p><strong>Benefits of Merging LoRA:</strong></p><ul><li><strong>VRAM efficiency:</strong> No additional memory overhead from adapter weights during inference</li><li><strong>Speed:</strong> Slightly faster inference as there&#39;s no need to apply adapter computations</li><li><strong>Quantization compatibility:</strong> Can re-quantize the merged model for maximum memory efficiency</li></ul><details class="hint-container details"><summary>Code</summary><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> diffusers </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxPipeline, AutoPipelineForText2Image, FluxTransformer2DModel, BitsAndBytesConfig</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch </span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">ckpt_id </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;black-forest-labs/FLUX.1-dev&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxPipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        ckpt_id, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">text_encoder</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">text_encoder_2</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">torch_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.float16</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">load_lora_weights</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;derekl35/alphonse_mucha_qlora_flux&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">weight_name</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;pytorch_lora_weights.safetensors&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">fuse_lora</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">unload_lora_weights</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline.transformer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">save_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;fused_transformer&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bnb_4bit_compute_dtype </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.bfloat16</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">nf4_config </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> BitsAndBytesConfig</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        load_in_4bit</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        bnb_4bit_quant_type</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;nf4&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        bnb_4bit_compute_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bnb_4bit_compute_dtype,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FluxTransformer2DModel.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;fused_transformer&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        quantization_config</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">nf4_config,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        torch_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bnb_4bit_compute_dtype,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> AutoPipelineForText2Image.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        ckpt_id, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">transformer</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">transformer, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">torch_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bnb_4bit_compute_dtype</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">enable_model_cpu_offload</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> pipeline</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;a puppy in a pond, alphonse mucha style&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">num_inference_steps</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">28</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">guidance_scale</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">3.5</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">height</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">768</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">width</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">512</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">generator</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">manual_seed</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">).images[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">save</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;alphonse_mucha_merged.png&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><h2 id="running-on-google-colab" tabindex="-1"><a class="header-anchor" href="#running-on-google-colab"><span>Running on Google Colab</span></a></h2><p>While we showcased results on an RTX 4090, the same code can be run on more accessible hardware like the T4 GPU available in <a href="https://colab.research.google.com/github/DerekLiu35/notebooks/blob/main/flux_lora_quant_blogpost.ipynb" target="_blank" rel="noopener noreferrer">Google Colab</a> for free.</p><p>On a T4, you can expect the fine-tuning process to take significantly longer around 4 hours for the same number of steps. This is a trade-off for accessibility, but it makes custom fine-tuning possible without high-end hardware. Be mindful of usage limits if running on Colab, as a 4-hour training run might push them.</p><h2 id="conclusion" tabindex="-1"><a class="header-anchor" href="#conclusion"><span>Conclusion</span></a></h2><p>QLoRA, coupled with the <code>diffusers</code> library, significantly democratizes the ability to customize state-of-the-art models like FLUX.1-dev. As demonstrated on an RTX 4090, efficient fine-tuning is well within reach, yielding high-quality stylistic adaptations. Furthermore, for users with the latest NVIDIA hardware, <code>torchao</code> enables even faster training through FP8 precision.</p><h3 id="share-your-creations-on-the-hub" tabindex="-1"><a class="header-anchor" href="#share-your-creations-on-the-hub"><span>Share your creations on the Hub!</span></a></h3><p>Sharing your fine-tuned LoRA adapters is a fantastic way to contribute to the open-source community. It allows others to easily try out your styles, build on your work, and helps create a vibrant ecosystem of creative AI tools.</p><p>If you&#39;ve trained a LoRA for FLUX.1-dev, we encourage you to <a href="https://huggingface.co/docs/transformers/en/model_sharing" target="_blank" rel="noopener noreferrer">share</a> it. The easiest way is to add the <code>--push_to_hub</code> flag to the training script. Alternatively, if you have already trained a model and want to upload it, you can use the following snippet.</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Prereqs:</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># - pip install huggingface_hub diffusers</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># - Run `huggingface-cli login` (or set HF_TOKEN env-var) once.</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># - save model</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> huggingface_hub </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> create_repo, upload_folder</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">repo_id </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;your-username/alphonse_mucha_qlora_flux&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">create_repo</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(repo_id, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">exist_ok</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">upload_folder</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        repo_id</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">repo_id,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        folder_path</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;alphonse_mucha_qlora_flux&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        commit_message</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;Add Alphonse Mucha LoRA adapter&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Check out our Mucha QLoRA <a href="https://huggingface.co/derekl35/alphonse_mucha_qlora_flux" target="_blank" rel="noopener noreferrer">https://huggingface.co/derekl35/alphonse_mucha_qlora_flux</a> FP8 LoRA <a href="https://huggingface.co/derekl35/alphonse_mucha_fp8_lora_flux" target="_blank" rel="noopener noreferrer">https://huggingface.co/derekl35/alphonse_mucha_fp8_lora_flux</a>. You can find both, plus other adapters, in <a href="https://huggingface.co/collections/derekl35/flux-qlora-68527afe2c0ca7bc82a6d8d9" target="_blank" rel="noopener noreferrer">this collection</a> as an example.</p><p>We can&#39;t wait to see what you create!</p></div><!--[--><div class="theme-hope-content"><Share colorful services="email,facebook,line,linkedin,messenger,qrcode,reddit,telegram,twitter"></Share></div><!--]--><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/vuepress-theme-hope/vuepress-theme-hope/edit/main/src/posts/reprints/flux-qlora.md" aria-label="Edit this page on GitHub" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page on GitHub<!----></a></div><div class="vp-meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/posts/reprints/niji-study-2-notan.html" aria-label="Study 2: Notan"><div class="hint"><span class="arrow start"></span>Prev</div><div class="link"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="contrast" width="1em" height="1em"></iconify-icon>Study 2: Notan</div></a><a class="route-link auto-link next" href="/posts/reprints/model-block-merge-1.html" aria-label="[Experiment Report] Investigating the Influence of Each U-Net Layer with Model Block Merge #1"><div class="hint">Next<span class="arrow end"></span></div><div class="link">[Experiment Report] Investigating the Influence of Each U-Net Layer with Model Block Merge #1<!----></div></a></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">My own footer</div><div class="vp-copyright">Copyright © 2025 Derek Liu, Marc Sun, Sayak Paul, merve, Linoy Tsaban </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script src="/assets/js/runtime~app.6e2a4ebc.js" defer></script><script src="/assets/js/9156.1c509bd1.js" defer></script><script src="/assets/js/app.d13efba1.js" defer></script>
  </body>
</html>
