<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.17" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.58" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="alternate" hreflang="zh-cn" href="https://neverbiasu.github.io/zh/posts/reprints/ai-art-newsletter-jan-25.html"><meta property="og:url" content="https://neverbiasu.github.io/posts/reprints/ai-art-newsletter-jan-25.html"><meta property="og:site_name" content="Nlog"><meta property="og:title" content="The AI tools for Art Newsletter - Issue 1"><meta property="og:description" content="The AI tools for Art Newsletter First issue 🎉 The AI space is moving so fast it’s hard to believe that a year ago we still struggled to generate people with the correct amount ..."><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="og:locale:alternate" content="zh-CN"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"The AI tools for Art Newsletter - Issue 1","image":[""],"dateModified":null,"author":[{"@type":"Person","name":"neverbiasu","url":"https://neverbiasu.github.io"}]}</script><title>The AI tools for Art Newsletter - Issue 1 | Nlog</title><meta name="description" content="The AI tools for Art Newsletter First issue 🎉 The AI space is moving so fast it’s hard to believe that a year ago we still struggled to generate people with the correct amount ...">
    <link rel="stylesheet" href="/assets/css/styles.580a8cdb.css">
    <link rel="preload" href="/assets/js/runtime~app.f513dbfa.js" as="script"><link rel="preload" href="/assets/css/styles.580a8cdb.css" as="style"><link rel="preload" href="/assets/js/9156.1c509bd1.js" as="script"><link rel="preload" href="/assets/js/app.87cd2552.js" as="script">
    <link rel="prefetch" href="/assets/js/zh_posts_reprints_crody's-model-merge-guide.html.aefbc33c.js" as="script"><link rel="prefetch" href="/assets/js/8300.f7204200.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_crody's-model-merge-guide.html.4636131a.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html.cd48e1e0.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html.24770636.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_what-is-block-merging.html.b7213272.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_X01.html.286d0b31.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_papers_workflow.html.49e6983b.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language.html.3bcbd621.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language.html.a432458f.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-impls_yolov9.html.d931746c.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_model-block-merge-1.html.bc9e83d9.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_ai-art-newsletter-jan-25.html.c7b97d73.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_006.html.f7f5f2c6.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_model-block-merge-2.html.016b931c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_sdo.html.62c55f45.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_resnet.html.7b4e6365.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_ai-art-newsletter-jan-25.html.85db2310.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything.html.ca66e748.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_014.html.2d20c099.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_niji-lesson-2-the-terminator-line.html.bd75f443.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_niji-study-1-measuring-with-your-eyes.html.a3d0b79a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything.html.4429ddf0.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_001.html.0cc7a3f6.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_markdown.html.cd727a63.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_colorizediffusion.html.f284135a.js" as="script"><link rel="prefetch" href="/assets/js/demo_markdown.html.a2be59df.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_niji-study-1-measuring-with-your-eyes.html.5a4b359a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_hunyuancustom.html.82f3d6e0.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_dairys_250222.html.06c69a55.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_037.html.a0b49644.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_033.html.9773d8f4.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_031.html.20a0624c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_icedit.html.03d6a980.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_032.html.4735e8c8.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_026.html.5614a949.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_transformer.html.12cd3945.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_alexnet.html.14b2d7ef.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_009.html.2102d264.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_022.html.b9e7e9e2.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_030.html.c43bd7aa.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_011.html.339c9ade.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_029.html.08338fe9.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_reptext.html.50a57560.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_generative-ai-powered-design.html.1a5d9075.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_034.html.cf0e405c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_036.html.17b68198.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_015.html.473e83a6.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_thoughts_platform-operation-thoughts-after-comfycon.html.e8fcd13a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_035.html.0ea943b3.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_020.html.69998eb7.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_generative-ai-powered-design.html.3852891b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_023.html.35bdf105.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_021.html.6adf8414.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_010.html.cd8e35fa.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_005.html.d52ec160.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_003.html.f31430a4.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_038.html.4fe410af.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_018.html.83564d7d.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_012.html.74ae0f28.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_explaining-tokens-the-language-and-currency-of-ai-nvidia-blog.html.5bbb2226.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_025.html.d33050f6.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_027.html.c1b44168.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_framepack.html.a3a1d6d2.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_028.html.28a9c9d8.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_024.html.afa69a35.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_013.html.209b696d.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_019.html.29dad8a2.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_illustrious-xl-v2.0-the-best-training-base-model-in-1536-age.html.4993a0c3.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_illustrious-xl-v2.0-the-best-training-base-model-in-1536-age.html.c0e6bed7.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_explaining-tokens-the-language-and-currency-of-ai-nvidia-blog.html.0aa02dbe.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_017.html.2a5b34d1.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_niji-lesson-2-the-terminator-line.html.45b8d34a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_niji-study-2-notan.html.eb128aae.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_016.html.ac9b960d.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_mcp-flash-in-the-pan-or-future-standard.html.7c4badd8.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_papers_checklist.html.8f0482a5.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_008.html.a7a36e1a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_002.html.e37efe48.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_mcp-flash-in-the-pan-or-future-standard.html.e460a1b6.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_004.html.f951a958.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_007.html.4a8c44de.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_niji-study-2-notan.html.6fbe1bc6.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_3steps-paper-reading.html.8bf7271e.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_dairys_250223.html.9b6f0008.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_experiments-with-mcp-using-github-copilot.html.325b729e.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_experimenting-with-mcp-using-github-copilot.html.d38eb7ba.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_illustrious-lu-v0.03.html.ba118f41.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_illustrious-lu-v0.03.html.ca077711.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_templates_papers.html.0ccf0b60.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_page.html.753e4b79.js" as="script"><link rel="prefetch" href="/assets/js/demo_page.html.4afa3f13.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_layout.html.9b825e86.js" as="script"><link rel="prefetch" href="/assets/js/demo_layout.html.187c1daf.js" as="script"><link rel="prefetch" href="/assets/js/zh_home.html.e9a86969.js" as="script"><link rel="prefetch" href="/assets/js/home.html.4ab09a81.js" as="script"><link rel="prefetch" href="/assets/js/demo_disable.html.307ed297.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_disable.html.145db3b1.js" as="script"><link rel="prefetch" href="/assets/js/zh_intro.html.7fb5a873.js" as="script"><link rel="prefetch" href="/assets/js/intro.html.eb684c35.js" as="script"><link rel="prefetch" href="/assets/js/zh_index.html.9a2f7b2a.js" as="script"><link rel="prefetch" href="/assets/js/index.html.dcce0346.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_web_vue-1.html.8aac8c61.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_index.html.bc7f02c8.js" as="script"><link rel="prefetch" href="/assets/js/demo_encrypt.html.cdc9232a.js" as="script"><link rel="prefetch" href="/assets/js/zh_demo_encrypt.html.78570576.js" as="script"><link rel="prefetch" href="/assets/js/tag_artificial-intelligence_index.html.927c4c09.js" as="script"><link rel="prefetch" href="/assets/js/demo_index.html.575191b4.js" as="script"><link rel="prefetch" href="/assets/js/category_model-development_index.html.3da09488.js" as="script"><link rel="prefetch" href="/assets/js/category_image-generation_index.html.a0244739.js" as="script"><link rel="prefetch" href="/assets/js/category_model-training_index.html.773cd11f.js" as="script"><link rel="prefetch" href="/assets/js/category_generative-ai_index.html.f810f2bc.js" as="script"><link rel="prefetch" href="/assets/js/tag_stable-diffusion_index.html.269405a2.js" as="script"><link rel="prefetch" href="/assets/js/category_anime-style_index.html.779b209a.js" as="script"><link rel="prefetch" href="/assets/js/tag_amazon-bedrock_index.html.125e13f3.js" as="script"><link rel="prefetch" href="/assets/js/tag_resource-guide_index.html.cb34dfda.js" as="script"><link rel="prefetch" href="/assets/js/category_explainer_index.html.f69576cd.js" as="script"><link rel="prefetch" href="/assets/js/category_reprints_index.html.6f6748ac.js" as="script"><link rel="prefetch" href="/assets/js/tag_fundamentals_index.html.353f6f8d.js" as="script"><link rel="prefetch" href="/assets/js/category_reprint_index.html.4ba60ec9.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_模型上下文协议_index.html.c186d81e.js" as="script"><link rel="prefetch" href="/assets/js/tag_illustrious_index.html.24eaa8ac.js" as="script"><link rel="prefetch" href="/assets/js/tag_inference_index.html.1f67f1a3.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_阿里巴巴ai研究_index.html.d7071405.js" as="script"><link rel="prefetch" href="/assets/js/tag_markdown_index.html.47f7c0f3.js" as="script"><link rel="prefetch" href="/assets/js/tag_drawing_index.html.40625043.js" as="script"><link rel="prefetch" href="/assets/js/tag_lumina_index.html.5ec1f6bc.js" as="script"><link rel="prefetch" href="/assets/js/tag_script_index.html.eee43662.js" as="script"><link rel="prefetch" href="/assets/js/tag_merge_index.html.12b59286.js" as="script"><link rel="prefetch" href="/assets/js/tag_model_index.html.d570405d.js" as="script"><link rel="prefetch" href="/assets/js/tag_vpred_index.html.a2942809.js" as="script"><link rel="prefetch" href="/assets/js/tag_notan_index.html.59254a97.js" as="script"><link rel="prefetch" href="/assets/js/tag_qwen3_index.html.5251c172.js" as="script"><link rel="prefetch" href="/assets/js/tag_llms_index.html.58fbb4d3.js" as="script"><link rel="prefetch" href="/assets/js/tag_niji_index.html.b6eb0af8.js" as="script"><link rel="prefetch" href="/assets/js/tag_qwen_index.html.8945a482.js" as="script"><link rel="prefetch" href="/assets/js/tag_sdxl_index.html.5ec0a972.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_大语言模型_index.html.0985c237.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_输入预处理_index.html.1bd558db.js" as="script"><link rel="prefetch" href="/assets/js/tag_aws_index.html.b4d7afb9.js" as="script"><link rel="prefetch" href="/assets/js/tag_llm_index.html.ba8b8540.js" as="script"><link rel="prefetch" href="/assets/js/tag_mcp_index.html.0b743712.js" as="script"><link rel="prefetch" href="/assets/js/tag_art_index.html.75469b85.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_artificial-intelligence_index.html.dfe2c298.js" as="script"><link rel="prefetch" href="/assets/js/category_index.html.54ad007c.js" as="script"><link rel="prefetch" href="/assets/js/tag_ai_index.html.af826e6e.js" as="script"><link rel="prefetch" href="/assets/js/tag_lu_index.html.51f46455.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_llm基准测试_index.html.26bed0dc.js" as="script"><link rel="prefetch" href="/assets/js/timeline_index.html.a7e9a4ac.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_阿里巴巴ai_index.html.f22a6121.js" as="script"><link rel="prefetch" href="/assets/js/article_index.html.630a4265.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_使用指南_index.html.5fc02901.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_图像生成_index.html.e38fbeeb.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_模型开发_index.html.1f86a4b0.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_模型研发_index.html.712a913a.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_模型训练_index.html.3443e619.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_论文精读_index.html.4800887c.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_动漫风格_index.html.df7360be.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_视频生成_index.html.3529cab5.js" as="script"><link rel="prefetch" href="/assets/js/tag_model-context-protocol_index.html.22b04bcf.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_index.html.613896db.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_使用指南_index.html.0bc7a168.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_反向传播_index.html.e994d29c.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_可控生成_index.html.aecf1f90.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_图像生成_index.html.959d833d.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_基础模型_index.html.9e240645.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_扩散模型_index.html.4df40bd3.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_游戏开发_index.html.b9257580.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_艺术课程_index.html.4b0cb0f8.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_视频生成_index.html.70b080c0.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_计算优化_index.html.2b9642da.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_页面配置_index.html.16ae4ec1.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_model-development_index.html.551b8d6f.js" as="script"><link rel="prefetch" href="/assets/js/tag_large-language-models_index.html.4c95ebe9.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_2048分辨率_index.html.4e58d376.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_image-generation_index.html.103cfe8f.js" as="script"><link rel="prefetch" href="/assets/js/star_index.html.19e783c3.js" as="script"><link rel="prefetch" href="/assets/js/tag_index.html.4cc57efe.js" as="script"><link rel="prefetch" href="/assets/js/tag_alibaba-ai-research_index.html.00f00478.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_epsilon预测_index.html.e3eff795.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_多模态ai_index.html.df0cad52.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_生成式ai_index.html.6cc3f904.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_stable-diffusion_index.html.eaaa74c2.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_多语言ai_index.html.39f84815.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_张吕敏_index.html.73238c82.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_model-training_index.html.0f7c5965.js" as="script"><link rel="prefetch" href="/assets/js/tag_epsilon-prediction_index.html.fef56f9a.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_generative-ai_index.html.fb0a6a42.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_公众号_index.html.8c195c50.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_编辑器_index.html.d360ec0e.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_amazon-bedrock_index.html.a61f7bc1.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_resource-guide_index.html.d04068e6.js" as="script"><link rel="prefetch" href="/assets/js/posts_index.html.3871cd02.js" as="script"><link rel="prefetch" href="/assets/js/tag_game-development_index.html.5d76e207.js" as="script"><link rel="prefetch" href="/assets/js/tag_image-generation_index.html.4dbf55db.js" as="script"><link rel="prefetch" href="/assets/js/tag_visual-hierarchy_index.html.2ac2527d.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_anime-style_index.html.e17873b0.js" as="script"><link rel="prefetch" href="/assets/js/tag_multilingual-ai_index.html.4c0272be.js" as="script"><link rel="prefetch" href="/assets/js/tag_stablediffusion_index.html.124c4414.js" as="script"><link rel="prefetch" href="/assets/js/tag_2048-resolution_index.html.ddffe0fa.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_fundamentals_index.html.9ee110b4.js" as="script"><link rel="prefetch" href="/assets/js/tag_llm-benchmarks_index.html.edfcf784.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_ai推理_index.html.4e222fc2.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_ai模型_index.html.0a8848fa.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_思考_index.html.4ebe0236.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_指南_index.html.bfeb79d9.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_日记_index.html.efc2811d.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_论文_index.html.5d587199.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_illustrious_index.html.20f3cc22.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_转载_index.html.9060c529.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_explainer_index.html.c33e9c28.js" as="script"><link rel="prefetch" href="/assets/js/tag_automatic1111_index.html.c12c3b66.js" as="script"><link rel="prefetch" href="/assets/js/tag_generative-ai_index.html.b752db09.js" as="script"><link rel="prefetch" href="/assets/js/tag_multimodal-ai_index.html.7ee6dcf5.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_reprints_index.html.660fbfd8.js" as="script"><link rel="prefetch" href="/assets/js/tag_ai-reasoning_index.html.77c62597.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_做饭_index.html.7c41eda4.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_创新_index.html.9cae2002.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_加密_index.html.8841eca0.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_协议_index.html.1970640f.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_大会_index.html.983cb142.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_平台_index.html.83a347da.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_开源_index.html.a2a77231.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_禁用_index.html.ce0a1fc8.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_训练_index.html.24e9bebe.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_运营_index.html.0a50b8f3.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_随想_index.html.ba47ca1a.js" as="script"><link rel="prefetch" href="/assets/js/tag_modelmerging_index.html.df0addc2.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_内容_index.html.89c6d892.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_动漫_index.html.4f609ad2.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_实习_index.html.dddaf71b.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_布局_index.html.5eecea6f.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_技术_index.html.f82d9c56.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_辩论_index.html.f65b3f2b.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_framepack_index.html.07dd623f.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_inference_index.html.778fb37a.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_reprint_index.html.b5f70076.js" as="script"><link rel="prefetch" href="/assets/js/tag_page-config_index.html.8d808e62.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_markdown_index.html.a1350b1c.js" as="script"><link rel="prefetch" href="/assets/js/category_papers_index.html.59f03152.js" as="script"><link rel="prefetch" href="/assets/js/tag_alibaba-ai_index.html.894b0a99.js" as="script"><link rel="prefetch" href="/assets/js/tag_art-lesson_index.html.b618c196.js" as="script"><link rel="prefetch" href="/assets/js/tag_base-model_index.html.c5b58cfb.js" as="script"><link rel="prefetch" href="/assets/js/tag_encryption_index.html.da016b00.js" as="script"><link rel="prefetch" href="/assets/js/tag_modelmerge_index.html.3d0402bf.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_drawing_index.html.dd6e272d.js" as="script"><link rel="prefetch" href="/assets/js/category_guide_index.html.b09fdbff.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_lumina_index.html.68c8b23b.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_script_index.html.e8d6f354.js" as="script"><link rel="prefetch" href="/assets/js/tag_ai-model_index.html.3172a9f6.js" as="script"><link rel="prefetch" href="/assets/js/tag_protocol_index.html.b00c0ab4.js" as="script"><link rel="prefetch" href="/assets/js/tag_training_index.html.d26c09d7.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_merge_index.html.bca3eb67.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_model_index.html.47c13d2c.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_notan_index.html.1c3f1573.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_qwen3_index.html.eb7ea33b.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_vpred_index.html.c67540a3.js" as="script"><link rel="prefetch" href="/assets/js/tag_disable_index.html.8c6e701e.js" as="script"><link rel="prefetch" href="/assets/js/posts_reprints_model-block-merge.html.0c3ac379.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_llms_index.html.ac9f4e69.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_niji_index.html.c55ad797.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_qwen_index.html.3518548c.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_sdxl_index.html.9d98c972.js" as="script"><link rel="prefetch" href="/assets/js/404.html.7aed0954.js" as="script"><link rel="prefetch" href="/assets/js/tag_debate_index.html.c7d3c227.js" as="script"><link rel="prefetch" href="/assets/js/tag_layout_index.html.bcdc80c4.js" as="script"><link rel="prefetch" href="/assets/js/tag_editor_index.html.b22bc8a3.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_art_index.html.9768d361.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_aws_index.html.06e8caf8.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_llm_index.html.b638107a.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_sdo_index.html.a88c4c12.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_mcp_index.html.7ae31099.js" as="script"><link rel="prefetch" href="/assets/js/tag_anime_index.html.15a54200.js" as="script"><link rel="prefetch" href="/assets/js/tag_guide_index.html.91bb56f9.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_lu_index.html.09d9476c.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_ai_index.html.5ab5815f.js" as="script"><link rel="prefetch" href="/assets/js/tag_tech_index.html.d2ce09af.js" as="script"><link rel="prefetch" href="/assets/js/zh_timeline_index.html.817ad8b0.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_index.html.f54b4216.js" as="script"><link rel="prefetch" href="/assets/js/zh_article_index.html.c1ccddf0.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_papers_index.html.ed8f1f15.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_templates_index.html.57f3fb88.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_workflows_index.html.265e7d02.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-weekly_index.html.88fc57b1.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_index.html.72b75c04.js" as="script"><link rel="prefetch" href="/assets/js/zh_star_index.html.4aa5e606.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_ai-impls_index.html.4907b247.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_reprints_index.html.3fbed4eb.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_thoughts_index.html.85e68346.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_dairys_index.html.0360a596.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_papers_index.html.f669eed4.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_index.html.cf9f0a11.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_web_index.html.6791ec8d.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><!--[--><a class="route-link vp-brand" href="/" aria-label="Take me home"><img class="vp-nav-logo" src="/logo.svg" alt><!----><span class="vp-site-name hide-in-pad">Nlog</span></a><!--]--><!----></div><div class="vp-navbar-center"><!----><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/home.html" aria-label="home"><!---->home<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/demo/" aria-label="Features demo"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="laptop-code" width="1em" height="1em"></iconify-icon><!--]-->Features demo<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Posts"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon>Posts<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Apple</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/apple/1.html" aria-label="Apple1"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->Apple1<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/apple/2.html" aria-label="Apple2"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->Apple2<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/apple/3.html" aria-label="/posts/apple/3.html"><!---->/posts/apple/3.html<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/apple/4.html" aria-label="/posts/apple/4.html"><!---->/posts/apple/4.html<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Banana</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/banana/1.html" aria-label="Banana 1"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->Banana 1<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/banana/2.html" aria-label="Banana 2"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->Banana 2<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/banana/3.html" aria-label="/posts/banana/3.html"><!---->/posts/banana/3.html<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/banana/4.html" aria-label="/posts/banana/4.html"><!---->/posts/banana/4.html<!----></a></li></ul></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/posts/cherry.html" aria-label="Cherry"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->Cherry<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/posts/dragonfruit.html" aria-label="Dragon Fruit"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="pen-to-square" width="1em" height="1em"></iconify-icon><!--]-->Dragon Fruit<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/posts/tomato.html" aria-label="/posts/tomato.html"><!---->/posts/tomato.html<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/posts/strawberry.html" aria-label="/posts/strawberry.html"><!---->/posts/strawberry.html<!----></a></li></ul></button></div></div></nav><!--]--><!----></div><div class="vp-navbar-end"><!----><!--[--><div class="vp-nav-item"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Select language"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon i18n-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="i18n icon" name="i18n" style="width:1rem;height:1rem;vertical-align:middle;"><path d="M379.392 460.8 494.08 575.488l-42.496 102.4L307.2 532.48 138.24 701.44l-71.68-72.704L234.496 460.8l-45.056-45.056c-27.136-27.136-51.2-66.56-66.56-108.544h112.64c7.68 14.336 16.896 27.136 26.112 35.84l45.568 46.08 45.056-45.056C382.976 312.32 409.6 247.808 409.6 204.8H0V102.4h256V0h102.4v102.4h256v102.4H512c0 70.144-37.888 161.28-87.04 210.944L378.88 460.8zM576 870.4 512 1024H409.6l256-614.4H768l256 614.4H921.6l-64-153.6H576zM618.496 768h196.608L716.8 532.48 618.496 768z"></path></svg><!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/posts/reprints/ai-art-newsletter-jan-25.html" aria-label="English"><!---->English<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/zh/posts/reprints/ai-art-newsletter-jan-25.html" aria-label="简体中文"><!---->简体中文<!----></a></li></ul></button></div></div><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/vuepress-theme-hope/vuepress-theme-hope" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--]--><!----><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/" aria-label="Blog Home"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="home" width="1em" height="1em"></iconify-icon><!--]-->Blog Home<!----></a></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header clickable"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="laptop-code" width="1em" height="1em"></iconify-icon><a class="route-link auto-link vp-sidebar-title no-external-link-icon" href="/demo/" aria-label="Demo"><!---->Demo<!----></a><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/demo/layout.html" aria-label="Layout"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="object-group" width="1em" height="1em"></iconify-icon><!--]-->Layout<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/demo/markdown.html" aria-label="Markdown Enhance"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fab fa-markdown" width="1em" height="1em"></iconify-icon><!--]-->Markdown Enhance<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/demo/page.html" aria-label="Page Config"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="file" width="1em" height="1em"></iconify-icon><!--]-->Page Config<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/demo/disable.html" aria-label="Disabling layout and features"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="gears" width="1em" height="1em"></iconify-icon><!--]-->Disabling layout and features<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/demo/encrypt.html" aria-label="Encryption Article"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="lock" width="1em" height="1em"></iconify-icon><!--]-->Encryption Article<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header active"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="book" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Articles</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">Reprints</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/generative-ai-powered-design.html" aria-label="Generative AI-Powered Design: Creating Game Environments with SD3.5 Large"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="openmoji:video-game" width="1em" height="1em"></iconify-icon><!--]-->Generative AI-Powered Design: Creating Game Environments with SD3.5 Large<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/niji-lesson-1-fundamentals-of-measurement-and-abstraction-the-theory-of-how-to-draw-everything.html" aria-label="Lesson 1: Fundamentals of Measurement and Abstraction: The Theory of (How to Draw) Everything"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="palette" width="1em" height="1em"></iconify-icon><!--]-->Lesson 1: Fundamentals of Measurement and Abstraction: The Theory of (How to Draw) Everything<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/mcp-flash-in-the-pan-or-future-standard.html" aria-label="MCP: Flash in the Pan or Future Standard?"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="openmoji:code-editor" width="1em" height="1em"></iconify-icon><!--]-->MCP: Flash in the Pan or Future Standard?<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/niji-lesson-2-the-terminator-line.html" aria-label="Lesson 2: The Terminator (Line)"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="palette" width="1em" height="1em"></iconify-icon><!--]-->Lesson 2: The Terminator (Line)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/niji-study-1-measuring-with-your-eyes.html" aria-label="Study 1: Measuring With Your Eyes"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="ruler" width="1em" height="1em"></iconify-icon><!--]-->Study 1: Measuring With Your Eyes<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/niji-study-2-notan.html" aria-label="Study 2: Notan"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="contrast" width="1em" height="1em"></iconify-icon><!--]-->Study 2: Notan<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/model-block-merge.html" aria-label="/posts/reprints/model-block-merge.html"><!---->/posts/reprints/model-block-merge.html<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/model-block-merge-1.html" aria-label="[Experiment Report] Investigating the Influence of Each U-Net Layer with Model Block Merge #1"><!---->[Experiment Report] Investigating the Influence of Each U-Net Layer with Model Block Merge #1<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/model-block-merge-2.html" aria-label="[Experiment Report] Investigating the Influence of Each U-Net Layer with Model Block Merge #1"><!---->[Experiment Report] Investigating the Influence of Each U-Net Layer with Model Block Merge #1<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/crody&#39;s-model-merge-guide.html" aria-label="Crody&#39;s Model Merge Guide // Team-C"><!---->Crody&#39;s Model Merge Guide // Team-C<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/experimenting-with-mcp-using-github-copilot.html" aria-label="Experimenting with MCP using GitHub Copilot"><!---->Experimenting with MCP using GitHub Copilot<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/explaining-tokens-the-language-and-currency-of-ai-nvidia-blog.html" aria-label="Explaining Tokens — the Language and Currency of AI"><!---->Explaining Tokens — the Language and Currency of AI<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/illustrious-xl-3.0-3.5-vpred-2048-resolution-and-natural-language.html" aria-label="Illustrious XL 3.0-3.5-vpred: 2048 Resolution and Natural Language"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="mdi:paint-outline" width="1em" height="1em"></iconify-icon><!--]-->Illustrious XL 3.0-3.5-vpred: 2048 Resolution and Natural Language<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/illustrious-xl-v2.0-the-best-training-base-model-in-1536-age.html" aria-label="Illustrious XL v2.0—The best training base model in 1536 age"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="mdi:paint-outline" width="1em" height="1em"></iconify-icon><!--]-->Illustrious XL v2.0—The best training base model in 1536 age<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/illustrious-lu-v0.03.html" aria-label="Illustrious-LU v0.03"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:microscope" width="1em" height="1em"></iconify-icon><!--]-->Illustrious-LU v0.03<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html" aria-label="Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 Overview"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:robot" width="1em" height="1em"></iconify-icon><!--]-->Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 Overview<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/posts/reprints/ai-art-newsletter-jan-25.html" aria-label="The AI tools for Art Newsletter - Issue 1"><!---->The AI tools for Art Newsletter - Issue 1<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/reprints/what-is-block-merging.html" aria-label="What is Block Merging?"><!---->What is Block Merging?<!----></a></li></ul></section></li></ul></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/intro.html" aria-label="Intro Page"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="circle-info" width="1em" height="1em"></iconify-icon><!--]-->Intro Page<!----></a></li><li><a class="auto-link external-link vp-sidebar-link" href="https://ecosystem.vuejs.press/plugins/markdown/revealjs/demo.html" aria-label="Slides" rel="noopener noreferrer" target="_blank"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="person-chalkboard" width="1em" height="1em"></iconify-icon><!--]-->Slides<!----></a></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->The AI tools for Art Newsletter - Issue 1</h1><div class="page-info"><span class="page-author-info" aria-label="Author🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://neverbiasu.github.io" target="_blank" rel="noopener noreferrer">neverbiasu</a></span><span property="author" content="neverbiasu"></span></span><!----><!----><!----><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 8 min</span><meta property="timeRequired" content="PT8M"></span><!----><!----></div><hr></div><div class="vp-toc-placeholder"><aside id="toc"><!----><div class="vp-toc-header">On This Page<button type="button" class="print-button" title="Print"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon" name="print"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#first-issue-🎉">First issue 🎉</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#table-of-contents">Table of Contents</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#major-releases-of-2024">Major Releases of 2024</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#image-generation">Image Generation</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#text-to-image-generation">Text-to-image generation</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#personalization-stylization">Personalization &amp; stylization</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#video-generation">Video Generation</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#audio-generation">Audio Generation</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#creative-tools-that-shined-in-2024">Creative Tools that Shined in 2024</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#what-should-we-expect-for-ai-art-in-2025">What should we expect for AI &amp; Art in 2025?</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#starting-off-strong-open-source-releases-of-january-25">Starting off strong - Open source releases of January 25</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#announcing-our-newsletter-🗞️">Announcing Our Newsletter 🗞️</a></li><!----><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!----></aside></div><!----><div class="theme-hope-content" vp-content><h1 id="the-ai-tools-for-art-newsletter" tabindex="-1"><a class="header-anchor" href="#the-ai-tools-for-art-newsletter"><span>The AI tools for Art Newsletter</span></a></h1><h3 id="first-issue-🎉" tabindex="-1"><a class="header-anchor" href="#first-issue-🎉"><span>First issue 🎉</span></a></h3><p>The AI space is moving so fast it’s hard to believe that a year ago we still struggled to generate people with the correct amount of fingers 😂.</p><p>The last couple of years have been pivotal for open source models and tools for artistic usage. AI tools for creative expression have never been more accessible, and we’re only scratching the surface. Join us as we look back at the key milestones, tools, and breakthroughs in AI &amp; Arts from 2024, and forward for what’s to come in 2025.</p><h2 id="table-of-contents" tabindex="-1"><a class="header-anchor" href="#table-of-contents"><span>Table of Contents</span></a></h2><ul><li><a href="#Major-Releases-of-2024">Major Releases of 2024</a></li><li><a href="#Image-Generation">Image Generation</a><ul><li><a href="#Text-to-image-generation">Text-to-image generation</a></li><li><a href="#Personalization-&amp;-stylization">Personalization &amp; stylization </a></li></ul></li><li><a href="#Video-Generation">Video Generation</a></li><li><a href="#Creative-Tools-that-Shined-in-2024">Creative Tools that Shined in 2024</a></li><li><a href="#What-should-we-expect-for-AI-&amp;-Art-in-2025?">What should we expect for AI &amp; Art in 2025?</a></li><li><a href="#Starting-off-strong---Open-source-releases-of-January-25">Starting off strong - Open source releases of January 25</a></li></ul><h2 id="major-releases-of-2024" tabindex="-1"><a class="header-anchor" href="#major-releases-of-2024"><span>Major Releases of 2024</span></a></h2><p>What were the standout releases of creative AI tools in 2024? We&#39;ll highlight the major releases across creative and artistic fields, with a particular focus on open-source developments in popular tasks like image and video generation.</p><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ai_art_newsletter_1/timeline_2.png" width="700" height="auto" alt="2024 highlights"><h2 id="image-generation" tabindex="-1"><a class="header-anchor" href="#image-generation"><span>Image Generation</span></a></h2><p>Over 2 years since the OG stable diffusion was released and made waves in image generation with open source models, it’s now safe to say that when it comes to image generation from text, image editing and controlled image generation - open source models are giving closed source models a run for their money.<br><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ai_art_newsletter_1/finger_meme.png" width="424" height="auto" alt="2024 highlights"></p><h3 id="text-to-image-generation" tabindex="-1"><a class="header-anchor" href="#text-to-image-generation"><span>Text-to-image generation</span></a></h3><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ai_art_newsletter_1/flux_grid.png" width="600" height="auto" alt="flux"> 2024 was the year we shifted paradigms of diffusion models - from the traditional Unet based architecture to Diffusion Transformer (DiT), as well as an objective switch to flow matching. <p><strong>TD;LR</strong> - diffusion models and <strong>Gaussian</strong> flow matching are equivalent. Flow matching proposes a vector field parametrization of the network output that is different compared to the ones commonly used in diffusion models previously.</p><ul><li>We recommend this <a href="https://diffusionflow.github.io" target="_blank" rel="noopener noreferrer">great blog by Google DeepMind</a> if you’re interested in learning more about flow matching and the connection with diffusion models</li></ul><p><strong>Back to practice</strong>: First to announce the shift was Stability AI with <a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium" target="_blank" rel="noopener noreferrer">Stable Diffusion 3</a>, however it was <a href="https://huggingface.co/Tencent-Hunyuan/HunyuanDiT" target="_blank" rel="noopener noreferrer">HunyuanDiT</a> that became the first open source model with DiT architecture.<br> This trend continued with the releases of <a href="https://huggingface.co/fal/AuraFlow" target="_blank" rel="noopener noreferrer">AuraFlow</a>, <a href="https://huggingface.co/black-forest-labs/FLUX.1-dev" target="_blank" rel="noopener noreferrer">Flux.1</a> and <a href="https://huggingface.co/stabilityai/stable-diffusion-3.5-large" target="_blank" rel="noopener noreferrer">Stable Diffusion 3.5</a>.</p><p>Among many pivotal moments in the (not so long) history of open source image generation models, it’s safe to say that the release of Flux.1 was one of them. <a href="https://huggingface.co/black-forest-labs/FLUX.1-dev" target="_blank" rel="noopener noreferrer">Flux [dev]</a> achieved a new state-of-the-art, surpassing popular closed source models like Midjourney v6.0, DALL·E 3 (HD) on various benchmarks.</p><h3 id="personalization-stylization" tabindex="-1"><a class="header-anchor" href="#personalization-stylization"><span>Personalization &amp; stylization</span></a></h3><p>A positive side effect of advancements in image models is the significant improvement in personalization techniques for text-to-image models and controlled generation.</p><p>Back in August 2022, transformative works like <a href="https://textual-inversion.github.io" target="_blank" rel="noopener noreferrer">Textual Inversion</a> and <a href="https://dreambooth.github.io" target="_blank" rel="noopener noreferrer">DreamBooth</a> enhanced our ability to <strong>teach and introduce new concepts to text-to-image models</strong>, drastically expanding what could be done with them. These opened the door to a stream of improvements and enhancements building on top of these techniques (such as LoRA for diffusion models).</p><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ai_art_newsletter_1/personalization_1.png" width="424" height="auto" alt="textual inversion - dreambooth"><p>However, an <strong>upper bound to the quality of the fine-tuned models is naturally the base model</strong> from which it was fine-tuned. In that sense, we can’t neglect Stable Diffusion XL, which was also a significant marker in personalization for open source image generation models. A testimony to that is that even now, many of the popular techniques and models for personalization and controlled generation are based on SDXL. The advanced abilities of SDXL (and models that were released after with similar quality) together with the growing understanding of the semantic roles of different components in the diffusion model architecture raises the question - <br> what can we achieve without further optimization?</p><p><em>cue in the rain of zero shot techniques</em> - 2024 was definitely the year when generating high quality portraits from reference photos was made possible with as little as <strong>a single reference image &amp; without any optimization</strong>. Training free techniques like <a href="https://huggingface.co/spaces/multimodalart/Ip-Adapter-FaceID" target="_blank" rel="noopener noreferrer">IP adapter FaceID</a>, <a href="https://huggingface.co/spaces/InstantX/InstantID" target="_blank" rel="noopener noreferrer">InstantID</a>, <a href="https://huggingface.co/spaces/TencentARC/PhotoMaker-V2" target="_blank" rel="noopener noreferrer">Photomaker</a> and more came out and demonstrated competitive if not even superior abilities to those of fine-tuned models.</p><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ai_art_newsletter_1/instantid.png" width="600" height="auto" alt="instantid"><p>Similarly, image editing and controlled generation - such as image generation with canny / depth / pose constraints made progress too - both thanks to the growing quality of the base models and the community’s growing understanding of the semantic roles different components have (<a href="https://huggingface.co/spaces/InstantX/InstantStyle" target="_blank" rel="noopener noreferrer">Instant Style</a>, <a href="https://huggingface.co/spaces/Yardenfren/B-LoRA" target="_blank" rel="noopener noreferrer">B-LoRA</a>)</p><p><strong>So what’s next?</strong> since the shift of paradigms to DiT and flow matching objectives, additional models came out trying to utilize DiT-based models like Flux and SD3.5 for similar purposes, but so far not quite beating the quality of the SDXL-based ones despite the superior quality of the underlying base model. This could be attributed to the relative lack of understanding of semantic roles of different components of the DiT compared to the Unet. 2025 could be the year when we identify those roles in DiTs as well, unlocking more possibilities with the next generation of image generation models.</p><h2 id="video-generation" tabindex="-1"><a class="header-anchor" href="#video-generation"><span>Video Generation</span></a></h2><figure class="image flex flex-col items-center text-center m-0 w-full"><video alt="demo4.mp4" autoplay loop autobuffer muted playsinline><source src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/video_gen/hunyuan-output.mp4" type="video/mp4"></video></figure><p>As opposed to image generation, with video we still have a way to go. But, it’s safe to say that we’re very far away from where we were a year ago. While we’re all about open-source, the credit for (some) of the significant leap in AI video generation goes to OpenAI’s sora for changing our expectations of video model capabilities quite radically. And as fofr put nicely in <em><a href="https://replicate.com/blog/ai-video-is-having-its-stable-diffusion-moment" target="_blank" rel="noopener noreferrer">AI video is having its Stable Diffusion moment</a></em> (which we recommend reading 🙂) - it <br> made everyone realize what is possible.</p><p>The recent surge of open-source video generation models, including <a href="https://huggingface.co/THUDM/CogVideoX-5b" target="_blank" rel="noopener noreferrer">CogVideoX</a>, <a href="https://huggingface.co/genmo/mochi-1-preview" target="_blank" rel="noopener noreferrer">Mochi</a>, <a href="https://huggingface.co/rhymes-ai/Allegro" target="_blank" rel="noopener noreferrer">Allegro</a>, <a href="https://huggingface.co/Lightricks/LTX-Video" target="_blank" rel="noopener noreferrer">LTX Video</a>, and <a href="https://huggingface.co/tencent/HunyuanVideo" target="_blank" rel="noopener noreferrer">HunyuanVideo</a>, has also been noteworthy. Video generation is inherently more challenging than image generation due to the need for motion quality, coherence, and consistency. Additionally, video generation requires substantial computational and memory resources, leading to significant generation latency. This often hinders local usage, making many new open video models inaccessible to community hardware without extensive memory optimizations and quantization approaches that impact both inference latency and the quality of generated videos. Nevertheless the open source community has made remarkable progress - which was recently covered in this blog on <a href="https://huggingface.co/blog/video_gen" target="_blank" rel="noopener noreferrer">the state of open video generation models</a>.</p><p>While this implies that most community members are still unable to experiment and develop with open-source video models, it also suggests that we can expect significant advancements in 2025.</p><h2 id="audio-generation" tabindex="-1"><a class="header-anchor" href="#audio-generation"><span>Audio Generation</span></a></h2><p>Audio generation has progressed significantly in the past year going from simple sounds to complete songs with lyrics. Despite challenges - Audio signals are complex and multifaceted, require more sophisticated mathematical models than models that generate text or images and training data quite scarce - 2024 saw open source releases like <a href="https://huggingface.co/OuteAI/OuteTTS-0.2-500M" target="_blank" rel="noopener noreferrer">OuteTTS</a> and <a href="https://huggingface.co/ai4bharat/indic-parler-tts" target="_blank" rel="noopener noreferrer">IndicParlerTTS</a> for text to speech and openai’s <a href="https://huggingface.co/openai/whisper-large-v3-turbo" target="_blank" rel="noopener noreferrer">Whisper large v3 turbo</a> for audio speech recognition. The year 2025 is already shaping up to be a breakthrough year for audio models, with a remarkable number of releases in January alone. We&#39;ve seen the release of three new text-to-speech models: <a href="https://huggingface.co/hexgrad/Kokoro-82M" target="_blank" rel="noopener noreferrer">Kokoro</a>, <a href="https://huggingface.co/HKUSTAudio/Llasa-3B" target="_blank" rel="noopener noreferrer">LLasa TTS</a> and <a href="https://huggingface.co/OuteAI/OuteTTS-0.3-1B" target="_blank" rel="noopener noreferrer">OuteTTS 0.3</a>, as well as two new music models: <a href="https://huggingface.co/models?search=jasco" target="_blank" rel="noopener noreferrer">JASCO</a> and <a href="https://huggingface.co/m-a-p/YuE-s1-7B-anneal-en-cot" target="_blank" rel="noopener noreferrer">YuE</a>. With this pace, we can expect even more exciting developments in the audio space throughout the year.</p><p>This song👇 was generated with YuE 🤯</p><figure class="image flex flex-col items-center text-center m-0 w-full"><audio alt="yue.mp3" controls><source src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ai_art_newsletter_1/I_wont_back_down_pop.mp3" type="audio/mp3"></audio></figure><h2 id="creative-tools-that-shined-in-2024" tabindex="-1"><a class="header-anchor" href="#creative-tools-that-shined-in-2024"><span>Creative Tools that Shined in 2024</span></a></h2><p>The beauty of open source is that it allows the community to experiment, find new usages for existing models / pipelines, improve on and build new tools together. Many of the creative AI tools that were popular this year are the fruit of joint community effort.</p><p>Here are some of our favorites:</p><h4 id="flux-fine-tuning" tabindex="-1"><a class="header-anchor" href="#flux-fine-tuning"><span>Flux fine-tuning</span></a></h4><p>Many of the amazing <a href="https://huggingface.co/spaces/multimodalart/flux-lora-the-explorer" target="_blank" rel="noopener noreferrer">Flux fine-tunes</a> created in the last year were trained thanks to the <a href="https://github.com/ostris/ai-toolkit" target="_blank" rel="noopener noreferrer">AI-toolkit</a> by <a href="https://huggingface.co/ostris" target="_blank" rel="noopener noreferrer">ostris</a>.</p><h4 id="face-to-all" tabindex="-1"><a class="header-anchor" href="#face-to-all"><span>Face to all</span></a></h4><p>Inspired by fofr&#39;s <a href="https://github.com/fofr/cog-face-to-many" target="_blank" rel="noopener noreferrer">face-to-many</a>, <a href="https://huggingface.co/spaces/multimodalart/face-to-all" target="_blank" rel="noopener noreferrer">Face to All</a> combines the viral <a href="https://huggingface.co/spaces/InstantX/InstantID" target="_blank" rel="noopener noreferrer">Instant ID model</a> with added ControlNet depth constraints and community fine-tuned SDXL LoRAs to create training-free and high-quality portraits in creative stylizations.</p><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ai_art_newsletter_1/face-to-all.png" width="512" height="auto" alt="face to all"><h4 id="flux-style-shaping" tabindex="-1"><a class="header-anchor" href="#flux-style-shaping"><span>Flux style shaping</span></a></h4><p>Based on a ComfyUI workflow by <a href="https://x.com/CitizenPlain" target="_blank" rel="noopener noreferrer">Nathan Shipley</a>, <a href="https://huggingface.co/spaces/multimodalart/flux-style-shaping" target="_blank" rel="noopener noreferrer">Flux style shaping</a> combines Flux [dev] Redux and Flux [dev] Depth for style transfer and optical illusion creation.</p><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ai_art_newsletter_1/styleshaping.jpeg" width="512" height="auto" alt="style shaping"><h4 id="outpainting-with-diffusers" tabindex="-1"><a class="header-anchor" href="#outpainting-with-diffusers"><span>Outpainting with diffusers</span></a></h4><p><a href="https://huggingface.co/spaces/fffiloni/diffusers-image-outpaint" target="_blank" rel="noopener noreferrer">Diffusers Image Outpaint</a> makes use of the diffusers Stable Diffusion XL Fill Pipeline together with an SDXL union controlnet to seamlessly expand an input image.</p><h4 id="live-portrait-face-poke" tabindex="-1"><a class="header-anchor" href="#live-portrait-face-poke"><span>Live portrait, Face Poke</span></a></h4><p>Adding mimics to a static portrait was never easier with <a href="https://huggingface.co/spaces/KwaiVGI/LivePortrait" target="_blank" rel="noopener noreferrer">Live Portrait</a> and <a href="https://huggingface.co/spaces/jbilcke-hf/FacePoke" target="_blank" rel="noopener noreferrer">Face Poke</a>.</p><figure class="image flex flex-col items-center text-center m-0 w-full"><video alt="face_poke.mp4" autoplay loop autobuffer muted playsinline><source src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ai_art_newsletter_1/isaac_1.mp4" type="video/mp4"></video></figure><h4 id="trellis" tabindex="-1"><a class="header-anchor" href="#trellis"><span>TRELLIS</span></a></h4><p><a href="https://huggingface.co/spaces/JeffreyXiang/TRELLIS" target="_blank" rel="noopener noreferrer">TRELLIS</a> is a 3D generation model for versatile and high-quality 3D asset creation that took over the 3D landscape with a bang.</p><figure class="image flex flex-col items-center text-center m-0 w-full"><video alt="trellis.mp4" autoplay loop autobuffer muted playsinline><source src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ai_art_newsletter_1/trellis.mp4" type="video/mp4"></video></figure><h4 id="ic-light" tabindex="-1"><a class="header-anchor" href="#ic-light"><span>IC Light</span></a></h4><p><a href="https://huggingface.co/spaces/lllyasviel/IC-Light" target="_blank" rel="noopener noreferrer">IC-Light</a>, which stands for &quot;Imposing Consistent Light&quot;, is a tool for relighting with foreground condition.</p><h2 id="what-should-we-expect-for-ai-art-in-2025" tabindex="-1"><a class="header-anchor" href="#what-should-we-expect-for-ai-art-in-2025"><span>What should we expect for AI &amp; Art in 2025?</span></a></h2><p>2025 is the year for open-source to catch up on video, movement, and audio models, making room for more modalities. With advancements in efficient computing and quantization, we can expect significant leaps in open-source video models. As we approach a (natural) plateau in image generation models, we can shift our focus to other tasks and modalities.</p><h2 id="starting-off-strong-open-source-releases-of-january-25" tabindex="-1"><a class="header-anchor" href="#starting-off-strong-open-source-releases-of-january-25"><span>Starting off strong - Open source releases of January 25</span></a></h2><ol><li><p><strong>YuE - series of open-source music foundation models</strong> for full song generation. YuE is possibly the best open source model for music generation (with an Apache 2.0 license!), achieving competitive results to closed source models like Suno.</p><p><strong>try it out &amp; read more</strong>: <a href="https://huggingface.co/spaces/fffiloni/YuE" target="_blank" rel="noopener noreferrer">demo</a>, <a href="https://huggingface.co/m-a-p/YuE-s1-7B-anneal-en-cot" target="_blank" rel="noopener noreferrer">model weights</a>.</p></li></ol><figure class="image flex flex-col items-center text-center m-0 w-full"><video alt="yue.mp4" autobuffer playsinline><source src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ai_art_newsletter_1/My first YuE (open source Suno) AI generated full song.mp4" type="video/mp4"></video></figure><ol start="2"><li><p><strong>Hunyuan 3D-2 , SPAR3D, DiffSplat - 3D generation models</strong>. 3D models are coming in hot - not long after the release of TRELLIS, Hunyuan 3D-2, SPAR3D and DiffSplat are here to take over the 3D landscape.</p><p><strong>try it out &amp; read more:</strong></p><ul><li><a href="https://huggingface.co/tencent/Hunyuan3D-2" target="_blank" rel="noopener noreferrer">Hunyuan3D-2</a></li><li><a href="https://huggingface.co/stabilityai/stable-point-aware-3d" target="_blank" rel="noopener noreferrer">SPAR3D</a></li><li><a href="https://huggingface.co/chenguolin/DiffSplat" target="_blank" rel="noopener noreferrer">DiffSplat</a></li></ul></li><li><p><strong>Lumina-Image 2.0</strong> - text to image model. Lumina is a 2B parameter model competitive with the 12B Flux.1 [dev] and with an Apache 2.0 license(!!).</p><p><strong>try it out &amp; read more</strong>: <a href="https://huggingface.co/spaces/benjamin-paine/Lumina-Image-2.0" target="_blank" rel="noopener noreferrer">demo</a>, <a href="https://huggingface.co/Alpha-VLLM/Lumina-Image-2.0" target="_blank" rel="noopener noreferrer">model weights</a>.</p></li><li><p><strong>ComfyUI-to-Gradio</strong> - a step-by-step guide on how to convert a complex ComfyUI workflow to a simple Gradio application, and how to deploy this application on Hugging Face Spaces ZeroGPU serverless structure, which allows for it to be deployed and run for free in a serverless manner <strong>read more</strong> <a href="https://huggingface.co/blog/run-comfyui-workflows-on-spaces" target="_blank" rel="noopener noreferrer"><strong>here</strong></a>.</p></li></ol><h2 id="announcing-our-newsletter-🗞️" tabindex="-1"><a class="header-anchor" href="#announcing-our-newsletter-🗞️"><span>Announcing Our Newsletter 🗞️</span></a></h2><p>Kicking off with this blog, we (<a href="https://huggingface.co/multimodalart" target="_blank" rel="noopener noreferrer">Poli</a> &amp; <a href="https://huggingface.co/linoyts" target="_blank" rel="noopener noreferrer">Linoy</a>) will be bringing you a monthly roundup of the latest in the creative AI world. In such a fast-evolving space, it’s tough to stay on top of all the new developments, let alone sift through them. That’s where we come in &amp; hopefully this way we can make creative AI tools more accessible</p></div><!--[--><div class="theme-hope-content"><Share colorful services="email,facebook,line,linkedin,messenger,qrcode,reddit,telegram,twitter"></Share></div><!--]--><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/vuepress-theme-hope/vuepress-theme-hope/edit/main/src/posts/reprints/ai-art-newsletter-jan-25.md" aria-label="Edit this page on GitHub" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page on GitHub<!----></a></div><div class="vp-meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/posts/reprints/qwen3-next-gen-ai-with-hybrid-thinking-and-multilingual-mastery-2025-overview.html" aria-label="Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 Overview"><div class="hint"><span class="arrow start"></span>Prev</div><div class="link"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:robot" width="1em" height="1em"></iconify-icon>Qwen3: Next-Gen AI with Hybrid Thinking and Multilingual Mastery | 2025 Overview</div></a><a class="route-link auto-link next" href="/posts/reprints/what-is-block-merging.html" aria-label="What is Block Merging?"><div class="hint">Next<span class="arrow end"></span></div><div class="link">What is Block Merging?<!----></div></a></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">My own footer</div><div class="vp-copyright">Copyright © 2025 neverbiasu </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script src="/assets/js/runtime~app.f513dbfa.js" defer></script><script src="/assets/js/9156.1c509bd1.js" defer></script><script src="/assets/js/app.87cd2552.js" defer></script>
  </body>
</html>
